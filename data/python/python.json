{
  "version": "1",
  "pip_version": "25.0.1",
  "installed": [
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "blinker",
        "version": "1.9.0",
        "summary": "Fast, simple object-to-object and broadcast signaling",
        "description": "# Blinker\n\nBlinker provides a fast dispatching system that allows any number of\ninterested parties to subscribe to events, or \"signals\".\n\n\n## Pallets Community Ecosystem\n\n> [!IMPORTANT]\\\n> This project is part of the Pallets Community Ecosystem. Pallets is the open\n> source organization that maintains Flask; Pallets-Eco enables community\n> maintenance of related projects. If you are interested in helping maintain\n> this project, please reach out on [the Pallets Discord server][discord].\n>\n> [discord]: https://discord.gg/pallets\n\n\n## Example\n\nSignal receivers can subscribe to specific senders or receive signals\nsent by any sender.\n\n```pycon\n>>> from blinker import signal\n>>> started = signal('round-started')\n>>> def each(round):\n...     print(f\"Round {round}\")\n...\n>>> started.connect(each)\n\n>>> def round_two(round):\n...     print(\"This is round two.\")\n...\n>>> started.connect(round_two, sender=2)\n\n>>> for round in range(1, 4):\n...     started.send(round)\n...\nRound 1!\nRound 2!\nThis is round two.\nRound 3!\n```\n\n",
        "description_content_type": "text/markdown",
        "author": "Jason Kirtland",
        "maintainer_email": "Pallets Ecosystem <contact@palletsprojects.com>",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python",
          "Typing :: Typed"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Chat, https://discord.gg/pallets",
          "Documentation, https://blinker.readthedocs.io",
          "Source, https://github.com/pallets-eco/blinker/"
        ]
      },
      "metadata_location": "C:\\Users\\rompe00m\\AppData\\Roaming\\Python\\Python312\\site-packages\\blinker-1.9.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "itsdangerous",
        "version": "2.2.0",
        "summary": "Safely pass data to untrusted environments and back.",
        "description": "# ItsDangerous\n\n... so better sign this\n\nVarious helpers to pass data to untrusted environments and to get it\nback safe and sound. Data is cryptographically signed to ensure that a\ntoken has not been tampered with.\n\nIt's possible to customize how data is serialized. Data is compressed as\nneeded. A timestamp can be added and verified automatically while\nloading a token.\n\n\n## A Simple Example\n\nHere's how you could generate a token for transmitting a user's id and\nname between web requests.\n\n```python\nfrom itsdangerous import URLSafeSerializer\nauth_s = URLSafeSerializer(\"secret key\", \"auth\")\ntoken = auth_s.dumps({\"id\": 5, \"name\": \"itsdangerous\"})\n\nprint(token)\n# eyJpZCI6NSwibmFtZSI6Iml0c2Rhbmdlcm91cyJ9.6YP6T0BaO67XP--9UzTrmurXSmg\n\ndata = auth_s.loads(token)\nprint(data[\"name\"])\n# itsdangerous\n```\n\n\n## Donate\n\nThe Pallets organization develops and supports ItsDangerous and other\npopular packages. In order to grow the community of contributors and\nusers, and allow the maintainers to devote more time to the projects,\n[please donate today][].\n\n[please donate today]: https://palletsprojects.com/donate\n\n",
        "description_content_type": "text/markdown",
        "maintainer_email": "Pallets <contact@palletsprojects.com>",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Typing :: Typed"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Changes, https://itsdangerous.palletsprojects.com/changes/",
          "Chat, https://discord.gg/pallets",
          "Documentation, https://itsdangerous.palletsprojects.com/",
          "Donate, https://palletsprojects.com/donate",
          "Source, https://github.com/pallets/itsdangerous/"
        ]
      },
      "metadata_location": "C:\\Users\\rompe00m\\AppData\\Roaming\\Python\\Python312\\site-packages\\itsdangerous-2.2.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "Werkzeug",
        "version": "3.1.3",
        "summary": "The comprehensive WSGI web application library.",
        "description": "# Werkzeug\n\n*werkzeug* German noun: \"tool\". Etymology: *werk* (\"work\"), *zeug* (\"stuff\")\n\nWerkzeug is a comprehensive [WSGI][] web application library. It began as\na simple collection of various utilities for WSGI applications and has\nbecome one of the most advanced WSGI utility libraries.\n\nIt includes:\n\n-   An interactive debugger that allows inspecting stack traces and\n    source code in the browser with an interactive interpreter for any\n    frame in the stack.\n-   A full-featured request object with objects to interact with\n    headers, query args, form data, files, and cookies.\n-   A response object that can wrap other WSGI applications and handle\n    streaming data.\n-   A routing system for matching URLs to endpoints and generating URLs\n    for endpoints, with an extensible system for capturing variables\n    from URLs.\n-   HTTP utilities to handle entity tags, cache control, dates, user\n    agents, cookies, files, and more.\n-   A threaded WSGI server for use while developing applications\n    locally.\n-   A test client for simulating HTTP requests during testing without\n    requiring running a server.\n\nWerkzeug doesn't enforce any dependencies. It is up to the developer to\nchoose a template engine, database adapter, and even how to handle\nrequests. It can be used to build all sorts of end user applications\nsuch as blogs, wikis, or bulletin boards.\n\n[Flask][] wraps Werkzeug, using it to handle the details of WSGI while\nproviding more structure and patterns for defining powerful\napplications.\n\n[WSGI]: https://wsgi.readthedocs.io/en/latest/\n[Flask]: https://www.palletsprojects.com/p/flask/\n\n\n## A Simple Example\n\n```python\n# save this as app.py\nfrom werkzeug.wrappers import Request, Response\n\n@Request.application\ndef application(request: Request) -> Response:\n    return Response(\"Hello, World!\")\n\nif __name__ == \"__main__\":\n    from werkzeug.serving import run_simple\n    run_simple(\"127.0.0.1\", 5000, application)\n```\n\n```\n$ python -m app\n  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n```\n\n\n## Donate\n\nThe Pallets organization develops and supports Werkzeug and other\npopular packages. In order to grow the community of contributors and\nusers, and allow the maintainers to devote more time to the projects,\n[please donate today][].\n\n[please donate today]: https://palletsprojects.com/donate\n\n",
        "description_content_type": "text/markdown",
        "maintainer_email": "Pallets <contact@palletsprojects.com>",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Topic :: Internet :: WWW/HTTP :: Dynamic Content",
          "Topic :: Internet :: WWW/HTTP :: WSGI",
          "Topic :: Internet :: WWW/HTTP :: WSGI :: Application",
          "Topic :: Internet :: WWW/HTTP :: WSGI :: Middleware",
          "Topic :: Software Development :: Libraries :: Application Frameworks",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "MarkupSafe>=2.1.1",
          "watchdog>=2.3 ; extra == \"watchdog\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Changes, https://werkzeug.palletsprojects.com/changes/",
          "Chat, https://discord.gg/pallets",
          "Documentation, https://werkzeug.palletsprojects.com/",
          "Donate, https://palletsprojects.com/donate",
          "Issue Tracker, https://github.com/pallets/werkzeug/issues/",
          "Source Code, https://github.com/pallets/werkzeug/"
        ],
        "provides_extra": [
          "watchdog"
        ]
      },
      "metadata_location": "C:\\Users\\rompe00m\\AppData\\Roaming\\Python\\Python312\\site-packages\\werkzeug-3.1.3.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "annotated-types",
        "version": "0.7.0",
        "summary": "Reusable constraint types to use with typing.Annotated",
        "description": "# annotated-types\n\n[![CI](https://github.com/annotated-types/annotated-types/workflows/CI/badge.svg?event=push)](https://github.com/annotated-types/annotated-types/actions?query=event%3Apush+branch%3Amain+workflow%3ACI)\n[![pypi](https://img.shields.io/pypi/v/annotated-types.svg)](https://pypi.python.org/pypi/annotated-types)\n[![versions](https://img.shields.io/pypi/pyversions/annotated-types.svg)](https://github.com/annotated-types/annotated-types)\n[![license](https://img.shields.io/github/license/annotated-types/annotated-types.svg)](https://github.com/annotated-types/annotated-types/blob/main/LICENSE)\n\n[PEP-593](https://peps.python.org/pep-0593/) added `typing.Annotated` as a way of\nadding context-specific metadata to existing types, and specifies that\n`Annotated[T, x]` _should_ be treated as `T` by any tool or library without special\nlogic for `x`.\n\nThis package provides metadata objects which can be used to represent common\nconstraints such as upper and lower bounds on scalar values and collection sizes,\na `Predicate` marker for runtime checks, and\ndescriptions of how we intend these metadata to be interpreted. In some cases,\nwe also note alternative representations which do not require this package.\n\n## Install\n\n```bash\npip install annotated-types\n```\n\n## Examples\n\n```python\nfrom typing import Annotated\nfrom annotated_types import Gt, Len, Predicate\n\nclass MyClass:\n    age: Annotated[int, Gt(18)]                         # Valid: 19, 20, ...\n                                                        # Invalid: 17, 18, \"19\", 19.0, ...\n    factors: list[Annotated[int, Predicate(is_prime)]]  # Valid: 2, 3, 5, 7, 11, ...\n                                                        # Invalid: 4, 8, -2, 5.0, \"prime\", ...\n\n    my_list: Annotated[list[int], Len(0, 10)]           # Valid: [], [10, 20, 30, 40, 50]\n                                                        # Invalid: (1, 2), [\"abc\"], [0] * 20\n```\n\n## Documentation\n\n_While `annotated-types` avoids runtime checks for performance, users should not\nconstruct invalid combinations such as `MultipleOf(\"non-numeric\")` or `Annotated[int, Len(3)]`.\nDownstream implementors may choose to raise an error, emit a warning, silently ignore\na metadata item, etc., if the metadata objects described below are used with an\nincompatible type - or for any other reason!_\n\n### Gt, Ge, Lt, Le\n\nExpress inclusive and/or exclusive bounds on orderable values - which may be numbers,\ndates, times, strings, sets, etc. Note that the boundary value need not be of the\nsame type that was annotated, so long as they can be compared: `Annotated[int, Gt(1.5)]`\nis fine, for example, and implies that the value is an integer x such that `x > 1.5`.\n\nWe suggest that implementors may also interpret `functools.partial(operator.le, 1.5)`\nas being equivalent to `Gt(1.5)`, for users who wish to avoid a runtime dependency on\nthe `annotated-types` package.\n\nTo be explicit, these types have the following meanings:\n\n* `Gt(x)` - value must be \"Greater Than\" `x` - equivalent to exclusive minimum\n* `Ge(x)` - value must be \"Greater than or Equal\" to `x` - equivalent to inclusive minimum\n* `Lt(x)` - value must be \"Less Than\" `x` - equivalent to exclusive maximum\n* `Le(x)` - value must be \"Less than or Equal\" to `x` - equivalent to inclusive maximum\n\n### Interval\n\n`Interval(gt, ge, lt, le)` allows you to specify an upper and lower bound with a single\nmetadata object. `None` attributes should be ignored, and non-`None` attributes\ntreated as per the single bounds above.\n\n### MultipleOf\n\n`MultipleOf(multiple_of=x)` might be interpreted in two ways:\n\n1. Python semantics, implying `value % multiple_of == 0`, or\n2. [JSONschema semantics](https://json-schema.org/draft/2020-12/json-schema-validation.html#rfc.section.6.2.1),\n   where `int(value / multiple_of) == value / multiple_of`.\n\nWe encourage users to be aware of these two common interpretations and their\ndistinct behaviours, especially since very large or non-integer numbers make\nit easy to cause silent data corruption due to floating-point imprecision.\n\nWe encourage libraries to carefully document which interpretation they implement.\n\n### MinLen, MaxLen, Len\n\n`Len()` implies that `min_length <= len(value) <= max_length` - lower and upper bounds are inclusive.\n\nAs well as `Len()` which can optionally include upper and lower bounds, we also\nprovide `MinLen(x)` and `MaxLen(y)` which are equivalent to `Len(min_length=x)`\nand `Len(max_length=y)` respectively.\n\n`Len`, `MinLen`, and `MaxLen` may be used with any type which supports `len(value)`.\n\nExamples of usage:\n\n* `Annotated[list, MaxLen(10)]` (or `Annotated[list, Len(max_length=10))`) - list must have a length of 10 or less\n* `Annotated[str, MaxLen(10)]` - string must have a length of 10 or less\n* `Annotated[list, MinLen(3))` (or `Annotated[list, Len(min_length=3))`) - list must have a length of 3 or more\n* `Annotated[list, Len(4, 6)]` - list must have a length of 4, 5, or 6\n* `Annotated[list, Len(8, 8)]` - list must have a length of exactly 8\n\n#### Changed in v0.4.0\n\n* `min_inclusive` has been renamed to `min_length`, no change in meaning\n* `max_exclusive` has been renamed to `max_length`, upper bound is now **inclusive** instead of **exclusive**\n* The recommendation that slices are interpreted as `Len` has been removed due to ambiguity and different semantic\n  meaning of the upper bound in slices vs. `Len`\n\nSee [issue #23](https://github.com/annotated-types/annotated-types/issues/23) for discussion.\n\n### Timezone\n\n`Timezone` can be used with a `datetime` or a `time` to express which timezones\nare allowed. `Annotated[datetime, Timezone(None)]` must be a naive datetime.\n`Timezone[...]` ([literal ellipsis](https://docs.python.org/3/library/constants.html#Ellipsis))\nexpresses that any timezone-aware datetime is allowed. You may also pass a specific\ntimezone string or [`tzinfo`](https://docs.python.org/3/library/datetime.html#tzinfo-objects)\nobject such as `Timezone(timezone.utc)` or `Timezone(\"Africa/Abidjan\")` to express that you only\nallow a specific timezone, though we note that this is often a symptom of fragile design.\n\n#### Changed in v0.x.x\n\n* `Timezone` accepts [`tzinfo`](https://docs.python.org/3/library/datetime.html#tzinfo-objects) objects instead of\n  `timezone`, extending compatibility to [`zoneinfo`](https://docs.python.org/3/library/zoneinfo.html) and third party libraries.\n\n### Unit\n\n`Unit(unit: str)` expresses that the annotated numeric value is the magnitude of\na quantity with the specified unit. For example, `Annotated[float, Unit(\"m/s\")]`\nwould be a float representing a velocity in meters per second.\n\nPlease note that `annotated_types` itself makes no attempt to parse or validate\nthe unit string in any way. That is left entirely to downstream libraries,\nsuch as [`pint`](https://pint.readthedocs.io) or\n[`astropy.units`](https://docs.astropy.org/en/stable/units/).\n\nAn example of how a library might use this metadata:\n\n```python\nfrom annotated_types import Unit\nfrom typing import Annotated, TypeVar, Callable, Any, get_origin, get_args\n\n# given a type annotated with a unit:\nMeters = Annotated[float, Unit(\"m\")]\n\n\n# you can cast the annotation to a specific unit type with any\n# callable that accepts a string and returns the desired type\nT = TypeVar(\"T\")\ndef cast_unit(tp: Any, unit_cls: Callable[[str], T]) -> T | None:\n    if get_origin(tp) is Annotated:\n        for arg in get_args(tp):\n            if isinstance(arg, Unit):\n                return unit_cls(arg.unit)\n    return None\n\n\n# using `pint`\nimport pint\npint_unit = cast_unit(Meters, pint.Unit)\n\n\n# using `astropy.units`\nimport astropy.units as u\nastropy_unit = cast_unit(Meters, u.Unit)\n```\n\n### Predicate\n\n`Predicate(func: Callable)` expresses that `func(value)` is truthy for valid values.\nUsers should prefer the statically inspectable metadata above, but if you need\nthe full power and flexibility of arbitrary runtime predicates... here it is.\n\nFor some common constraints, we provide generic types:\n\n* `IsLower       = Annotated[T, Predicate(str.islower)]`\n* `IsUpper       = Annotated[T, Predicate(str.isupper)]`\n* `IsDigit       = Annotated[T, Predicate(str.isdigit)]`\n* `IsFinite      = Annotated[T, Predicate(math.isfinite)]`\n* `IsNotFinite   = Annotated[T, Predicate(Not(math.isfinite))]`\n* `IsNan         = Annotated[T, Predicate(math.isnan)]`\n* `IsNotNan      = Annotated[T, Predicate(Not(math.isnan))]`\n* `IsInfinite    = Annotated[T, Predicate(math.isinf)]`\n* `IsNotInfinite = Annotated[T, Predicate(Not(math.isinf))]`\n\nso that you can write e.g. `x: IsFinite[float] = 2.0` instead of the longer\n(but exactly equivalent) `x: Annotated[float, Predicate(math.isfinite)] = 2.0`.\n\nSome libraries might have special logic to handle known or understandable predicates,\nfor example by checking for `str.isdigit` and using its presence to both call custom\nlogic to enforce digit-only strings, and customise some generated external schema.\nUsers are therefore encouraged to avoid indirection like `lambda s: s.lower()`, in\nfavor of introspectable methods such as `str.lower` or `re.compile(\"pattern\").search`.\n\nTo enable basic negation of commonly used predicates like `math.isnan` without introducing introspection that makes it impossible for implementers to introspect the predicate we provide a `Not` wrapper that simply negates the predicate in an introspectable manner. Several of the predicates listed above are created in this manner.\n\nWe do not specify what behaviour should be expected for predicates that raise\nan exception.  For example `Annotated[int, Predicate(str.isdigit)]` might silently\nskip invalid constraints, or statically raise an error; or it might try calling it\nand then propagate or discard the resulting\n`TypeError: descriptor 'isdigit' for 'str' objects doesn't apply to a 'int' object`\nexception.  We encourage libraries to document the behaviour they choose.\n\n### Doc\n\n`doc()` can be used to add documentation information in `Annotated`, for function and method parameters, variables, class attributes, return types, and any place where `Annotated` can be used.\n\nIt expects a value that can be statically analyzed, as the main use case is for static analysis, editors, documentation generators, and similar tools.\n\nIt returns a `DocInfo` class with a single attribute `documentation` containing the value passed to `doc()`.\n\nThis is the early adopter's alternative form of the [`typing-doc` proposal](https://github.com/tiangolo/fastapi/blob/typing-doc/typing_doc.md).\n\n### Integrating downstream types with `GroupedMetadata`\n\nImplementers may choose to provide a convenience wrapper that groups multiple pieces of metadata.\nThis can help reduce verbosity and cognitive overhead for users.\nFor example, an implementer like Pydantic might provide a `Field` or `Meta` type that accepts keyword arguments and transforms these into low-level metadata:\n\n```python\nfrom dataclasses import dataclass\nfrom typing import Iterator\nfrom annotated_types import GroupedMetadata, Ge\n\n@dataclass\nclass Field(GroupedMetadata):\n    ge: int | None = None\n    description: str | None = None\n\n    def __iter__(self) -> Iterator[object]:\n        # Iterating over a GroupedMetadata object should yield annotated-types\n        # constraint metadata objects which describe it as fully as possible,\n        # and may include other unknown objects too.\n        if self.ge is not None:\n            yield Ge(self.ge)\n        if self.description is not None:\n            yield Description(self.description)\n```\n\nLibraries consuming annotated-types constraints should check for `GroupedMetadata` and unpack it by iterating over the object and treating the results as if they had been \"unpacked\" in the `Annotated` type.  The same logic should be applied to the [PEP 646 `Unpack` type](https://peps.python.org/pep-0646/), so that `Annotated[T, Field(...)]`, `Annotated[T, Unpack[Field(...)]]` and `Annotated[T, *Field(...)]` are all treated consistently.\n\nLibraries consuming annotated-types should also ignore any metadata they do not recongize that came from unpacking a `GroupedMetadata`, just like they ignore unrecognized metadata in `Annotated` itself.\n\nOur own `annotated_types.Interval` class is a `GroupedMetadata` which unpacks itself into `Gt`, `Lt`, etc., so this is not an abstract concern.  Similarly, `annotated_types.Len` is a `GroupedMetadata` which unpacks itself into `MinLen` (optionally) and `MaxLen`.\n\n### Consuming metadata\n\nWe intend to not be prescriptive as to _how_ the metadata and constraints are used, but as an example of how one might parse constraints from types annotations see our [implementation in `test_main.py`](https://github.com/annotated-types/annotated-types/blob/f59cf6d1b5255a0fe359b93896759a180bec30ae/tests/test_main.py#L94-L103).\n\nIt is up to the implementer to determine how this metadata is used.\nYou could use the metadata for runtime type checking, for generating schemas or to generate example data, amongst other use cases.\n\n## Design & History\n\nThis package was designed at the PyCon 2022 sprints by the maintainers of Pydantic\nand Hypothesis, with the goal of making it as easy as possible for end-users to\nprovide more informative annotations for use by runtime libraries.\n\nIt is deliberately minimal, and following PEP-593 allows considerable downstream\ndiscretion in what (if anything!) they choose to support. Nonetheless, we expect\nthat staying simple and covering _only_ the most common use-cases will give users\nand maintainers the best experience we can. If you'd like more constraints for your\ntypes - follow our lead, by defining them and documenting them downstream!\n",
        "description_content_type": "text/markdown",
        "author_email": "Adrian Garcia Badaracco <1755071+adriangb@users.noreply.github.com>, Samuel Colvin <s@muelcolvin.com>, Zac Hatfield-Dodds <zac@zhd.dev>",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Environment :: Console",
          "Environment :: MacOS X",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "License :: OSI Approved :: MIT License",
          "Operating System :: POSIX :: Linux",
          "Operating System :: Unix",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "typing-extensions>=4.0.0; python_version < '3.9'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://github.com/annotated-types/annotated-types",
          "Source, https://github.com/annotated-types/annotated-types",
          "Changelog, https://github.com/annotated-types/annotated-types/releases"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\annotated_types-0.7.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "arrow",
        "version": "1.3.0",
        "summary": "Better dates & times for Python",
        "description": "Arrow: Better dates & times for Python\n======================================\n\n.. start-inclusion-marker-do-not-remove\n\n.. image:: https://github.com/arrow-py/arrow/workflows/tests/badge.svg?branch=master\n   :alt: Build Status\n   :target: https://github.com/arrow-py/arrow/actions?query=workflow%3Atests+branch%3Amaster\n\n.. image:: https://codecov.io/gh/arrow-py/arrow/branch/master/graph/badge.svg\n   :alt: Coverage\n   :target: https://codecov.io/gh/arrow-py/arrow\n\n.. image:: https://img.shields.io/pypi/v/arrow.svg\n   :alt: PyPI Version\n   :target: https://pypi.python.org/pypi/arrow\n\n.. image:: https://img.shields.io/pypi/pyversions/arrow.svg\n   :alt: Supported Python Versions\n   :target: https://pypi.python.org/pypi/arrow\n\n.. image:: https://img.shields.io/pypi/l/arrow.svg\n   :alt: License\n   :target: https://pypi.python.org/pypi/arrow\n\n.. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n   :alt: Code Style: Black\n   :target: https://github.com/psf/black\n\n\n**Arrow** is a Python library that offers a sensible and human-friendly approach to creating, manipulating, formatting and converting dates, times and timestamps. It implements and updates the datetime type, plugging gaps in functionality and providing an intelligent module API that supports many common creation scenarios. Simply put, it helps you work with dates and times with fewer imports and a lot less code.\n\nArrow is named after the `arrow of time <https://en.wikipedia.org/wiki/Arrow_of_time>`_ and is heavily inspired by `moment.js <https://github.com/moment/moment>`_ and `requests <https://github.com/psf/requests>`_.\n\nWhy use Arrow over built-in modules?\n------------------------------------\n\nPython's standard library and some other low-level modules have near-complete date, time and timezone functionality, but don't work very well from a usability perspective:\n\n- Too many modules: datetime, time, calendar, dateutil, pytz and more\n- Too many types: date, time, datetime, tzinfo, timedelta, relativedelta, etc.\n- Timezones and timestamp conversions are verbose and unpleasant\n- Timezone naivety is the norm\n- Gaps in functionality: ISO 8601 parsing, timespans, humanization\n\nFeatures\n--------\n\n- Fully-implemented, drop-in replacement for datetime\n- Support for Python 3.6+\n- Timezone-aware and UTC by default\n- Super-simple creation options for many common input scenarios\n- ``shift`` method with support for relative offsets, including weeks\n- Format and parse strings automatically\n- Wide support for the `ISO 8601 <https://en.wikipedia.org/wiki/ISO_8601>`_ standard\n- Timezone conversion\n- Support for ``dateutil``, ``pytz``, and ``ZoneInfo`` tzinfo objects\n- Generates time spans, ranges, floors and ceilings for time frames ranging from microsecond to year\n- Humanize dates and times with a growing list of contributed locales\n- Extensible for your own Arrow-derived types\n- Full support for PEP 484-style type hints\n\nQuick Start\n-----------\n\nInstallation\n~~~~~~~~~~~~\n\nTo install Arrow, use `pip <https://pip.pypa.io/en/stable/quickstart/>`_ or `pipenv <https://docs.pipenv.org>`_:\n\n.. code-block:: console\n\n    $ pip install -U arrow\n\nExample Usage\n~~~~~~~~~~~~~\n\n.. code-block:: python\n\n    >>> import arrow\n    >>> arrow.get('2013-05-11T21:23:58.970460+07:00')\n    <Arrow [2013-05-11T21:23:58.970460+07:00]>\n\n    >>> utc = arrow.utcnow()\n    >>> utc\n    <Arrow [2013-05-11T21:23:58.970460+00:00]>\n\n    >>> utc = utc.shift(hours=-1)\n    >>> utc\n    <Arrow [2013-05-11T20:23:58.970460+00:00]>\n\n    >>> local = utc.to('US/Pacific')\n    >>> local\n    <Arrow [2013-05-11T13:23:58.970460-07:00]>\n\n    >>> local.timestamp()\n    1368303838.970460\n\n    >>> local.format()\n    '2013-05-11 13:23:58 -07:00'\n\n    >>> local.format('YYYY-MM-DD HH:mm:ss ZZ')\n    '2013-05-11 13:23:58 -07:00'\n\n    >>> local.humanize()\n    'an hour ago'\n\n    >>> local.humanize(locale='ko-kr')\n    'í•œì‹œê°„ ì „'\n\n.. end-inclusion-marker-do-not-remove\n\nDocumentation\n-------------\n\nFor full documentation, please visit `arrow.readthedocs.io <https://arrow.readthedocs.io>`_.\n\nContributing\n------------\n\nContributions are welcome for both code and localizations (adding and updating locales). Begin by gaining familiarity with the Arrow library and its features. Then, jump into contributing:\n\n#. Find an issue or feature to tackle on the `issue tracker <https://github.com/arrow-py/arrow/issues>`_. Issues marked with the `\"good first issue\" label <https://github.com/arrow-py/arrow/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22>`_ may be a great place to start!\n#. Fork `this repository <https://github.com/arrow-py/arrow>`_ on GitHub and begin making changes in a branch.\n#. Add a few tests to ensure that the bug was fixed or the feature works as expected.\n#. Run the entire test suite and linting checks by running one of the following commands: ``tox && tox -e lint,docs`` (if you have `tox <https://tox.readthedocs.io>`_ installed) **OR** ``make build39 && make test && make lint`` (if you do not have Python 3.9 installed, replace ``build39`` with the latest Python version on your system).\n#. Submit a pull request and await feedback ðŸ˜ƒ.\n\nIf you have any questions along the way, feel free to ask them `here <https://github.com/arrow-py/arrow/discussions>`_.\n\nSupport Arrow\n-------------\n\n`Open Collective <https://opencollective.com/>`_ is an online funding platform that provides tools to raise money and share your finances with full transparency. It is the platform of choice for individuals and companies to make one-time or recurring donations directly to the project. If you are interested in making a financial contribution, please visit the `Arrow collective <https://opencollective.com/arrow>`_.\n\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "arrow",
          "date",
          "time",
          "datetime",
          "timestamp",
          "timezone",
          "humanize"
        ],
        "author_email": "Chris Smith <crsmithdev@gmail.com>",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "License :: OSI Approved :: Apache Software License",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Operating System :: OS Independent"
        ],
        "requires_dist": [
          "python-dateutil>=2.7.0",
          "types-python-dateutil>=2.8.10",
          "doc8 ; extra == \"doc\"",
          "sphinx>=7.0.0 ; extra == \"doc\"",
          "sphinx-autobuild ; extra == \"doc\"",
          "sphinx-autodoc-typehints ; extra == \"doc\"",
          "sphinx_rtd_theme>=1.3.0 ; extra == \"doc\"",
          "dateparser==1.* ; extra == \"test\"",
          "pre-commit ; extra == \"test\"",
          "pytest ; extra == \"test\"",
          "pytest-cov ; extra == \"test\"",
          "pytest-mock ; extra == \"test\"",
          "pytz==2021.1 ; extra == \"test\"",
          "simplejson==3.* ; extra == \"test\""
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://arrow.readthedocs.io",
          "Issues, https://github.com/arrow-py/arrow/issues",
          "Source, https://github.com/arrow-py/arrow"
        ],
        "provides_extra": [
          "doc",
          "test"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\arrow-1.3.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "astroid",
        "version": "3.3.5",
        "summary": "An abstract syntax tree for Python with inference support.",
        "description": "Astroid\n=======\n\n.. image:: https://codecov.io/gh/pylint-dev/astroid/branch/main/graph/badge.svg?token=Buxy4WptLb\n    :target: https://codecov.io/gh/pylint-dev/astroid\n    :alt: Coverage badge from codecov\n\n.. image:: https://readthedocs.org/projects/astroid/badge/?version=latest\n    :target: http://astroid.readthedocs.io/en/latest/?badge=latest\n    :alt: Documentation Status\n\n.. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n    :target: https://github.com/ambv/black\n\n.. image:: https://results.pre-commit.ci/badge/github/pylint-dev/astroid/main.svg\n   :target: https://results.pre-commit.ci/latest/github/pylint-dev/astroid/main\n   :alt: pre-commit.ci status\n\n.. |tidelift_logo| image:: https://raw.githubusercontent.com/pylint-dev/astroid/main/doc/media/Tidelift_Logos_RGB_Tidelift_Shorthand_On-White.png\n   :width: 200\n   :alt: Tidelift\n\n.. list-table::\n   :widths: 10 100\n\n   * - |tidelift_logo|\n     - Professional support for astroid is available as part of the\n       `Tidelift Subscription`_.  Tidelift gives software development teams a single source for\n       purchasing and maintaining their software, with professional grade assurances\n       from the experts who know it best, while seamlessly integrating with existing\n       tools.\n\n.. _Tidelift Subscription: https://tidelift.com/subscription/pkg/pypi-astroid?utm_source=pypi-astroid&utm_medium=referral&utm_campaign=readme\n\n\n\nWhat's this?\n------------\n\nThe aim of this module is to provide a common base representation of\npython source code. It is currently the library powering pylint's capabilities.\n\nIt provides a compatible representation which comes from the `_ast`\nmodule.  It rebuilds the tree generated by the builtin _ast module by\nrecursively walking down the AST and building an extended ast. The new\nnode classes have additional methods and attributes for different\nusages. They include some support for static inference and local name\nscopes. Furthermore, astroid can also build partial trees by inspecting living\nobjects.\n\n\nInstallation\n------------\n\nExtract the tarball, jump into the created directory and run::\n\n    pip install .\n\n\nIf you want to do an editable installation, you can run::\n\n    pip install -e .\n\n\nIf you have any questions, please mail the code-quality@python.org\nmailing list for support. See\nhttp://mail.python.org/mailman/listinfo/code-quality for subscription\ninformation and archives.\n\nDocumentation\n-------------\nhttp://astroid.readthedocs.io/en/latest/\n\n\nPython Versions\n---------------\n\nastroid 2.0 is currently available for Python 3 only. If you want Python 2\nsupport, use an older version of astroid (though note that these versions\nare no longer supported).\n\nTest\n----\n\nTests are in the 'test' subdirectory. To launch the whole tests suite, you can use\neither `tox` or `pytest`::\n\n    tox\n    pytest\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "static code analysis",
          "python",
          "abstract syntax tree"
        ],
        "license": "LGPL-2.1-or-later",
        "license_file": [
          "LICENSE",
          "CONTRIBUTORS.txt"
        ],
        "classifier": [
          "Development Status :: 6 - Mature",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: GNU Lesser General Public License v2 (LGPLv2)",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Software Development :: Quality Assurance",
          "Topic :: Software Development :: Testing"
        ],
        "requires_dist": [
          "typing-extensions>=4.0.0; python_version < \"3.11\""
        ],
        "requires_python": ">=3.9.0",
        "project_url": [
          "Docs, https://pylint.readthedocs.io/projects/astroid/en/latest/",
          "Source Code, https://github.com/pylint-dev/astroid",
          "Bug tracker, https://github.com/pylint-dev/astroid/issues",
          "Discord server, https://discord.gg/Egy6P8AMB5"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\astroid-3.3.5.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "asttokens",
        "version": "2.4.1",
        "summary": "Annotate AST trees with source code positions",
        "description": "ASTTokens\n=========\n\n.. image:: https://img.shields.io/pypi/v/asttokens.svg\n    :target: https://pypi.python.org/pypi/asttokens/\n.. image:: https://img.shields.io/pypi/pyversions/asttokens.svg\n    :target: https://pypi.python.org/pypi/asttokens/\n.. image:: https://github.com/gristlabs/asttokens/actions/workflows/build-and-test.yml/badge.svg\n    :target: https://github.com/gristlabs/asttokens/actions/workflows/build-and-test.yml\n.. image:: https://readthedocs.org/projects/asttokens/badge/?version=latest\n    :target: http://asttokens.readthedocs.io/en/latest/index.html\n.. image:: https://coveralls.io/repos/github/gristlabs/asttokens/badge.svg\n    :target: https://coveralls.io/github/gristlabs/asttokens\n\n.. Start of user-guide\n\nThe ``asttokens`` module annotates Python abstract syntax trees (ASTs) with the positions of tokens\nand text in the source code that generated them.\n\nIt makes it possible for tools that work with logical AST nodes to find the particular text that\nresulted in those nodes, for example for automated refactoring or highlighting.\n\nInstallation\n------------\nasttokens is available on PyPI: https://pypi.python.org/pypi/asttokens/::\n\n    pip install asttokens\n\nThe code is on GitHub: https://github.com/gristlabs/asttokens.\n\nThe API Reference is here: http://asttokens.readthedocs.io/en/latest/api-index.html.\n\nUsage\n-----\nASTTokens works with both Python2 and Python3.\n\nASTTokens can annotate both trees built by `ast <https://docs.python.org/2/library/ast.html>`_,\nAND those built by `astroid <https://github.com/PyCQA/astroid>`_.\n\nHere's an example:\n\n.. code-block:: python\n\n    import asttokens, ast\n    source = \"Robot('blue').walk(steps=10*n)\"\n    atok = asttokens.ASTTokens(source, parse=True)\n\nOnce the tree has been marked, nodes get ``.first_token``, ``.last_token`` attributes, and\nthe ``ASTTokens`` object offers helpful methods:\n\n.. code-block:: python\n\n    attr_node = next(n for n in ast.walk(atok.tree) if isinstance(n, ast.Attribute))\n    print(atok.get_text(attr_node))\n    start, end = attr_node.last_token.startpos, attr_node.last_token.endpos\n    print(atok.text[:start] + 'RUN' + atok.text[end:])\n\nWhich produces this output:\n\n.. code-block:: text\n\n    Robot('blue').walk\n    Robot('blue').RUN(steps=10*n)\n\nThe ``ASTTokens`` object also offers methods to walk and search the list of tokens that make up\nthe code (or a particular AST node), which is more useful and powerful than dealing with the text\ndirectly.\n\n\nContribute\n----------\n\nTo contribute:\n\n1. Fork this repository, and clone your fork.\n2. Install the package with test dependencies (ideally in a virtualenv) with::\n\n    pip install -e '.[test]'\n\n3. Run tests in your current interpreter with the command ``pytest`` or ``python -m pytest``.\n4. Run tests across all supported interpreters with the ``tox`` command. You will need to have the interpreters installed separately. We recommend ``pyenv`` for that. Use ``tox -p auto`` to run the tests in parallel.\n5. By default certain tests which take a very long time to run are skipped, but they are run on travis CI. To run them locally, set the environment variable ``ASTTOKENS_SLOW_TESTS``. For example run ``ASTTOKENS_SLOW_TESTS=1 tox`` to run the full suite of tests.\n",
        "keywords": [
          "code",
          "ast",
          "parse",
          "tokenize",
          "refactor"
        ],
        "home_page": "https://github.com/gristlabs/asttokens",
        "author": "Dmitry Sagalovskiy, Grist Labs",
        "author_email": "dmitry@getgrist.com",
        "license": "Apache 2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Software Development :: Code Generators",
          "Topic :: Software Development :: Compilers",
          "Topic :: Software Development :: Interpreters",
          "Topic :: Software Development :: Pre-processors",
          "Environment :: Console",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_dist": [
          "six >=1.12.0",
          "typing ; python_version < \"3.5\"",
          "astroid <2,>=1 ; (python_version < \"3\") and extra == 'astroid'",
          "astroid <4,>=2 ; (python_version >= \"3\") and extra == 'astroid'",
          "pytest ; extra == 'test'",
          "astroid <2,>=1 ; (python_version < \"3\") and extra == 'test'",
          "astroid <4,>=2 ; (python_version >= \"3\") and extra == 'test'"
        ],
        "provides_extra": [
          "astroid",
          "test"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\asttokens-2.4.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "attrs",
        "version": "24.2.0",
        "summary": "Classes Without Boilerplate",
        "description": "<p align=\"center\">\n  <a href=\"https://www.attrs.org/\">\n    <img src=\"https://raw.githubusercontent.com/python-attrs/attrs/main/docs/_static/attrs_logo.svg\" width=\"35%\" alt=\"attrs\" />\n  </a>\n</p>\n\n\n*attrs* is the Python package that will bring back the **joy** of **writing classes** by relieving you from the drudgery of implementing object protocols (aka [dunder methods](https://www.attrs.org/en/latest/glossary.html#term-dunder-methods)).\n[Trusted by NASA](https://docs.github.com/en/account-and-profile/setting-up-and-managing-your-github-profile/customizing-your-profile/personalizing-your-profile#list-of-qualifying-repositories-for-mars-2020-helicopter-contributor-achievement) for Mars missions since 2020!\n\nIts main goal is to help you to write **concise** and **correct** software without slowing down your code.\n\n\n## Sponsors\n\n*attrs* would not be possible without our [amazing sponsors](https://github.com/sponsors/hynek).\nEspecially those generously supporting us at the *The Organization* tier and higher:\n\n<!-- sponsor-break-begin -->\n\n<p align=\"center\">\n\n<!-- [[[cog\nimport pathlib, tomllib\n\nfor sponsor in tomllib.loads(pathlib.Path(\"pyproject.toml\").read_text())[\"tool\"][\"sponcon\"][\"sponsors\"]:\n      print(f'<a href=\"{sponsor[\"url\"]}\"><img title=\"{sponsor[\"title\"]}\" src=\"https://www.attrs.org/en/24.2.0/_static/sponsors/{sponsor[\"img\"]}\" width=\"190\" /></a>')\n]]] -->\n<a href=\"https://www.variomedia.de/\"><img title=\"Variomedia AG\" src=\"https://www.attrs.org/en/24.2.0/_static/sponsors/Variomedia.svg\" width=\"190\" /></a>\n<a href=\"https://tidelift.com/?utm_source=lifter&utm_medium=referral&utm_campaign=hynek\"><img title=\"Tidelift\" src=\"https://www.attrs.org/en/24.2.0/_static/sponsors/Tidelift.svg\" width=\"190\" /></a>\n<a href=\"https://klaviyo.com/\"><img title=\"Klaviyo\" src=\"https://www.attrs.org/en/24.2.0/_static/sponsors/Klaviyo.svg\" width=\"190\" /></a>\n<a href=\"https://filepreviews.io/\"><img title=\"FilePreviews\" src=\"https://www.attrs.org/en/24.2.0/_static/sponsors/FilePreviews.svg\" width=\"190\" /></a>\n<!-- [[[end]]] -->\n\n</p>\n\n<!-- sponsor-break-end -->\n\n<p align=\"center\">\n   <strong>Please consider <a href=\"https://github.com/sponsors/hynek\">joining them</a> to help make <em>attrs</em>â€™s maintenance more sustainable!</strong>\n</p>\n\n<!-- teaser-end -->\n\n## Example\n\n*attrs* gives you a class decorator and a way to declaratively define the attributes on that class:\n\n<!-- code-begin -->\n\n```pycon\n>>> from attrs import asdict, define, make_class, Factory\n\n>>> @define\n... class SomeClass:\n...     a_number: int = 42\n...     list_of_numbers: list[int] = Factory(list)\n...\n...     def hard_math(self, another_number):\n...         return self.a_number + sum(self.list_of_numbers) * another_number\n\n\n>>> sc = SomeClass(1, [1, 2, 3])\n>>> sc\nSomeClass(a_number=1, list_of_numbers=[1, 2, 3])\n\n>>> sc.hard_math(3)\n19\n>>> sc == SomeClass(1, [1, 2, 3])\nTrue\n>>> sc != SomeClass(2, [3, 2, 1])\nTrue\n\n>>> asdict(sc)\n{'a_number': 1, 'list_of_numbers': [1, 2, 3]}\n\n>>> SomeClass()\nSomeClass(a_number=42, list_of_numbers=[])\n\n>>> C = make_class(\"C\", [\"a\", \"b\"])\n>>> C(\"foo\", \"bar\")\nC(a='foo', b='bar')\n```\n\nAfter *declaring* your attributes, *attrs* gives you:\n\n- a concise and explicit overview of the class's attributes,\n- a nice human-readable `__repr__`,\n- equality-checking methods,\n- an initializer,\n- and much more,\n\n*without* writing dull boilerplate code again and again and *without* runtime performance penalties.\n\n---\n\nThis example uses *attrs*'s modern APIs that have been introduced in version 20.1.0, and the *attrs* package import name that has been added in version 21.3.0.\nThe classic APIs (`@attr.s`, `attr.ib`, plus their serious-business aliases) and the `attr` package import name will remain **indefinitely**.\n\nCheck out [*On The Core API Names*](https://www.attrs.org/en/latest/names.html) for an in-depth explanation!\n\n\n### Hate Type Annotations!?\n\nNo problem!\nTypes are entirely **optional** with *attrs*.\nSimply assign `attrs.field()` to the attributes instead of annotating them with types:\n\n```python\nfrom attrs import define, field\n\n@define\nclass SomeClass:\n    a_number = field(default=42)\n    list_of_numbers = field(factory=list)\n```\n\n\n## Data Classes\n\nOn the tin, *attrs* might remind you of `dataclasses` (and indeed, `dataclasses` [are a descendant](https://hynek.me/articles/import-attrs/) of *attrs*).\nIn practice it does a lot more and is more flexible.\nFor instance, it allows you to define [special handling of NumPy arrays for equality checks](https://www.attrs.org/en/stable/comparison.html#customization), allows more ways to [plug into the initialization process](https://www.attrs.org/en/stable/init.html#hooking-yourself-into-initialization), has a replacement for `__init_subclass__`, and allows for stepping through the generated methods using a debugger.\n\nFor more details, please refer to our [comparison page](https://www.attrs.org/en/stable/why.html#data-classes), but generally speaking, we are more likely to commit crimes against nature to make things work that one would expect to work, but that are quite complicated in practice.\n\n\n## Project Information\n\n- [**Changelog**](https://www.attrs.org/en/stable/changelog.html)\n- [**Documentation**](https://www.attrs.org/)\n- [**PyPI**](https://pypi.org/project/attrs/)\n- [**Source Code**](https://github.com/python-attrs/attrs)\n- [**Contributing**](https://github.com/python-attrs/attrs/blob/main/.github/CONTRIBUTING.md)\n- [**Third-party Extensions**](https://github.com/python-attrs/attrs/wiki/Extensions-to-attrs)\n- **Get Help**: use the `python-attrs` tag on [Stack Overflow](https://stackoverflow.com/questions/tagged/python-attrs)\n\n\n### *attrs* for Enterprise\n\nAvailable as part of the Tidelift Subscription.\n\nThe maintainers of *attrs* and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source packages you use to build your applications.\nSave time, reduce risk, and improve code health, while paying the maintainers of the exact packages you use.\n[Learn more](https://tidelift.com/?utm_source=lifter&utm_medium=referral&utm_campaign=hynek).\n\n## Release Information\n\n### Deprecations\n\n- Given the amount of warnings raised in the broader ecosystem, we've decided to only soft-deprecate the *hash* argument to `@define` / `@attr.s`.\n  Please don't use it in new code, but we don't intend to remove it anymore.\n  [#1330](https://github.com/python-attrs/attrs/issues/1330)\n\n\n### Changes\n\n- `attrs.converters.pipe()` (and its syntactic sugar of passing a list for `attrs.field()`'s / `attr.ib()`'s *converter* argument) works again when passing `attrs.setters.convert` to *on_setattr* (which is default for `attrs.define`).\n  [#1328](https://github.com/python-attrs/attrs/issues/1328)\n- Restored support for PEP [649](https://peps.python.org/pep-0649/) / [749](https://peps.python.org/pep-0749/)-implementing Pythons -- currently 3.14-dev.\n  [#1329](https://github.com/python-attrs/attrs/issues/1329)\n\n\n\n---\n\n[Full changelog â†’](https://www.attrs.org/en/stable/changelog.html)\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "attribute",
          "boilerplate",
          "class"
        ],
        "author_email": "Hynek Schlawack <hs@ox.cx>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "importlib-metadata; python_version < '3.8'",
          "cloudpickle; (platform_python_implementation == 'CPython') and extra == 'benchmark'",
          "hypothesis; extra == 'benchmark'",
          "mypy>=1.11.1; (platform_python_implementation == 'CPython' and python_version >= '3.9') and extra == 'benchmark'",
          "pympler; extra == 'benchmark'",
          "pytest-codspeed; extra == 'benchmark'",
          "pytest-mypy-plugins; (platform_python_implementation == 'CPython' and python_version >= '3.9' and python_version < '3.13') and extra == 'benchmark'",
          "pytest-xdist[psutil]; extra == 'benchmark'",
          "pytest>=4.3.0; extra == 'benchmark'",
          "cloudpickle; (platform_python_implementation == 'CPython') and extra == 'cov'",
          "coverage[toml]>=5.3; extra == 'cov'",
          "hypothesis; extra == 'cov'",
          "mypy>=1.11.1; (platform_python_implementation == 'CPython' and python_version >= '3.9') and extra == 'cov'",
          "pympler; extra == 'cov'",
          "pytest-mypy-plugins; (platform_python_implementation == 'CPython' and python_version >= '3.9' and python_version < '3.13') and extra == 'cov'",
          "pytest-xdist[psutil]; extra == 'cov'",
          "pytest>=4.3.0; extra == 'cov'",
          "cloudpickle; (platform_python_implementation == 'CPython') and extra == 'dev'",
          "hypothesis; extra == 'dev'",
          "mypy>=1.11.1; (platform_python_implementation == 'CPython' and python_version >= '3.9') and extra == 'dev'",
          "pre-commit; extra == 'dev'",
          "pympler; extra == 'dev'",
          "pytest-mypy-plugins; (platform_python_implementation == 'CPython' and python_version >= '3.9' and python_version < '3.13') and extra == 'dev'",
          "pytest-xdist[psutil]; extra == 'dev'",
          "pytest>=4.3.0; extra == 'dev'",
          "cogapp; extra == 'docs'",
          "furo; extra == 'docs'",
          "myst-parser; extra == 'docs'",
          "sphinx; extra == 'docs'",
          "sphinx-notfound-page; extra == 'docs'",
          "sphinxcontrib-towncrier; extra == 'docs'",
          "towncrier<24.7; extra == 'docs'",
          "cloudpickle; (platform_python_implementation == 'CPython') and extra == 'tests'",
          "hypothesis; extra == 'tests'",
          "mypy>=1.11.1; (platform_python_implementation == 'CPython' and python_version >= '3.9') and extra == 'tests'",
          "pympler; extra == 'tests'",
          "pytest-mypy-plugins; (platform_python_implementation == 'CPython' and python_version >= '3.9' and python_version < '3.13') and extra == 'tests'",
          "pytest-xdist[psutil]; extra == 'tests'",
          "pytest>=4.3.0; extra == 'tests'",
          "mypy>=1.11.1; (platform_python_implementation == 'CPython' and python_version >= '3.9') and extra == 'tests-mypy'",
          "pytest-mypy-plugins; (platform_python_implementation == 'CPython' and python_version >= '3.9' and python_version < '3.13') and extra == 'tests-mypy'"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Documentation, https://www.attrs.org/",
          "Changelog, https://www.attrs.org/en/stable/changelog.html",
          "GitHub, https://github.com/python-attrs/attrs",
          "Funding, https://github.com/sponsors/hynek",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-attrs?utm_source=pypi-attrs&utm_medium=pypi"
        ],
        "provides_extra": [
          "benchmark",
          "cov",
          "dev",
          "docs",
          "tests",
          "tests-mypy"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\attrs-24.2.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "backcall",
        "version": "0.2.0",
        "summary": "Specifications for callback functions passed in to an API",
        "description": "========\nbackcall\n========\n\n.. image:: https://travis-ci.org/takluyver/backcall.png?branch=master\n        :target: https://travis-ci.org/takluyver/backcall\n\nSpecifications for callback functions passed in to an API\n\nIf your code lets other people supply callback functions, it's important to\nspecify the function signature you expect, and check that functions support that.\nAdding extra parameters later would break other peoples code unless you're careful.\n\nbackcall provides a way of specifying the callback signature using a prototype\nfunction::\n\n    from backcall import callback_prototype\n    \n    @callback_prototype\n    def handle_ping(sender, delay=None):\n        # Specify positional parameters without a default, and keyword\n        # parameters with a default.\n        pass\n    \n    def register_ping_handler(callback):\n        # This checks and adapts the function passed in:\n        callback = handle_ping.adapt(callback)\n        ping_callbacks.append(callback)\n\nIf the callback takes fewer parameters than your prototype, *backcall* will wrap\nit in a function that discards the extra arguments. If the callback expects\nmore arguments, a TypeError is thrown when it is registered.\n\nFor more details, see the `docs <http://backcall.readthedocs.org/en/latest/>`_ or\nthe `Demo notebook <http://nbviewer.ipython.org/github/takluyver/backcall/blob/master/Demo.ipynb>`_.\n\nThe tests are run with `pytest <http://pytest.org/latest/>`_. In the root directory,\nexecute::\n\n    py.test\n\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/takluyver/backcall",
        "author": "Thomas Kluyver",
        "author_email": "thomas@kluyver.me.uk",
        "license": "UNKNOWN",
        "classifier": [
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\backcall-0.2.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "beautifulsoup4",
        "version": "4.12.3",
        "summary": "Screen-scraping library",
        "description": "Beautiful Soup is a library that makes it easy to scrape information\nfrom web pages. It sits atop an HTML or XML parser, providing Pythonic\nidioms for iterating, searching, and modifying the parse tree.\n\n# Quick start\n\n```\n>>> from bs4 import BeautifulSoup\n>>> soup = BeautifulSoup(\"<p>Some<b>bad<i>HTML\")\n>>> print(soup.prettify())\n<html>\n <body>\n  <p>\n   Some\n   <b>\n    bad\n    <i>\n     HTML\n    </i>\n   </b>\n  </p>\n </body>\n</html>\n>>> soup.find(text=\"bad\")\n'bad'\n>>> soup.i\n<i>HTML</i>\n#\n>>> soup = BeautifulSoup(\"<tag1>Some<tag2/>bad<tag3>XML\", \"xml\")\n#\n>>> print(soup.prettify())\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<tag1>\n Some\n <tag2/>\n bad\n <tag3>\n  XML\n </tag3>\n</tag1>\n```\n\nTo go beyond the basics, [comprehensive documentation is available](https://www.crummy.com/software/BeautifulSoup/bs4/doc/).\n\n# Links\n\n* [Homepage](https://www.crummy.com/software/BeautifulSoup/bs4/)\n* [Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n* [Discussion group](https://groups.google.com/group/beautifulsoup/)\n* [Development](https://code.launchpad.net/beautifulsoup/)\n* [Bug tracker](https://bugs.launchpad.net/beautifulsoup/)\n* [Complete changelog](https://bazaar.launchpad.net/~leonardr/beautifulsoup/bs4/view/head:/CHANGELOG)\n\n# Note on Python 2 sunsetting\n\nBeautiful Soup's support for Python 2 was discontinued on December 31,\n2020: one year after the sunset date for Python 2 itself. From this\npoint onward, new Beautiful Soup development will exclusively target\nPython 3. The final release of Beautiful Soup 4 to support Python 2\nwas 4.9.3.\n\n# Supporting the project\n\nIf you use Beautiful Soup as part of your professional work, please consider a\n[Tidelift subscription](https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=readme).\nThis will support many of the free software projects your organization\ndepends on, not just Beautiful Soup.\n\nIf you use Beautiful Soup for personal projects, the best way to say\nthank you is to read\n[Tool Safety](https://www.crummy.com/software/BeautifulSoup/zine/), a zine I\nwrote about what Beautiful Soup has taught me about software\ndevelopment.\n\n# Building the documentation\n\nThe bs4/doc/ directory contains full documentation in Sphinx\nformat. Run `make html` in that directory to create HTML\ndocumentation.\n\n# Running the unit tests\n\nBeautiful Soup supports unit test discovery using Pytest:\n\n```\n$ pytest\n```\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "HTML",
          "XML",
          "parse",
          "soup"
        ],
        "author_email": "Leonard Richardson <leonardr@segfault.org>",
        "license": "MIT License",
        "license_file": [
          "AUTHORS",
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Text Processing :: Markup :: HTML",
          "Topic :: Text Processing :: Markup :: SGML",
          "Topic :: Text Processing :: Markup :: XML"
        ],
        "requires_dist": [
          "soupsieve>1.2",
          "cchardet; extra == 'cchardet'",
          "chardet; extra == 'chardet'",
          "charset-normalizer; extra == 'charset-normalizer'",
          "html5lib; extra == 'html5lib'",
          "lxml; extra == 'lxml'"
        ],
        "requires_python": ">=3.6.0",
        "project_url": [
          "Download, https://www.crummy.com/software/BeautifulSoup/bs4/download/",
          "Homepage, https://www.crummy.com/software/BeautifulSoup/bs4/"
        ],
        "provides_extra": [
          "cchardet",
          "chardet",
          "charset-normalizer",
          "html5lib",
          "lxml"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\beautifulsoup4-4.12.3.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "bleach",
        "version": "6.1.0",
        "summary": "An easy safelist-based HTML-sanitizing tool.",
        "description": "======\nBleach\n======\n\n.. image:: https://github.com/mozilla/bleach/workflows/Test/badge.svg\n   :target: https://github.com/mozilla/bleach/actions?query=workflow%3ATest\n\n.. image:: https://github.com/mozilla/bleach/workflows/Lint/badge.svg\n   :target: https://github.com/mozilla/bleach/actions?query=workflow%3ALint\n\n.. image:: https://badge.fury.io/py/bleach.svg\n   :target: http://badge.fury.io/py/bleach\n\n**NOTE: 2023-01-23: Bleach is deprecated.** See issue:\n`<https://github.com/mozilla/bleach/issues/698>`__\n\nBleach is an allowed-list-based HTML sanitizing library that escapes or strips\nmarkup and attributes.\n\nBleach can also linkify text safely, applying filters that Django's ``urlize``\nfilter cannot, and optionally setting ``rel`` attributes, even on links already\nin the text.\n\nBleach is intended for sanitizing text from *untrusted* sources. If you find\nyourself jumping through hoops to allow your site administrators to do lots of\nthings, you're probably outside the use cases. Either trust those users, or\ndon't.\n\nBecause it relies on html5lib_, Bleach is as good as modern browsers at dealing\nwith weird, quirky HTML fragments. And *any* of Bleach's methods will fix\nunbalanced or mis-nested tags.\n\nThe version on GitHub_ is the most up-to-date and contains the latest bug\nfixes. You can find full documentation on `ReadTheDocs`_.\n\n:Code:           https://github.com/mozilla/bleach\n:Documentation:  https://bleach.readthedocs.io/\n:Issue tracker:  https://github.com/mozilla/bleach/issues\n:License:        Apache License v2; see LICENSE file\n\n\nReporting Bugs\n==============\n\nFor regular bugs, please report them `in our issue tracker\n<https://github.com/mozilla/bleach/issues>`_.\n\nIf you believe that you've found a security vulnerability, please `file a secure\nbug report in our bug tracker\n<https://bugzilla.mozilla.org/enter_bug.cgi?assigned_to=nobody%40mozilla.org&product=Webtools&component=Bleach-security&groups=webtools-security>`_\nor send an email to *security AT mozilla DOT org*.\n\nFor more information on security-related bug disclosure and the PGP key to use\nfor sending encrypted mail or to verify responses received from that address,\nplease read our wiki page at\n`<https://www.mozilla.org/en-US/security/#For_Developers>`_.\n\n\nSecurity\n========\n\nBleach is a security-focused library.\n\nWe have a responsible security vulnerability reporting process. Please use\nthat if you're reporting a security issue.\n\nSecurity issues are fixed in private. After we land such a fix, we'll do a\nrelease.\n\nFor every release, we mark security issues we've fixed in the ``CHANGES`` in\nthe **Security issues** section. We include any relevant CVE links.\n\n\nInstalling Bleach\n=================\n\nBleach is available on PyPI_, so you can install it with ``pip``::\n\n    $ pip install bleach\n\n\nUpgrading Bleach\n================\n\n.. warning::\n\n   Before doing any upgrades, read through `Bleach Changes\n   <https://bleach.readthedocs.io/en/latest/changes.html>`_ for backwards\n   incompatible changes, newer versions, etc.\n\n   Bleach follows `semver 2`_ versioning. Vendored libraries will not\n   be changed in patch releases.\n\n\nBasic use\n=========\n\nThe simplest way to use Bleach is:\n\n.. code-block:: python\n\n    >>> import bleach\n\n    >>> bleach.clean('an <script>evil()</script> example')\n    u'an &lt;script&gt;evil()&lt;/script&gt; example'\n\n    >>> bleach.linkify('an http://example.com url')\n    u'an <a href=\"http://example.com\" rel=\"nofollow\">http://example.com</a> url'\n\n\nCode of Conduct\n===============\n\nThis project and repository is governed by Mozilla's code of conduct and\netiquette guidelines. For more details please see the `CODE_OF_CONDUCT.md\n</CODE_OF_CONDUCT.md>`_\n\n\n.. _html5lib: https://github.com/html5lib/html5lib-python\n.. _GitHub: https://github.com/mozilla/bleach\n.. _ReadTheDocs: https://bleach.readthedocs.io/\n.. _PyPI: https://pypi.org/project/bleach/\n.. _semver 2: https://semver.org/\n\n\nBleach changes\n==============\n\nVersion 6.1.0 (October 6th, 2023)\n---------------------------------\n\n**Backwards incompatible changes**\n\n* Dropped support for Python 3.7. (#709)\n\n**Security fixes**\n\nNone\n\n**Bug fixes**\n\n* Add support for Python 3.12. (#710)\n* Fix linkify with arrays in querystring (#436)\n* Handle more cases with < followed by character data (#705)\n* Fix entities inside a tags in linkification (#704)\n* Update cap for tinycss2 to <1.3 (#702)\n* Updated Sphinx requirement\n* Add dependabot for github actions and update github actions\n\n\nVersion 6.0.0 (January 23rd, 2023)\n----------------------------------\n\n**Backwards incompatible changes**\n\n* ``bleach.clean``, ``bleach.sanitizer.Cleaner``,\n  ``bleach.html5lib_shim.BleachHTMLParser``: the ``tags`` and ``protocols``\n  arguments were changed from lists to sets.\n\n  Old pre-6.0.0:\n\n  .. code-block:: python\n\n     bleach.clean(\n         \"some text\",\n         tags=[\"a\", \"p\", \"img\"],\n         #    ^               ^ list\n         protocols=[\"http\", \"https\"],\n         #         ^               ^ list\n     )\n\n\n  New 6.0.0 and later:\n\n  .. code-block:: python\n\n     bleach.clean(\n         \"some text\",\n         tags={\"a\", \"p\", \"img\"},\n         #    ^               ^ set\n         protocols={\"http\", \"https\"},\n         #         ^               ^ set\n     )\n\n* ``bleach.linkify``, ``bleach.linkifier.Linker``: the ``skip_tags`` and\n  ``recognized_tags`` arguments were changed from lists to sets.\n\n  Old pre-6.0.0:\n\n  .. code-block:: python\n\n     bleach.linkify(\n         \"some text\",\n         skip_tags=[\"pre\"],\n         #         ^     ^ list\n     )\n\n     linker = Linker(\n         skip_tags=[\"pre\"],\n         #         ^     ^ list\n         recognized_tags=html5lib_shim.HTML_TAGS + [\"custom-element\"],\n         #                                       ^ ^                ^ list\n         #                                       |\n         #                                       | list concatenation\n     )\n\n  New 6.0.0 and later:\n\n  .. code-block:: python\n\n     bleach.linkify(\n         \"some text\",\n         skip_tags={\"pre\"},\n         #         ^     ^ set\n     )\n\n     linker = Linker(\n         skip_tags={\"pre\"},\n         #         ^     ^ set\n         recognized_tags=html5lib_shim.HTML_TAGS | {\"custom-element\"},\n         #                                       ^ ^                ^ set\n         #                                       |\n         #                                       | union operator\n     )\n\n* ``bleach.sanitizer.BleachSanitizerFilter``: ``strip_allowed_elements`` is now\n  ``strip_allowed_tags``. We now use \"tags\" everywhere rather than a mishmash\n  of \"tags\" in some places and \"elements\" in others.\n\n\n**Security fixes**\n\nNone\n\n\n**Bug fixes**\n\n* Add support for Python 3.11. (#675)\n\n* Fix API weirness in ``BleachSanitizerFilter``. (#649)\n\n  We're using \"tags\" instead of \"elements\" everywhere--no more weird\n  overloading of \"elements\" anymore.\n\n  Also, it no longer calls the superclass constructor.\n\n* Add warning when ``css_sanitizer`` isn't set, but the ``style``\n  attribute is allowed. (#676)\n\n* Fix linkify handling of character entities. (#501)\n\n* Rework dev dependencies to use ``requirements-dev.txt`` and\n  ``requirements-flake8.txt`` instead of extras.\n\n* Fix project infrastructure to be tox-based so it's easier to have CI\n  run the same things we're running in development and with flake8\n  in an isolated environment.\n\n* Update action versions in CI.\n\n* Switch to f-strings where possible. Make tests parametrized to be\n  easier to read/maintain.\n\n\nVersion 5.0.1 (June 27th, 2022)\n-------------------------------\n\n**Security fixes**\n\nNone\n\n\n**Bug fixes**\n\n* Add missing comma to tinycss2 require. Thank you, @shadchin!\n\n* Add url parse tests based on wpt url tests. (#688)\n\n* Support scheme-less urls if \"https\" is in allow list. (#662)\n\n* Handle escaping ``<`` in edge cases where it doesn't start a tag. (#544)\n\n* Fix reference warnings in docs. (#660)\n\n* Correctly urlencode email address parts. Thank you, @larseggert! (#659)\n\n\nVersion 5.0.0 (April 7th, 2022)\n-------------------------------\n\n**Backwards incompatible changes**\n\n* ``clean`` and ``linkify`` now preserve the order of HTML attributes. Thank\n  you, @askoretskly! (#566)\n\n* Drop support for Python 3.6. Thank you, @hugovk! (#629)\n\n* CSS sanitization in style tags is completely different now. If you're using\n  Bleach ``clean`` to sanitize css in style tags, you'll need to update your\n  code and you'll need to install the ``css`` extras::\n\n      pip install 'bleach[css]'\n\n  See `the documentation on sanitizing CSS for how to do it\n  <https://bleach.readthedocs.io/en/latest/clean.html#sanitizing-css>`_. (#633)\n\n**Security fixes**\n\nNone\n\n**Bug fixes**\n\n* Rework dev dependencies. We no longer have\n  ``requirements-dev.in``/``requirements-dev.txt``. Instead, we're using\n  ``dev`` extras.\n\n  See `development docs <https://bleach.readthedocs.io/en/latest/dev.html>`_\n  for more details. (#620)\n\n* Add newline when dropping block-level tags. Thank you, @jvanasco! (#369)\n\n\nVersion 4.1.0 (August 25th, 2021)\n---------------------------------\n\n**Features**\n\n* Python 3.9 support\n\n**Security fixes**\n\nNone\n\n**Bug fixes**\n\n* Update sanitizer clean to use vendored 3.6.14 stdlib urllib.parse to\n  fix test failures on Python 3.9. (#536)\n\n\nVersion 4.0.0 (August 3rd, 2021)\n--------------------------------\n\n**Backwards incompatible changes**\n\n* Drop support for unsupported Python versions <3.6. (#520)\n\n**Security fixes**\n\nNone\n\n**Features**\n\n* fix attribute name in the linkify docs (thanks @CheesyFeet!)\n\n\nVersion 3.3.1 (July 14th, 2021)\n-------------------------------\n\n**Security fixes**\n\nNone\n\n**Features**\n\n* add more tests for CVE-2021-23980 / GHSA-vv2x-vrpj-qqpq\n* bump python version to 3.8 for tox doc, vendorverify, and lint targets\n* update bug report template tag\n* update vendorverify script to detect and fail when extra files are vendored\n* update release process docs to check vendorverify passes locally\n\n**Bug fixes**\n\n* remove extra vendored django present in the v3.3.0 whl (#595)\n* duplicate h1 header doc fix (thanks Nguyá»…n Gia Phong / @McSinyx!)\n\n\nVersion 3.3.0 (February 1st, 2021)\n----------------------------------\n\n**Backwards incompatible changes**\n\n* clean escapes HTML comments even when strip_comments=False\n\n**Security fixes**\n\n* Fix bug 1621692 / GHSA-m6xf-fq7q-8743. See the advisory for details.\n\n**Features**\n\nNone\n\n**Bug fixes**\n\nNone\n\n\nVersion 3.2.3 (January 26th, 2021)\n----------------------------------\n\n**Security fixes**\n\nNone\n\n**Features**\n\nNone\n\n**Bug fixes**\n\n* fix clean and linkify raising ValueErrors for certain inputs. Thank you @Google-Autofuzz.\n\n\nVersion 3.2.2 (January 20th, 2021)\n----------------------------------\n\n**Security fixes**\n\nNone\n\n**Features**\n\n* Migrate CI to Github Actions. Thank you @hugovk.\n\n**Bug fixes**\n\n* fix linkify raising an IndexError on certain inputs. Thank you @Google-Autofuzz.\n\n\nVersion 3.2.1 (September 18th, 2020)\n------------------------------------\n\n**Security fixes**\n\nNone\n\n**Features**\n\nNone\n\n**Bug fixes**\n\n* change linkifier to add rel=\"nofollow\" as documented. Thank you @mitar.\n* suppress html5lib sanitizer DeprecationWarnings (#557)\n\n\nVersion 3.2.0 (September 16th, 2020)\n------------------------------------\n\n**Security fixes**\n\nNone\n\n**Features**\n\nNone\n\n**Bug fixes**\n\n* ``html5lib`` dependency to version 1.1.0. Thank you Sam Sneddon.\n* update tests_website terminology. Thank you Thomas Grainger.\n\n\nVersion 3.1.5 (April 29th, 2020)\n--------------------------------\n\n**Security fixes**\n\nNone\n\n**Features**\n\nNone\n\n**Bug fixes**\n\n* replace missing ``setuptools`` dependency with ``packaging``. Thank you Benjamin Peterson.\n\n\nVersion 3.1.4 (March 24th, 2020)\n--------------------------------\n\n**Security fixes**\n\n* ``bleach.clean`` behavior parsing style attributes could result in a\n  regular expression denial of service (ReDoS).\n\n  Calls to ``bleach.clean`` with an allowed tag with an allowed\n  ``style`` attribute were vulnerable to ReDoS. For example,\n  ``bleach.clean(..., attributes={'a': ['style']})``.\n\n  This issue was confirmed in Bleach versions v3.1.3, v3.1.2, v3.1.1,\n  v3.1.0, v3.0.0, v2.1.4, and v2.1.3. Earlier versions used a similar\n  regular expression and should be considered vulnerable too.\n\n  Anyone using Bleach <=v3.1.3 is encouraged to upgrade.\n\n  https://bugzilla.mozilla.org/show_bug.cgi?id=1623633\n\n**Backwards incompatible changes**\n\n* Style attributes with dashes, or single or double quoted values are\n  cleaned instead of passed through.\n\n**Features**\n\nNone\n\n**Bug fixes**\n\nNone\n\n\nVersion 3.1.3 (March 17th, 2020)\n--------------------------------\n\n**Security fixes**\n\nNone\n\n**Backwards incompatible changes**\n\n* Drop support for Python 3.4. Thank you, @hugovk!\n\n* Drop deprecated ``setup.py test`` support. Thank you, @jdufresne! (#507)\n\n**Features**\n\n* Add support for Python 3.8. Thank you, @jdufresne!\n\n* Add support for PyPy 7. Thank you, @hugovk!\n\n* Add pypy3 testing to tox and travis. Thank you, @jdufresne!\n\n**Bug fixes**\n\n* Add relative link to code of conduct. (#442)\n\n* Fix typo: curren -> current in tests/test_clean.py Thank you, timgates42! (#504)\n\n* Fix handling of non-ascii style attributes. Thank you, @sekineh! (#426)\n\n* Simplify tox configuration. Thank you, @jdufresne!\n\n* Make documentation reproducible. Thank you, @lamby!\n\n* Fix typos in code comments. Thank you, @zborboa-g!\n\n* Fix exception value testing. Thank you, @mastizada!\n\n* Fix parser-tags NoneType exception. Thank you, @bope!\n\n* Improve TLD support in linkify. Thank you, @pc-coholic!\n\n\nVersion 3.1.2 (March 11th, 2020)\n--------------------------------\n\n**Security fixes**\n\n* ``bleach.clean`` behavior parsing embedded MathML and SVG content\n  with RCDATA tags did not match browser behavior and could result in\n  a mutation XSS.\n\n  Calls to ``bleach.clean`` with ``strip=False`` and ``math`` or\n  ``svg`` tags and one or more of the RCDATA tags ``script``,\n  ``noscript``, ``style``, ``noframes``, ``iframe``, ``noembed``, or\n  ``xmp`` in the allowed tags whitelist were vulnerable to a mutation\n  XSS.\n\n  This security issue was confirmed in Bleach version v3.1.1. Earlier\n  versions are likely affected too.\n\n  Anyone using Bleach <=v3.1.1 is encouraged to upgrade.\n\n  https://bugzilla.mozilla.org/show_bug.cgi?id=1621692\n\n**Backwards incompatible changes**\n\nNone\n\n**Features**\n\nNone\n\n**Bug fixes**\n\nNone\n\n\nVersion 3.1.1 (February 13th, 2020)\n-----------------------------------\n\n**Security fixes**\n\n* ``bleach.clean`` behavior parsing ``noscript`` tags did not match\n  browser behavior.\n\n  Calls to ``bleach.clean`` allowing ``noscript`` and one or more of\n  the raw text tags (``title``, ``textarea``, ``script``, ``style``,\n  ``noembed``, ``noframes``, ``iframe``, and ``xmp``) were vulnerable\n  to a mutation XSS.\n\n  This security issue was confirmed in Bleach versions v2.1.4, v3.0.2,\n  and v3.1.0. Earlier versions are probably affected too.\n\n  Anyone using Bleach <=v3.1.0 is highly encouraged to upgrade.\n\n  https://bugzilla.mozilla.org/show_bug.cgi?id=1615315\n\n**Backwards incompatible changes**\n\nNone\n\n**Features**\n\nNone\n\n**Bug fixes**\n\nNone\n\n\nVersion 3.1.0 (January 9th, 2019)\n---------------------------------\n\n**Security fixes**\n\nNone\n\n**Backwards incompatible changes**\n\nNone\n\n**Features**\n\n* Add ``recognized_tags`` argument to the linkify ``Linker`` class. This\n  fixes issues when linkifying on its own and having some tags get escaped.\n  It defaults to a list of HTML5 tags. Thank you, Chad Birch! (#409)\n\n**Bug fixes**\n\n* Add ``six>=1.9`` to requirements. Thank you, Dave Shawley (#416)\n\n* Fix cases where attribute names could have invalid characters in them.\n  (#419)\n\n* Fix problems with ``LinkifyFilter`` not being able to match links\n  across ``&amp;``. (#422)\n\n* Fix ``InputStreamWithMemory`` when the ``BleachHTMLParser`` is\n  parsing ``meta`` tags. (#431)\n\n* Fix doctests. (#357)\n\n\nVersion 3.0.2 (October 11th, 2018)\n----------------------------------\n\n**Security fixes**\n\nNone\n\n**Backwards incompatible changes**\n\nNone\n\n**Features**\n\nNone\n\n**Bug fixes**\n\n* Merge ``Characters`` tokens after sanitizing them. This fixes issues in the\n  ``LinkifyFilter`` where it was only linkifying parts of urls. (#374)\n\n\nVersion 3.0.1 (October 9th, 2018)\n---------------------------------\n\n**Security fixes**\n\nNone\n\n**Backwards incompatible changes**\n\nNone\n\n**Features**\n\n* Support Python 3.7. It supported Python 3.7 just fine, but we added 3.7 to\n  the list of Python environments we test so this is now officially supported.\n  (#377)\n\n**Bug fixes**\n\n* Fix ``list`` object has no attribute ``lower`` in ``clean``. (#398)\n* Fix ``abbr`` getting escaped in ``linkify``. (#400)\n\n\nVersion 3.0.0 (October 3rd, 2018)\n---------------------------------\n\n**Security fixes**\n\nNone\n\n**Backwards incompatible changes**\n\n* A bunch of functions were moved from one module to another.\n\n  These were moved from ``bleach.sanitizer`` to ``bleach.html5lib_shim``:\n\n  * ``convert_entity``\n  * ``convert_entities``\n  * ``match_entity``\n  * ``next_possible_entity``\n  * ``BleachHTMLSerializer``\n  * ``BleachHTMLTokenizer``\n  * ``BleachHTMLParser``\n\n  These functions and classes weren't documented and aren't part of the\n  public API, but people read code and might be using them so we're\n  considering it an incompatible API change.\n\n  If you're using them, you'll need to update your code.\n\n**Features**\n\n* Bleach no longer depends on html5lib. html5lib==1.0.1 is now vendored into\n  Bleach. You can remove it from your requirements file if none of your other\n  requirements require html5lib.\n\n  This means Bleach will now work fine with other libraries that depend on\n  html5lib regardless of what version of html5lib they require. (#386)\n\n**Bug fixes**\n\n* Fixed tags getting added when using clean or linkify. This was a\n  long-standing regression from the Bleach 2.0 rewrite. (#280, #392)\n\n* Fixed ``<isindex>`` getting replaced with a string. Now it gets escaped or\n  stripped depending on whether it's in the allowed tags or not. (#279)\n\n\nVersion 2.1.4 (August 16th, 2018)\n---------------------------------\n\n**Security fixes**\n\nNone\n\n**Backwards incompatible changes**\n\n* Dropped support for Python 3.3. (#328)\n\n**Features**\n\nNone\n\n**Bug fixes**\n\n* Handle ambiguous ampersands in correctly. (#359)\n\n\nVersion 2.1.3 (March 5th, 2018)\n-------------------------------\n\n**Security fixes**\n\n* Attributes that have URI values weren't properly sanitized if the\n  values contained character entities. Using character entities, it\n  was possible to construct a URI value with a scheme that was not\n  allowed that would slide through unsanitized.\n\n  This security issue was introduced in Bleach 2.1. Anyone using\n  Bleach 2.1 is highly encouraged to upgrade.\n\n  https://bugzilla.mozilla.org/show_bug.cgi?id=1442745\n\n**Backwards incompatible changes**\n\nNone\n\n**Features**\n\nNone\n\n**Bug fixes**\n\n* Fixed some other edge cases for attribute URI value sanitizing and\n  improved testing of this code.\n\n\nVersion 2.1.2 (December 7th, 2017)\n----------------------------------\n\n**Security fixes**\n\nNone\n\n**Backwards incompatible changes**\n\nNone\n\n**Features**\n\nNone\n\n**Bug fixes**\n\n* Support html5lib-python 1.0.1. (#337)\n\n* Add deprecation warning for supporting html5lib-python < 1.0.\n\n* Switch to semver.\n\n\nVersion 2.1.1 (October 2nd, 2017)\n---------------------------------\n\n**Security fixes**\n\nNone\n\n**Backwards incompatible changes**\n\nNone\n\n**Features**\n\nNone\n\n**Bug fixes**\n\n* Fix ``setup.py`` opening files when ``LANG=``. (#324)\n\n\nVersion 2.1 (September 28th, 2017)\n----------------------------------\n\n**Security fixes**\n\n* Convert control characters (backspace particularly) to \"?\" preventing\n  malicious copy-and-paste situations. (#298)\n\n  See `<https://github.com/mozilla/bleach/issues/298>`_ for more details.\n\n  This affects all previous versions of Bleach. Check the comments on that\n  issue for ways to alleviate the issue if you can't upgrade to Bleach 2.1.\n\n\n**Backwards incompatible changes**\n\n* Redid versioning. ``bleach.VERSION`` is no longer available. Use the string\n  version at ``bleach.__version__`` and parse it with\n  ``pkg_resources.parse_version``. (#307)\n\n* clean, linkify: linkify and clean should only accept text types; thank you,\n  Janusz! (#292)\n\n* clean, linkify: accept only unicode or utf-8-encoded str (#176)\n\n\n**Features**\n\n\n**Bug fixes**\n\n* ``bleach.clean()`` no longer unescapes entities including ones that are missing\n  a ``;`` at the end which can happen in urls and other places. (#143)\n\n* linkify: fix http links inside of mailto links; thank you, sedrubal! (#300)\n\n* clarify security policy in docs (#303)\n\n* fix dependency specification for html5lib 1.0b8, 1.0b9, and 1.0b10; thank you,\n  ZoltÃ¡n! (#268)\n\n* add Bleach vs. html5lib comparison to README; thank you, Stu Cox! (#278)\n\n* fix KeyError exceptions on tags without href attr; thank you, Alex Defsen!\n  (#273)\n\n* add test website and scripts to test ``bleach.clean()`` output in browser;\n  thank you, Greg Guthe!\n\n\nVersion 2.0 (March 8th, 2017)\n-----------------------------\n\n**Security fixes**\n\n* None\n\n\n**Backwards incompatible changes**\n\n* Removed support for Python 2.6. (#206)\n\n* Removed support for Python 3.2. (#224)\n\n* Bleach no longer supports html5lib < 0.99999999 (8 9s).\n\n  This version is a rewrite to use the new sanitizing API since the old\n  one was dropped in html5lib 0.99999999 (8 9s).\n\n  If you're using 0.9999999 (7 9s) upgrade to 0.99999999 (8 9s) or higher.\n\n  If you're using 1.0b8 (equivalent to 0.9999999 (7 9s)), upgrade to 1.0b9\n  (equivalent to 0.99999999 (8 9s)) or higher.\n\n* ``bleach.clean`` and friends were rewritten\n\n  ``clean`` was reimplemented as an html5lib filter and happens at a different\n  step in the HTML parsing -> traversing -> serializing process. Because of\n  that, there are some differences in clean's output as compared with previous\n  versions.\n\n  Amongst other things, this version will add end tags even if the tag in\n  question is to be escaped.\n\n* ``bleach.clean`` and friends attribute callables now take three arguments:\n  tag, attribute name and attribute value. Previously they only took attribute\n  name and attribute value.\n\n  All attribute callables will need to be updated.\n\n* ``bleach.linkify`` was rewritten\n\n  ``linkify`` was reimplemented as an html5lib Filter. As such, it no longer\n  accepts a ``tokenizer`` argument.\n\n  The callback functions for adjusting link attributes now takes a namespaced\n  attribute.\n\n  Previously you'd do something like this::\n\n      def check_protocol(attrs, is_new):\n          if not attrs.get('href', '').startswith('http:', 'https:')):\n              return None\n          return attrs\n\n  Now it's more like this::\n\n      def check_protocol(attrs, is_new):\n          if not attrs.get((None, u'href'), u'').startswith(('http:', 'https:')):\n              #            ^^^^^^^^^^^^^^^\n              return None\n          return attrs\n\n  Further, you need to make sure you're always using unicode values. If you\n  don't then html5lib will raise an assertion error that the value is not\n  unicode.\n\n  All linkify filters will need to be updated.\n\n* ``bleach.linkify`` and friends had a ``skip_pre`` argument--that's been\n  replaced with a more general ``skip_tags`` argument.\n\n  Before, you might do::\n\n      bleach.linkify(some_text, skip_pre=True)\n\n  The equivalent with Bleach 2.0 is::\n\n      bleach.linkify(some_text, skip_tags=['pre'])\n\n  You can skip other tags, too, like ``style`` or ``script`` or other places\n  where you don't want linkification happening.\n\n  All uses of linkify that use ``skip_pre`` will need to be updated.\n\n\n**Changes**\n\n* Supports Python 3.6.\n\n* Supports html5lib >= 0.99999999 (8 9s).\n\n* There's a ``bleach.sanitizer.Cleaner`` class that you can instantiate with your\n  favorite clean settings for easy reuse.\n\n* There's a ``bleach.linkifier.Linker`` class that you can instantiate with your\n  favorite linkify settings for easy reuse.\n\n* There's a ``bleach.linkifier.LinkifyFilter`` which is an htm5lib filter that\n  you can pass as a filter to ``bleach.sanitizer.Cleaner`` allowing you to clean\n  and linkify in one pass.\n\n* ``bleach.clean`` and friends can now take a callable as an attributes arg value.\n\n* Tons of bug fixes.\n\n* Cleaned up tests.\n\n* Documentation fixes.\n\n\nVersion 1.5 (November 4th, 2016)\n--------------------------------\n\n**Security fixes**\n\n* None\n\n**Backwards incompatible changes**\n\n* clean: The list of ``ALLOWED_PROTOCOLS`` now defaults to http, https and\n  mailto.\n\n  Previously it was a long list of protocols something like ed2k, ftp, http,\n  https, irc, mailto, news, gopher, nntp, telnet, webcal, xmpp, callto, feed,\n  urn, aim, rsync, tag, ssh, sftp, rtsp, afs, data. (#149)\n\n**Changes**\n\n* clean: Added ``protocols`` to arguments list to let you override the list of\n  allowed protocols. Thank you, Andreas Malecki! (#149)\n\n* linkify: Fix a bug involving periods at the end of an email address. Thank you,\n  Lorenz Schori! (#219)\n\n* linkify: Fix linkification of non-ascii ports. Thank you Alexandre, Macabies!\n  (#207)\n\n* linkify: Fix linkify inappropriately removing node tails when dropping nodes.\n  (#132)\n\n* Fixed a test that failed periodically. (#161)\n\n* Switched from nose to py.test. (#204)\n\n* Add test matrix for all supported Python and html5lib versions. (#230)\n\n* Limit to html5lib ``>=0.999,!=0.9999,!=0.99999,<0.99999999`` because 0.9999\n  and 0.99999 are busted.\n\n* Add support for ``python setup.py test``. (#97)\n\n\nVersion 1.4.3 (May 23rd, 2016)\n------------------------------\n\n**Security fixes**\n\n* None\n\n**Changes**\n\n* Limit to html5lib ``>=0.999,<0.99999999`` because of impending change to\n  sanitizer api. #195\n\n\nVersion 1.4.2 (September 11, 2015)\n----------------------------------\n\n**Changes**\n\n* linkify: Fix hang in linkify with ``parse_email=True``. (#124)\n\n* linkify: Fix crash in linkify when removing a link that is a first-child. (#136)\n\n* Updated TLDs.\n\n* linkify: Don't remove exterior brackets when linkifying. (#146)\n\n\nVersion 1.4.1 (December 15, 2014)\n---------------------------------\n\n**Changes**\n\n* Consistent order of attributes in output.\n\n* Python 3.4 support.\n\n\nVersion 1.4 (January 12, 2014)\n------------------------------\n\n**Changes**\n\n* linkify: Update linkify to use etree type Treewalker instead of simpletree.\n\n* Updated html5lib to version ``>=0.999``.\n\n* Update all code to be compatible with Python 3 and 2 using six.\n\n* Switch to Apache License.\n\n\nVersion 1.3\n-----------\n\n* Used by Python 3-only fork.\n\n\nVersion 1.2.2 (May 18, 2013)\n----------------------------\n\n* Pin html5lib to version 0.95 for now due to major API break.\n\n\nVersion 1.2.1 (February 19, 2013)\n---------------------------------\n\n* ``clean()`` no longer considers ``feed:`` an acceptable protocol due to\n  inconsistencies in browser behavior.\n\n\nVersion 1.2 (January 28, 2013)\n------------------------------\n\n* ``linkify()`` has changed considerably. Many keyword arguments have been\n  replaced with a single callbacks list. Please see the documentation for more\n  information.\n\n* Bleach will no longer consider unacceptable protocols when linkifying.\n\n* ``linkify()`` now takes a tokenizer argument that allows it to skip\n  sanitization.\n\n* ``delinkify()`` is gone.\n\n* Removed exception handling from ``_render``. ``clean()`` and ``linkify()`` may\n  now throw.\n\n* ``linkify()`` correctly ignores case for protocols and domain names.\n\n* ``linkify()`` correctly handles markup within an <a> tag.\n\n\nVersion 1.1.5\n-------------\n\n\nVersion 1.1.4\n-------------\n\n\nVersion 1.1.3 (July 10, 2012)\n-----------------------------\n\n* Fix parsing bare URLs when parse_email=True.\n\n\nVersion 1.1.2 (June 1, 2012)\n----------------------------\n\n* Fix hang in style attribute sanitizer. (#61)\n\n* Allow ``/`` in style attribute values.\n\n\nVersion 1.1.1 (February 17, 2012)\n---------------------------------\n\n* Fix tokenizer for html5lib 0.9.5.\n\n\nVersion 1.1.0 (October 24, 2011)\n--------------------------------\n\n* ``linkify()`` now understands port numbers. (#38)\n\n* Documented character encoding behavior. (#41)\n\n* Add an optional target argument to ``linkify()``.\n\n* Add ``delinkify()`` method. (#45)\n\n* Support subdomain whitelist for ``delinkify()``. (#47, #48)\n\n\nVersion 1.0.4 (September 2, 2011)\n---------------------------------\n\n* Switch to SemVer git tags.\n\n* Make ``linkify()`` smarter about trailing punctuation. (#30)\n\n* Pass ``exc_info`` to logger during rendering issues.\n\n* Add wildcard key for attributes. (#19)\n\n* Make ``linkify()`` use the ``HTMLSanitizer`` tokenizer. (#36)\n\n* Fix URLs wrapped in parentheses. (#23)\n\n* Make ``linkify()`` UTF-8 safe. (#33)\n\n\nVersion 1.0.3 (June 14, 2011)\n-----------------------------\n\n* ``linkify()`` works with 3rd level domains. (#24)\n\n* ``clean()`` supports vendor prefixes in style values. (#31, #32)\n\n* Fix ``linkify()`` email escaping.\n\n\nVersion 1.0.2 (June 6, 2011)\n----------------------------\n\n* ``linkify()`` supports email addresses.\n\n* ``clean()`` supports callables in attributes filter.\n\n\nVersion 1.0.1 (April 12, 2011)\n------------------------------\n\n* ``linkify()`` doesn't drop trailing slashes. (#21)\n* ``linkify()`` won't linkify 'libgl.so.1'. (#22)\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/mozilla/bleach",
        "maintainer": "Will Kahn-Greene",
        "maintainer_email": "willkg@mozilla.com",
        "license": "Apache Software License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "six >=1.9.0",
          "webencodings",
          "tinycss2 <1.3,>=1.1.0 ; extra == 'css'"
        ],
        "requires_python": ">=3.8",
        "provides_extra": [
          "css"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\bleach-6.1.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "boolean.py",
        "version": "4.0",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "Define boolean algebras, create and parse boolean expressions and create custom boolean DSL.",
        "description": "\n\nThis library helps you deal with boolean expressions and algebra with variables\nand the boolean functions AND, OR, NOT.\n\nYou can parse expressions from strings and simplify and compare expressions.\nYou can also easily create your custom algreba and mini DSL and create custom\ntokenizers to handle custom expressions.\n\nFor extensive documentation look either into the docs directory or view it online, at\nhttps://booleanpy.readthedocs.org/en/latest/\n\nhttps://github.com/bastikr/boolean.py\n\nCopyright (c) 2009-2020 Sebastian Kraemer, basti.kr@gmail.com and others\nSPDX-License-Identifier: BSD-2-Clause\n\n\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "boolean expression",
          "boolean algebra",
          "logic",
          "expression parser"
        ],
        "home_page": "https://github.com/bastikr/boolean.py",
        "author": "Sebastian Kraemer",
        "author_email": "basti.kr@gmail.com",
        "license": "BSD-2-Clause",
        "license_file": [
          "LICENSE.txt",
          "README.rst",
          "CHANGELOG.rst"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Topic :: Scientific/Engineering :: Mathematics",
          "Topic :: Software Development :: Compilers",
          "Topic :: Software Development :: Libraries",
          "Topic :: Utilities"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\boolean.py-4.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "boto3",
        "version": "1.35.21",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "The AWS SDK for Python",
        "description": "===============================\nBoto3 - The AWS SDK for Python\n===============================\n\n|Version| |Python| |License|\n\nBoto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for\nPython, which allows Python developers to write software that makes use\nof services like Amazon S3 and Amazon EC2. You can find the latest, most\nup to date, documentation at our `doc site`_, including a list of\nservices that are supported.\n\nBoto3 is maintained and published by `Amazon Web Services`_.\n\nBoto (pronounced boh-toh) was named after the fresh water dolphin native to the Amazon river. The name was chosen by the author of the original Boto library, Mitch Garnaat, as a reference to the company.\n\nNotices\n-------\n\nOn 2023-12-13, support for Python 3.7 ended for Boto3. This follows the\nPython Software Foundation `end of support <https://peps.python.org/pep-0537/#lifespan>`__\nfor the runtime which occurred on 2023-06-27.\nFor more information, see this `blog post <https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/>`__.\n\n.. _boto: https://docs.pythonboto.org/\n.. _`doc site`: https://boto3.amazonaws.com/v1/documentation/api/latest/index.html\n.. _`Amazon Web Services`: https://aws.amazon.com/what-is-aws/\n.. |Python| image:: https://img.shields.io/pypi/pyversions/boto3.svg?style=flat\n    :target: https://pypi.python.org/pypi/boto3/\n    :alt: Python Versions\n.. |Version| image:: http://img.shields.io/pypi/v/boto3.svg?style=flat\n    :target: https://pypi.python.org/pypi/boto3/\n    :alt: Package Version\n.. |License| image:: http://img.shields.io/pypi/l/boto3.svg?style=flat\n    :target: https://github.com/boto/boto3/blob/develop/LICENSE\n    :alt: License\n\nGetting Started\n---------------\nAssuming that you have a supported version of Python installed, you can first\nset up your environment with:\n\n.. code-block:: sh\n\n    $ python -m venv .venv\n    ...\n    $ . .venv/bin/activate\n\nThen, you can install boto3 from PyPI with:\n\n.. code-block:: sh\n\n    $ python -m pip install boto3\n\nor install from source with:\n\n.. code-block:: sh\n\n    $ git clone https://github.com/boto/boto3.git\n    $ cd boto3\n    $ python -m pip install -r requirements.txt\n    $ python -m pip install -e .\n\n\nUsing Boto3\n~~~~~~~~~~~~~~\nAfter installing boto3\n\nNext, set up credentials (in e.g. ``~/.aws/credentials``):\n\n.. code-block:: ini\n\n    [default]\n    aws_access_key_id = YOUR_KEY\n    aws_secret_access_key = YOUR_SECRET\n\nThen, set up a default region (in e.g. ``~/.aws/config``):\n\n.. code-block:: ini\n\n   [default]\n   region=us-east-1\n\nOther credential configuration methods can be found `here <https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html>`__\n\nThen, from a Python interpreter:\n\n.. code-block:: python\n\n    >>> import boto3\n    >>> s3 = boto3.resource('s3')\n    >>> for bucket in s3.buckets.all():\n            print(bucket.name)\n\nRunning Tests\n~~~~~~~~~~~~~\nYou can run tests in all supported Python versions using ``tox``. By default,\nit will run all of the unit and functional tests, but you can also specify your own\n``pytest`` options. Note that this requires that you have all supported\nversions of Python installed, otherwise you must pass ``-e`` or run the\n``pytest`` command directly:\n\n.. code-block:: sh\n\n    $ tox\n    $ tox -- unit/test_session.py\n    $ tox -e py26,py33 -- integration/\n\nYou can also run individual tests with your default Python version:\n\n.. code-block:: sh\n\n    $ pytest tests/unit\n\n\nGetting Help\n------------\n\nWe use GitHub issues for tracking bugs and feature requests and have limited\nbandwidth to address them. Please use these community resources for getting\nhelp:\n\n* Ask a question on `Stack Overflow <https://stackoverflow.com/>`__ and tag it with `boto3 <https://stackoverflow.com/questions/tagged/boto3>`__\n* Open a support ticket with `AWS Support <https://console.aws.amazon.com/support/home#/>`__\n* If it turns out that you may have found a bug, please `open an issue <https://github.com/boto/boto3/issues/new>`__\n\n\nContributing\n------------\n\nWe value feedback and contributions from our community. Whether it's a bug report, new feature, correction, or additional documentation, we welcome your issues and pull requests. Please read through this `CONTRIBUTING <https://github.com/boto/boto3/blob/develop/CONTRIBUTING.rst>`__ document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your contribution.\n\n\nMaintenance and Support for SDK Major Versions\n----------------------------------------------\n\nBoto3 was made generally available on 06/22/2015 and is currently in the full support phase of the availability life cycle.\n\nFor information about maintenance and support for SDK major versions and their underlying dependencies, see the following in the AWS SDKs and Tools Shared Configuration and Credentials Reference Guide:\n\n* `AWS SDKs and Tools Maintenance Policy <https://docs.aws.amazon.com/sdkref/latest/guide/maint-policy.html>`__\n* `AWS SDKs and Tools Version Support Matrix <https://docs.aws.amazon.com/sdkref/latest/guide/version-support-matrix.html>`__\n\n\nMore Resources\n--------------\n\n* `NOTICE <https://github.com/boto/boto3/blob/develop/NOTICE>`__\n* `Changelog <https://github.com/boto/boto3/blob/develop/CHANGELOG.rst>`__\n* `License <https://github.com/boto/boto3/blob/develop/LICENSE>`__\n\n\n",
        "home_page": "https://github.com/boto/boto3",
        "author": "Amazon Web Services",
        "license": "Apache License 2.0",
        "license_file": [
          "LICENSE",
          "NOTICE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12"
        ],
        "requires_dist": [
          "botocore (<1.36.0,>=1.35.21)",
          "jmespath (<2.0.0,>=0.7.1)",
          "s3transfer (<0.11.0,>=0.10.0)",
          "botocore[crt] (<2.0a0,>=1.21.0) ; extra == 'crt'"
        ],
        "requires_python": ">= 3.8",
        "project_url": [
          "Documentation, https://boto3.amazonaws.com/v1/documentation/api/latest/index.html",
          "Source, https://github.com/boto/boto3"
        ],
        "provides_extra": [
          "crt"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\boto3-1.35.21.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "botocore",
        "version": "1.35.21",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "Low-level, data-driven core of boto 3.",
        "description": "botocore\n========\n\n|Version| |Python| |License|\n\nA low-level interface to a growing number of Amazon Web Services. The\nbotocore package is the foundation for the\n`AWS CLI <https://github.com/aws/aws-cli>`__ as well as\n`boto3 <https://github.com/boto/boto3>`__.\n\nBotocore is maintained and published by `Amazon Web Services`_.\n\nNotices\n-------\n\nOn 2023-12-13, support was dropped for Python 3.7. This follows the\nPython Software Foundation `end of support <https://www.python.org/dev/peps/pep-0537/#lifespan>`__\nfor the runtime which occurred on 2023-06-27.\nFor more information, see this `blog post <https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/>`__.\n\n.. _`Amazon Web Services`: https://aws.amazon.com/what-is-aws/\n.. |Python| image:: https://img.shields.io/pypi/pyversions/botocore.svg?style=flat\n    :target: https://pypi.python.org/pypi/botocore/\n    :alt: Python Versions\n.. |Version| image:: http://img.shields.io/pypi/v/botocore.svg?style=flat\n    :target: https://pypi.python.org/pypi/botocore/\n    :alt: Package Version\n.. |License| image:: http://img.shields.io/pypi/l/botocore.svg?style=flat\n    :target: https://github.com/boto/botocore/blob/develop/LICENSE.txt\n    :alt: License\n\nGetting Started\n---------------\nAssuming that you have Python and ``virtualenv`` installed, set up your environment and install the required dependencies like this or you can install the library using ``pip``:\n\n.. code-block:: sh\n\n    $ git clone https://github.com/boto/botocore.git\n    $ cd botocore\n    $ virtualenv venv\n    ...\n    $ . venv/bin/activate\n    $ pip install -r requirements.txt\n    $ pip install -e .\n\n.. code-block:: sh\n\n    $ pip install botocore\n\nUsing Botocore\n~~~~~~~~~~~~~~\nAfter installing botocore\n\nNext, set up credentials (in e.g. ``~/.aws/credentials``):\n\n.. code-block:: ini\n\n    [default]\n    aws_access_key_id = YOUR_KEY\n    aws_secret_access_key = YOUR_SECRET\n\nThen, set up a default region (in e.g. ``~/.aws/config``):\n\n.. code-block:: ini\n\n   [default]\n   region=us-east-1\n\nOther credentials configuration method can be found `here <https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html>`__\n\nThen, from a Python interpreter:\n\n.. code-block:: python\n\n    >>> import botocore.session\n    >>> session = botocore.session.get_session()\n    >>> client = session.create_client('ec2')\n    >>> print(client.describe_instances())\n\n\nGetting Help\n------------\n\nWe use GitHub issues for tracking bugs and feature requests and have limited\nbandwidth to address them. Please use these community resources for getting\nhelp. Please note many of the same resources available for ``boto3`` are\napplicable for ``botocore``:\n\n* Ask a question on `Stack Overflow <https://stackoverflow.com/>`__ and tag it with `boto3 <https://stackoverflow.com/questions/tagged/boto3>`__\n* Open a support ticket with `AWS Support <https://console.aws.amazon.com/support/home#/>`__\n* If it turns out that you may have found a bug, please `open an issue <https://github.com/boto/botocore/issues/new/choose>`__\n\n\nContributing\n------------\n\nWe value feedback and contributions from our community. Whether it's a bug report, new feature, correction, or additional documentation, we welcome your issues and pull requests. Please read through this `CONTRIBUTING <https://github.com/boto/botocore/blob/develop/CONTRIBUTING.rst>`__ document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your contribution.\n\n\nMaintenance and Support for SDK Major Versions\n----------------------------------------------\n\nBotocore was made generally available on 06/22/2015 and is currently in the full support phase of the availability life cycle.\n\nFor information about maintenance and support for SDK major versions and their underlying dependencies, see the following in the AWS SDKs and Tools Reference Guide:\n\n* `AWS SDKs and Tools Maintenance Policy <https://docs.aws.amazon.com/sdkref/latest/guide/maint-policy.html>`__\n* `AWS SDKs and Tools Version Support Matrix <https://docs.aws.amazon.com/sdkref/latest/guide/version-support-matrix.html>`__\n\n\nMore Resources\n--------------\n\n* `NOTICE <https://github.com/boto/botocore/blob/develop/NOTICE>`__\n* `Changelog <https://github.com/boto/botocore/blob/develop/CHANGELOG.rst>`__\n* `License <https://github.com/boto/botocore/blob/develop/LICENSE.txt>`__\n\n\n",
        "home_page": "https://github.com/boto/botocore",
        "author": "Amazon Web Services",
        "license": "Apache License 2.0",
        "license_file": [
          "LICENSE.txt",
          "NOTICE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: System Administrators",
          "Natural Language :: English",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12"
        ],
        "requires_dist": [
          "jmespath (<2.0.0,>=0.7.1)",
          "python-dateutil (<3.0.0,>=2.1)",
          "urllib3 (<1.27,>=1.25.4) ; python_version < \"3.10\"",
          "urllib3 (!=2.2.0,<3,>=1.25.4) ; python_version >= \"3.10\"",
          "awscrt (==0.21.5) ; extra == 'crt'"
        ],
        "requires_python": ">= 3.8",
        "provides_extra": [
          "crt"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\botocore-1.35.21.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "build",
        "version": "1.2.1",
        "summary": "A simple, correct Python build frontend",
        "description": "# build\n\n[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/pypa/build/main.svg)](https://results.pre-commit.ci/latest/github/pypa/build/main)\n[![CI test](https://github.com/pypa/build/actions/workflows/test.yml/badge.svg)](https://github.com/pypa/build/actions/workflows/test.yml)\n[![codecov](https://codecov.io/gh/pypa/build/branch/main/graph/badge.svg)](https://codecov.io/gh/pypa/build)\n\n[![Documentation Status](https://readthedocs.org/projects/pypa-build/badge/?version=latest)](https://build.pypa.io/en/latest/?badge=latest)\n[![PyPI version](https://badge.fury.io/py/build.svg)](https://pypi.org/project/build/)\n[![Discord](https://img.shields.io/discord/803025117553754132?label=Discord%20chat%20%23build)](https://discord.gg/pypa)\n\nA simple, correct Python build frontend.\n\nSee the [documentation](https://build.pypa.io) for more information.\n\n### Installation\n\n`build` can be installed via `pip` or an equivalent via:\n\n```console\n$ pip install build\n```\n\n### Usage\n\n```console\n$ python -m build\n```\n\nThis will build the package in an isolated environment, generating a\nsource-distribution and wheel in the directory `dist/`.\nSee the [documentation](https://build.pypa.io) for full information.\n\n### Code of Conduct\n\nEveryone interacting in the build's codebase, issue trackers, chat rooms, and mailing lists is expected to follow\nthe [PSF Code of Conduct].\n\n[psf code of conduct]: https://github.com/pypa/.github/blob/main/CODE_OF_CONDUCT.md\n\n",
        "description_content_type": "text/markdown",
        "author_email": "Filipe LaÃ­ns <lains@riseup.net>, BernÃ¡t GÃ¡bor <gaborjbernat@gmail.com>, layday <layday@protonmail.com>, Henry Schreiner <henryschreineriii@gmail.com>",
        "classifier": [
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_dist": [
          "packaging >= 19.1",
          "pyproject_hooks",
          "colorama; os_name == \"nt\"",
          "importlib-metadata >= 4.6; python_full_version < \"3.10.2\"",
          "tomli >= 1.1.0; python_version < \"3.11\"",
          "furo >= 2023.08.17 ; extra == \"docs\"",
          "sphinx ~= 7.0 ; extra == \"docs\"",
          "sphinx-argparse-cli >= 1.5 ; extra == \"docs\"",
          "sphinx-autodoc-typehints >= 1.10 ; extra == \"docs\"",
          "sphinx-issues >= 3.0.0 ; extra == \"docs\"",
          "build[uv, virtualenv] ; extra == \"test\"",
          "filelock >= 3 ; extra == \"test\"",
          "pytest >= 6.2.4 ; extra == \"test\"",
          "pytest-cov >= 2.12 ; extra == \"test\"",
          "pytest-mock >= 2 ; extra == \"test\"",
          "pytest-rerunfailures >= 9.1 ; extra == \"test\"",
          "pytest-xdist >= 1.34 ; extra == \"test\"",
          "wheel >= 0.36.0 ; extra == \"test\"",
          "setuptools >= 42.0.0 ; extra == \"test\" and ( python_version < \"3.10\")",
          "setuptools >= 56.0.0 ; extra == \"test\" and ( python_version == \"3.10\")",
          "setuptools >= 56.0.0 ; extra == \"test\" and ( python_version == \"3.11\")",
          "setuptools >= 67.8.0 ; extra == \"test\" and ( python_version >= \"3.12\")",
          "build[uv] ; extra == \"typing\"",
          "importlib-metadata >= 5.1 ; extra == \"typing\"",
          "mypy ~= 1.9.0 ; extra == \"typing\"",
          "tomli ; extra == \"typing\"",
          "typing-extensions >= 3.7.4.3 ; extra == \"typing\"",
          "uv >= 0.1.18 ; extra == \"uv\"",
          "virtualenv >= 20.0.35 ; extra == \"virtualenv\""
        ],
        "requires_python": ">= 3.8",
        "project_url": [
          "changelog, https://build.pypa.io/en/stable/changelog.html",
          "homepage, https://build.pypa.io",
          "issues, https://github.com/pypa/build/issues",
          "source, https://github.com/pypa/build"
        ],
        "provides_extra": [
          "docs",
          "test",
          "typing",
          "uv",
          "virtualenv"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\build-1.2.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "capycli",
        "version": "2.5.0",
        "summary": "CaPyCli - Clearing Automation Python Command Line Interface for SW360",
        "description": "<!--\n# SPDX-FileCopyrightText: (c) 2018-2024 Siemens\n# SPDX-License-Identifier: MIT\n-->\n\n![Header_Image](images/Github-social-capycli.png)\n\n# CaPyCli - Clearing Automation Python Command Line Tool for SW360\n\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/sw360/capycli/blob/main/License.md)\n[![PyPI](https://shields.io/pypi/v/capycli)](https://pypi.org/project/capycli/)\n[![Python Version](https://img.shields.io/badge/python-3.8%2C3.9%2C3.10%2C3.11-yellow?logo=python)](https://www.python.org/doc/versions/)\n[![Static Checks](https://github.com/sw360/capycli/actions/workflows/static-checks.yml/badge.svg)](https://github.com/sw360/capycli/actions/workflows/static-checks.yml)\n[![Unit Tests](https://github.com/sw360/capycli/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/sw360/capycli/actions/workflows/unit-tests.yml)\n[![Coverage](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/tngraf/c8f15831ecdcf6e86ab2b69cbb2d4f89/raw/df1a91c074c5ee34dc1f0dcf82bc0e76e39b5b4e/capycli-cobertura-coverage.json&color=green)](https://github.com/sw360/capycli/actions/workflows/unit-tests.yml)\n[![SBOM](https://img.shields.io/badge/SBOM-CycloneDX-brightgreen)](https://github.com/tngraf/Tethys.Dgml/blob/master/SBOM/sbom.cyclonedx.xml)\n[![REUSE status](https://api.reuse.software/badge/git.fsfe.org/reuse/api)](https://api.reuse.software/info/git.fsfe.org/reuse/api)\n\nPython 3 scripts to allow license clearing automation using the\n[SW360](https://github.com/eclipse/sw360) software catalogue.\n\n## What is SW360?\n\n[SW360](https://github.com/eclipse/sw360) is a software component catalogue application designed to\nprovide a central place for sharing information about software components used by an organization.\nIt is designed to neatly integrate into existing infrastructures related to the management of\nsoftware artifacts and projects by providing separate backend services for distinct tasks and a set\nof portlets to access these services. A complete deployment unit exists (vagrant box or docker\ncontainer) that contains a complete configuration of all services and portlets.\n\nCompanies like Cariad, Siemens or Toshiba use SW360 to track their use of third party software components.\n\n## Why CaPyCli?\n\nSW360 is for software developers and software developers love to automate tasks. The SW360 user\ninterface is nice if you want to check a project or search for a single component. But if you have\na project with a JavaScript frontend and hundreds of components, you do not want to add all of them\nmanually. You want to be able to determine your software bill of materials (SBOM) and you want to\nmap this SBOM to the information that is already available of SW360.\n\nCaPyCli allows you to\n\n* determine your list of dependencies, your software bill of materials (SBOM)\n* determine meta-data for the SBOM items and download source files\n* map an SBOM to the data available on SW360\n* create all missing components and releases\n* create a project that contains all releases of your SBOM\n* track the progress on license compliance checks\n* show information about the project and its releases\n* show information about export control information and security vulnerabilities (if tracked via SW360)\n\n## Basic Syntax\n\n```code\nCaPyCli command [sub-command...] [options]\n\nCommands and Sub-Commands\n    getdependencies     dependency detection specific commands\n        Nuget             determine dependencies for a .Net/Nuget project\n        Python            determine dependencies for a Python project\n        Javascript        determine dependencies for a JavaScript project\n        MavenPom          determine dependencies for a Java/Maven project using the pom.xml file\n        MavenList         determine dependencies for a Java/Maven project using a Maven command\n\n    bom                 bill of material (SBOM) specific commands\n        Show              display contents of a SBOM\n        Convert           convert SBOM formats\n        Filter            apply filter file to a SBOM\n        Check             check that all releases in the SBOM exist on target SW360 instance\n        CheckItemStatus   show additional information about SBOM items on SW360\n        Map               map a given SBOM to data on SW360\n        CreateReleases    create new releases for existing components on SW360\n        CreateComponents  create new components and releases on SW360 (use with care!)\n        DownloadSources   download source files from the URL specified in the SBOM\n        Granularity       check a bill of material for potential component granularity issues\n        Diff              compare two bills of material.\n        Merge             merge two bills of material.\n        Findsources       determine the source code for SBOM items.\n\n    mapping\n        ToHtml            create a HTML page showing the mapping result\n        ToXlsx            create an Excel sheet showing the mapping result\n\n    moverview\n        ToHtml            create a HTML page showing the mapping result overview\n        ToXlsx            create an Excel sheet showing the mapping result overview\n\n    project\n        Find              find a project by name\n        Prerequisites     checks whether all prerequisites for a successful\n                          software clearing are fulfilled\n        Show              show project details\n        Licenses          show licenses of all cleared compponents\n        Create            create or update a project on SW360\n        Update            update an exiting project, preserving linked releases\n        GetLicenseInfo    get license info of all project components\n        CreateReadme      create a Readme_OSS\n        Vulnerabilities   show security vulnerabilities of a project\n        ECC               Show export control status of a project\n\nOptions:\n  command                                           command and subcommand to process\n  -h, --help                                        show a help message and exit\n  -i INPUTFILE, --inputfile INPUTFILE               input file to read from\n  -ri RAW_INPUT, --raw-input RAW_INPUT              raw data input file to parse repository urls\n  -o OUTPUTFILE, --outputfile OUTPUTFILE            output file to write to\n  -filterfile FILTERFILE                            filter file to use\n  -v VERBOSE                                        be verbose\n  -t SW360_TOKEN, --token SW360_TOKEN               use this token for access to SW360\n  -oa, --oauth2                                     this is an oauth2 token\n  -url SW360_URL                                    use this URL for access to SW360\n  --nocache NOCACHE                                 do not use component cache\n  -cf CACHEFILE, --cachefile CACHEFILE              cache file name to use\n  -rc REFRESH_CACHE, --refresh_cache REFRESH_CACHE  refresh component cache\n  -sc, --similar                                    look for components with similar name\n  -ov CREATE_OVERVIEW, --overview CREATE_OVERVIEW   create an mapping overview JSON file\n  -mr WRITE_MAPRESULT, --mapresult WRITE_MAPRESULT  create a JSON file with the mapping details\n  -name                                             name of the project\n  -version                                          version of the project\n  -id ID                                            SW360 id of the project, supersedes name and \n                                                    version parameters\n  -ncli NCLI, --no-overwrite-cli NCLI               do not overwrite existing CLI files\n  -nconf NCONF, --no-overwrite-config NCONF         do not overwrite an existing configuration file\n  -dest DESTINATION, --destination DESTINATION      the destination folder\n  -source SOURCE                                    source folder or additional source file\n  --dbx DBX                                         relaxed handling of debian version numbers\n  --download                                        enable automatic download of missing sources\n  --search-meta-data SEARCH_META_DATA               search for component meta-data\n  -old-version OLD_VERSION                          previous version\n  -ex                                               show exit code\n  -rr RESULT_REQUIRED                               there must be a clearing result available\n  -xml XML                                          use XML format\n  -package-source PACKAGE_SOURCE                    URL of the package manager to use\n  -all                                              show/use all items\n  -format FORMAT                                    format to use (text, json, xml)\n  -fe FORCE_EXIT, --forceexit FORCE_EXIT            force a specific exit code\n  -m MODE, --mode MODE                              specific mode for some commands\n  -if INPUTFORMAT                                   Specify input file format\n  -of OUTPUTFORMAT                                  Specify output file format\n  -X DEBUG                                          Enable debug output\n  --forceerror FORCE_ERROR                          force an error exit code in case of visual errors\n```\n\n## Use Cases\n\nOver the time we implemented more and more commands with more and more parameters.  \nWe understand that it is hard for beginners to find the right command for the task\nthey want to do. Have a look at our [Use Case Overview](UseCaseOverview.md).\n\n## Software Clearing Approaches\n\nFrom time to time there are questions **why** a command has been implemented in this\nspecific way or why a command exists at all. Not all organization have the same\napproach when doing license compliance. Have a look at our\n[Software Clearing Approach Overview](SoftwareClearingApproachOverview.md) to see our\napproaches.\n\n## Note about Python Dependency Detection\n\nAt the moment there is only support for dependencies defined in a `requirements.txt` file.  \nPoetry users can create the `requirements.txt` file via\n\n```sh\npoetry export --format requirements.txt -o requirements.txt --without-hashes\n```\n\nIf you are using pipenv, you can create the `requirements.txt` file via\n\n```sh\npipenv lock -r > requirements.txt\n```\n\nIf your dependencies are defined in `setup.py` you may take a look at\nhttps://dephell.readthedocs.io/cmd-deps-convert.html or\nhttps://github.com/jazzband/pip-tools#example-usage-for-pip-compile to generate\na `requirements.txt` file.\n\nProbably the best solution is if you enhance CaPyCli to support poetry, pipenv or setup.py\ndirectly and open a merge request.\n\n## Examples\n\n### Find project by name\n\nCommand:\n\n```sh\ncapycli project find -name \"tr-card\"\n- or -\npython -m capycli project find -name tr-card\n```\n\nResult\n\n```sh\nCaPyCli - Find a project by name\n\n  Searching for projects by name\n    TR-Card, 1.0 => ID = ff697cd18fe178b26fc601b60e00fcdf\n```\n\nMore examples and usage notes can be found in [examples.md](examples.md).\n\n## Prerequisites\n\n* Python 3\n* A SW360 read (and write) token, see next section.\n\n## API Access\n\nAccess to the SW360 REST API requires an access token.\nThe token can be requested on SW360/Preferences/REST API Token.\n\nThe scripts in this repository expect, that a valid token\nis stored in the environment variable ``SW360ProductionToken``.\nAlternatively you can specify a token using the `-t` option.\n\nFor proper access to an SW360 instance the correct url must be own.\nThe SW360 url can be specified on the commandline with the `-url`\nparameter, via the environment variable ``SW360ServerUrl`` or in the\nconfig file (`.capycli.cfg`).\n\n## SBOM Format\n\nThe software bill of materials (SBOM) is a crucial information for most operations.\nThere is no common description what a bill of materials should contain.\nThere are different formats available, for example the SBOM of CyCloneDX,\nnevertheless most tools have their own SBOM format.\nWe have decided also to have our own flavor of CycloneDX, see [SBOM](Readme_BOM.md),\nfocused on the information we need to handle components, releases and projects\non SW360. It is a simple JSON format. CaPyCli reads or writes exactly the\ninformation that is needed.\nConversion support from or to our SBOM format is available.\nFor converting CycloneDX (XML) to JSON or for converting SPDX SBOMs, we like\nto refer you to the open source tools from [CycloneDX](https://cyclonedx.org/).\n\n## Mapping a SBOM to SW360\n\nSBOM mapping is described in an extra file, see [SBOM Mapping](Readme_Mapping.md).\n\n## Project Management\n\nThis is a Python project managed using ```Poetry```.\n\n## Installation\n\n### From PyPi\n\n* using `pip`:\n\n  ```shell\n  pip install capycli\n  ```\n\n## Copyright & License\n\nCopyright 2018-2024 Siemens\n\nThis program and the accompanying materials are made\navailable under the terms of the MIT License.  \nSPDX-License-Identifier: MIT\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "sw360",
          "cli",
          "automation",
          "license",
          "compliance",
          "clearing"
        ],
        "home_page": "https://github.com/sw360/capycli",
        "author": "Thomas Graf",
        "author_email": "thomas.graf@siemens.com",
        "license": "MIT",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3 :: Only"
        ],
        "requires_dist": [
          "beautifulsoup4 (>=4.11.1,<5.0.0)",
          "chardet (==5.2.0)",
          "cli-support (==2.0.1)",
          "colorama (>=0.4.3,<0.5.0)",
          "cyclonedx-bom (>=3.11.0,<4.0.0)",
          "cyclonedx-python-lib (>3.1.1)",
          "dateparser (>=1.1.8,<2.0.0)",
          "importlib-resources (>=5.12.0,<6.0.0)",
          "openpyxl (>=3.0.3,<4.0.0)",
          "packageurl-python (>0.8,<1.0)",
          "pyjwt (>=1.7.1,<2.0.0)",
          "requests (>=2.31.0,<3.0.0)",
          "requirements-parser (==0.5.0)",
          "semver (==3.0.2)",
          "sw360 (>=1.5.0,<2.0.0)",
          "tomli (>=2.0.1,<3.0.0)",
          "urllib3",
          "wheel (>=0.38.4,<0.39.0)"
        ],
        "requires_python": ">=3.8,<4.0",
        "project_url": [
          "Repository, https://github.com/sw360/capycli",
          "issues, https://github.com/sw360/capycli/issues"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\capycli-2.5.0.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "certifi",
        "version": "2024.7.4",
        "summary": "Python package for providing Mozilla's CA Bundle.",
        "description": "Certifi: Python SSL Certificates\n================================\n\nCertifi provides Mozilla's carefully curated collection of Root Certificates for\nvalidating the trustworthiness of SSL certificates while verifying the identity\nof TLS hosts. It has been extracted from the `Requests`_ project.\n\nInstallation\n------------\n\n``certifi`` is available on PyPI. Simply install it with ``pip``::\n\n    $ pip install certifi\n\nUsage\n-----\n\nTo reference the installed certificate authority (CA) bundle, you can use the\nbuilt-in function::\n\n    >>> import certifi\n\n    >>> certifi.where()\n    '/usr/local/lib/python3.7/site-packages/certifi/cacert.pem'\n\nOr from the command line::\n\n    $ python -m certifi\n    /usr/local/lib/python3.7/site-packages/certifi/cacert.pem\n\nEnjoy!\n\n.. _`Requests`: https://requests.readthedocs.io/en/master/\n\nAddition/Removal of Certificates\n--------------------------------\n\nCertifi does not support any addition/removal or other modification of the\nCA trust store content. This project is intended to provide a reliable and\nhighly portable root of trust to python deployments. Look to upstream projects\nfor methods to use alternate trust.\n",
        "home_page": "https://github.com/certifi/python-certifi",
        "author": "Kenneth Reitz",
        "author_email": "me@kennethreitz.com",
        "license": "MPL-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)",
          "Natural Language :: English",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12"
        ],
        "requires_python": ">=3.6",
        "project_url": [
          "Source, https://github.com/certifi/python-certifi"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\certifi-2024.7.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "chardet",
        "version": "5.2.0",
        "summary": "Universal encoding detector for Python 3",
        "description": "Chardet: The Universal Character Encoding Detector\n--------------------------------------------------\n\n.. image:: https://img.shields.io/travis/chardet/chardet/stable.svg\n   :alt: Build status\n   :target: https://travis-ci.org/chardet/chardet\n\n.. image:: https://img.shields.io/coveralls/chardet/chardet/stable.svg\n   :target: https://coveralls.io/r/chardet/chardet\n\n.. image:: https://img.shields.io/pypi/v/chardet.svg\n   :target: https://warehouse.python.org/project/chardet/\n   :alt: Latest version on PyPI\n\n.. image:: https://img.shields.io/pypi/l/chardet.svg\n   :alt: License\n\n\nDetects\n - ASCII, UTF-8, UTF-16 (2 variants), UTF-32 (4 variants)\n - Big5, GB2312, EUC-TW, HZ-GB-2312, ISO-2022-CN (Traditional and Simplified Chinese)\n - EUC-JP, SHIFT_JIS, CP932, ISO-2022-JP (Japanese)\n - EUC-KR, ISO-2022-KR, Johab (Korean)\n - KOI8-R, MacCyrillic, IBM855, IBM866, ISO-8859-5, windows-1251 (Cyrillic)\n - ISO-8859-5, windows-1251 (Bulgarian)\n - ISO-8859-1, windows-1252, MacRoman (Western European languages)\n - ISO-8859-7, windows-1253 (Greek)\n - ISO-8859-8, windows-1255 (Visual and Logical Hebrew)\n - TIS-620 (Thai)\n\n.. note::\n   Our ISO-8859-2 and windows-1250 (Hungarian) probers have been temporarily\n   disabled until we can retrain the models.\n\nRequires Python 3.7+.\n\nInstallation\n------------\n\nInstall from `PyPI <https://pypi.org/project/chardet/>`_::\n\n    pip install chardet\n\nDocumentation\n-------------\n\nFor users, docs are now available at https://chardet.readthedocs.io/.\n\nCommand-line Tool\n-----------------\n\nchardet comes with a command-line script which reports on the encodings of one\nor more files::\n\n    % chardetect somefile someotherfile\n    somefile: windows-1252 with confidence 0.5\n    someotherfile: ascii with confidence 1.0\n\nAbout\n-----\n\nThis is a continuation of Mark Pilgrim's excellent original chardet port from C, and `Ian Cordasco <https://github.com/sigmavirus24>`_'s\n`charade <https://github.com/sigmavirus24/charade>`_ Python 3-compatible fork.\n\n:maintainer: Dan Blanchard\n",
        "keywords": [
          "encoding",
          "i18n",
          "xml"
        ],
        "home_page": "https://github.com/chardet/chardet",
        "author": "Mark Pilgrim",
        "author_email": "mark@diveintomark.org",
        "maintainer": "Daniel Blanchard",
        "maintainer_email": "dan.blanchard@gmail.com",
        "license": "LGPL",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: GNU Lesser General Public License v2 or later (LGPLv2+)",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Text Processing :: Linguistic"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Documentation, https://chardet.readthedocs.io/",
          "GitHub Project, https://github.com/chardet/chardet",
          "Issue Tracker, https://github.com/chardet/chardet/issues"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\chardet-5.2.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "charset-normalizer",
        "version": "3.3.2",
        "summary": "The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet.",
        "description": "<h1 align=\"center\">Charset Detection, for Everyone ðŸ‘‹</h1>\n\n<p align=\"center\">\n  <sup>The Real First Universal Charset Detector</sup><br>\n  <a href=\"https://pypi.org/project/charset-normalizer\">\n    <img src=\"https://img.shields.io/pypi/pyversions/charset_normalizer.svg?orange=blue\" />\n  </a>\n  <a href=\"https://pepy.tech/project/charset-normalizer/\">\n    <img alt=\"Download Count Total\" src=\"https://static.pepy.tech/badge/charset-normalizer/month\" />\n  </a>\n  <a href=\"https://bestpractices.coreinfrastructure.org/projects/7297\">\n    <img src=\"https://bestpractices.coreinfrastructure.org/projects/7297/badge\">\n  </a>\n</p>\n<p align=\"center\">\n  <sup><i>Featured Packages</i></sup><br>\n  <a href=\"https://github.com/jawah/niquests\">\n   <img alt=\"Static Badge\" src=\"https://img.shields.io/badge/Niquests-HTTP_1.1%2C%202%2C_and_3_Client-cyan\">\n  </a>\n  <a href=\"https://github.com/jawah/wassima\">\n   <img alt=\"Static Badge\" src=\"https://img.shields.io/badge/Wassima-Certifi_Killer-cyan\">\n  </a>\n</p>\n<p align=\"center\">\n  <sup><i>In other language (unofficial port - by the community)</i></sup><br>\n  <a href=\"https://github.com/nickspring/charset-normalizer-rs\">\n   <img alt=\"Static Badge\" src=\"https://img.shields.io/badge/Rust-red\">\n  </a>\n</p>\n\n> A library that helps you read text from an unknown charset encoding.<br /> Motivated by `chardet`,\n> I'm trying to resolve the issue by taking a new approach.\n> All IANA character set names for which the Python core library provides codecs are supported.\n\n<p align=\"center\">\n  >>>>> <a href=\"https://charsetnormalizerweb.ousret.now.sh\" target=\"_blank\">ðŸ‘‰ Try Me Online Now, Then Adopt Me ðŸ‘ˆ </a> <<<<<\n</p>\n\nThis project offers you an alternative to **Universal Charset Encoding Detector**, also known as **Chardet**.\n\n| Feature                                          | [Chardet](https://github.com/chardet/chardet) |                                         Charset Normalizer                                         | [cChardet](https://github.com/PyYoshi/cChardet) |\n|--------------------------------------------------|:---------------------------------------------:|:--------------------------------------------------------------------------------------------------:|:-----------------------------------------------:|\n| `Fast`                                           |                       âŒ                       |                                                 âœ…                                                  |                        âœ…                        |\n| `Universal**`                                    |                       âŒ                       |                                                 âœ…                                                  |                        âŒ                        |\n| `Reliable` **without** distinguishable standards |                       âŒ                       |                                                 âœ…                                                  |                        âœ…                        |\n| `Reliable` **with** distinguishable standards    |                       âœ…                       |                                                 âœ…                                                  |                        âœ…                        |\n| `License`                                        |           LGPL-2.1<br>_restrictive_           |                                                MIT                                                 |            MPL-1.1<br>_restrictive_             |\n| `Native Python`                                  |                       âœ…                       |                                                 âœ…                                                  |                        âŒ                        |\n| `Detect spoken language`                         |                       âŒ                       |                                                 âœ…                                                  |                       N/A                       |\n| `UnicodeDecodeError Safety`                      |                       âŒ                       |                                                 âœ…                                                  |                        âŒ                        |\n| `Whl Size (min)`                                 |                   193.6 kB                    |                                               42 kB                                                |                     ~200 kB                     |\n| `Supported Encoding`                             |                      33                       | ðŸŽ‰ [99](https://charset-normalizer.readthedocs.io/en/latest/user/support.html#supported-encodings) |                       40                        |\n\n<p align=\"center\">\n<img src=\"https://i.imgflip.com/373iay.gif\" alt=\"Reading Normalized Text\" width=\"226\"/><img src=\"https://media.tenor.com/images/c0180f70732a18b4965448d33adba3d0/tenor.gif\" alt=\"Cat Reading Text\" width=\"200\"/>\n</p>\n\n*\\*\\* : They are clearly using specific code for a specific encoding even if covering most of used one*<br> \nDid you got there because of the logs? See [https://charset-normalizer.readthedocs.io/en/latest/user/miscellaneous.html](https://charset-normalizer.readthedocs.io/en/latest/user/miscellaneous.html)\n\n## âš¡ Performance\n\nThis package offer better performance than its counterpart Chardet. Here are some numbers.\n\n| Package                                       | Accuracy | Mean per file (ms) | File per sec (est) |\n|-----------------------------------------------|:--------:|:------------------:|:------------------:|\n| [chardet](https://github.com/chardet/chardet) |   86 %   |       200 ms       |     5 file/sec     |\n| charset-normalizer                            | **98 %** |     **10 ms**      |    100 file/sec    |\n\n| Package                                       | 99th percentile | 95th percentile | 50th percentile |\n|-----------------------------------------------|:---------------:|:---------------:|:---------------:|\n| [chardet](https://github.com/chardet/chardet) |     1200 ms     |     287 ms      |      23 ms      |\n| charset-normalizer                            |     100 ms      |      50 ms      |      5 ms       |\n\nChardet's performance on larger file (1MB+) are very poor. Expect huge difference on large payload.\n\n> Stats are generated using 400+ files using default parameters. More details on used files, see GHA workflows.\n> And yes, these results might change at any time. The dataset can be updated to include more files.\n> The actual delays heavily depends on your CPU capabilities. The factors should remain the same.\n> Keep in mind that the stats are generous and that Chardet accuracy vs our is measured using Chardet initial capability\n> (eg. Supported Encoding) Challenge-them if you want.\n\n## âœ¨ Installation\n\nUsing pip:\n\n```sh\npip install charset-normalizer -U\n```\n\n## ðŸš€ Basic Usage\n\n### CLI\nThis package comes with a CLI.\n\n```\nusage: normalizer [-h] [-v] [-a] [-n] [-m] [-r] [-f] [-t THRESHOLD]\n                  file [file ...]\n\nThe Real First Universal Charset Detector. Discover originating encoding used\non text file. Normalize text to unicode.\n\npositional arguments:\n  files                 File(s) to be analysed\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --verbose         Display complementary information about file if any.\n                        Stdout will contain logs about the detection process.\n  -a, --with-alternative\n                        Output complementary possibilities if any. Top-level\n                        JSON WILL be a list.\n  -n, --normalize       Permit to normalize input file. If not set, program\n                        does not write anything.\n  -m, --minimal         Only output the charset detected to STDOUT. Disabling\n                        JSON output.\n  -r, --replace         Replace file when trying to normalize it instead of\n                        creating a new one.\n  -f, --force           Replace file without asking if you are sure, use this\n                        flag with caution.\n  -t THRESHOLD, --threshold THRESHOLD\n                        Define a custom maximum amount of chaos allowed in\n                        decoded content. 0. <= chaos <= 1.\n  --version             Show version information and exit.\n```\n\n```bash\nnormalizer ./data/sample.1.fr.srt\n```\n\nor\n\n```bash\npython -m charset_normalizer ./data/sample.1.fr.srt\n```\n\nðŸŽ‰ Since version 1.4.0 the CLI produce easily usable stdout result in JSON format.\n\n```json\n{\n    \"path\": \"/home/default/projects/charset_normalizer/data/sample.1.fr.srt\",\n    \"encoding\": \"cp1252\",\n    \"encoding_aliases\": [\n        \"1252\",\n        \"windows_1252\"\n    ],\n    \"alternative_encodings\": [\n        \"cp1254\",\n        \"cp1256\",\n        \"cp1258\",\n        \"iso8859_14\",\n        \"iso8859_15\",\n        \"iso8859_16\",\n        \"iso8859_3\",\n        \"iso8859_9\",\n        \"latin_1\",\n        \"mbcs\"\n    ],\n    \"language\": \"French\",\n    \"alphabets\": [\n        \"Basic Latin\",\n        \"Latin-1 Supplement\"\n    ],\n    \"has_sig_or_bom\": false,\n    \"chaos\": 0.149,\n    \"coherence\": 97.152,\n    \"unicode_path\": null,\n    \"is_preferred\": true\n}\n```\n\n### Python\n*Just print out normalized text*\n```python\nfrom charset_normalizer import from_path\n\nresults = from_path('./my_subtitle.srt')\n\nprint(str(results.best()))\n```\n\n*Upgrade your code without effort*\n```python\nfrom charset_normalizer import detect\n```\n\nThe above code will behave the same as **chardet**. We ensure that we offer the best (reasonable) BC result possible.\n\nSee the docs for advanced usage : [readthedocs.io](https://charset-normalizer.readthedocs.io/en/latest/)\n\n## ðŸ˜‡ Why\n\nWhen I started using Chardet, I noticed that it was not suited to my expectations, and I wanted to propose a\nreliable alternative using a completely different method. Also! I never back down on a good challenge!\n\nI **don't care** about the **originating charset** encoding, because **two different tables** can\nproduce **two identical rendered string.**\nWhat I want is to get readable text, the best I can. \n\nIn a way, **I'm brute forcing text decoding.** How cool is that ? ðŸ˜Ž\n\nDon't confuse package **ftfy** with charset-normalizer or chardet. ftfy goal is to repair unicode string whereas charset-normalizer to convert raw file in unknown encoding to unicode.\n\n## ðŸ° How\n\n  - Discard all charset encoding table that could not fit the binary content.\n  - Measure noise, or the mess once opened (by chunks) with a corresponding charset encoding.\n  - Extract matches with the lowest mess detected.\n  - Additionally, we measure coherence / probe for a language.\n\n**Wait a minute**, what is noise/mess and coherence according to **YOU ?**\n\n*Noise :* I opened hundred of text files, **written by humans**, with the wrong encoding table. **I observed**, then\n**I established** some ground rules about **what is obvious** when **it seems like** a mess.\n I know that my interpretation of what is noise is probably incomplete, feel free to contribute in order to\n improve or rewrite it.\n\n*Coherence :* For each language there is on earth, we have computed ranked letter appearance occurrences (the best we can). So I thought\nthat intel is worth something here. So I use those records against decoded text to check if I can detect intelligent design.\n\n## âš¡ Known limitations\n\n  - Language detection is unreliable when text contains two or more languages sharing identical letters. (eg. HTML (english tags) + Turkish content (Sharing Latin characters))\n  - Every charset detector heavily depends on sufficient content. In common cases, do not bother run detection on very tiny content.\n\n## âš ï¸ About Python EOLs\n\n**If you are running:**\n\n- Python >=2.7,<3.5: Unsupported\n- Python 3.5: charset-normalizer < 2.1\n- Python 3.6: charset-normalizer < 3.1\n- Python 3.7: charset-normalizer < 4.0\n\nUpgrade your Python interpreter as soon as possible.\n\n## ðŸ‘¤ Contributing\n\nContributions, issues and feature requests are very much welcome.<br />\nFeel free to check [issues page](https://github.com/ousret/charset_normalizer/issues) if you want to contribute.\n\n## ðŸ“ License\n\nCopyright Â© [Ahmed TAHRI @Ousret](https://github.com/Ousret).<br />\nThis project is [MIT](https://github.com/Ousret/charset_normalizer/blob/master/LICENSE) licensed.\n\nCharacters frequencies used in this project Â© 2012 [Denny VrandeÄiÄ‡](http://simia.net/letters/)\n\n## ðŸ’¼ For Enterprise\n\nProfessional support for charset-normalizer is available as part of the [Tidelift\nSubscription][1]. Tidelift gives software development teams a single source for\npurchasing and maintaining their software, with professional grade assurances\nfrom the experts who know it best, while seamlessly integrating with existing\ntools.\n\n[1]: https://tidelift.com/subscription/pkg/pypi-charset-normalizer?utm_source=pypi-charset-normalizer&utm_medium=readme\n\n# Changelog\nAll notable changes to charset-normalizer will be documented in this file. This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/).\n\n## [3.3.2](https://github.com/Ousret/charset_normalizer/compare/3.3.1...3.3.2) (2023-10-31)\n\n### Fixed\n- Unintentional memory usage regression when using large payload that match several encoding (#376)\n- Regression on some detection case showcased in the documentation (#371)\n\n### Added\n- Noise (md) probe that identify malformed arabic representation due to the presence of letters in isolated form (credit to my wife)\n\n## [3.3.1](https://github.com/Ousret/charset_normalizer/compare/3.3.0...3.3.1) (2023-10-22)\n\n### Changed\n- Optional mypyc compilation upgraded to version 1.6.1 for Python >= 3.8\n- Improved the general detection reliability based on reports from the community\n\n## [3.3.0](https://github.com/Ousret/charset_normalizer/compare/3.2.0...3.3.0) (2023-09-30)\n\n### Added\n- Allow to execute the CLI (e.g. normalizer) through `python -m charset_normalizer.cli` or `python -m charset_normalizer`\n- Support for 9 forgotten encoding that are supported by Python but unlisted in `encoding.aliases` as they have no alias (#323)\n\n### Removed\n- (internal) Redundant utils.is_ascii function and unused function is_private_use_only\n- (internal) charset_normalizer.assets is moved inside charset_normalizer.constant\n\n### Changed\n- (internal) Unicode code blocks in constants are updated using the latest v15.0.0 definition to improve detection\n- Optional mypyc compilation upgraded to version 1.5.1 for Python >= 3.8\n\n### Fixed\n- Unable to properly sort CharsetMatch when both chaos/noise and coherence were close due to an unreachable condition in \\_\\_lt\\_\\_ (#350)\n\n## [3.2.0](https://github.com/Ousret/charset_normalizer/compare/3.1.0...3.2.0) (2023-06-07)\n\n### Changed\n- Typehint for function `from_path` no longer enforce `PathLike` as its first argument\n- Minor improvement over the global detection reliability\n\n### Added\n- Introduce function `is_binary` that relies on main capabilities, and optimized to detect binaries\n- Propagate `enable_fallback` argument throughout `from_bytes`, `from_path`, and `from_fp` that allow a deeper control over the detection (default True)\n- Explicit support for Python 3.12\n\n### Fixed\n- Edge case detection failure where a file would contain 'very-long' camel cased word (Issue #289)\n\n## [3.1.0](https://github.com/Ousret/charset_normalizer/compare/3.0.1...3.1.0) (2023-03-06)\n\n### Added\n- Argument `should_rename_legacy` for legacy function `detect` and disregard any new arguments without errors (PR #262)\n\n### Removed\n- Support for Python 3.6 (PR #260)\n\n### Changed\n- Optional speedup provided by mypy/c 1.0.1\n\n## [3.0.1](https://github.com/Ousret/charset_normalizer/compare/3.0.0...3.0.1) (2022-11-18)\n\n### Fixed\n- Multi-bytes cutter/chunk generator did not always cut correctly (PR #233)\n\n### Changed\n- Speedup provided by mypy/c 0.990 on Python >= 3.7\n\n## [3.0.0](https://github.com/Ousret/charset_normalizer/compare/2.1.1...3.0.0) (2022-10-20)\n\n### Added\n- Extend the capability of explain=True when cp_isolation contains at most two entries (min one), will log in details of the Mess-detector results\n- Support for alternative language frequency set in charset_normalizer.assets.FREQUENCIES\n- Add parameter `language_threshold` in `from_bytes`, `from_path` and `from_fp` to adjust the minimum expected coherence ratio\n- `normalizer --version` now specify if current version provide extra speedup (meaning mypyc compilation whl)\n\n### Changed\n- Build with static metadata using 'build' frontend\n- Make the language detection stricter\n- Optional: Module `md.py` can be compiled using Mypyc to provide an extra speedup up to 4x faster than v2.1\n\n### Fixed\n- CLI with opt --normalize fail when using full path for files\n- TooManyAccentuatedPlugin induce false positive on the mess detection when too few alpha character have been fed to it\n- Sphinx warnings when generating the documentation\n\n### Removed\n- Coherence detector no longer return 'Simple English' instead return 'English'\n- Coherence detector no longer return 'Classical Chinese' instead return 'Chinese'\n- Breaking: Method `first()` and `best()` from CharsetMatch\n- UTF-7 will no longer appear as \"detected\" without a recognized SIG/mark (is unreliable/conflict with ASCII)\n- Breaking: Class aliases CharsetDetector, CharsetDoctor, CharsetNormalizerMatch and CharsetNormalizerMatches\n- Breaking: Top-level function `normalize`\n- Breaking: Properties `chaos_secondary_pass`, `coherence_non_latin` and `w_counter` from CharsetMatch\n- Support for the backport `unicodedata2`\n\n## [3.0.0rc1](https://github.com/Ousret/charset_normalizer/compare/3.0.0b2...3.0.0rc1) (2022-10-18)\n\n### Added\n- Extend the capability of explain=True when cp_isolation contains at most two entries (min one), will log in details of the Mess-detector results\n- Support for alternative language frequency set in charset_normalizer.assets.FREQUENCIES\n- Add parameter `language_threshold` in `from_bytes`, `from_path` and `from_fp` to adjust the minimum expected coherence ratio\n\n### Changed\n- Build with static metadata using 'build' frontend\n- Make the language detection stricter\n\n### Fixed\n- CLI with opt --normalize fail when using full path for files\n- TooManyAccentuatedPlugin induce false positive on the mess detection when too few alpha character have been fed to it\n\n### Removed\n- Coherence detector no longer return 'Simple English' instead return 'English'\n- Coherence detector no longer return 'Classical Chinese' instead return 'Chinese'\n\n## [3.0.0b2](https://github.com/Ousret/charset_normalizer/compare/3.0.0b1...3.0.0b2) (2022-08-21)\n\n### Added\n- `normalizer --version` now specify if current version provide extra speedup (meaning mypyc compilation whl)\n\n### Removed\n- Breaking: Method `first()` and `best()` from CharsetMatch\n- UTF-7 will no longer appear as \"detected\" without a recognized SIG/mark (is unreliable/conflict with ASCII)\n\n### Fixed\n- Sphinx warnings when generating the documentation\n\n## [3.0.0b1](https://github.com/Ousret/charset_normalizer/compare/2.1.0...3.0.0b1) (2022-08-15)\n\n### Changed\n- Optional: Module `md.py` can be compiled using Mypyc to provide an extra speedup up to 4x faster than v2.1\n\n### Removed\n- Breaking: Class aliases CharsetDetector, CharsetDoctor, CharsetNormalizerMatch and CharsetNormalizerMatches\n- Breaking: Top-level function `normalize`\n- Breaking: Properties `chaos_secondary_pass`, `coherence_non_latin` and `w_counter` from CharsetMatch\n- Support for the backport `unicodedata2`\n\n## [2.1.1](https://github.com/Ousret/charset_normalizer/compare/2.1.0...2.1.1) (2022-08-19)\n\n### Deprecated\n- Function `normalize` scheduled for removal in 3.0\n\n### Changed\n- Removed useless call to decode in fn is_unprintable (#206)\n\n### Fixed\n- Third-party library (i18n xgettext) crashing not recognizing utf_8 (PEP 263) with underscore from [@aleksandernovikov](https://github.com/aleksandernovikov) (#204)\n\n## [2.1.0](https://github.com/Ousret/charset_normalizer/compare/2.0.12...2.1.0) (2022-06-19)\n\n### Added\n- Output the Unicode table version when running the CLI with `--version` (PR #194)\n\n### Changed\n- Re-use decoded buffer for single byte character sets from [@nijel](https://github.com/nijel) (PR #175)\n- Fixing some performance bottlenecks from [@deedy5](https://github.com/deedy5) (PR #183)\n\n### Fixed\n- Workaround potential bug in cpython with Zero Width No-Break Space located in Arabic Presentation Forms-B, Unicode 1.1 not acknowledged as space (PR #175)\n- CLI default threshold aligned with the API threshold from [@oleksandr-kuzmenko](https://github.com/oleksandr-kuzmenko) (PR #181)\n\n### Removed\n- Support for Python 3.5 (PR #192)\n\n### Deprecated\n- Use of backport unicodedata from `unicodedata2` as Python is quickly catching up, scheduled for removal in 3.0 (PR #194)\n\n## [2.0.12](https://github.com/Ousret/charset_normalizer/compare/2.0.11...2.0.12) (2022-02-12)\n\n### Fixed\n- ASCII miss-detection on rare cases (PR #170) \n\n## [2.0.11](https://github.com/Ousret/charset_normalizer/compare/2.0.10...2.0.11) (2022-01-30)\n\n### Added\n- Explicit support for Python 3.11 (PR #164)\n\n### Changed\n- The logging behavior have been completely reviewed, now using only TRACE and DEBUG levels (PR #163 #165)\n\n## [2.0.10](https://github.com/Ousret/charset_normalizer/compare/2.0.9...2.0.10) (2022-01-04)\n\n### Fixed\n- Fallback match entries might lead to UnicodeDecodeError for large bytes sequence (PR #154)\n\n### Changed\n- Skipping the language-detection (CD) on ASCII (PR #155)\n\n## [2.0.9](https://github.com/Ousret/charset_normalizer/compare/2.0.8...2.0.9) (2021-12-03)\n\n### Changed\n- Moderating the logging impact (since 2.0.8) for specific environments (PR #147)\n\n### Fixed\n- Wrong logging level applied when setting kwarg `explain` to True (PR #146)\n\n## [2.0.8](https://github.com/Ousret/charset_normalizer/compare/2.0.7...2.0.8) (2021-11-24)\n### Changed\n- Improvement over Vietnamese detection (PR #126)\n- MD improvement on trailing data and long foreign (non-pure latin) data (PR #124)\n- Efficiency improvements in cd/alphabet_languages from [@adbar](https://github.com/adbar) (PR #122)\n- call sum() without an intermediary list following PEP 289 recommendations from [@adbar](https://github.com/adbar) (PR #129)\n- Code style as refactored by Sourcery-AI (PR #131) \n- Minor adjustment on the MD around european words (PR #133)\n- Remove and replace SRTs from assets / tests (PR #139)\n- Initialize the library logger with a `NullHandler` by default from [@nmaynes](https://github.com/nmaynes) (PR #135)\n- Setting kwarg `explain` to True will add provisionally (bounded to function lifespan) a specific stream handler (PR #135)\n\n### Fixed\n- Fix large (misleading) sequence giving UnicodeDecodeError (PR #137)\n- Avoid using too insignificant chunk (PR #137)\n\n### Added\n- Add and expose function `set_logging_handler` to configure a specific StreamHandler from [@nmaynes](https://github.com/nmaynes) (PR #135)\n- Add `CHANGELOG.md` entries, format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/) (PR #141)\n\n## [2.0.7](https://github.com/Ousret/charset_normalizer/compare/2.0.6...2.0.7) (2021-10-11)\n### Added\n- Add support for Kazakh (Cyrillic) language detection (PR #109)\n\n### Changed\n- Further, improve inferring the language from a given single-byte code page (PR #112)\n- Vainly trying to leverage PEP263 when PEP3120 is not supported (PR #116)\n- Refactoring for potential performance improvements in loops from [@adbar](https://github.com/adbar) (PR #113)\n- Various detection improvement (MD+CD) (PR #117)\n\n### Removed\n- Remove redundant logging entry about detected language(s) (PR #115)\n\n### Fixed\n- Fix a minor inconsistency between Python 3.5 and other versions regarding language detection (PR #117 #102)\n\n## [2.0.6](https://github.com/Ousret/charset_normalizer/compare/2.0.5...2.0.6) (2021-09-18)\n### Fixed\n- Unforeseen regression with the loss of the backward-compatibility with some older minor of Python 3.5.x (PR #100)\n- Fix CLI crash when using --minimal output in certain cases (PR #103)\n\n### Changed\n- Minor improvement to the detection efficiency (less than 1%) (PR #106 #101)\n\n## [2.0.5](https://github.com/Ousret/charset_normalizer/compare/2.0.4...2.0.5) (2021-09-14)\n### Changed\n- The project now comply with: flake8, mypy, isort and black to ensure a better overall quality (PR #81)\n- The BC-support with v1.x was improved, the old staticmethods are restored (PR #82)\n- The Unicode detection is slightly improved (PR #93)\n- Add syntax sugar \\_\\_bool\\_\\_ for results CharsetMatches list-container (PR #91)\n\n### Removed\n- The project no longer raise warning on tiny content given for detection, will be simply logged as warning instead (PR #92)\n\n### Fixed\n- In some rare case, the chunks extractor could cut in the middle of a multi-byte character and could mislead the mess detection (PR #95)\n- Some rare 'space' characters could trip up the UnprintablePlugin/Mess detection (PR #96)\n- The MANIFEST.in was not exhaustive (PR #78)\n\n## [2.0.4](https://github.com/Ousret/charset_normalizer/compare/2.0.3...2.0.4) (2021-07-30)\n### Fixed\n- The CLI no longer raise an unexpected exception when no encoding has been found (PR #70)\n- Fix accessing the 'alphabets' property when the payload contains surrogate characters (PR #68)\n- The logger could mislead (explain=True) on detected languages and the impact of one MBCS match (PR #72)\n- Submatch factoring could be wrong in rare edge cases (PR #72)\n- Multiple files given to the CLI were ignored when publishing results to STDOUT. (After the first path) (PR #72)\n- Fix line endings from CRLF to LF for certain project files (PR #67)\n\n### Changed\n- Adjust the MD to lower the sensitivity, thus improving the global detection reliability (PR #69 #76)\n- Allow fallback on specified encoding if any (PR #71)\n\n## [2.0.3](https://github.com/Ousret/charset_normalizer/compare/2.0.2...2.0.3) (2021-07-16)\n### Changed\n- Part of the detection mechanism has been improved to be less sensitive, resulting in more accurate detection results. Especially ASCII. (PR #63)\n- According to the community wishes, the detection will fall back on ASCII or UTF-8 in a last-resort case. (PR #64)\n\n## [2.0.2](https://github.com/Ousret/charset_normalizer/compare/2.0.1...2.0.2) (2021-07-15)\n### Fixed\n- Empty/Too small JSON payload miss-detection fixed. Report from [@tseaver](https://github.com/tseaver) (PR #59) \n\n### Changed\n- Don't inject unicodedata2 into sys.modules from [@akx](https://github.com/akx) (PR #57)\n\n## [2.0.1](https://github.com/Ousret/charset_normalizer/compare/2.0.0...2.0.1) (2021-07-13)\n### Fixed\n- Make it work where there isn't a filesystem available, dropping assets frequencies.json. Report from [@sethmlarson](https://github.com/sethmlarson). (PR #55)\n- Using explain=False permanently disable the verbose output in the current runtime (PR #47)\n- One log entry (language target preemptive) was not show in logs when using explain=True (PR #47)\n- Fix undesired exception (ValueError) on getitem of instance CharsetMatches (PR #52)\n\n### Changed\n- Public function normalize default args values were not aligned with from_bytes (PR #53)\n\n### Added\n- You may now use charset aliases in cp_isolation and cp_exclusion arguments (PR #47)\n\n## [2.0.0](https://github.com/Ousret/charset_normalizer/compare/1.4.1...2.0.0) (2021-07-02)\n### Changed\n- 4x to 5 times faster than the previous 1.4.0 release. At least 2x faster than Chardet.\n- Accent has been made on UTF-8 detection, should perform rather instantaneous.\n- The backward compatibility with Chardet has been greatly improved. The legacy detect function returns an identical charset name whenever possible.\n- The detection mechanism has been slightly improved, now Turkish content is detected correctly (most of the time)\n- The program has been rewritten to ease the readability and maintainability. (+Using static typing)+\n- utf_7 detection has been reinstated.\n\n### Removed\n- This package no longer require anything when used with Python 3.5 (Dropped cached_property)\n- Removed support for these languages: Catalan, Esperanto, Kazakh, Baque, VolapÃ¼k, Azeri, Galician, Nynorsk, Macedonian, and Serbocroatian.\n- The exception hook on UnicodeDecodeError has been removed.\n\n### Deprecated\n- Methods coherence_non_latin, w_counter, chaos_secondary_pass of the class CharsetMatch are now deprecated and scheduled for removal in v3.0\n\n### Fixed\n- The CLI output used the relative path of the file(s). Should be absolute.\n\n## [1.4.1](https://github.com/Ousret/charset_normalizer/compare/1.4.0...1.4.1) (2021-05-28)\n### Fixed\n- Logger configuration/usage no longer conflict with others (PR #44)\n\n## [1.4.0](https://github.com/Ousret/charset_normalizer/compare/1.3.9...1.4.0) (2021-05-21)\n### Removed\n- Using standard logging instead of using the package loguru.\n- Dropping nose test framework in favor of the maintained pytest.\n- Choose to not use dragonmapper package to help with gibberish Chinese/CJK text.\n- Require cached_property only for Python 3.5 due to constraint. Dropping for every other interpreter version.\n- Stop support for UTF-7 that does not contain a SIG.\n- Dropping PrettyTable, replaced with pure JSON output in CLI.\n\n### Fixed\n- BOM marker in a CharsetNormalizerMatch instance could be False in rare cases even if obviously present. Due to the sub-match factoring process.\n- Not searching properly for the BOM when trying utf32/16 parent codec.\n\n### Changed\n- Improving the package final size by compressing frequencies.json.\n- Huge improvement over the larges payload.\n\n### Added\n- CLI now produces JSON consumable output.\n- Return ASCII if given sequences fit. Given reasonable confidence.\n\n## [1.3.9](https://github.com/Ousret/charset_normalizer/compare/1.3.8...1.3.9) (2021-05-13)\n\n### Fixed\n- In some very rare cases, you may end up getting encode/decode errors due to a bad bytes payload (PR #40)\n\n## [1.3.8](https://github.com/Ousret/charset_normalizer/compare/1.3.7...1.3.8) (2021-05-12)\n\n### Fixed\n- Empty given payload for detection may cause an exception if trying to access the `alphabets` property. (PR #39)\n\n## [1.3.7](https://github.com/Ousret/charset_normalizer/compare/1.3.6...1.3.7) (2021-05-12)\n\n### Fixed\n- The legacy detect function should return UTF-8-SIG if sig is present in the payload. (PR #38)\n\n## [1.3.6](https://github.com/Ousret/charset_normalizer/compare/1.3.5...1.3.6) (2021-02-09)\n\n### Changed\n- Amend the previous release to allow prettytable 2.0 (PR #35)\n\n## [1.3.5](https://github.com/Ousret/charset_normalizer/compare/1.3.4...1.3.5) (2021-02-08)\n\n### Fixed\n- Fix error while using the package with a python pre-release interpreter (PR #33)\n\n### Changed\n- Dependencies refactoring, constraints revised.\n\n### Added\n- Add python 3.9 and 3.10 to the supported interpreters\n\nMIT License\n\nCopyright (c) 2019 TAHRI Ahmed R.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "encoding",
          "charset",
          "charset-detector",
          "detector",
          "normalization",
          "unicode",
          "chardet",
          "detect"
        ],
        "home_page": "https://github.com/Ousret/charset_normalizer",
        "author": "Ahmed TAHRI",
        "author_email": "ahmed.tahri@cloudnursery.dev",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "License :: OSI Approved :: MIT License",
          "Intended Audience :: Developers",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Text Processing :: Linguistic",
          "Topic :: Utilities",
          "Typing :: Typed"
        ],
        "requires_python": ">=3.7.0",
        "project_url": [
          "Bug Reports, https://github.com/Ousret/charset_normalizer/issues",
          "Documentation, https://charset-normalizer.readthedocs.io/en/latest"
        ],
        "provides_extra": [
          "unicode_backport"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\charset_normalizer-3.3.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "click",
        "version": "8.1.7",
        "summary": "Composable command line interface toolkit",
        "description": "\\$ click\\_\n==========\n\nClick is a Python package for creating beautiful command line interfaces\nin a composable way with as little code as necessary. It's the \"Command\nLine Interface Creation Kit\". It's highly configurable but comes with\nsensible defaults out of the box.\n\nIt aims to make the process of writing command line tools quick and fun\nwhile also preventing any frustration caused by the inability to\nimplement an intended CLI API.\n\nClick in three points:\n\n-   Arbitrary nesting of commands\n-   Automatic help page generation\n-   Supports lazy loading of subcommands at runtime\n\n\nInstalling\n----------\n\nInstall and update using `pip`_:\n\n.. code-block:: text\n\n    $ pip install -U click\n\n.. _pip: https://pip.pypa.io/en/stable/getting-started/\n\n\nA Simple Example\n----------------\n\n.. code-block:: python\n\n    import click\n\n    @click.command()\n    @click.option(\"--count\", default=1, help=\"Number of greetings.\")\n    @click.option(\"--name\", prompt=\"Your name\", help=\"The person to greet.\")\n    def hello(count, name):\n        \"\"\"Simple program that greets NAME for a total of COUNT times.\"\"\"\n        for _ in range(count):\n            click.echo(f\"Hello, {name}!\")\n\n    if __name__ == '__main__':\n        hello()\n\n.. code-block:: text\n\n    $ python hello.py --count=3\n    Your name: Click\n    Hello, Click!\n    Hello, Click!\n    Hello, Click!\n\n\nDonate\n------\n\nThe Pallets organization develops and supports Click and other popular\npackages. In order to grow the community of contributors and users, and\nallow the maintainers to devote more time to the projects, `please\ndonate today`_.\n\n.. _please donate today: https://palletsprojects.com/donate\n\n\nLinks\n-----\n\n-   Documentation: https://click.palletsprojects.com/\n-   Changes: https://click.palletsprojects.com/changes/\n-   PyPI Releases: https://pypi.org/project/click/\n-   Source Code: https://github.com/pallets/click\n-   Issue Tracker: https://github.com/pallets/click/issues\n-   Chat: https://discord.gg/pallets\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://palletsprojects.com/p/click/",
        "maintainer": "Pallets",
        "maintainer_email": "contact@palletsprojects.com",
        "license": "BSD-3-Clause",
        "license_file": [
          "LICENSE.rst"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python"
        ],
        "requires_dist": [
          "colorama ; platform_system == \"Windows\"",
          "importlib-metadata ; python_version < \"3.8\""
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Donate, https://palletsprojects.com/donate",
          "Documentation, https://click.palletsprojects.com/",
          "Changes, https://click.palletsprojects.com/changes/",
          "Source Code, https://github.com/pallets/click/",
          "Issue Tracker, https://github.com/pallets/click/issues/",
          "Chat, https://discord.gg/pallets"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\click-8.1.7.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "cli-support",
        "version": "2.0.1",
        "summary": "Support component license information (CLI) files",
        "description": "# CLI Support for Python\n\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/sw360/clipython/blob/master/License.md)\n[![Python Version](https://img.shields.io/badge/python-3.8%2C3.9%2C3.10%2C3.11-yellow?logo=python)](https://www.python.org/doc/versions/)\n[![PyPI](https://shields.io/pypi/v/cli-support)](https://pypi.org/project/cli-support)\n[![Static checks](https://github.com/sw360/clipython/actions/workflows/python-package.yml/badge.svg)](https://github.com/sw360/clipython/actions/workflows/python-package.yml)\n[![Unit tests](https://github.com/sw360/clipython/actions/workflows/unit-test.yml/badge.svg)](https://github.com/sw360/clipython/actions/workflows/unit-test.yml)\n\nPython library to read and write Component License Information (CLI) files. They can be\ncreated by [FOSSology](https://www.fossology.org) and stored in\n[SW360](https://www.eclipse.org/sw360/).\n\nFor more information about the CLI file format, please have a look at\n[ComponentLicenseInformation.md](ComponentLicenseInformation.md).\n\n## Usage\n\n### Installation\n\nThis project is available as [Python package on PyPi.org](https://pypi.org/project/cli-support/).  \nInstall cli_support and required dependencies:\n\n  ```shell\n  pip install cli_support\n  ```\n\n### Required Packages\n\n* none\n\n## Using the API\n\n* Start using the API:\n\n  ```python\n  import cli_support\n  clifile = cli_support.CLI.CliFile()\n  clifile.read_from_file(\"cli_filename\")\n  ```\n\n## Contribute\n\n* All contributions in form of bug reports, feature requests or merge requests are welcome!\n* Please use proper [docstrings](https://realpython.com/documenting-python-code/) to document\n  functions and classes.\n* Extend the testsuite **poetry run pytest** with the new functions/classes\n\n## Build\n\n### Building Python package\n\nFor building the library, you need [Poetry](https://python-poetry.org/). Build is then\nsimply triggered using\n\n```shell\npoetry build\n```\n\nThis creates the source and wheel files in ```dist/``` subdirectory -- which can then\nbe uploaded or installed locally using ```pip```.\n\n## Test\n\nStart the complete test suite or a specific test case (and generate coverage report):\n\n```shell\npoetry run pytest\n```\n\nor\n\n```shell\npoetry run coverage run -m pytest\npoetry run coverage report -m --omit \"*/site-packages/*.py\"\npoetry run coverage html --omit \"*/site-packages/*.py\"\n```\n\n## Demo\n\nThe script ``show_licenses.py`` shows how to use the library to retrieve some information\nof a given CLI file.\n\n```shell\npython ./show_licenses.py ./test/testfiles/CLIXML_MIT_simple.xml\n```\n\n## License\n\nThe project is licensed under the MIT license.  \nSPDX-License-Identifier: MIT\n\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/sw360/clipython",
        "author": "Thomas Graf",
        "author_email": "thomas.graf@siemens.com",
        "license": "MIT",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3 :: Only"
        ],
        "requires_python": ">=3.8,<4.0",
        "project_url": [
          "Repository, https://github.com/sw360/clipython"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\cli_support-2.0.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "colorama",
        "version": "0.4.6",
        "summary": "Cross-platform colored terminal text.",
        "description": ".. image:: https://img.shields.io/pypi/v/colorama.svg\n    :target: https://pypi.org/project/colorama/\n    :alt: Latest Version\n\n.. image:: https://img.shields.io/pypi/pyversions/colorama.svg\n    :target: https://pypi.org/project/colorama/\n    :alt: Supported Python versions\n\n.. image:: https://github.com/tartley/colorama/actions/workflows/test.yml/badge.svg\n    :target: https://github.com/tartley/colorama/actions/workflows/test.yml\n    :alt: Build Status\n\nColorama\n========\n\nMakes ANSI escape character sequences (for producing colored terminal text and\ncursor positioning) work under MS Windows.\n\n.. |donate| image:: https://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif\n  :target: https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=2MZ9D2GMLYCUJ&item_name=Colorama&currency_code=USD\n  :alt: Donate with Paypal\n\n`PyPI for releases <https://pypi.org/project/colorama/>`_ |\n`Github for source <https://github.com/tartley/colorama>`_ |\n`Colorama for enterprise on Tidelift <https://github.com/tartley/colorama/blob/master/ENTERPRISE.md>`_\n\nIf you find Colorama useful, please |donate| to the authors. Thank you!\n\nInstallation\n------------\n\nTested on CPython 2.7, 3.7, 3.8, 3.9 and 3.10 and Pypy 2.7 and 3.8.\n\nNo requirements other than the standard library.\n\n.. code-block:: bash\n\n    pip install colorama\n    # or\n    conda install -c anaconda colorama\n\nDescription\n-----------\n\nANSI escape character sequences have long been used to produce colored terminal\ntext and cursor positioning on Unix and Macs. Colorama makes this work on\nWindows, too, by wrapping ``stdout``, stripping ANSI sequences it finds (which\nwould appear as gobbledygook in the output), and converting them into the\nappropriate win32 calls to modify the state of the terminal. On other platforms,\nColorama does nothing.\n\nThis has the upshot of providing a simple cross-platform API for printing\ncolored terminal text from Python, and has the happy side-effect that existing\napplications or libraries which use ANSI sequences to produce colored output on\nLinux or Macs can now also work on Windows, simply by calling\n``colorama.just_fix_windows_console()`` (since v0.4.6) or ``colorama.init()``\n(all versions, but may have other side-effects â€“ see below).\n\nAn alternative approach is to install ``ansi.sys`` on Windows machines, which\nprovides the same behaviour for all applications running in terminals. Colorama\nis intended for situations where that isn't easy (e.g., maybe your app doesn't\nhave an installer.)\n\nDemo scripts in the source code repository print some colored text using\nANSI sequences. Compare their output under Gnome-terminal's built in ANSI\nhandling, versus on Windows Command-Prompt using Colorama:\n\n.. image:: https://github.com/tartley/colorama/raw/master/screenshots/ubuntu-demo.png\n    :width: 661\n    :height: 357\n    :alt: ANSI sequences on Ubuntu under gnome-terminal.\n\n.. image:: https://github.com/tartley/colorama/raw/master/screenshots/windows-demo.png\n    :width: 668\n    :height: 325\n    :alt: Same ANSI sequences on Windows, using Colorama.\n\nThese screenshots show that, on Windows, Colorama does not support ANSI 'dim\ntext'; it looks the same as 'normal text'.\n\nUsage\n-----\n\nInitialisation\n..............\n\nIf the only thing you want from Colorama is to get ANSI escapes to work on\nWindows, then run:\n\n.. code-block:: python\n\n    from colorama import just_fix_windows_console\n    just_fix_windows_console()\n\nIf you're on a recent version of Windows 10 or better, and your stdout/stderr\nare pointing to a Windows console, then this will flip the magic configuration\nswitch to enable Windows' built-in ANSI support.\n\nIf you're on an older version of Windows, and your stdout/stderr are pointing to\na Windows console, then this will wrap ``sys.stdout`` and/or ``sys.stderr`` in a\nmagic file object that intercepts ANSI escape sequences and issues the\nappropriate Win32 calls to emulate them.\n\nIn all other circumstances, it does nothing whatsoever. Basically the idea is\nthat this makes Windows act like Unix with respect to ANSI escape handling.\n\nIt's safe to call this function multiple times. It's safe to call this function\non non-Windows platforms, but it won't do anything. It's safe to call this\nfunction when one or both of your stdout/stderr are redirected to a file â€“ it\nwon't do anything to those streams.\n\nAlternatively, you can use the older interface with more features (but also more\npotential footguns):\n\n.. code-block:: python\n\n    from colorama import init\n    init()\n\nThis does the same thing as ``just_fix_windows_console``, except for the\nfollowing differences:\n\n- It's not safe to call ``init`` multiple times; you can end up with multiple\n  layers of wrapping and broken ANSI support.\n\n- Colorama will apply a heuristic to guess whether stdout/stderr support ANSI,\n  and if it thinks they don't, then it will wrap ``sys.stdout`` and\n  ``sys.stderr`` in a magic file object that strips out ANSI escape sequences\n  before printing them. This happens on all platforms, and can be convenient if\n  you want to write your code to emit ANSI escape sequences unconditionally, and\n  let Colorama decide whether they should actually be output. But note that\n  Colorama's heuristic is not particularly clever.\n\n- ``init`` also accepts explicit keyword args to enable/disable various\n  functionality â€“ see below.\n\nTo stop using Colorama before your program exits, simply call ``deinit()``.\nThis will restore ``stdout`` and ``stderr`` to their original values, so that\nColorama is disabled. To resume using Colorama again, call ``reinit()``; it is\ncheaper than calling ``init()`` again (but does the same thing).\n\nMost users should depend on ``colorama >= 0.4.6``, and use\n``just_fix_windows_console``. The old ``init`` interface will be supported\nindefinitely for backwards compatibility, but we don't plan to fix any issues\nwith it, also for backwards compatibility.\n\nColored Output\n..............\n\nCross-platform printing of colored text can then be done using Colorama's\nconstant shorthand for ANSI escape sequences. These are deliberately\nrudimentary, see below.\n\n.. code-block:: python\n\n    from colorama import Fore, Back, Style\n    print(Fore.RED + 'some red text')\n    print(Back.GREEN + 'and with a green background')\n    print(Style.DIM + 'and in dim text')\n    print(Style.RESET_ALL)\n    print('back to normal now')\n\n...or simply by manually printing ANSI sequences from your own code:\n\n.. code-block:: python\n\n    print('\\033[31m' + 'some red text')\n    print('\\033[39m') # and reset to default color\n\n...or, Colorama can be used in conjunction with existing ANSI libraries\nsuch as the venerable `Termcolor <https://pypi.org/project/termcolor/>`_\nthe fabulous `Blessings <https://pypi.org/project/blessings/>`_,\nor the incredible `_Rich <https://pypi.org/project/rich/>`_.\n\nIf you wish Colorama's Fore, Back and Style constants were more capable,\nthen consider using one of the above highly capable libraries to generate\ncolors, etc, and use Colorama just for its primary purpose: to convert\nthose ANSI sequences to also work on Windows:\n\nSIMILARLY, do not send PRs adding the generation of new ANSI types to Colorama.\nWe are only interested in converting ANSI codes to win32 API calls, not\nshortcuts like the above to generate ANSI characters.\n\n.. code-block:: python\n\n    from colorama import just_fix_windows_console\n    from termcolor import colored\n\n    # use Colorama to make Termcolor work on Windows too\n    just_fix_windows_console()\n\n    # then use Termcolor for all colored text output\n    print(colored('Hello, World!', 'green', 'on_red'))\n\nAvailable formatting constants are::\n\n    Fore: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.\n    Back: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.\n    Style: DIM, NORMAL, BRIGHT, RESET_ALL\n\n``Style.RESET_ALL`` resets foreground, background, and brightness. Colorama will\nperform this reset automatically on program exit.\n\nThese are fairly well supported, but not part of the standard::\n\n    Fore: LIGHTBLACK_EX, LIGHTRED_EX, LIGHTGREEN_EX, LIGHTYELLOW_EX, LIGHTBLUE_EX, LIGHTMAGENTA_EX, LIGHTCYAN_EX, LIGHTWHITE_EX\n    Back: LIGHTBLACK_EX, LIGHTRED_EX, LIGHTGREEN_EX, LIGHTYELLOW_EX, LIGHTBLUE_EX, LIGHTMAGENTA_EX, LIGHTCYAN_EX, LIGHTWHITE_EX\n\nCursor Positioning\n..................\n\nANSI codes to reposition the cursor are supported. See ``demos/demo06.py`` for\nan example of how to generate them.\n\nInit Keyword Args\n.................\n\n``init()`` accepts some ``**kwargs`` to override default behaviour.\n\ninit(autoreset=False):\n    If you find yourself repeatedly sending reset sequences to turn off color\n    changes at the end of every print, then ``init(autoreset=True)`` will\n    automate that:\n\n    .. code-block:: python\n\n        from colorama import init\n        init(autoreset=True)\n        print(Fore.RED + 'some red text')\n        print('automatically back to default color again')\n\ninit(strip=None):\n    Pass ``True`` or ``False`` to override whether ANSI codes should be\n    stripped from the output. The default behaviour is to strip if on Windows\n    or if output is redirected (not a tty).\n\ninit(convert=None):\n    Pass ``True`` or ``False`` to override whether to convert ANSI codes in the\n    output into win32 calls. The default behaviour is to convert if on Windows\n    and output is to a tty (terminal).\n\ninit(wrap=True):\n    On Windows, Colorama works by replacing ``sys.stdout`` and ``sys.stderr``\n    with proxy objects, which override the ``.write()`` method to do their work.\n    If this wrapping causes you problems, then this can be disabled by passing\n    ``init(wrap=False)``. The default behaviour is to wrap if ``autoreset`` or\n    ``strip`` or ``convert`` are True.\n\n    When wrapping is disabled, colored printing on non-Windows platforms will\n    continue to work as normal. To do cross-platform colored output, you can\n    use Colorama's ``AnsiToWin32`` proxy directly:\n\n    .. code-block:: python\n\n        import sys\n        from colorama import init, AnsiToWin32\n        init(wrap=False)\n        stream = AnsiToWin32(sys.stderr).stream\n\n        # Python 2\n        print >>stream, Fore.BLUE + 'blue text on stderr'\n\n        # Python 3\n        print(Fore.BLUE + 'blue text on stderr', file=stream)\n\nRecognised ANSI Sequences\n.........................\n\nANSI sequences generally take the form::\n\n    ESC [ <param> ; <param> ... <command>\n\nWhere ``<param>`` is an integer, and ``<command>`` is a single letter. Zero or\nmore params are passed to a ``<command>``. If no params are passed, it is\ngenerally synonymous with passing a single zero. No spaces exist in the\nsequence; they have been inserted here simply to read more easily.\n\nThe only ANSI sequences that Colorama converts into win32 calls are::\n\n    ESC [ 0 m       # reset all (colors and brightness)\n    ESC [ 1 m       # bright\n    ESC [ 2 m       # dim (looks same as normal brightness)\n    ESC [ 22 m      # normal brightness\n\n    # FOREGROUND:\n    ESC [ 30 m      # black\n    ESC [ 31 m      # red\n    ESC [ 32 m      # green\n    ESC [ 33 m      # yellow\n    ESC [ 34 m      # blue\n    ESC [ 35 m      # magenta\n    ESC [ 36 m      # cyan\n    ESC [ 37 m      # white\n    ESC [ 39 m      # reset\n\n    # BACKGROUND\n    ESC [ 40 m      # black\n    ESC [ 41 m      # red\n    ESC [ 42 m      # green\n    ESC [ 43 m      # yellow\n    ESC [ 44 m      # blue\n    ESC [ 45 m      # magenta\n    ESC [ 46 m      # cyan\n    ESC [ 47 m      # white\n    ESC [ 49 m      # reset\n\n    # cursor positioning\n    ESC [ y;x H     # position cursor at x across, y down\n    ESC [ y;x f     # position cursor at x across, y down\n    ESC [ n A       # move cursor n lines up\n    ESC [ n B       # move cursor n lines down\n    ESC [ n C       # move cursor n characters forward\n    ESC [ n D       # move cursor n characters backward\n\n    # clear the screen\n    ESC [ mode J    # clear the screen\n\n    # clear the line\n    ESC [ mode K    # clear the line\n\nMultiple numeric params to the ``'m'`` command can be combined into a single\nsequence::\n\n    ESC [ 36 ; 45 ; 1 m     # bright cyan text on magenta background\n\nAll other ANSI sequences of the form ``ESC [ <param> ; <param> ... <command>``\nare silently stripped from the output on Windows.\n\nAny other form of ANSI sequence, such as single-character codes or alternative\ninitial characters, are not recognised or stripped. It would be cool to add\nthem though. Let me know if it would be useful for you, via the Issues on\nGitHub.\n\nStatus & Known Problems\n-----------------------\n\nI've personally only tested it on Windows XP (CMD, Console2), Ubuntu\n(gnome-terminal, xterm), and OS X.\n\nSome valid ANSI sequences aren't recognised.\n\nIf you're hacking on the code, see `README-hacking.md`_. ESPECIALLY, see the\nexplanation there of why we do not want PRs that allow Colorama to generate new\ntypes of ANSI codes.\n\nSee outstanding issues and wish-list:\nhttps://github.com/tartley/colorama/issues\n\nIf anything doesn't work for you, or doesn't do what you expected or hoped for,\nI'd love to hear about it on that issues list, would be delighted by patches,\nand would be happy to grant commit access to anyone who submits a working patch\nor two.\n\n.. _README-hacking.md: README-hacking.md\n\nLicense\n-------\n\nCopyright Jonathan Hartley & Arnon Yaari, 2013-2020. BSD 3-Clause license; see\nLICENSE file.\n\nProfessional support\n--------------------\n\n.. |tideliftlogo| image:: https://cdn2.hubspot.net/hubfs/4008838/website/logos/logos_for_download/Tidelift_primary-shorthand-logo.png\n   :alt: Tidelift\n   :target: https://tidelift.com/subscription/pkg/pypi-colorama?utm_source=pypi-colorama&utm_medium=referral&utm_campaign=readme\n\n.. list-table::\n   :widths: 10 100\n\n   * - |tideliftlogo|\n     - Professional support for colorama is available as part of the\n       `Tidelift Subscription`_.\n       Tidelift gives software development teams a single source for purchasing\n       and maintaining their software, with professional grade assurances from\n       the experts who know it best, while seamlessly integrating with existing\n       tools.\n\n.. _Tidelift Subscription: https://tidelift.com/subscription/pkg/pypi-colorama?utm_source=pypi-colorama&utm_medium=referral&utm_campaign=readme\n\nThanks\n------\n\nSee the CHANGELOG for more thanks!\n\n* Marc Schlaich (schlamar) for a ``setup.py`` fix for Python2.5.\n* Marc Abramowitz, reported & fixed a crash on exit with closed ``stdout``,\n  providing a solution to issue #7's setuptools/distutils debate,\n  and other fixes.\n* User 'eryksun', for guidance on correctly instantiating ``ctypes.windll``.\n* Matthew McCormick for politely pointing out a longstanding crash on non-Win.\n* Ben Hoyt, for a magnificent fix under 64-bit Windows.\n* Jesse at Empty Square for submitting a fix for examples in the README.\n* User 'jamessp', an observant documentation fix for cursor positioning.\n* User 'vaal1239', Dave Mckee & Lackner Kristof for a tiny but much-needed Win7\n  fix.\n* Julien Stuyck, for wisely suggesting Python3 compatible updates to README.\n* Daniel Griffith for multiple fabulous patches.\n* Oscar Lesta for a valuable fix to stop ANSI chars being sent to non-tty\n  output.\n* Roger Binns, for many suggestions, valuable feedback, & bug reports.\n* Tim Golden for thought and much appreciated feedback on the initial idea.\n* User 'Zearin' for updates to the README file.\n* John Szakmeister for adding support for light colors\n* Charles Merriam for adding documentation to demos\n* Jurko for a fix on 64-bit Windows CPython2.5 w/o ctypes\n* Florian Bruhin for a fix when stdout or stderr are None\n* Thomas Weininger for fixing ValueError on Windows\n* Remi Rampin for better Github integration and fixes to the README file\n* Simeon Visser for closing a file handle using 'with' and updating classifiers\n  to include Python 3.3 and 3.4\n* Andy Neff for fixing RESET of LIGHT_EX colors.\n* Jonathan Hartley for the initial idea and implementation.\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "ansi",
          "color",
          "colour",
          "crossplatform",
          "terminal",
          "text",
          "windows",
          "xplatform"
        ],
        "author_email": "Jonathan Hartley <tartley@tartley.com>",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Terminals"
        ],
        "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,!=3.5.*,!=3.6.*,>=2.7",
        "project_url": [
          "Homepage, https://github.com/tartley/colorama"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\colorama-0.4.6.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "contourpy",
        "version": "1.3.1",
        "summary": "Python library for calculating contours of 2D quadrilateral grids",
        "description": "<img alt=\"ContourPy\" src=\"https://raw.githubusercontent.com/contourpy/contourpy/main/docs/_static/contourpy_logo_horiz.svg\" height=\"90\">\n\nContourPy is a Python library for calculating contours of 2D quadrilateral grids.  It is written in C++11 and wrapped using pybind11.\n\nIt contains the 2005 and 2014 algorithms used in Matplotlib as well as a newer algorithm that includes more features and is available in both serial and multithreaded versions.  It provides an easy way for Python libraries to use contouring algorithms without having to include Matplotlib as a dependency.\n\n  * **Documentation**: https://contourpy.readthedocs.io\n  * **Source code**: https://github.com/contourpy/contourpy\n\n| | |\n| --- | --- |\n| Latest release | [![PyPI version](https://img.shields.io/pypi/v/contourpy.svg?label=pypi&color=fdae61)](https://pypi.python.org/pypi/contourpy) [![conda-forge version](https://img.shields.io/conda/v/conda-forge/contourpy.svg?label=conda-forge&color=a6d96a)](https://anaconda.org/conda-forge/contourpy) |\n| Downloads | [![PyPi downloads](https://img.shields.io/pypi/dm/contourpy?label=pypi&style=flat&color=fdae61)](https://pepy.tech/project/contourpy) |\n| Python version | [![Platforms](https://img.shields.io/pypi/pyversions/contourpy?color=fdae61)](https://pypi.org/project/contourpy/) |\n| Coverage | [![Codecov](https://img.shields.io/codecov/c/gh/contourpy/contourpy?color=fdae61&label=codecov)](https://app.codecov.io/gh/contourpy/contourpy) |\n",
        "description_content_type": "text/markdown",
        "author_email": "Ian Thomas <ianthomas23@gmail.com>",
        "license": "BSD 3-Clause License\n\n Copyright (c) 2021-2024, ContourPy Developers.\n All rights reserved.\n\n Redistribution and use in source and binary forms, with or without\n modification, are permitted provided that the following conditions are met:\n\n 1. Redistributions of source code must retain the above copyright notice, this\n    list of conditions and the following disclaimer.\n\n 2. Redistributions in binary form must reproduce the above copyright notice,\n    this list of conditions and the following disclaimer in the documentation\n    and/or other materials provided with the distribution.\n\n 3. Neither the name of the copyright holder nor the names of its\n    contributors may be used to endorse or promote products derived from\n    this software without specific prior written permission.\n\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: Science/Research",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: C++",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Scientific/Engineering :: Information Analysis",
          "Topic :: Scientific/Engineering :: Mathematics",
          "Topic :: Scientific/Engineering :: Visualization"
        ],
        "requires_dist": [
          "numpy>=1.23",
          "furo; extra == \"docs\"",
          "sphinx>=7.2; extra == \"docs\"",
          "sphinx-copybutton; extra == \"docs\"",
          "bokeh; extra == \"bokeh\"",
          "selenium; extra == \"bokeh\"",
          "contourpy[bokeh,docs]; extra == \"mypy\"",
          "docutils-stubs; extra == \"mypy\"",
          "mypy==1.11.1; extra == \"mypy\"",
          "types-Pillow; extra == \"mypy\"",
          "contourpy[test-no-images]; extra == \"test\"",
          "matplotlib; extra == \"test\"",
          "Pillow; extra == \"test\"",
          "pytest; extra == \"test-no-images\"",
          "pytest-cov; extra == \"test-no-images\"",
          "pytest-rerunfailures; extra == \"test-no-images\"",
          "pytest-xdist; extra == \"test-no-images\"",
          "wurlitzer; extra == \"test-no-images\""
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Homepage, https://github.com/contourpy/contourpy",
          "Changelog, https://contourpy.readthedocs.io/en/latest/changelog.html",
          "Documentation, https://contourpy.readthedocs.io",
          "Repository, https://github.com/contourpy/contourpy"
        ],
        "provides_extra": [
          "docs",
          "bokeh",
          "mypy",
          "test",
          "test-no-images"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\contourpy-1.3.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "cycler",
        "version": "0.12.1",
        "summary": "Composable style cycles",
        "description": "|PyPi|_ |Conda|_ |Supported Python versions|_ |GitHub Actions|_ |Codecov|_\n\n.. |PyPi| image:: https://img.shields.io/pypi/v/cycler.svg?style=flat\n.. _PyPi: https://pypi.python.org/pypi/cycler\n\n.. |Conda| image:: https://img.shields.io/conda/v/conda-forge/cycler\n.. _Conda:  https://anaconda.org/conda-forge/cycler\n\n.. |Supported Python versions| image:: https://img.shields.io/pypi/pyversions/cycler.svg\n.. _Supported Python versions: https://pypi.python.org/pypi/cycler\n\n.. |GitHub Actions| image:: https://github.com/matplotlib/cycler/actions/workflows/tests.yml/badge.svg\n.. _GitHub Actions: https://github.com/matplotlib/cycler/actions\n\n.. |Codecov| image:: https://codecov.io/github/matplotlib/cycler/badge.svg?branch=main&service=github\n.. _Codecov: https://codecov.io/github/matplotlib/cycler?branch=main\n\ncycler: composable cycles\n=========================\n\nDocs: https://matplotlib.org/cycler/\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "cycle",
          "kwargs"
        ],
        "author_email": "Thomas A Caswell <matplotlib-users@python.org>",
        "license": "Copyright (c) 2015, matplotlib project\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of the matplotlib project nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "License :: OSI Approved :: BSD License",
          "Development Status :: 4 - Beta",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3 :: Only"
        ],
        "requires_dist": [
          "ipython ; extra == 'docs'",
          "matplotlib ; extra == 'docs'",
          "numpydoc ; extra == 'docs'",
          "sphinx ; extra == 'docs'",
          "pytest ; extra == 'tests'",
          "pytest-cov ; extra == 'tests'",
          "pytest-xdist ; extra == 'tests'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "homepage, https://matplotlib.org/cycler/",
          "repository, https://github.com/matplotlib/cycler"
        ],
        "provides_extra": [
          "docs",
          "tests"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\cycler-0.12.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "cyclonedx-bom",
        "version": "3.11.7",
        "summary": "CycloneDX Software Bill of Materials (SBOM) generation utility",
        "description": "# CycloneDX Python SBOM Generation Tool\n\n[![shield_pypi-version]][link_pypi]\n[![shield_docker-version]][link_docker]\n[![shield_rtfd]][link_rtfd]\n[![shield_gh-workflow-test]][link_gh-workflow-test]\n[![shield_coverage]][link_codacy]\n[![shield_license]][license_file]  \n[![shield_website]][link_website]\n[![shield_slack]][link_slack]\n[![shield_groups]][link_discussion]\n[![shield_twitter-follow]][link_twitter]\n\n----\n\nThis project provides a runnable Python-based application for generating CycloneDX bill-of-material documents from either:\n\n* Your current Python Environment\n* Your project's manifest (e.g. `Pipfile.lock`, `poetry.lock` or `requirements.txt`)\n* Conda as a Package Manager\n\nThe BOM will contain an aggregate of all your current project's dependencies, or those defined by the manifest you supply.\n\n[CycloneDX](https://cyclonedx.org/) is a lightweight BOM specification that is easily created, human-readable, and simple to parse.\n\nRead the full [documentation][link_rtfd] for more details.\n\n## Installation\n\nInstall this from [PyPi.org][link_pypi] using your preferred Python package manager.\n\nExample using `pip`:\n\n```shell\npip install cyclonedx-bom\n```\n\nExample using `poetry`:\n\n```shell\npoetry add cyclonedx-bom\n```\n\n## Usage\n\nCall via one of commands:\n\n```shell\ncyclonedx-py\npython3 -m cyclonedx_py\n```\n\n## Basic usage\n\n```shellSession\n$ cyclonedx-py --help\nusage: cyclonedx-py [-h] (-c | -cj | -e | -p | -pip | -r) [-i FILE_PATH]\n                 [--format {json,xml}] [--schema-version {1.4,1.3,1.2,1.1,1.0}]\n                 [-o FILE_PATH] [-F] [-X]\n\nCycloneDX SBOM Generator\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -c, --conda           Build a SBOM based on the output from `conda list\n                        --explicit` or `conda list --explicit --md5`\n  -cj, --conda-json     Build a SBOM based on the output from `conda list\n                        --json`\n  -e, --e, --environment\n                        Build a SBOM based on the packages installed in your\n                        current Python environment (default)\n  -p, --p, --poetry     Build a SBOM based on a Poetry poetry.lock's contents.\n                        Use with -i to specify absolute path to a `poetry.lock`\n                        you wish to use, else we'll look for one in the\n                        current working directory.\n  -pip, --pip           Build a SBOM based on a PipEnv Pipfile.lock's\n                        contents. Use with -i to specify absolute path to a\n                        `Pipfile.lock` you wish to use, else we'll look for\n                        one in the current working directory.\n  -r, --r, --requirements\n                        Build a SBOM based on a requirements.txt's contents.\n                        Use with -i to specify absolute path to a\n                        `requirements.txt` you wish to use, else we'll look\n                        for one in the current working directory.\n  -X                    Enable debug output\n\nInput Method:\n  Flags to determine how this tool obtains its input\n\n  -i FILE_PATH, --in-file FILE_PATH\n                        File to read input from. Use \"-\" to read from STDIN.\n\nSBOM Output Configuration:\n  Choose the output format and schema version\n\n  --format {json,xml}   The output format for your SBOM (default: xml)\n  --schema-version {1.4,1.3,1.2,1.1,1.0}\n                        The CycloneDX schema version for your SBOM (default:\n                        1.4)\n  -o FILE_PATH, --o FILE_PATH, --output FILE_PATH\n                        Output file path for your SBOM (set to '-' to output\n                        to STDOUT)\n  -F, --force           If outputting to a file and the stated file already\n                        exists, it will be overwritten.\n  -pb, --purl-bom-ref   Use a component's PURL for the bom-ref value, instead\n                        of a random UUID\n```\n\n### Advanced usage and details\n\nSee the full [documentation][link_rtfd] for advanced usage and details on input formats, switches and options.\n\n## Python Support\n\nWe endeavour to support all functionality for all [current actively supported Python versions](https://www.python.org/downloads/).\nHowever, some features may not be possible/present in older Python versions due to their lack of support.\n\n## Contributing\n\nFeel free to open issues, bugreports or pull requests.  \nSee the [CONTRIBUTING][contributing_file] file for details.\n\n## Copyright & License\n\nCycloneDX BOM is Copyright (c) OWASP Foundation. All Rights Reserved.  \nPermission to modify and redistribute is granted under the terms of the Apache 2.0 license.  \nSee the [LICENSE][license_file] file for the full license.\n\n[license_file]: https://github.com/CycloneDX/cyclonedx-python/blob/main/LICENSE\n[contributing_file]: https://github.com/CycloneDX/cyclonedx-python/blob/main/CONTRIBUTING.md\n[link_rtfd]: https://cyclonedx-bom-tool.readthedocs.io/\n\n[shield_gh-workflow-test]: https://img.shields.io/github/actions/workflow/status/CycloneDX/cyclonedx-python/python.yml?branch=main&logo=GitHub&logoColor=white \"build\"\n[shield_rtfd]: https://img.shields.io/readthedocs/cyclonedx-bom-tool?logo=readthedocs&logoColor=white\n[shield_pypi-version]: https://img.shields.io/pypi/v/cyclonedx-bom?logo=Python&logoColor=white&label=PyPI \"PyPI\"\n[shield_docker-version]: https://img.shields.io/docker/v/cyclonedx/cyclonedx-python?logo=docker&logoColor=white&label=docker \"docker\"\n[shield_license]: https://img.shields.io/github/license/CycloneDX/cyclonedx-python?logo=open%20source%20initiative&logoColor=white \"license\"\n[shield_website]: https://img.shields.io/badge/https://-cyclonedx.org-blue.svg \"homepage\"\n[shield_slack]: https://img.shields.io/badge/slack-join-blue?logo=Slack&logoColor=white \"slack join\"\n[shield_groups]: https://img.shields.io/badge/discussion-groups.io-blue.svg \"groups discussion\"\n[shield_twitter-follow]: https://img.shields.io/badge/Twitter-follow-blue?logo=Twitter&logoColor=white \"twitter follow\"\n[link_gh-workflow-test]: https://github.com/CycloneDX/cyclonedx-python/actions/workflows/python.yml?query=branch%3Amain\n[shield_coverage]: https://img.shields.io/codacy/coverage/682ceda9a1044832a087afb95ae280fe?logo=Codacy&logoColor=white \"test coverage\"\n[link_pypi]: https://pypi.org/project/cyclonedx-bom/\n[link_docker]: https://hub.docker.com/r/cyclonedx/cyclonedx-python\n[link_codacy]: https://app.codacy.com/gh/CycloneDX/cyclonedx-python\n[link_website]: https://cyclonedx.org/\n[link_slack]: https://cyclonedx.org/slack/invite\n[link_discussion]: https://groups.io/g/CycloneDX\n[link_twitter]: https://twitter.com/CycloneDX_Spec\n\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/CycloneDX/cyclonedx-python/#readme",
        "author": "Steven Springett",
        "author_email": "steve.springett@owasp.org",
        "maintainer": "Paul Horton",
        "maintainer_email": "phorton@sonatype.com",
        "license": "Apache-2.0",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "Intended Audience :: Legal Industry",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Topic :: Security",
          "Topic :: Software Development",
          "Topic :: System :: Software Distribution",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "chardet (>=5.0,<6.0)",
          "cyclonedx-python-lib (>=2.0.0,<4.0.0)",
          "importlib-metadata (>=3.4) ; python_version < \"3.8\"",
          "packageurl-python (>=0.9)",
          "pip-requirements-parser (>=32.0.0,<33.0.0)",
          "setuptools (>=47.0.0)",
          "toml (>=0.10.0,<0.11.0)"
        ],
        "requires_python": ">=3.6,<4.0",
        "project_url": [
          "Documentation, https://cyclonedx-bom-tool.readthedocs.io/",
          "Repository, https://github.com/CycloneDX/cyclonedx-python"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\cyclonedx_bom-3.11.7.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "cyclonedx-python-lib",
        "version": "3.1.5",
        "summary": "A library for producing CycloneDX SBOM (Software Bill of Materials) files.",
        "description": "# Python Library for generating CycloneDX\n\n[![shield_gh-workflow-test]][link_gh-workflow-test]\n[![shield_rtfd]][link_rtfd]\n[![shield_pypi-version]][link_pypi]\n[![shield_conda-forge-version]][link_conda-forge]\n[![shield_license]][license_file]  \n[![shield_website]][link_website]\n[![shield_slack]][link_slack]\n[![shield_groups]][link_discussion]\n[![shield_twitter-follow]][link_twitter]\n\n----\n\nThis CycloneDX module for Python can generate valid CycloneDX bill-of-material document containing an aggregate of all\nproject dependencies.\n\nThis module is not designed for standalone use.\n\nIf you're looking for a CycloneDX tool to run to generate (SBOM) software bill-of-materials documents, why not checkout: [CycloneDX Python][cyclonedx-python]\n\nAdditionally, the following tool can be used as well (and this library was written to help improve it) [Jake][jake].\n\nAdditionally, you can use this module yourself in your application to programmatically generate SBOMs.\n\nCycloneDX is a lightweight BOM specification that is easily created, human-readable, and simple to parse.\n\nView our documentation [here](https://cyclonedx-python-library.readthedocs.io/).\n\n## Python Support\n\nWe endeavour to support all functionality for all [current actively supported Python versions](https://www.python.org/downloads/).\nHowever, some features may not be possible/present in older Python versions due to their lack of support.\n\n## Changelog\n\nSee our [CHANGELOG][chaneglog_file].\n\n## Contributing\n\nFeel free to open issues, bugreports or pull requests.  \nSee the [CONTRIBUTING][contributing_file] file for details.\n\n## Copyright & License\n\nCycloneDX Python Lib is Copyright (c) OWASP Foundation. All Rights Reserved.  \nPermission to modify and redistribute is granted under the terms of the Apache 2.0 license.  \nSee the [LICENSE][license_file] file for the full license.\n\n[cyclonedx-python]: https://github.com/CycloneDX/cyclonedx-python\n[jake]: https://github.com/sonatype-nexus-community/jake\n\n[license_file]: https://github.com/CycloneDX/cyclonedx-python-lib/blob/master/LICENSE\n[chaneglog_file]: https://github.com/CycloneDX/cyclonedx-python-lib/blob/master/CHANGELOG.md\n[contributing_file]: https://github.com/CycloneDX/cyclonedx-python-lib/blob/master/CONTRIBUTING.md\n\n[shield_gh-workflow-test]: https://img.shields.io/github/actions/workflow/status/CycloneDX/cyclonedx-python-lib/poetry.yml?branch=main&logo=GitHub&logoColor=white \"build\"\n[shield_pypi-version]: https://img.shields.io/pypi/v/cyclonedx-python-lib?logo=pypi&logoColor=white&label=PyPI \"PyPI\"\n[shield_conda-forge-version]: https://img.shields.io/conda/vn/conda-forge/cyclonedx-python-lib?logo=anaconda&logoColor=white&label=conda-forge \"conda-forge\"\n[shield_rtfd]: https://img.shields.io/readthedocs/cyclonedx-python-library?logo=readthedocs&logoColor=white \"Read the Docs\"\n[shield_license]: https://img.shields.io/github/license/CycloneDX/cyclonedx-python-lib?logo=open%20source%20initiative&logoColor=white \"license\"\n[shield_website]: https://img.shields.io/badge/https://-cyclonedx.org-blue.svg \"homepage\"\n[shield_slack]: https://img.shields.io/badge/slack-join-blue?logo=Slack&logoColor=white \"slack join\"\n[shield_groups]: https://img.shields.io/badge/discussion-groups.io-blue.svg \"groups discussion\"\n[shield_twitter-follow]: https://img.shields.io/badge/Twitter-follow-blue?logo=Twitter&logoColor=white \"twitter follow\"\n[link_gh-workflow-test]: https://github.com/CycloneDX/cyclonedx-python-lib/actions/workflows/poetry.yml?query=branch%3Amain\n[link_pypi]: https://pypi.org/project/cyclonedx-python-lib/\n[link_conda-forge]: https://anaconda.org/conda-forge/cyclonedx-python-lib\n[link_rtfd]: https://cyclonedx-python-library.readthedocs.io/en/latest/?badge=latest\n[link_website]: https://cyclonedx.org/\n[link_slack]: https://cyclonedx.org/slack/invite\n[link_discussion]: https://groups.io/g/CycloneDX\n[link_twitter]: https://twitter.com/CycloneDX_Spec\n\n[PEP-508]: https://www.python.org/dev/peps/pep-0508/\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "BOM",
          "SBOM",
          "SCA",
          "OWASP"
        ],
        "home_page": "https://github.com/CycloneDX/cyclonedx-python-lib",
        "author": "Paul Horton",
        "author_email": "phorton@sonatype.com",
        "maintainer": "Paul Horton",
        "maintainer_email": "phorton@sonatype.com",
        "license": "Apache-2.0",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "Intended Audience :: Legal Industry",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Topic :: Security",
          "Topic :: Software Development",
          "Topic :: System :: Software Distribution",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "importlib-metadata (>=3.4) ; python_version < \"3.8\"",
          "packageurl-python (>=0.9)",
          "setuptools (>=47.0.0)",
          "sortedcontainers (>=2.4.0,<3.0.0)",
          "toml (>=0.10.0,<0.11.0)"
        ],
        "requires_python": ">=3.6,<4.0",
        "project_url": [
          "Bug Tracker, https://github.com/CycloneDX/cyclonedx-python-lib/issues",
          "Repository, https://github.com/CycloneDX/cyclonedx-python-lib"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\cyclonedx_python_lib-3.1.5.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "dateparser",
        "version": "1.2.0",
        "summary": "Date parsing library designed to parse dates from HTML pages",
        "description": "==========================\nIntroduction to dateparser\n==========================\n\n\nFeatures\n========\n\n* Generic parsing of dates in over 200 language locales plus numerous formats in a language agnostic fashion.\n* Generic parsing of relative dates like: ``'1 min ago'``, ``'2 weeks ago'``, ``'3 months, 1 week and 1 day ago'``, ``'in 2 days'``, ``'tomorrow'``.\n* Generic parsing of dates with time zones abbreviations or UTC offsets like: ``'August 14, 2015 EST'``, ``'July 4, 2013 PST'``, ``'21 July 2013 10:15 pm +0500'``.\n* Date lookup in longer texts.\n* Support for non-Gregorian calendar systems. See `Supported Calendars`_.\n* Extensive test coverage.\n\n\nBasic Usage\n===========\n\nThe most straightforward way is to use the `dateparser.parse <#dateparser.parse>`_ function,\nthat wraps around most of the functionality in the module.\n\n\n   \n   :noindex:\n\n\nPopular Formats\n---------------\n\n    >>> import dateparser\n    >>> dateparser.parse('12/12/12')\n    datetime.datetime(2012, 12, 12, 0, 0)\n    >>> dateparser.parse('Fri, 12 Dec 2014 10:55:50')\n    datetime.datetime(2014, 12, 12, 10, 55, 50)\n    >>> dateparser.parse('Martes 21 de Octubre de 2014')  # Spanish (Tuesday 21 October 2014)\n    datetime.datetime(2014, 10, 21, 0, 0)\n    >>> dateparser.parse('Le 11 DÃ©cembre 2014 Ã  09:00')  # French (11 December 2014 at 09:00)\n    datetime.datetime(2014, 12, 11, 9, 0)\n    >>> dateparser.parse('13 ÑÐ½Ð²Ð°Ñ€Ñ 2015 Ð³. Ð² 13:34')  # Russian (13 January 2015 at 13:34)\n    datetime.datetime(2015, 1, 13, 13, 34)\n    >>> dateparser.parse('1 à¹€à¸”à¸·à¸­à¸™à¸•à¸¸à¸¥à¸²à¸„à¸¡ 2005, 1:00 AM')  # Thai (1 October 2005, 1:00 AM)\n    datetime.datetime(2005, 10, 1, 1, 0)\n\nThis will try to parse a date from the given string, attempting to\ndetect the language each time.\n\nYou can specify the language(s), if known, using ``languages`` argument. In this case, given languages are used and language detection is skipped:\n\n    >>> dateparser.parse('2015, Ago 15, 1:08 pm', languages=['pt', 'es'])\n    datetime.datetime(2015, 8, 15, 13, 8)\n\nIf you know the possible formats of the dates, you can\nuse the ``date_formats`` argument:\n\n    >>> dateparser.parse('22 DÃ©cembre 2010', date_formats=['%d %B %Y'])\n    datetime.datetime(2010, 12, 22, 0, 0)\n\n\nRelative Dates\n--------------\n\n    >>> parse('1 hour ago')\n    datetime.datetime(2015, 5, 31, 23, 0)\n    >>> parse('Il ya 2 heures')  # French (2 hours ago)\n    datetime.datetime(2015, 5, 31, 22, 0)\n    >>> parse('1 anno 2 mesi')  # Italian (1 year 2 months)\n    datetime.datetime(2014, 4, 1, 0, 0)\n    >>> parse('yaklaÅŸÄ±k 23 saat Ã¶nce')  # Turkish (23 hours ago)\n    datetime.datetime(2015, 5, 31, 1, 0)\n    >>> parse('Hace una semana')  # Spanish (a week ago)\n    datetime.datetime(2015, 5, 25, 0, 0)\n    >>> parse('2å°æ—¶å‰')  # Chinese (2 hours ago)\n    datetime.datetime(2015, 5, 31, 22, 0)\n\n.. note:: Testing above code might return different values for you depending on your environment's current date and time.\n\n.. note:: For `Finnish` language, please specify ``settings={'SKIP_TOKENS': []}`` to correctly parse relative dates.\n\nOOTB Language Based Date Order Preference\n-----------------------------------------\n\n   >>> # parsing ambiguous date\n   >>> parse('02-03-2016')  # assumes english language, uses MDY date order\n   datetime.datetime(2016, 2, 3, 0, 0)\n   >>> parse('le 02-03-2016')  # detects french, uses DMY date order\n   datetime.datetime(2016, 3, 2, 0, 0)\n\n.. note:: Ordering is not locale based, that's why do not expect `DMY` order for UK/Australia English. You can specify date order in that case as follows using `settings`:\n\n    >>> parse('18-12-15 06:00', settings={'DATE_ORDER': 'DMY'})\n    datetime.datetime(2015, 12, 18, 6, 0)\n\nFor more on date order, please look at `settings`.\n\n\nTimezone and UTC Offset\n-----------------------\n\nBy default, `dateparser` returns tzaware `datetime` if timezone is present in date string. Otherwise, it returns a naive `datetime` object.\n\n    >>> parse('January 12, 2012 10:00 PM EST')\n    datetime.datetime(2012, 1, 12, 22, 0, tzinfo=<StaticTzInfo 'EST'>)\n\n    >>> parse('January 12, 2012 10:00 PM -0500')\n    datetime.datetime(2012, 1, 12, 22, 0, tzinfo=<StaticTzInfo 'UTC\\-05:00'>)\n\n    >>> parse('2 hours ago EST')\n    datetime.datetime(2017, 3, 10, 15, 55, 39, 579667, tzinfo=<StaticTzInfo 'EST'>)\n\n    >>> parse('2 hours ago -0500')\n    datetime.datetime(2017, 3, 10, 15, 59, 30, 193431, tzinfo=<StaticTzInfo 'UTC\\-05:00'>)\n\n If date has no timezone name/abbreviation or offset, you can specify it using `TIMEZONE` setting.\n\n    >>> parse('January 12, 2012 10:00 PM', settings={'TIMEZONE': 'US/Eastern'})\n    datetime.datetime(2012, 1, 12, 22, 0)\n\n    >>> parse('January 12, 2012 10:00 PM', settings={'TIMEZONE': '+0500'})\n    datetime.datetime(2012, 1, 12, 22, 0)\n\n``TIMEZONE`` option may not be useful alone as it only attaches given timezone to\nresultant ``datetime`` object. But can be useful in cases where you want conversions from and to different\ntimezones or when simply want a tzaware date with given timezone info attached.\n\n    >>> parse('January 12, 2012 10:00 PM', settings={'TIMEZONE': 'US/Eastern', 'RETURN_AS_TIMEZONE_AWARE': True})\n    datetime.datetime(2012, 1, 12, 22, 0, tzinfo=<DstTzInfo 'US/Eastern' EST-1 day, 19:00:00 STD>)\n\n\n    >>> parse('10:00 am', settings={'TIMEZONE': 'EST', 'TO_TIMEZONE': 'EDT'})\n    datetime.datetime(2016, 9, 25, 11, 0)\n\nSome more use cases for conversion of timezones.\n\n    >>> parse('10:00 am EST', settings={'TO_TIMEZONE': 'EDT'})  # date string has timezone info\n    datetime.datetime(2017, 3, 12, 11, 0, tzinfo=<StaticTzInfo 'EDT'>)\n\n    >>> parse('now EST', settings={'TO_TIMEZONE': 'UTC'})  # relative dates\n    datetime.datetime(2017, 3, 10, 23, 24, 47, 371823, tzinfo=<StaticTzInfo 'UTC'>)\n\nIn case, no timezone is present in date string or defined in `settings`. You can still\nreturn tzaware ``datetime``. It is especially useful in case of relative dates when uncertain\nwhat timezone is relative base.\n\n    >>> parse('2 minutes ago', settings={'RETURN_AS_TIMEZONE_AWARE': True})\n    datetime.datetime(2017, 3, 11, 4, 25, 24, 152670, tzinfo=<DstTzInfo 'Asia/Karachi' PKT+5:00:00 STD>)\n\nIn case, you want to compute relative dates in UTC instead of default system's local timezone, you can use `TIMEZONE` setting.\n\n    >>> parse('4 minutes ago', settings={'TIMEZONE': 'UTC'})\n    datetime.datetime(2017, 3, 10, 23, 27, 59, 647248, tzinfo=<StaticTzInfo 'UTC'>)\n\n.. note:: In case, when timezone is present both in string and also specified using `settings`, string is parsed into tzaware representation and then converted to timezone specified in `settings`.\n\n   >>> parse('10:40 pm PKT', settings={'TIMEZONE': 'UTC'})\n   datetime.datetime(2017, 3, 12, 17, 40, tzinfo=<StaticTzInfo 'UTC'>)\n\n   >>> parse('20 mins ago EST', settings={'TIMEZONE': 'UTC'})\n   datetime.datetime(2017, 3, 12, 21, 16, 0, 885091, tzinfo=<StaticTzInfo 'UTC'>)\n\nFor more on timezones, please look at `settings`.\n\n\nIncomplete Dates\n----------------\n\n    >>> from dateparser import parse\n    >>> parse('December 2015')  # default behavior\n    datetime.datetime(2015, 12, 16, 0, 0)\n    >>> parse('December 2015', settings={'PREFER_DAY_OF_MONTH': 'last'})\n    datetime.datetime(2015, 12, 31, 0, 0)\n    >>> parse('December 2015', settings={'PREFER_DAY_OF_MONTH': 'first'})\n    datetime.datetime(2015, 12, 1, 0, 0)\n\n    >>> parse('March')\n    datetime.datetime(2015, 3, 16, 0, 0)\n    >>> parse('March', settings={'PREFER_DATES_FROM': 'future'})\n    datetime.datetime(2016, 3, 16, 0, 0)\n    >>> # parsing with preference set for 'past'\n    >>> parse('August', settings={'PREFER_DATES_FROM': 'past'})\n    datetime.datetime(2015, 8, 15, 0, 0)\n\n    >>> import dateparser\n    >>> dateparser.parse(\"2015\") # default behavior\n    datetime.datetime(2015, 3, 27, 0, 0)\n    >>> dateparser.parse(\"2015\", settings={\"PREFER_MONTH_OF_YEAR\": \"last\"})\n    datetime.datetime(2015, 12, 27, 0, 0)\n    >>> dateparser.parse(\"2015\", settings={\"PREFER_MONTH_OF_YEAR\": \"first\"})\n    datetime.datetime(2015, 1, 27, 0, 0)\n    >>> dateparser.parse(\"2015\", settings={\"PREFER_MONTH_OF_YEAR\": \"current\"})\n    datetime.datetime(2015, 3, 27, 0, 0)\n\nYou can also ignore parsing incomplete dates altogether by setting `STRICT_PARSING` flag as follows:\n\n    >>> parse('December 2015', settings={'STRICT_PARSING': True})\n    None\n\nFor more on handling incomplete dates, please look at `settings`.\n\n\nSearch for Dates in Longer Chunks of Text\n-----------------------------------------\n\n.. warning:: Support for searching dates is really limited and needs a lot of improvement, we look forward to community's contribution to get better on that part. See \"`contributing`\".\n\n\nYou can extract dates from longer strings of text. They are returned as list of tuples with text chunk containing the date and parsed datetime object.\n\n\n\n   \n   :noindex:\n\nAdvanced Usage\n==============\nIf you need more control over what is being parser check the `settings` section as well as the `using-datedataparser` section.\n\n\nDependencies\n============\n\n`dateparser` relies on following libraries in some ways:\n\n  * dateutil_'s module ``relativedelta`` for its freshness parser.\n  * convertdate_ to convert *Jalali* dates to *Gregorian*.\n  * hijri-converter_ to convert *Hijri* dates to *Gregorian*.\n  * tzlocal_ to reliably get local timezone.\n  * ruamel.yaml_ (optional) for operations on language files.\n\n.. _dateutil: https://pypi.python.org/pypi/python-dateutil\n.. _convertdate: https://pypi.python.org/pypi/convertdate\n.. _hijri-converter: https://pypi.python.org/pypi/hijri-converter\n.. _tzlocal: https://pypi.python.org/pypi/tzlocal\n.. _ruamel.yaml: https://pypi.python.org/pypi/ruamel.yaml\n\nSupported languages and locales\n===============================\nYou can check the supported locales by visiting the \"`supported-locales`\" section.\n\n\nSupported Calendars\n===================\n\nApart from the Georgian calendar, `dateparser` supports the `Persian Jalali calendar` and the `Hijri/Islami calendar`\n\nTo be able to use them you need to install the `calendar` extra by typing:\n\n    pip install dateparser[calendars]\n\n\n* Example using the `Persian Jalali calendar`. For more information, refer to `Persian Jalali Calendar <https://en.wikipedia.org/wiki/Iranian_calendars#Zoroastrian_calendar>`_.\n\n    >>> from dateparser.calendars.jalali import JalaliCalendar\n    >>> JalaliCalendar('Ø¬Ù…Ø¹Ù‡ Ø³ÛŒ Ø§Ù… Ø§Ø³ÙÙ†Ø¯ Û±Û³Û¸Û·').get_date()\n    DateData(date_obj=datetime.datetime(2009, 3, 20, 0, 0), period='day', locale=None)\n\n\n* Example using the `Hijri/Islamic Calendar`. For more information, refer to `Hijri Calendar <https://en.wikipedia.org/wiki/Islamic_calendar>`_.\n\n    >>> from dateparser.calendars.hijri import HijriCalendar\n    >>> HijriCalendar('17-01-1437 Ù‡Ù€ 08:30 Ù…Ø³Ø§Ø¡Ù‹').get_date()\n    DateData(date_obj=datetime.datetime(2015, 10, 30, 20, 30), period='day', locale=None)\n\n.. note:: `HijriCalendar` only works with Python â‰¥ 3.6.\n\n\n.. :changelog:\n\nHistory\n=======\n\n1.2.0 (2023-11-17)\n------------------\n\nNew features:\n\n- New ``PREFER_MONTH_OF_YEAR`` setting (#1146)\n\nFixes:\n\n- Absolute years in Russian are no longer being treated as a number of years in\n  the past (#1129)\n\nCleanups and internal improvements:\n\n- Removed the use of ``datetime.utcnow``, deprecated on Python 3.12 (#1179)\n- Applied Black formatting to the code base (#1158)\n- Initial integration with OSSFuzz (#1198)\n- Extended test cases (#1191)\n\n\n1.1.8 (2023-03-22)\n------------------\n\nImprovements:\n\n- Improved date parsing for Chinese (#1148)\n- Improved date parsing for Czech (#1151)\n- Reorder language by popularity (#1152)\n- Fix leak of memory in cache (#1140)\n- Add support for \"\\d units later\" (#1154)\n- Move modification in CLDR data to yaml (#1153)\n- Add support to use timezone via settings to get PREFER_DATES_FROM result (#1155)\n\n\n1.1.7 (2023-02-02)\n------------------\n\nImprovements:\n\n- Add an â€œagoâ€ synonym for Arabic (#1128)\n- Improved date parsing for Czech (#1131)\n- Improved date parsing for Indonesian (#1134)\n\n\n1.1.6 (2023-01-12)\n------------------\n\nImprovements:\n\n- Fix the bug where Monday is parsed as a month (#1121)\n- Prevent ReDoS in Spanish sentence splitting regex (#1084)\n\n\n1.1.5 (2022-12-29)\n------------------\n\nImprovements:\n\n- Parse short versions of day, month, and year (#1103)\n- Add a test for â€œin 1dâ€ (#1104)\n- Update languages_info (#1107)\n- Add a workaround for zipimporter not having exec_module before Python 3.10 (#1069)\n- Stabilize tests at midnight (#1111)\n- Add a test case for French (#1110)\n\nCleanups:\n\n- Remove the requirements-build file (#1113)\n\n\n1.1.4 (2022-11-21)\n------------------\n\nImprovements:\n\n- Improved support for languages such as Slovak, Indonesian, Hindi, German and Japanese (#1064, #1094, #986, #1071, #1068)\n- Recursively create a model home (#996)\n- Replace regex sub with simple string replace (#1095)\n- Add Python 3.10, 3.11 support (#1096)\n- Drop support for Python 3.5, 3.6 versions (#1097)\n\n\n1.1.3 (2022-11-03)\n------------------\n\nNew features:\n\n- Add support for fractional units (#876)\n\nImprovements:\n\n- Fix the returned datetime skipping a day with time+timezone input and PREFER_DATES_FROM = 'future' (#1002)\n- Fix input translatation breaking keep_formatting (#720)\n- English: support \"till date\" (#1005)\n- English: support â€œafterâ€ and â€œbeforeâ€ in relative dates (#1008)\n\nCleanups:\n\n- Reorganize internal data (#1090)\n- CI updates (#1088)\n\n\n1.1.2 (2022-10-20)\n------------------\n\nImprovements:\n\n- Added support for negative timestamp (#1060)\n- Fixed PytzUsageWarning for Python versions >= 3.6 (#1062)\n- Added support for dates with dots and spaces (#1028)\n- Improved support for Ukrainian, Croatian and Russian (#1072, #1074, #1079, #1082, #1073, #1083)\n- Added support for parsing Unix timestamps consistently regardless of timezones (#954)\n- Improved tests (#1086)\n\n\n1.1.1 (2022-03-17)\n------------------\n\nImprovements:\n\n- Fixed issue with regex library by pinning dependencies to an earlier version (< 2022.3.15, #1046).\n- Extended support for Russian language dates starting with lowercase (#999).\n- Allowed to use_given_order for languages too (#997).\n- Fixed link to settings section (#1018).\n- Defined UTF-8 encoding for Windows (#998).\n- Fixed directories creation error in CLI utils (#1022).\n\n\n1.1.0 (2021-10-04)\n------------------\n\nNew features:\n\n* Support language detection based on ``langdetect``, ``fastText``, or a\n  custom implementation (see #932)\n* Add support for 'by <time>' (see #839)\n* Sort default language list by internet usage (see #805)\n\nImprovements:\n\n* Improved support of Chinese (#910), Czech (#977)\n* Improvements in ``search_dates`` (see #953)\n* Make order of previous locales deterministic (see #851)\n* Fix parsing with trailing space (see #841)\n* Consider ``RETURN_TIME_AS_PERIOD`` for timestamp times (see #922)\n* Exclude failing regex version (see #974)\n* Ongoing work multithreading support (see #881, #885)\n* Add demo URL (see #883)\n\nQA:\n\n* Migrate pipelines from Travis CI to Github Actions (see #859, #879, #884,\n  #886, #911, #966)\n* Use versioned CLDR data (see #825)\n* Add a script to update table of supported languages and locales (see #601)\n* Sort 'skip' keys in yaml files (see #844)\n* Improve test coverage (see #827)\n* Code cleanup (see #888, #907, #951, #958, #957)\n\n\n1.0.0 (2020-10-29)\n------------------\n\nBreaking changes:\n\n* Drop support for Python 2.7 and pypy (see #727, #744, #748, #749, #754, #755, #758, #761, #763, #764, #777 and #783)\n* Now ``DateDataParser.get_date_data()`` returns a ``DateData`` object instead of a ``dict`` (see #778).\n* From now wrong ``settings`` are not silenced and raise ``SettingValidationError`` (see #797)\n* Now ``dateparser.parse()`` is deterministic and doesn't try previous locales. Also, ``DateDataParser.get_date_data()`` doesn't try the previous locales by default (see #781)\n* Remove the ``'base-formats'`` parser (see #721)\n* Extract the ``'no-spaces-time'`` parser from the ``'absolute-time'`` parser and make it an optional parser (see #786)\n* Remove ``numeral_translation_data`` (see #782)\n* Remove the undocumented ``SKIP_TOKENS_PARSER`` and ``FUZZY`` settings (see #728, #794)\n* Remove support for using strings in ``date_formats`` (see #726)\n* The undocumented ``ExactLanguageSearch`` class has been moved to the private scope and some internal methods have changed (see #778)\n* Changes in ``dateparser.utils``: ``normalize_unicode()`` doesn't accept ``bytes`` as input and ``convert_to_unicode`` has been deprecated (see #749)\n\nNew features:\n\n* Add Python 3.9 support (see #732, #823)\n* Detect hours separated with a period/dot (see #741)\n* Add support for \"decade\" (see #762)\n* Add support for the hijri calendar in Python â‰¥ 3.6 (see #718)\n\nImprovements:\n\n* New logo! (see #719)\n* Improve the README and docs (see #779, #722)\n* Fix the \"calendars\" extra (see #740)\n* Fix leap years when ``PREFER_DATES_FROM`` is set (see #738)\n* Fix ``STRICT_PARSING`` setting in ``no-spaces-time`` parser (see #715)\n* Consider ``RETURN_AS_TIME_PERIOD`` setting for ``relative-time`` parser (see #807)\n* Parse the 24hr time format with meridian info (see #634)\n* Other small improvements (see #698, #709, #710, #712, #730, #731, #735, #739, #784, #788, #795 and #801)\n\n\n0.7.6 (2020-06-12)\n------------------\n\nImprovements:\n\n* Rename ``scripts`` to ``dateparser_scripts`` to avoid name collisions with modules from other packages or projects (see #707)\n\n\n0.7.5 (2020-06-10)\n------------------\n\nNew features:\n\n* Add Python 3.8 support (see #664)\n* Implement a ``REQUIRE_PARTS`` setting (see #703)\n* Add support for subscript and superscript numbers (see #684)\n* Extended French support (see #672)\n* Extended German support (see #673)\n\n\nImprovements:\n\n* Migrate test suite to Pytest (see #662)\n* Add test to check the `yaml` and `json` files content (see #663 and #692)\n* Add flake8 pipeline with pytest-flake8 (see #665)\n* Add partial support for 8-digit dates without separators (see #639)\n* Fix possible ``OverflowError`` errors and explicitly avoid to raise ``ValueError`` when parsing relative dates (see #686)\n* Fix double-digit GMT and UTC parsing (see #632)\n* Fix bug when using ``DATE_ORDER`` (see #628)\n* Fix bug when parsing relative time with timezone (see #503)\n* Fix milliseconds parsing (see #572 and #661)\n* Fix wrong values to be interpreted as ``'future'`` in ``PREFER_DATES_FROM`` (see #629)\n* Other small improvements (see #667, #675, #511, #626, #512, #509, #696, #702 and #699)\n\n\n0.7.4 (2020-03-06)\n------------------\nNew features:\n\n* Extended Norwegian support (see #598)\n* Implement a ``PARSERS`` setting (see #603)\n\nImprovements:\n\n* Add support for ``PREFER_DATES_FROM`` in relative/freshness parser (see #414)\n* Add support for ``PREFER_DAY_OF_MONTH`` in base-formats parser (see #611)\n* Added UTC -00:00 as a valid offset (see #574)\n* Fix support for â€œoneâ€ (see #593)\n* Fix TypeError when parsing some invalid dates (see #536)\n* Fix tokenizer for non recognized characters (see #622)\n* Prevent installing regex 2019.02.19 (see #600)\n* Resolve DeprecationWarning related to raw string escape sequences (see #596)\n* Implement a tox environment to build the documentation (see #604)\n* Improve tests stability (see #591, #605)\n* Documentation improvements (see #510, #578, #619, #614, #620)\n* Performance improvements (see #570, #569, #625)\n\n\n0.7.3 (2020-03-06)\n------------------\n* Broken version\n\n\n0.7.2 (2019-09-17)\n------------------\n\nFeatures:\n\n* Extended Czech support\n* Added ``time`` to valid periods\n* Added timezone information to dates found with ``search_dates()``\n* Support strings as date formats\n\n\nImprovements:\n\n* Fixed Collections ABCs depreciation warning\n* Fixed dates with trailing colons not being parsed\n* Fixed date format override on any settings change\n* Fixed parsing current weekday as past date, regardless of settings\n* Added UTC -2:30 as a valid offset\n* Added Python 3.7 to supported versions, dropped support for Python 3.3 and 3.4\n* Moved to importlib from imp where possible\n* Improved support for Catalan\n* Documentation improvements\n\n\n0.7.1 (2019-02-12)\n------------------\n\nFeatures/news:\n\n* Added detected language to return value of ``search_dates()``\n* Performance improvements\n* Refreshed versions of dependencies\n\nImprovements:\n\n* Fixed unpickleable ``DateTime`` objects with timezones\n* Fixed regex pattern to avoid new behaviour of re.split in Python 3.7\n* Fixed an exception thrown when parsing colons\n* Fixed tests failing on days with number greater than 30\n* Fixed ``ZeroDivisionError`` exceptions\n\n\n\n0.7.0 (2018-02-08)\n------------------\n\nFeatures added during Google Summer of Code 2017:\n\n* Harvesting language data from Unicode CLDR database (https://github.com/unicode-cldr/cldr-json), which includes over 200 locales (#321) - authored by Sarthak Maddan.\n  See full currently supported locale list in README.\n* Extracting dates from longer strings of text (#324) - authored by Elena Zakharova.\n  Special thanks for their awesome contributions!\n\n\nNew features:\n\n* Added (independently from CLDR) Georgian (#308) and Swedish (#305)\n\nImprovements:\n\n* Improved support of Chinese (#359), Thai (#345), French (#301, #304), Russian (#302)\n* Removed ruamel.yaml from dependencies (#374). This should reduce the number of installation issues and improve performance as the result of moving away from YAML as basic data storage format.\n  Note that YAML is still used as format for support language files.\n* Improved performance through using pre-compiling frequent regexes and lazy loading of data (#293, #294, #295, #315)\n* Extended tests (#316, #317, #318, #323)\n* Updated nose_parameterized to its current package, parameterized (#381)\n\n\nPlanned for next release:\n\n* Full language and locale names\n* Performance and stability improvements\n* Documentation improvements\n\n\n0.6.0 (2017-03-13)\n------------------\n\nNew features:\n\n* Consistent parsing in terms of true python representation of date string. See #281\n* Added support for Bangla, Bulgarian and Hindi languages.\n\nImprovements:\n\n* Major bug fixes related to parser and system's locale. See #277, #282\n* Type check for timezone arguments in settings. see #267\n* Pinned dependencies' versions in requirements. See #265\n* Improved support for cn, es, dutch languages. See #274, #272, #285\n\nPackaging:\n\n* Make calendars extras to be used at the time of installation if need to use calendars feature.\n\n\n0.5.1 (2016-12-18)\n------------------\n\nNew features:\n\n* Added support for Hebrew\n\nImprovements:\n\n* Safer loading of YAML. See #251\n* Better timezone parsing for freshness dates. See #256\n* Pinned dependencies' versions in requirements. See #265\n* Improved support for zh, fi languages. See #249, #250, #248, #244\n\n\n0.5.0 (2016-09-26)\n------------------\n\nNew features:\n\n* ``DateDataParser`` now also returns detected language in the result dictionary.\n* Explicit and lucid timezone conversion for a given datestring using ``TIMEZONE``, ``TO_TIMEZONE`` settings.\n* Added Hungarian language.\n* Added setting, ``STRICT_PARSING`` to ignore incomplete dates.\n\nImprovements:\n\n* Fixed quite a few parser bugs reported in issues #219, #222, #207, #224.\n* Improved support for chinese language.\n* Consistent interface for both Jalali and Hijri parsers.\n\n\n0.4.0 (2016-06-17)\n------------------\n\nNew features:\n\n* Support for Language based date order preference while parsing ambiguous dates.\n* Support for parsing dates with no spaces in between components.\n* Support for custom date order preference using ``settings``.\n* Support for parsing generic relative dates in future.e.g. \"tomorrow\", \"in two weeks\", etc.\n* Added ``RELATIVE_BASE`` settings to set date context to any datetime in past or future.\n* Replaced ``dateutil.parser.parse`` with dateparser's own parser.\n\nImprovements:\n\n* Added simplifications for \"12 noon\" and \"12 midnight\".\n* Fixed several bugs\n* Replaced PyYAML library by its active fork `ruamel.yaml` which also fixed the issues with installation on windows using python35.\n* More predictable ``date_formats`` handling.\n\n\n0.3.5 (2016-04-27)\n------------------\n\nNew features:\n\n* Danish language support.\n* Japanese language support.\n* Support for parsing date strings with accents.\n\nImprovements:\n\n* Transformed languages.yaml into base file and separate files for each language.\n* Fixed vietnamese language simplifications.\n* No more version restrictions for python-dateutil.\n* Timezone parsing improvements.\n* Fixed test environments.\n* Cleaned language codes. Now we strictly follow codes as in ISO 639-1.\n* Improved chinese dates parsing.\n\n\n0.3.4 (2016-03-03)\n------------------\n\nImprovements:\n\n* Fixed broken version 0.3.3 by excluding latest python-dateutil version.\n\n0.3.3 (2016-02-29)\n------------------\n\nNew features:\n\n* Finnish language support.\n\nImprovements:\n\n* Faster parsing with switching to regex module.\n* ``RETURN_AS_TIMEZONE_AWARE`` setting to return tz aware date object.\n* Fixed conflicts with month/weekday names similarity across languages.\n\n0.3.2 (2016-01-25)\n------------------\n\nNew features:\n\n* Added Hijri Calendar support.\n* Added settings for better control over parsing dates.\n* Support to convert parsed time to the given timezone for both complete and relative dates.\n\nImprovements:\n\n* Fixed problem with caching `datetime.now` in `FreshnessDateDataParser`.\n* Added month names and week day names abbreviations to several languages.\n* More simplifications for Russian and Ukrainian languages.\n* Fixed problem with parsing time component of date strings with several kinds of apostrophes.\n\n\n0.3.1 (2015-10-28)\n------------------\n\nNew features:\n\n* Support for Jalali Calendar.\n* Belarusian language support.\n* Indonesian language support.\n\n\nImprovements:\n\n* Extended support for Russian and Polish.\n* Fixed bug with time zone recognition.\n* Fixed bug with incorrect translation of \"second\" for Portuguese.\n\n\n0.3.0 (2015-07-29)\n------------------\n\nNew features:\n\n* Compatibility with Python 3 and PyPy.\n\nImprovements:\n\n* `languages.yaml` data cleaned up to make it human-readable.\n* Improved Spanish date parsing.\n\n\n0.2.1 (2015-07-13)\n------------------\n\n* Support for generic parsing of dates with UTC offset.\n* Support for Tagalog/Filipino dates.\n* Improved support for French and Spanish dates.\n\n\n0.2.0 (2015-06-17)\n------------------\n\n* Easy to use ``parse`` function\n* Languages definitions using YAML.\n* Using translation based approach for parsing non-english languages. Previously, `dateutil.parserinfo` was used for language definitions.\n* Better period extraction.\n* Improved tests.\n* Added a number of new simplifications for more comprehensive generic parsing.\n* Improved validation for dates.\n* Support for Polish, Thai and Arabic dates.\n* Support for `pytz` timezones.\n* Fixed building and packaging issues.\n\n\n0.1.0 (2014-11-24)\n------------------\n\n* First release on PyPI.\n",
        "keywords": [
          "dateparser"
        ],
        "home_page": "https://github.com/scrapinghub/dateparser",
        "author": "Scrapinghub",
        "author_email": "opensource@zyte.com",
        "license": "BSD",
        "license_file": [
          "LICENSE",
          "AUTHORS.rst"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Natural Language :: English",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: Implementation :: CPython"
        ],
        "requires_dist": [
          "python-dateutil",
          "pytz",
          "regex !=2019.02.19,!=2021.8.27",
          "tzlocal",
          "hijri-converter ; extra == 'calendars'",
          "convertdate ; extra == 'calendars'",
          "fasttext ; extra == 'fasttext'",
          "langdetect ; extra == 'langdetect'"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "History, https://dateparser.readthedocs.io/en/latest/history.html"
        ],
        "provides_extra": [
          "calendars",
          "fasttext",
          "langdetect"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\dateparser-1.2.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "decorator",
        "version": "5.1.1",
        "platform": [
          "All"
        ],
        "summary": "Decorators for Humans",
        "description": "Decorators for Humans\n=====================\n\nThe goal of the decorator module is to make it easy to define\nsignature-preserving function decorators and decorator factories.\nIt also includes an implementation of multiple dispatch and other niceties\n(please check the docs). It is released under a two-clauses\nBSD license, i.e. basically you can do whatever you want with it but I am not\nresponsible.\n\nInstallation\n-------------\n\nIf you are lazy, just perform\n\n ``$ pip install decorator``\n\nwhich will install just the module on your system.\n\nIf you prefer to install the full distribution from source, including\nthe documentation, clone the `GitHub repo`_ or download the tarball_, unpack it and run\n\n ``$ pip install .``\n\nin the main directory, possibly as superuser.\n\n.. _tarball: https://pypi.org/project/decorator/#files\n.. _GitHub repo: https://github.com/micheles/decorator\n\nTesting\n--------\n\nIf you have the source code installation you can run the tests with\n\n `$ python src/tests/test.py -v`\n\nor (if you have setuptools installed)\n\n `$ python setup.py test`\n\nNotice that you may run into trouble if in your system there\nis an older version of the decorator module; in such a case remove the\nold version. It is safe even to copy the module `decorator.py` over\nan existing one, since we kept backward-compatibility for a long time.\n\nRepository\n---------------\n\nThe project is hosted on GitHub. You can look at the source here:\n\n https://github.com/micheles/decorator\n\nDocumentation\n---------------\n\nThe documentation has been moved to https://github.com/micheles/decorator/blob/master/docs/documentation.md\n\nFrom there you can get a PDF version by simply using the print\nfunctionality of your browser.\n\nHere is the documentation for previous versions of the module:\n\nhttps://github.com/micheles/decorator/blob/4.3.2/docs/tests.documentation.rst\nhttps://github.com/micheles/decorator/blob/4.2.1/docs/tests.documentation.rst\nhttps://github.com/micheles/decorator/blob/4.1.2/docs/tests.documentation.rst\nhttps://github.com/micheles/decorator/blob/4.0.0/documentation.rst\nhttps://github.com/micheles/decorator/blob/3.4.2/documentation.rst\n\nFor the impatient\n-----------------\n\nHere is an example of how to define a family of decorators tracing slow\noperations:\n\n.. code-block:: python\n\n   from decorator import decorator\n\n   @decorator\n   def warn_slow(func, timelimit=60, *args, **kw):\n       t0 = time.time()\n       result = func(*args, **kw)\n       dt = time.time() - t0\n       if dt > timelimit:\n           logging.warn('%s took %d seconds', func.__name__, dt)\n       else:\n           logging.info('%s took %d seconds', func.__name__, dt)\n       return result\n\n   @warn_slow  # warn if it takes more than 1 minute\n   def preprocess_input_files(inputdir, tempdir):\n       ...\n\n   @warn_slow(timelimit=600)  # warn if it takes more than 10 minutes\n   def run_calculation(tempdir, outdir):\n       ...\n\nEnjoy!\n\n\n",
        "keywords": [
          "decorators",
          "generic",
          "utility"
        ],
        "home_page": "https://github.com/micheles/decorator",
        "author": "Michele Simionato",
        "author_email": "michele.simionato@gmail.com",
        "license": "new BSD License",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: Implementation :: CPython",
          "Topic :: Software Development :: Libraries",
          "Topic :: Utilities"
        ],
        "requires_python": ">=3.5"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\decorator-5.1.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "defusedxml",
        "version": "0.7.1",
        "platform": [
          "all"
        ],
        "summary": "XML bomb protection for Python stdlib modules",
        "description": "===================================================\ndefusedxml -- defusing XML bombs and other exploits\n===================================================\n\n.. image:: https://img.shields.io/pypi/v/defusedxml.svg\n    :target: https://pypi.org/project/defusedxml/\n    :alt: Latest Version\n\n.. image:: https://img.shields.io/pypi/pyversions/defusedxml.svg\n    :target: https://pypi.org/project/defusedxml/\n    :alt: Supported Python versions\n\n.. image:: https://travis-ci.org/tiran/defusedxml.svg?branch=master\n    :target: https://travis-ci.org/tiran/defusedxml\n    :alt: Travis CI\n\n.. image:: https://codecov.io/github/tiran/defusedxml/coverage.svg?branch=master\n    :target: https://codecov.io/github/tiran/defusedxml?branch=master\n    :alt: codecov\n\n.. image:: https://img.shields.io/pypi/dm/defusedxml.svg\n    :target: https://pypistats.org/packages/defusedxml\n    :alt: PyPI downloads\n\n.. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n    :target: https://github.com/psf/black\n    :alt: Code style: black\n\n..\n\n    \"It's just XML, what could probably go wrong?\"\n\nChristian Heimes <christian@python.org>\n\nSynopsis\n========\n\nThe results of an attack on a vulnerable XML library can be fairly dramatic.\nWith just a few hundred **Bytes** of XML data an attacker can occupy several\n**Gigabytes** of memory within **seconds**. An attacker can also keep\nCPUs busy for a long time with a small to medium size request. Under some\ncircumstances it is even possible to access local files on your\nserver, to circumvent a firewall, or to abuse services to rebound attacks to\nthird parties.\n\nThe attacks use and abuse less common features of XML and its parsers. The\nmajority of developers are unacquainted with features such as processing\ninstructions and entity expansions that XML inherited from SGML. At best\nthey know about ``<!DOCTYPE>`` from experience with HTML but they are not\naware that a document type definition (DTD) can generate an HTTP request\nor load a file from the file system.\n\nNone of the issues is new. They have been known for a long time. Billion\nlaughs was first reported in 2003. Nevertheless some XML libraries and\napplications are still vulnerable and even heavy users of XML are\nsurprised by these features. It's hard to say whom to blame for the\nsituation. It's too short sighted to shift all blame on XML parsers and\nXML libraries for using insecure default settings. After all they\nproperly implement XML specifications. Application developers must not rely\nthat a library is always configured for security and potential harmful data\nby default.\n\n\n.. contents:: Table of Contents\n   :depth: 2\n\n\nAttack vectors\n==============\n\nbillion laughs / exponential entity expansion\n---------------------------------------------\n\nThe `Billion Laughs`_ attack -- also known as exponential entity expansion --\nuses multiple levels of nested entities. The original example uses 9 levels\nof 10 expansions in each level to expand the string ``lol`` to a string of\n3 * 10 :sup:`9` bytes, hence the name \"billion laughs\". The resulting string\noccupies 3 GB (2.79 GiB) of memory; intermediate strings require additional\nmemory. Because most parsers don't cache the intermediate step for every\nexpansion it is repeated over and over again. It increases the CPU load even\nmore.\n\nAn XML document of just a few hundred bytes can disrupt all services on a\nmachine within seconds.\n\nExample XML::\n\n    <!DOCTYPE xmlbomb [\n    <!ENTITY a \"1234567890\" >\n    <!ENTITY b \"&a;&a;&a;&a;&a;&a;&a;&a;\">\n    <!ENTITY c \"&b;&b;&b;&b;&b;&b;&b;&b;\">\n    <!ENTITY d \"&c;&c;&c;&c;&c;&c;&c;&c;\">\n    ]>\n    <bomb>&d;</bomb>\n\n\nquadratic blowup entity expansion\n---------------------------------\n\nA quadratic blowup attack is similar to a `Billion Laughs`_ attack; it abuses\nentity expansion, too. Instead of nested entities it repeats one large entity\nwith a couple of thousand chars over and over again. The attack isn't as\nefficient as the exponential case but it avoids triggering countermeasures of\nparsers against heavily nested entities. Some parsers limit the depth and\nbreadth of a single entity but not the total amount of expanded text\nthroughout an entire XML document.\n\nA medium-sized XML document with a couple of hundred kilobytes can require a\ncouple of hundred MB to several GB of memory. When the attack is combined\nwith some level of nested expansion an attacker is able to achieve a higher\nratio of success.\n\n::\n\n    <!DOCTYPE bomb [\n    <!ENTITY a \"xxxxxxx... a couple of ten thousand chars\">\n    ]>\n    <bomb>&a;&a;&a;... repeat</bomb>\n\n\nexternal entity expansion (remote)\n----------------------------------\n\nEntity declarations can contain more than just text for replacement. They can\nalso point to external resources by public identifiers or system identifiers.\nSystem identifiers are standard URIs. When the URI is a URL (e.g. a\n``http://`` locator) some parsers download the resource from the remote\nlocation and embed them into the XML document verbatim.\n\nSimple example of a parsed external entity::\n\n    <!DOCTYPE external [\n    <!ENTITY ee SYSTEM \"http://www.python.org/some.xml\">\n    ]>\n    <root>&ee;</root>\n\nThe case of parsed external entities works only for valid XML content. The\nXML standard also supports unparsed external entities with a\n``NData declaration``.\n\nExternal entity expansion opens the door to plenty of exploits. An attacker\ncan abuse a vulnerable XML library and application to rebound and forward\nnetwork requests with the IP address of the server. It highly depends\non the parser and the application what kind of exploit is possible. For\nexample:\n\n* An attacker can circumvent firewalls and gain access to restricted\n  resources as all the requests are made from an internal and trustworthy\n  IP address, not from the outside.\n* An attacker can abuse a service to attack, spy on or DoS your servers but\n  also third party services. The attack is disguised with the IP address of\n  the server and the attacker is able to utilize the high bandwidth of a big\n  machine.\n* An attacker can exhaust additional resources on the machine, e.g. with\n  requests to a service that doesn't respond or responds with very large\n  files.\n* An attacker may gain knowledge, when, how often and from which IP address\n  an XML document is accessed.\n* An attacker could send mail from inside your network if the URL handler\n  supports ``smtp://`` URIs.\n\n\nexternal entity expansion (local file)\n--------------------------------------\n\nExternal entities with references to local files are a sub-case of external\nentity expansion. It's listed as an extra attack because it deserves extra\nattention. Some XML libraries such as lxml disable network access by default\nbut still allow entity expansion with local file access by default. Local\nfiles are either referenced with a ``file://`` URL or by a file path (either\nrelative or absolute).\n\nAn attacker may be able to access and download all files that can be read by\nthe application process. This may include critical configuration files, too.\n\n::\n\n    <!DOCTYPE external [\n    <!ENTITY ee SYSTEM \"file:///PATH/TO/simple.xml\">\n    ]>\n    <root>&ee;</root>\n\n\nDTD retrieval\n-------------\n\nThis case is similar to external entity expansion, too. Some XML libraries\nlike Python's xml.dom.pulldom retrieve document type definitions from remote\nor local locations. Several attack scenarios from the external entity case\napply to this issue as well.\n\n::\n\n    <?xml version=\"1.0\" encoding=\"utf-8\"?>\n    <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n      \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n    <html>\n        <head/>\n        <body>text</body>\n    </html>\n\n\nPython XML Libraries\n====================\n\n.. csv-table:: vulnerabilities and features\n   :header: \"kind\", \"sax\", \"etree\", \"minidom\", \"pulldom\", \"xmlrpc\", \"lxml\", \"genshi\"\n   :widths: 24, 7, 8, 8, 7, 8, 8, 8\n   :stub-columns: 0\n\n   \"billion laughs\", \"**True**\", \"**True**\", \"**True**\", \"**True**\", \"**True**\", \"False (1)\", \"False (5)\"\n   \"quadratic blowup\", \"**True**\", \"**True**\", \"**True**\", \"**True**\", \"**True**\", \"**True**\", \"False (5)\"\n   \"external entity expansion (remote)\", \"**True**\", \"False (3)\", \"False (4)\", \"**True**\", \"false\", \"False (1)\", \"False (5)\"\n   \"external entity expansion (local file)\", \"**True**\", \"False (3)\", \"False (4)\", \"**True**\", \"false\", \"**True**\", \"False (5)\"\n   \"DTD retrieval\", \"**True**\", \"False\", \"False\", \"**True**\", \"false\", \"False (1)\", \"False\"\n   \"gzip bomb\", \"False\", \"False\", \"False\", \"False\", \"**True**\", \"**partly** (2)\", \"False\"\n   \"xpath support (7)\", \"False\", \"False\", \"False\", \"False\", \"False\", \"**True**\", \"False\"\n   \"xsl(t) support (7)\", \"False\", \"False\", \"False\", \"False\", \"False\", \"**True**\", \"False\"\n   \"xinclude support (7)\", \"False\", \"**True** (6)\", \"False\", \"False\", \"False\", \"**True** (6)\", \"**True**\"\n   \"C library\", \"expat\", \"expat\", \"expat\", \"expat\", \"expat\", \"libxml2\", \"expat\"\n\n1. Lxml is protected against billion laughs attacks and doesn't do network\n   lookups by default.\n2. libxml2 and lxml are not directly vulnerable to gzip decompression bombs\n   but they don't protect you against them either.\n3. xml.etree doesn't expand entities and raises a ParserError when an entity\n   occurs.\n4. minidom doesn't expand entities and simply returns the unexpanded entity\n   verbatim.\n5. genshi.input of genshi 0.6 doesn't support entity expansion and raises a\n   ParserError when an entity occurs.\n6. Library has (limited) XInclude support but requires an additional step to\n   process inclusion.\n7. These are features but they may introduce exploitable holes, see\n   `Other things to consider`_\n\n\nSettings in standard library\n----------------------------\n\n\nxml.sax.handler Features\n........................\n\nfeature_external_ges (http://xml.org/sax/features/external-general-entities)\n  disables external entity expansion\n\nfeature_external_pes (http://xml.org/sax/features/external-parameter-entities)\n  the option is ignored and doesn't modify any functionality\n\nDOM xml.dom.xmlbuilder.Options\n..............................\n\nexternal_parameter_entities\n  ignored\n\nexternal_general_entities\n  ignored\n\nexternal_dtd_subset\n  ignored\n\nentities\n  unsure\n\n\ndefusedxml\n==========\n\nThe `defusedxml package`_ (`defusedxml on PyPI`_)\ncontains several Python-only workarounds and fixes\nfor denial of service and other vulnerabilities in Python's XML libraries.\nIn order to benefit from the protection you just have to import and use the\nlisted functions / classes from the right defusedxml module instead of the\noriginal module. Merely `defusedxml.xmlrpc`_ is implemented as monkey patch.\n\nInstead of::\n\n   >>> from xml.etree.ElementTree import parse\n   >>> et = parse(xmlfile)\n\nalter code to::\n\n   >>> from defusedxml.ElementTree import parse\n   >>> et = parse(xmlfile)\n\nAdditionally the package has an **untested** function to monkey patch\nall stdlib modules with ``defusedxml.defuse_stdlib()``.\n\nAll functions and parser classes accept three additional keyword arguments.\nThey return either the same objects as the original functions or compatible\nsubclasses.\n\nforbid_dtd (default: False)\n  disallow XML with a ``<!DOCTYPE>`` processing instruction and raise a\n  *DTDForbidden* exception when a DTD processing instruction is found.\n\nforbid_entities (default: True)\n  disallow XML with ``<!ENTITY>`` declarations inside the DTD and raise an\n  *EntitiesForbidden* exception when an entity is declared.\n\nforbid_external (default: True)\n  disallow any access to remote or local resources in external entities\n  or DTD and raising an *ExternalReferenceForbidden* exception when a DTD\n  or entity references an external resource.\n\n\ndefusedxml (package)\n--------------------\n\nDefusedXmlException, DTDForbidden, EntitiesForbidden,\nExternalReferenceForbidden, NotSupportedError\n\ndefuse_stdlib() (*experimental*)\n\n\ndefusedxml.cElementTree\n-----------------------\n\n**NOTE** ``defusedxml.cElementTree`` is deprecated and will be removed in a\nfuture release. Import from ``defusedxml.ElementTree`` instead.\n\nparse(), iterparse(), fromstring(), XMLParser\n\n\ndefusedxml.ElementTree\n-----------------------\n\nparse(), iterparse(), fromstring(), XMLParser\n\n\ndefusedxml.expatreader\n----------------------\n\ncreate_parser(), DefusedExpatParser\n\n\ndefusedxml.sax\n--------------\n\nparse(), parseString(), make_parser()\n\n\ndefusedxml.expatbuilder\n-----------------------\n\nparse(), parseString(), DefusedExpatBuilder, DefusedExpatBuilderNS\n\n\ndefusedxml.minidom\n------------------\n\nparse(), parseString()\n\n\ndefusedxml.pulldom\n------------------\n\nparse(), parseString()\n\n\ndefusedxml.xmlrpc\n-----------------\n\nThe fix is implemented as monkey patch for the stdlib's xmlrpc package (3.x)\nor xmlrpclib module (2.x). The function `monkey_patch()` enables the fixes,\n`unmonkey_patch()` removes the patch and puts the code in its former state.\n\nThe monkey patch protects against XML related attacks as well as\ndecompression bombs and excessively large requests or responses. The default\nsetting is 30 MB for requests, responses and gzip decompression. You can\nmodify the default by changing the module variable `MAX_DATA`. A value of\n`-1` disables the limit.\n\n\ndefusedxml.lxml\n---------------\n\n**DEPRECATED** The module is deprecated and will be removed in a future\nrelease.\n\nThe module acts as an *example* how you could protect code that uses\nlxml.etree. It implements a custom Element class that filters out\nEntity instances, a custom parser factory and a thread local storage for\nparser instances. It also has a check_docinfo() function which inspects\na tree for internal or external DTDs and entity declarations. In order to\ncheck for entities lxml > 3.0 is required.\n\nparse(), fromstring()\nRestrictedElement, GlobalParserTLS, getDefaultParser(), check_docinfo()\n\n\ndefusedexpat\n============\n\nThe `defusedexpat package`_ (`defusedexpat on PyPI`_)\ncomes with binary extensions and a\n`modified expat`_ library instead of the standard `expat parser`_. It's\nbasically a stand-alone version of the patches for Python's standard\nlibrary C extensions.\n\nModifications in expat\n----------------------\n\nnew definitions::\n\n  XML_BOMB_PROTECTION\n  XML_DEFAULT_MAX_ENTITY_INDIRECTIONS\n  XML_DEFAULT_MAX_ENTITY_EXPANSIONS\n  XML_DEFAULT_RESET_DTD\n\nnew XML_FeatureEnum members::\n\n  XML_FEATURE_MAX_ENTITY_INDIRECTIONS\n  XML_FEATURE_MAX_ENTITY_EXPANSIONS\n  XML_FEATURE_IGNORE_DTD\n\nnew XML_Error members::\n\n  XML_ERROR_ENTITY_INDIRECTIONS\n  XML_ERROR_ENTITY_EXPANSION\n\nnew API functions::\n\n  int XML_GetFeature(XML_Parser parser,\n                     enum XML_FeatureEnum feature,\n                     long *value);\n  int XML_SetFeature(XML_Parser parser,\n                     enum XML_FeatureEnum feature,\n                     long value);\n  int XML_GetFeatureDefault(enum XML_FeatureEnum feature,\n                            long *value);\n  int XML_SetFeatureDefault(enum XML_FeatureEnum feature,\n                            long value);\n\nXML_FEATURE_MAX_ENTITY_INDIRECTIONS\n   Limit the amount of indirections that are allowed to occur during the\n   expansion of a nested entity. A counter starts when an entity reference\n   is encountered. It resets after the entity is fully expanded. The limit\n   protects the parser against exponential entity expansion attacks (aka\n   billion laughs attack). When the limit is exceeded the parser stops and\n   fails with `XML_ERROR_ENTITY_INDIRECTIONS`.\n   A value of 0 disables the protection.\n\n   Supported range\n     0 .. UINT_MAX\n   Default\n     40\n\nXML_FEATURE_MAX_ENTITY_EXPANSIONS\n   Limit the total length of all entity expansions throughout the entire\n   document. The lengths of all entities are accumulated in a parser variable.\n   The setting protects against quadratic blowup attacks (lots of expansions\n   of a large entity declaration). When the sum of all entities exceeds\n   the limit, the parser stops and fails with `XML_ERROR_ENTITY_EXPANSION`.\n   A value of 0 disables the protection.\n\n   Supported range\n     0 .. UINT_MAX\n   Default\n     8 MiB\n\nXML_FEATURE_RESET_DTD\n   Reset all DTD information after the <!DOCTYPE> block has been parsed. When\n   the flag is set (default: false) all DTD information after the\n   endDoctypeDeclHandler has been called. The flag can be set inside the\n   endDoctypeDeclHandler. Without DTD information any entity reference in\n   the document body leads to `XML_ERROR_UNDEFINED_ENTITY`.\n\n   Supported range\n     0, 1\n   Default\n     0\n\n\nHow to avoid XML vulnerabilities\n================================\n\nBest practices\n--------------\n\n* Don't allow DTDs\n* Don't expand entities\n* Don't resolve externals\n* Limit parse depth\n* Limit total input size\n* Limit parse time\n* Favor a SAX or iterparse-like parser for potential large data\n* Validate and properly quote arguments to XSL transformations and\n  XPath queries\n* Don't use XPath expression from untrusted sources\n* Don't apply XSL transformations that come untrusted sources\n\n(based on Brad Hill's `Attacking XML Security`_)\n\n\nOther things to consider\n========================\n\nXML, XML parsers and processing libraries have more features and possible\nissue that could lead to DoS vulnerabilities or security exploits in\napplications. I have compiled an incomplete list of theoretical issues that\nneed further research and more attention. The list is deliberately pessimistic\nand a bit paranoid, too. It contains things that might go wrong under daffy\ncircumstances.\n\n\nattribute blowup / hash collision attack\n----------------------------------------\n\nXML parsers may use an algorithm with quadratic runtime O(n :sup:`2`) to\nhandle attributes and namespaces. If it uses hash tables (dictionaries) to\nstore attributes and namespaces the implementation may be vulnerable to\nhash collision attacks, thus reducing the performance to O(n :sup:`2`) again.\nIn either case an attacker is able to forge a denial of service attack with\nan XML document that contains thousands upon thousands of attributes in\na single node.\n\nI haven't researched yet if expat, pyexpat or libxml2 are vulnerable.\n\n\ndecompression bomb\n------------------\n\nThe issue of decompression bombs (aka `ZIP bomb`_) apply to all XML libraries\nthat can parse compressed XML stream like gzipped HTTP streams or LZMA-ed\nfiles. For an attacker it can reduce the amount of transmitted data by three\nmagnitudes or more. Gzip is able to compress 1 GiB zeros to roughly 1 MB,\nlzma is even better::\n\n    $ dd if=/dev/zero bs=1M count=1024 | gzip > zeros.gz\n    $ dd if=/dev/zero bs=1M count=1024 | lzma -z > zeros.xy\n    $ ls -sh zeros.*\n    1020K zeros.gz\n     148K zeros.xy\n\nNone of Python's standard XML libraries decompress streams except for\n``xmlrpclib``. The module is vulnerable <https://bugs.python.org/issue16043>\nto decompression bombs.\n\nlxml can load and process compressed data through libxml2 transparently.\nlibxml2 can handle even very large blobs of compressed data efficiently\nwithout using too much memory. But it doesn't protect applications from\ndecompression bombs. A carefully written SAX or iterparse-like approach can\nbe safe.\n\n\nProcessing Instruction\n----------------------\n\n`PI`_'s like::\n\n  <?xml-stylesheet type=\"text/xsl\" href=\"style.xsl\"?>\n\nmay impose more threats for XML processing. It depends if and how a\nprocessor handles processing instructions. The issue of URL retrieval with\nnetwork or local file access apply to processing instructions, too.\n\n\nOther DTD features\n------------------\n\n`DTD`_ has more features like ``<!NOTATION>``. I haven't researched how\nthese features may be a security threat.\n\n\nXPath\n-----\n\nXPath statements may introduce DoS vulnerabilities. Code should never execute\nqueries from untrusted sources. An attacker may also be able to create an XML\ndocument that makes certain XPath queries costly or resource hungry.\n\n\nXPath injection attacks\n-----------------------\n\nXPath injeciton attacks pretty much work like SQL injection attacks.\nArguments to XPath queries must be quoted and validated properly, especially\nwhen they are taken from the user. The page `Avoid the dangers of XPath injection`_\nlist some ramifications of XPath injections.\n\nPython's standard library doesn't have XPath support. Lxml supports\nparameterized XPath queries which does proper quoting. You just have to use\nits xpath() method correctly::\n\n   # DON'T\n   >>> tree.xpath(\"/tag[@id='%s']\" % value)\n\n   # instead do\n   >>> tree.xpath(\"/tag[@id=$tagid]\", tagid=name)\n\n\nXInclude\n--------\n\n`XML Inclusion`_ is another way to load and include external files::\n\n   <root xmlns:xi=\"http://www.w3.org/2001/XInclude\">\n     <xi:include href=\"filename.txt\" parse=\"text\" />\n   </root>\n\nThis feature should be disabled when XML files from an untrusted source are\nprocessed. Some Python XML libraries and libxml2 support XInclude but don't\nhave an option to sandbox inclusion and limit it to allowed directories.\n\n\nXMLSchema location\n------------------\n\nA validating XML parser may download schema files from the information in a\n``xsi:schemaLocation`` attribute.\n\n::\n\n  <ead xmlns=\"urn:isbn:1-931666-22-9\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"urn:isbn:1-931666-22-9 http://www.loc.gov/ead/ead.xsd\">\n  </ead>\n\n\nXSL Transformation\n------------------\n\nYou should keep in mind that XSLT is a Turing complete language. Never\nprocess XSLT code from unknown or untrusted source! XSLT processors may\nallow you to interact with external resources in ways you can't even imagine.\nSome processors even support extensions that allow read/write access to file\nsystem, access to JRE objects or scripting with Jython.\n\nExample from `Attacking XML Security`_ for Xalan-J::\n\n    <xsl:stylesheet version=\"1.0\"\n     xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"\n     xmlns:rt=\"http://xml.apache.org/xalan/java/java.lang.Runtime\"\n     xmlns:ob=\"http://xml.apache.org/xalan/java/java.lang.Object\"\n     exclude-result-prefixes= \"rt ob\">\n     <xsl:template match=\"/\">\n       <xsl:variable name=\"runtimeObject\" select=\"rt:getRuntime()\"/>\n       <xsl:variable name=\"command\"\n         select=\"rt:exec($runtimeObject, &apos;c:\\Windows\\system32\\cmd.exe&apos;)\"/>\n       <xsl:variable name=\"commandAsString\" select=\"ob:toString($command)\"/>\n       <xsl:value-of select=\"$commandAsString\"/>\n     </xsl:template>\n    </xsl:stylesheet>\n\n\nRelated CVEs\n============\n\nCVE-2013-1664\n  Unrestricted entity expansion induces DoS vulnerabilities in Python XML\n  libraries (XML bomb)\n\nCVE-2013-1665\n  External entity expansion in Python XML libraries inflicts potential\n  security flaws and DoS vulnerabilities\n\n\nOther languages / frameworks\n=============================\n\nSeveral other programming languages and frameworks are vulnerable as well. A\ncouple of them are affected by the fact that libxml2 up to 2.9.0 has no\nprotection against quadratic blowup attacks. Most of them have potential\ndangerous default settings for entity expansion and external entities, too.\n\nPerl\n----\n\nPerl's XML::Simple is vulnerable to quadratic entity expansion and external\nentity expansion (both local and remote).\n\n\nRuby\n----\n\nRuby's REXML document parser is vulnerable to entity expansion attacks\n(both quadratic and exponential) but it doesn't do external entity\nexpansion by default. In order to counteract entity expansion you have to\ndisable the feature::\n\n  REXML::Document.entity_expansion_limit = 0\n\nlibxml-ruby and hpricot don't expand entities in their default configuration.\n\n\nPHP\n---\n\nPHP's SimpleXML API is vulnerable to quadratic entity expansion and loads\nentities from local and remote resources. The option ``LIBXML_NONET`` disables\nnetwork access but still allows local file access. ``LIBXML_NOENT`` seems to\nhave no effect on entity expansion in PHP 5.4.6.\n\n\nC# / .NET / Mono\n----------------\n\nInformation in `XML DoS and Defenses (MSDN)`_ suggest that .NET is\nvulnerable with its default settings. The article contains code snippets\nhow to create a secure XML reader::\n\n  XmlReaderSettings settings = new XmlReaderSettings();\n  settings.ProhibitDtd = false;\n  settings.MaxCharactersFromEntities = 1024;\n  settings.XmlResolver = null;\n  XmlReader reader = XmlReader.Create(stream, settings);\n\n\nJava\n----\n\nUntested. The documentation of Xerces and its `Xerces SecurityMananger`_\nsounds like Xerces is also vulnerable to billion laugh attacks with its\ndefault settings. It also does entity resolving when an\n``org.xml.sax.EntityResolver`` is configured. I'm not yet sure about the\ndefault setting here.\n\nJava specialists suggest to have a custom builder factory::\n\n  DocumentBuilderFactory builderFactory = DocumentBuilderFactory.newInstance();\n  builderFactory.setXIncludeAware(False);\n  builderFactory.setExpandEntityReferences(False);\n  builderFactory.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, True);\n  # either\n  builderFactory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", True);\n  # or if you need DTDs\n  builderFactory.setFeature(\"http://xml.org/sax/features/external-general-entities\", False);\n  builderFactory.setFeature(\"http://xml.org/sax/features/external-parameter-entities\", False);\n  builderFactory.setFeature(\"http://apache.org/xml/features/nonvalidating/load-external-dtd\", False);\n  builderFactory.setFeature(\"http://apache.org/xml/features/nonvalidating/load-dtd-grammar\", False);\n\n\nTODO\n====\n\n* DOM: Use xml.dom.xmlbuilder options for entity handling\n* SAX: take feature_external_ges and feature_external_pes (?) into account\n* test experimental monkey patching of stdlib modules\n* improve documentation\n\n\nLicense\n=======\n\nCopyright (c) 2013-2017 by Christian Heimes <christian@python.org>\n\nLicensed to PSF under a Contributor Agreement.\n\nSee https://www.python.org/psf/license for licensing details.\n\n\nAcknowledgements\n================\n\nBrett Cannon (Python Core developer)\n  review and code cleanup\n\nAntoine Pitrou (Python Core developer)\n  code review\n\nAaron Patterson, Ben Murphy and Michael Koziarski (Ruby community)\n  Many thanks to Aaron, Ben and Michael from the Ruby community for their\n  report and assistance.\n\nThierry Carrez (OpenStack)\n  Many thanks to Thierry for his report to the Python Security Response\n  Team on behalf of the OpenStack security team.\n\nCarl Meyer (Django)\n  Many thanks to Carl for his report to PSRT on behalf of the Django security\n  team.\n\nDaniel Veillard (libxml2)\n  Many thanks to Daniel for his insight and assistance with libxml2.\n\nsemantics GmbH (https://www.semantics.de/)\n  Many thanks to my employer semantics for letting me work on the issue\n  during working hours as part of semantics's open source initiative.\n\n\nReferences\n==========\n\n* `XML DoS and Defenses (MSDN)`_\n* `Billion Laughs`_ on Wikipedia\n* `ZIP bomb`_ on Wikipedia\n* `Configure SAX parsers for secure processing`_\n* `Testing for XML Injection`_\n\n.. _defusedxml package: https://github.com/tiran/defusedxml\n.. _defusedxml on PyPI: https://pypi.python.org/pypi/defusedxml\n.. _defusedexpat package: https://github.com/tiran/defusedexpat\n.. _defusedexpat on PyPI: https://pypi.python.org/pypi/defusedexpat\n.. _modified expat: https://github.com/tiran/expat\n.. _expat parser: http://expat.sourceforge.net/\n.. _Attacking XML Security: https://www.isecpartners.com/media/12976/iSEC-HILL-Attacking-XML-Security-bh07.pdf\n.. _Billion Laughs: https://en.wikipedia.org/wiki/Billion_laughs\n.. _XML DoS and Defenses (MSDN): https://msdn.microsoft.com/en-us/magazine/ee335713.aspx\n.. _ZIP bomb: https://en.wikipedia.org/wiki/Zip_bomb\n.. _DTD: https://en.wikipedia.org/wiki/Document_Type_Definition\n.. _PI: https://en.wikipedia.org/wiki/Processing_Instruction\n.. _Avoid the dangers of XPath injection: http://www.ibm.com/developerworks/xml/library/x-xpathinjection/index.html\n.. _Configure SAX parsers for secure processing: http://www.ibm.com/developerworks/xml/library/x-tipcfsx/index.html\n.. _Testing for XML Injection: https://www.owasp.org/index.php/Testing_for_XML_Injection_(OWASP-DV-008)\n.. _Xerces SecurityMananger: https://xerces.apache.org/xerces2-j/javadocs/xerces2/org/apache/xerces/util/SecurityManager.html\n.. _XML Inclusion: https://www.w3.org/TR/xinclude/#include_element\n\nChangelog\n=========\n\ndefusedxml 0.7.1\n---------------------\n\n*Release date: 08-Mar-2021*\n\n- Fix regression ``defusedxml.ElementTree.ParseError`` (#63)\n  The ``ParseError`` exception is now the same class object as\n  ``xml.etree.ElementTree.ParseError`` again.\n\n\ndefusedxml 0.7.0\n----------------\n\n*Release date: 4-Mar-2021*\n\n- No changes\n\n\ndefusedxml 0.7.0rc2\n-------------------\n\n*Release date: 12-Jan-2021*\n\n- Re-add and deprecate ``defusedxml.cElementTree``\n- Use GitHub Actions instead of TravisCI\n- Restore ``ElementTree`` attribute of ``xml.etree`` module after patching\n\ndefusedxml 0.7.0rc1\n-------------------\n\n*Release date: 04-May-2020*\n\n- Add support for Python 3.9\n- ``defusedxml.cElementTree`` is not available with Python 3.9.\n- Python 2 is deprecate. Support for Python 2 will be removed in 0.8.0.\n\n\ndefusedxml 0.6.0\n----------------\n\n*Release date: 17-Apr-2019*\n\n- Increase test coverage.\n- Add badges to README.\n\n\ndefusedxml 0.6.0rc1\n-------------------\n\n*Release date: 14-Apr-2019*\n\n- Test on Python 3.7 stable and 3.8-dev\n- Drop support for Python 3.4\n- No longer pass *html* argument to XMLParse. It has been deprecated and\n  ignored for a long time. The DefusedXMLParser still takes a html argument.\n  A deprecation warning is issued when the argument is False and a TypeError\n  when it's True.\n- defusedxml now fails early when pyexpat stdlib module is not available or\n  broken.\n- defusedxml.ElementTree.__all__ now lists ParseError as public attribute.\n- The defusedxml.ElementTree and defusedxml.cElementTree modules had a typo\n  and used XMLParse instead of XMLParser as an alias for DefusedXMLParser.\n  Both the old and fixed name are now available.\n\n\ndefusedxml 0.5.0\n----------------\n\n*Release date: 07-Feb-2017*\n\n- No changes\n\n\ndefusedxml 0.5.0.rc1\n--------------------\n\n*Release date: 28-Jan-2017*\n\n- Add compatibility with Python 3.6\n- Drop support for Python 2.6, 3.1, 3.2, 3.3\n- Fix lxml tests (XMLSyntaxError: Detected an entity reference loop)\n\n\ndefusedxml 0.4.1\n----------------\n\n*Release date: 28-Mar-2013*\n\n- Add more demo exploits, e.g. python_external.py and Xalan XSLT demos.\n- Improved documentation.\n\n\ndefusedxml 0.4\n--------------\n\n*Release date: 25-Feb-2013*\n\n- As per http://seclists.org/oss-sec/2013/q1/340 please REJECT\n  CVE-2013-0278, CVE-2013-0279 and CVE-2013-0280 and use CVE-2013-1664,\n  CVE-2013-1665 for OpenStack/etc.\n- Add missing parser_list argument to sax.make_parser(). The argument is\n  ignored, though. (thanks to Florian Apolloner)\n- Add demo exploit for external entity attack on Python's SAX parser, XML-RPC\n  and WebDAV.\n\n\ndefusedxml 0.3\n--------------\n\n*Release date: 19-Feb-2013*\n\n- Improve documentation\n\n\ndefusedxml 0.2\n--------------\n\n*Release date: 15-Feb-2013*\n\n- Rename ExternalEntitiesForbidden to ExternalReferenceForbidden\n- Rename defusedxml.lxml.check_dtd() to check_docinfo()\n- Unify argument names in callbacks\n- Add arguments and formatted representation to exceptions\n- Add forbid_external argument to all functions and classes\n- More tests\n- LOTS of documentation\n- Add example code for other languages (Ruby, Perl, PHP) and parsers (Genshi)\n- Add protection against XML and gzip attacks to xmlrpclib\n\ndefusedxml 0.1\n--------------\n\n*Release date: 08-Feb-2013*\n\n- Initial and internal release for PSRT review\n\n\n",
        "keywords": [
          "xml",
          "bomb",
          "DoS"
        ],
        "home_page": "https://github.com/tiran/defusedxml",
        "download_url": "https://pypi.python.org/pypi/defusedxml",
        "author": "Christian Heimes",
        "author_email": "christian@python.org",
        "maintainer": "Christian Heimes",
        "maintainer_email": "christian@python.org",
        "license": "PSFL",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Python Software Foundation License",
          "Natural Language :: English",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Topic :: Text Processing :: Markup :: XML"
        ],
        "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\defusedxml-0.7.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "dill",
        "version": "0.3.9",
        "platform": [
          "Linux",
          "Windows",
          "Mac"
        ],
        "summary": "serialize all of Python",
        "description": "-----------------------------\ndill: serialize all of Python\n-----------------------------\n\nAbout Dill\n==========\n\n``dill`` extends Python's ``pickle`` module for serializing and de-serializing\nPython objects to the majority of the built-in Python types. Serialization\nis the process of converting an object to a byte stream, and the inverse\nof which is converting a byte stream back to a Python object hierarchy.\n\n``dill`` provides the user the same interface as the ``pickle`` module, and\nalso includes some additional features. In addition to pickling Python\nobjects, ``dill`` provides the ability to save the state of an interpreter\nsession in a single command.  Hence, it would be feasible to save an\ninterpreter session, close the interpreter, ship the pickled file to\nanother computer, open a new interpreter, unpickle the session and\nthus continue from the 'saved' state of the original interpreter\nsession.\n\n``dill`` can be used to store Python objects to a file, but the primary\nusage is to send Python objects across the network as a byte stream.\n``dill`` is quite flexible, and allows arbitrary user defined classes\nand functions to be serialized.  Thus ``dill`` is not intended to be\nsecure against erroneously or maliciously constructed data. It is\nleft to the user to decide whether the data they unpickle is from\na trustworthy source.\n\n``dill`` is part of ``pathos``, a Python framework for heterogeneous computing.\n``dill`` is in active development, so any user feedback, bug reports, comments,\nor suggestions are highly appreciated.  A list of issues is located at\nhttps://github.com/uqfoundation/dill/issues, with a legacy list maintained at\nhttps://uqfoundation.github.io/project/pathos/query.\n\n\nMajor Features\n==============\n\n``dill`` can pickle the following standard types:\n\n    - none, type, bool, int, float, complex, bytes, str,\n    - tuple, list, dict, file, buffer, builtin,\n    - Python classes, namedtuples, dataclasses, metaclasses,\n    - instances of classes,\n    - set, frozenset, array, functions, exceptions\n\n``dill`` can also pickle more 'exotic' standard types:\n\n    - functions with yields, nested functions, lambdas,\n    - cell, method, unboundmethod, module, code, methodwrapper,\n    - methoddescriptor, getsetdescriptor, memberdescriptor, wrapperdescriptor,\n    - dictproxy, slice, notimplemented, ellipsis, quit\n\n``dill`` cannot yet pickle these standard types:\n\n    - frame, generator, traceback\n\n``dill`` also provides the capability to:\n\n    - save and load Python interpreter sessions\n    - save and extract the source code from functions and classes\n    - interactively diagnose pickling errors\n\n\nCurrent Release\n===============\n\nThe latest released version of ``dill`` is available from:\n\n    https://pypi.org/project/dill\n\n``dill`` is distributed under a 3-clause BSD license.\n\n\nDevelopment Version\n===================\n\nYou can get the latest development version with all the shiny new features at:\n\n    https://github.com/uqfoundation\n\nIf you have a new contribution, please submit a pull request.\n\n\nInstallation\n============\n\n``dill`` can be installed with ``pip``::\n\n    $ pip install dill\n\nTo optionally include the ``objgraph`` diagnostic tool in the install::\n\n    $ pip install dill[graph]\n\nTo optionally include the ``gprof2dot`` diagnostic tool in the install::\n\n    $ pip install dill[profile]\n\nFor windows users, to optionally install session history tools::\n\n    $ pip install dill[readline]\n\n\nRequirements\n============\n\n``dill`` requires:\n\n    - ``python`` (or ``pypy``), **>=3.8**\n    - ``setuptools``, **>=42**\n\nOptional requirements:\n\n    - ``objgraph``, **>=1.7.2**\n    - ``gprof2dot``, **>=2022.7.29**\n    - ``pyreadline``, **>=1.7.1** (on windows)\n\n\nBasic Usage\n===========\n\n``dill`` is a drop-in replacement for ``pickle``. Existing code can be\nupdated to allow complete pickling using::\n\n    >>> import dill as pickle\n\nor::\n\n    >>> from dill import dumps, loads\n\n``dumps`` converts the object to a unique byte string, and ``loads`` performs\nthe inverse operation::\n\n    >>> squared = lambda x: x**2\n    >>> loads(dumps(squared))(3)\n    9\n\nThere are a number of options to control serialization which are provided\nas keyword arguments to several ``dill`` functions:\n\n* with *protocol*, the pickle protocol level can be set. This uses the\n  same value as the ``pickle`` module, *DEFAULT_PROTOCOL*.\n* with *byref=True*, ``dill`` to behave a lot more like pickle with\n  certain objects (like modules) pickled by reference as opposed to\n  attempting to pickle the object itself.\n* with *recurse=True*, objects referred to in the global dictionary are\n  recursively traced and pickled, instead of the default behavior of\n  attempting to store the entire global dictionary.\n* with *fmode*, the contents of the file can be pickled along with the file\n  handle, which is useful if the object is being sent over the wire to a\n  remote system which does not have the original file on disk. Options are\n  *HANDLE_FMODE* for just the handle, *CONTENTS_FMODE* for the file content\n  and *FILE_FMODE* for content and handle.\n* with *ignore=False*, objects reconstructed with types defined in the\n  top-level script environment use the existing type in the environment\n  rather than a possibly different reconstructed type.\n\nThe default serialization can also be set globally in *dill.settings*.\nThus, we can modify how ``dill`` handles references to the global dictionary\nlocally or globally::\n\n    >>> import dill.settings\n    >>> dumps(absolute) == dumps(absolute, recurse=True)\n    False\n    >>> dill.settings['recurse'] = True\n    >>> dumps(absolute) == dumps(absolute, recurse=True)\n    True\n\n``dill`` also includes source code inspection, as an alternate to pickling::\n\n    >>> import dill.source\n    >>> print(dill.source.getsource(squared))\n    squared = lambda x:x**2\n\nTo aid in debugging pickling issues, use *dill.detect* which provides\ntools like pickle tracing::\n\n    >>> import dill.detect\n    >>> with dill.detect.trace():\n    >>>     dumps(squared)\n    â”¬ F1: <function <lambda> at 0x7fe074f8c280>\n    â”œâ”¬ F2: <function _create_function at 0x7fe074c49c10>\n    â”‚â”” # F2 [34 B]\n    â”œâ”¬ Co: <code object <lambda> at 0x7fe07501eb30, file \"<stdin>\", line 1>\n    â”‚â”œâ”¬ F2: <function _create_code at 0x7fe074c49ca0>\n    â”‚â”‚â”” # F2 [19 B]\n    â”‚â”” # Co [87 B]\n    â”œâ”¬ D1: <dict object at 0x7fe0750d4680>\n    â”‚â”” # D1 [22 B]\n    â”œâ”¬ D2: <dict object at 0x7fe074c5a1c0>\n    â”‚â”” # D2 [2 B]\n    â”œâ”¬ D2: <dict object at 0x7fe074f903c0>\n    â”‚â”œâ”¬ D2: <dict object at 0x7fe074f8ebc0>\n    â”‚â”‚â”” # D2 [2 B]\n    â”‚â”” # D2 [23 B]\n    â”” # F1 [180 B]\n\nWith trace, we see how ``dill`` stored the lambda (``F1``) by first storing\n``_create_function``, the underlying code object (``Co``) and ``_create_code``\n(which is used to handle code objects), then we handle the reference to\nthe global dict (``D2``) plus other dictionaries (``D1`` and ``D2``) that\nsave the lambda object's state. A ``#`` marks when the object is actually stored.\n\n\nMore Information\n================\n\nProbably the best way to get started is to look at the documentation at\nhttp://dill.rtfd.io. Also see ``dill.tests`` for a set of scripts that\ndemonstrate how ``dill`` can serialize different Python objects. You can\nrun the test suite with ``python -m dill.tests``. The contents of any\npickle file can be examined with ``undill``.  As ``dill`` conforms to\nthe ``pickle`` interface, the examples and documentation found at\nhttp://docs.python.org/library/pickle.html also apply to ``dill``\nif one will ``import dill as pickle``. The source code is also generally\nwell documented, so further questions may be resolved by inspecting the\ncode itself. Please feel free to submit a ticket on github, or ask a\nquestion on stackoverflow (**@Mike McKerns**).\nIf you would like to share how you use ``dill`` in your work, please send\nan email (to **mmckerns at uqfoundation dot org**).\n\n\nCitation\n========\n\nIf you use ``dill`` to do research that leads to publication, we ask that you\nacknowledge use of ``dill`` by citing the following in your publication::\n\n    M.M. McKerns, L. Strand, T. Sullivan, A. Fang, M.A.G. Aivazis,\n    \"Building a framework for predictive science\", Proceedings of\n    the 10th Python in Science Conference, 2011;\n    http://arxiv.org/pdf/1202.1056\n\n    Michael McKerns and Michael Aivazis,\n    \"pathos: a framework for heterogeneous computing\", 2010- ;\n    https://uqfoundation.github.io/project/pathos\n\nPlease see https://uqfoundation.github.io/project/pathos or\nhttp://arxiv.org/pdf/1202.1056 for further information.\n",
        "home_page": "https://github.com/uqfoundation/dill",
        "download_url": "https://pypi.org/project/dill/#files",
        "author": "Mike McKerns",
        "author_email": "mmckerns@uqfoundation.org",
        "maintainer": "Mike McKerns",
        "maintainer_email": "mmckerns@uqfoundation.org",
        "license": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: Science/Research",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Scientific/Engineering",
          "Topic :: Software Development"
        ],
        "requires_dist": [
          "objgraph >=1.7.2 ; extra == 'graph'",
          "gprof2dot >=2022.7.29 ; extra == 'profile'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, http://dill.rtfd.io",
          "Source Code, https://github.com/uqfoundation/dill",
          "Bug Tracker, https://github.com/uqfoundation/dill/issues"
        ],
        "provides_extra": [
          "graph",
          "profile",
          "readline"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\dill-0.3.9.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "distlib",
        "version": "0.3.8",
        "platform": [
          "any"
        ],
        "summary": "Distribution utilities",
        "description": "|badge1| |badge2|\n\n.. |badge1| image:: https://img.shields.io/github/actions/workflow/status/pypa/distlib/package-tests.yml\n   :alt: GitHub Workflow Status (with event)\n\n.. |badge2| image:: https://img.shields.io/codecov/c/github/pypa/distlib\n   :target: https://app.codecov.io/gh/pypa/distlib\n   :alt: GitHub coverage status\n\nWhat is it?\n-----------\n\nDistlib is a library which implements low-level functions that relate to\npackaging and distribution of Python software. It is intended to be used as the\nbasis for third-party packaging tools. The documentation is available at\n\nhttps://distlib.readthedocs.io/\n\nMain features\n-------------\n\nDistlib currently offers the following features:\n\n* The package ``distlib.database``, which implements a database of installed\n  distributions, as defined by :pep:`376`, and distribution dependency graph\n  logic. Support is also provided for non-installed distributions (i.e.\n  distributions registered with metadata on an index like PyPI), including\n  the ability to scan for dependencies and building dependency graphs.\n* The package ``distlib.index``, which implements an interface to perform\n  operations on an index, such as registering a project, uploading a\n  distribution or uploading documentation. Support is included for verifying\n  SSL connections (with domain matching) and signing/verifying packages using\n  GnuPG.\n* The package ``distlib.metadata``, which implements distribution metadata as\n  defined by :pep:`643`, :pep:`566`, :pep:`345`, :pep:`314` and :pep:`241`.\n* The package ``distlib.markers``, which implements environment markers as\n  defined by :pep:`508`.\n* The package ``distlib.manifest``, which implements lists of files used\n  in packaging source distributions.\n* The package ``distlib.locators``, which allows finding distributions, whether\n  on PyPI (XML-RPC or via the \"simple\" interface), local directories or some\n  other source.\n* The package ``distlib.resources``, which allows access to data files stored\n  in Python packages, both in the file system and in .zip files.\n* The package ``distlib.scripts``, which allows installing of scripts with\n  adjustment of shebang lines and support for native Windows executable\n  launchers.\n* The package ``distlib.version``, which implements version specifiers as\n  defined by :pep:`440`, but also support for working with \"legacy\" versions and\n  semantic versions.\n* The package ``distlib.wheel``, which provides support for building and\n  installing from the Wheel format for binary distributions (see :pep:`427`).\n* The package ``distlib.util``, which contains miscellaneous functions and\n  classes which are useful in packaging, but which do not fit neatly into\n  one of the other packages in ``distlib``.* The package implements enhanced\n  globbing functionality such as the ability to use ``**`` in patterns to\n  specify recursing into subdirectories.\n\n\nPython version and platform compatibility\n-----------------------------------------\n\nDistlib is intended to be used on and is tested on Python versions 2.7 and 3.6 or later,\npypy-2.7 and pypy3 on Linux, Windows, and macOS.\n\nProject status\n--------------\n\nThe project has reached a mature status in its development: there is a comprehensive\ntest suite and it has been exercised on Windows, Ubuntu and macOS. The project is used\nby well-known projects such as `pip <https://pypi.org/pypi/pip>`_ and `caniusepython3\n<https://pypi.org/pypi/caniusepython3>`_.\n\nThis project was migrated from Mercurial to Git and from BitBucket to GitHub, and\nalthough all information of importance has been retained across the migration, some\ncommit references in issues and issue comments may have become invalid.\n\nCode of Conduct\n---------------\n\nEveryone interacting in the distlib project's codebases, issue trackers, chat\nrooms, and mailing lists is expected to follow the `PyPA Code of Conduct`_.\n\n.. _PyPA Code of Conduct: https://www.pypa.io/en/latest/code-of-conduct/\n\n\n",
        "home_page": "https://github.com/pypa/distlib",
        "author": "Vinay Sajip",
        "author_email": "vinay_sajip@red-dove.com",
        "license": "PSF-2.0",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Python Software Foundation License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Topic :: Software Development"
        ],
        "project_url": [
          "Documentation, https://distlib.readthedocs.io/",
          "Source, https://github.com/pypa/distlib",
          "Tracker, https://github.com/pypa/distlib/issues"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\distlib-0.3.8.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "docopt",
        "version": "0.6.2",
        "summary": "Pythonic argument parser, that will make you smile",
        "description": "``docopt`` creates *beautiful* command-line interfaces\n======================================================================\n\nVideo introduction to **docopt**: `PyCon UK 2012: Create *beautiful*\ncommand-line interfaces with Python <http://youtu.be/pXhcPJK5cMc>`_\n\n    New in version 0.6.1:\n\n    - Fix issue `#85 <https://github.com/docopt/docopt/issues/85>`_\n      which caused improper handling of ``[options]`` shortcut\n      if it was present several times.\n\n    New in version 0.6.0:\n\n    - New argument ``options_first``, disallows interspersing options\n      and arguments.  If you supply ``options_first=True`` to\n      ``docopt``, it will interpret all arguments as positional\n      arguments after first positional argument.\n\n    - If option with argument could be repeated, its default value\n      will be interpreted as space-separated list. E.g. with\n      ``[default: ./here ./there]`` will be interpreted as\n      ``['./here', './there']``.\n\n    Breaking changes:\n\n    - Meaning of ``[options]`` shortcut slightly changed. Previously\n      it ment *\"any known option\"*. Now it means *\"any option not in\n      usage-pattern\"*.  This avoids the situation when an option is\n      allowed to be repeated unintentionaly.\n\n    - ``argv`` is ``None`` by default, not ``sys.argv[1:]``.\n      This allows ``docopt`` to always use the *latest* ``sys.argv``,\n      not ``sys.argv`` during import time.\n\nIsn't it awesome how ``optparse`` and ``argparse`` generate help\nmessages based on your code?!\n\n*Hell no!*  You know what's awesome?  It's when the option parser *is*\ngenerated based on the beautiful help message that you write yourself!\nThis way you don't need to write this stupid repeatable parser-code,\nand instead can write only the help message--*the way you want it*.\n\n**docopt** helps you create most beautiful command-line interfaces\n*easily*:\n\n.. code:: python\n\n    \"\"\"Naval Fate.\n\n    Usage:\n      naval_fate.py ship new <name>...\n      naval_fate.py ship <name> move <x> <y> [--speed=<kn>]\n      naval_fate.py ship shoot <x> <y>\n      naval_fate.py mine (set|remove) <x> <y> [--moored | --drifting]\n      naval_fate.py (-h | --help)\n      naval_fate.py --version\n\n    Options:\n      -h --help     Show this screen.\n      --version     Show version.\n      --speed=<kn>  Speed in knots [default: 10].\n      --moored      Moored (anchored) mine.\n      --drifting    Drifting mine.\n\n    \"\"\"\n    from docopt import docopt\n\n\n    if __name__ == '__main__':\n        arguments = docopt(__doc__, version='Naval Fate 2.0')\n        print(arguments)\n\nBeat that! The option parser is generated based on the docstring above\nthat is passed to ``docopt`` function.  ``docopt`` parses the usage\npattern (``\"Usage: ...\"``) and option descriptions (lines starting\nwith dash \"``-``\") and ensures that the program invocation matches the\nusage pattern; it parses options, arguments and commands based on\nthat. The basic idea is that *a good help message has all necessary\ninformation in it to make a parser*.\n\nAlso, `PEP 257 <http://www.python.org/dev/peps/pep-0257/>`_ recommends\nputting help message in the module docstrings.\n\nInstallation\n======================================================================\n\nUse `pip <http://pip-installer.org>`_ or easy_install::\n\n    pip install docopt==0.6.2\n\nAlternatively, you can just drop ``docopt.py`` file into your\nproject--it is self-contained.\n\n**docopt** is tested with Python 2.5, 2.6, 2.7, 3.2, 3.3 and PyPy.\n\nAPI\n======================================================================\n\n.. code:: python\n\n    from docopt import docopt\n\n.. code:: python\n\n    docopt(doc, argv=None, help=True, version=None, options_first=False)\n\n``docopt`` takes 1 required and 4 optional arguments:\n\n- ``doc`` could be a module docstring (``__doc__``) or some other\n  string that contains a **help message** that will be parsed to\n  create the option parser.  The simple rules of how to write such a\n  help message are given in next sections.  Here is a quick example of\n  such a string:\n\n.. code:: python\n\n    \"\"\"Usage: my_program.py [-hso FILE] [--quiet | --verbose] [INPUT ...]\n\n    -h --help    show this\n    -s --sorted  sorted output\n    -o FILE      specify output file [default: ./test.txt]\n    --quiet      print less text\n    --verbose    print more text\n\n    \"\"\"\n\n- ``argv`` is an optional argument vector; by default ``docopt`` uses\n  the argument vector passed to your program (``sys.argv[1:]``).\n  Alternatively you can supply a list of strings like ``['--verbose',\n  '-o', 'hai.txt']``.\n\n- ``help``, by default ``True``, specifies whether the parser should\n  automatically print the help message (supplied as ``doc``) and\n  terminate, in case ``-h`` or ``--help`` option is encountered\n  (options should exist in usage pattern, more on that below). If you\n  want to handle ``-h`` or ``--help`` options manually (as other\n  options), set ``help=False``.\n\n- ``version``, by default ``None``, is an optional argument that\n  specifies the version of your program. If supplied, then, (assuming\n  ``--version`` option is mentioned in usage pattern) when parser\n  encounters the ``--version`` option, it will print the supplied\n  version and terminate.  ``version`` could be any printable object,\n  but most likely a string, e.g. ``\"2.1.0rc1\"``.\n\n    Note, when ``docopt`` is set to automatically handle ``-h``,\n    ``--help`` and ``--version`` options, you still need to mention\n    them in usage pattern for this to work. Also, for your users to\n    know about them.\n\n- ``options_first``, by default ``False``.  If set to ``True`` will\n  disallow mixing options and positional argument.  I.e. after first\n  positional argument, all arguments will be interpreted as positional\n  even if the look like options.  This can be used for strict\n  compatibility with POSIX, or if you want to dispatch your arguments\n  to other programs.\n\nThe **return** value is a simple dictionary with options, arguments\nand commands as keys, spelled exactly like in your help message.  Long\nversions of options are given priority. For example, if you invoke the\ntop example as::\n\n    naval_fate.py ship Guardian move 100 150 --speed=15\n\nthe return dictionary will be:\n\n.. code:: python\n\n    {'--drifting': False,    'mine': False,\n     '--help': False,        'move': True,\n     '--moored': False,      'new': False,\n     '--speed': '15',        'remove': False,\n     '--version': False,     'set': False,\n     '<name>': ['Guardian'], 'ship': True,\n     '<x>': '100',           'shoot': False,\n     '<y>': '150'}\n\nHelp message format\n======================================================================\n\nHelp message consists of 2 parts:\n\n- Usage pattern, e.g.::\n\n    Usage: my_program.py [-hso FILE] [--quiet | --verbose] [INPUT ...]\n\n- Option descriptions, e.g.::\n\n    -h --help    show this\n    -s --sorted  sorted output\n    -o FILE      specify output file [default: ./test.txt]\n    --quiet      print less text\n    --verbose    print more text\n\nTheir format is described below; other text is ignored.\n\nUsage pattern format\n----------------------------------------------------------------------\n\n**Usage pattern** is a substring of ``doc`` that starts with\n``usage:`` (case *insensitive*) and ends with a *visibly* empty line.\nMinimum example:\n\n.. code:: python\n\n    \"\"\"Usage: my_program.py\n\n    \"\"\"\n\nThe first word after ``usage:`` is interpreted as your program's name.\nYou can specify your program's name several times to signify several\nexclusive patterns:\n\n.. code:: python\n\n    \"\"\"Usage: my_program.py FILE\n              my_program.py COUNT FILE\n\n    \"\"\"\n\nEach pattern can consist of the following elements:\n\n- **<arguments>**, **ARGUMENTS**. Arguments are specified as either\n  upper-case words, e.g. ``my_program.py CONTENT-PATH`` or words\n  surrounded by angular brackets: ``my_program.py <content-path>``.\n- **--options**.  Options are words started with dash (``-``), e.g.\n  ``--output``, ``-o``.  You can \"stack\" several of one-letter\n  options, e.g. ``-oiv`` which will be the same as ``-o -i -v``. The\n  options can have arguments, e.g.  ``--input=FILE`` or ``-i FILE`` or\n  even ``-iFILE``. However it is important that you specify option\n  descriptions if you want for option to have an argument, a default\n  value, or specify synonymous short/long versions of option (see next\n  section on option descriptions).\n- **commands** are words that do *not* follow the described above\n  conventions of ``--options`` or ``<arguments>`` or ``ARGUMENTS``,\n  plus two special commands: dash \"``-``\" and double dash \"``--``\"\n  (see below).\n\nUse the following constructs to specify patterns:\n\n- **[ ]** (brackets) **optional** elements.  e.g.: ``my_program.py\n  [-hvqo FILE]``\n- **( )** (parens) **required** elements.  All elements that are *not*\n  put in **[ ]** are also required, e.g.: ``my_program.py\n  --path=<path> <file>...`` is the same as ``my_program.py\n  (--path=<path> <file>...)``.  (Note, \"required options\" might be not\n  a good idea for your users).\n- **|** (pipe) **mutualy exclusive** elements. Group them using **(\n  )** if one of the mutually exclusive elements is required:\n  ``my_program.py (--clockwise | --counter-clockwise) TIME``. Group\n  them using **[ ]** if none of the mutually-exclusive elements are\n  required: ``my_program.py [--left | --right]``.\n- **...** (ellipsis) **one or more** elements. To specify that\n  arbitrary number of repeating elements could be accepted, use\n  ellipsis (``...``), e.g.  ``my_program.py FILE ...`` means one or\n  more ``FILE``-s are accepted.  If you want to accept zero or more\n  elements, use brackets, e.g.: ``my_program.py [FILE ...]``. Ellipsis\n  works as a unary operator on the expression to the left.\n- **[options]** (case sensitive) shortcut for any options.  You can\n  use it if you want to specify that the usage pattern could be\n  provided with any options defined below in the option-descriptions\n  and do not want to enumerate them all in usage-pattern.  -\n  \"``[--]``\". Double dash \"``--``\" is used by convention to separate\n  positional arguments that can be mistaken for options. In order to\n  support this convention add \"``[--]``\" to you usage patterns.  -\n  \"``[-]``\". Single dash \"``-``\" is used by convention to signify that\n  ``stdin`` is used instead of a file. To support this add \"``[-]``\"\n  to you usage patterns. \"``-``\" act as a normal command.\n\nIf your pattern allows to match argument-less option (a flag) several\ntimes::\n\n    Usage: my_program.py [-v | -vv | -vvv]\n\nthen number of occurences of the option will be counted. I.e.\n``args['-v']`` will be ``2`` if program was invoked as ``my_program\n-vv``. Same works for commands.\n\nIf your usage patterns allows to match same-named option with argument\nor positional argument several times, the matched arguments will be\ncollected into a list::\n\n    Usage: my_program.py <file> <file> --path=<path>...\n\nI.e. invoked with ``my_program.py file1 file2 --path=./here\n--path=./there`` the returned dict will contain ``args['<file>'] ==\n['file1', 'file2']`` and ``args['--path'] == ['./here', './there']``.\n\n\nOption descriptions format\n----------------------------------------------------------------------\n\n**Option descriptions** consist of a list of options that you put\nbelow your usage patterns.\n\nIt is necessary to list option descriptions in order to specify:\n\n- synonymous short and long options,\n- if an option has an argument,\n- if option's argument has a default value.\n\nThe rules are as follows:\n\n- Every line in ``doc`` that starts with ``-`` or ``--`` (not counting\n  spaces) is treated as an option description, e.g.::\n\n    Options:\n      --verbose   # GOOD\n      -o FILE     # GOOD\n    Other: --bad  # BAD, line does not start with dash \"-\"\n\n- To specify that option has an argument, put a word describing that\n  argument after space (or equals \"``=``\" sign) as shown below. Follow\n  either <angular-brackets> or UPPER-CASE convention for options'\n  arguments.  You can use comma if you want to separate options. In\n  the example below, both lines are valid, however you are recommended\n  to stick to a single style.::\n\n    -o FILE --output=FILE       # without comma, with \"=\" sign\n    -i <file>, --input <file>   # with comma, wihtout \"=\" sing\n\n- Use two spaces to separate options with their informal description::\n\n    --verbose More text.   # BAD, will be treated as if verbose option had\n                           # an argument \"More\", so use 2 spaces instead\n    -q        Quit.        # GOOD\n    -o FILE   Output file. # GOOD\n    --stdout  Use stdout.  # GOOD, 2 spaces\n\n- If you want to set a default value for an option with an argument,\n  put it into the option-description, in form ``[default:\n  <my-default-value>]``::\n\n    --coefficient=K  The K coefficient [default: 2.95]\n    --output=FILE    Output file [default: test.txt]\n    --directory=DIR  Some directory [default: ./]\n\n- If the option is not repeatable, the value inside ``[default: ...]``\n  will be interpeted as string.  If it *is* repeatable, it will be\n  splited into a list on whitespace::\n\n    Usage: my_program.py [--repeatable=<arg> --repeatable=<arg>]\n                         [--another-repeatable=<arg>]...\n                         [--not-repeatable=<arg>]\n\n    # will be ['./here', './there']\n    --repeatable=<arg>          [default: ./here ./there]\n\n    # will be ['./here']\n    --another-repeatable=<arg>  [default: ./here]\n\n    # will be './here ./there', because it is not repeatable\n    --not-repeatable=<arg>      [default: ./here ./there]\n\nExamples\n----------------------------------------------------------------------\n\nWe have an extensive list of `examples\n<https://github.com/docopt/docopt/tree/master/examples>`_ which cover\nevery aspect of functionality of **docopt**.  Try them out, read the\nsource if in doubt.\n\nSubparsers, multi-level help and *huge* applications (like git)\n----------------------------------------------------------------------\n\nIf you want to split your usage-pattern into several, implement\nmulti-level help (whith separate help-screen for each subcommand),\nwant to interface with existing scripts that don't use **docopt**, or\nyou're building the next \"git\", you will need the new ``options_first``\nparameter (described in API section above). To get you started quickly\nwe implemented a subset of git command-line interface as an example:\n`examples/git\n<https://github.com/docopt/docopt/tree/master/examples/git>`_\n\n\nData validation\n----------------------------------------------------------------------\n\n**docopt** does one thing and does it well: it implements your\ncommand-line interface.  However it does not validate the input data.\nOn the other hand there are libraries like `python schema\n<https://github.com/halst/schema>`_ which make validating data a\nbreeze.  Take a look at `validation_example.py\n<https://github.com/docopt/docopt/tree/master/examples/validation_example.py>`_\nwhich uses **schema** to validate data and report an error to the\nuser.\n\nDevelopment\n======================================================================\n\nWe would *love* to hear what you think about **docopt** on our `issues\npage <http://github.com/docopt/docopt/issues>`_\n\nMake pull requrests, report bugs, suggest ideas and discuss\n**docopt**. You can also drop a line directly to\n<vladimir@keleshev.com>.\n\nPorting ``docopt`` to other languages\n======================================================================\n\nWe think **docopt** is so good, we want to share it beyond the Python\ncommunity!\n\nThe follosing ports are available:\n\n- `Ruby port <http://github.com/docopt/docopt.rb>`_\n- `CoffeeScript port <http://github.com/docopt/docopt.coffee>`_\n- `Lua port <http://github.com/docopt/docopt.lua>`_\n- `PHP port <http://github.com/docopt/docopt.php>`_\n\nBut you can always create a port for your favorite language!  You are\nencouraged to use the Python version as a reference implementation.  A\nLanguage-agnostic test suite is bundled with `Python implementation\n<http://github.com/docopt/docopt>`_.\n\nPorting discussion is on `issues page\n<http://github.com/docopt/docopt/issues>`_.\n\nChangelog\n======================================================================\n\n**docopt** follows `semantic versioning <http://semver.org>`_.  The\nfirst release with stable API will be 1.0.0 (soon).  Until then, you\nare encouraged to specify explicitly the version in your dependency\ntools, e.g.::\n\n    pip install docopt==0.6.2\n\n- 0.6.2 `Wheel <http://pythonwheels.com/>`_ support.\n- 0.6.1 Bugfix release.\n- 0.6.0 ``options_first`` parameter.\n  **Breaking changes**: Corrected ``[options]`` meaning.\n  ``argv`` defaults to ``None``.\n- 0.5.0 Repeated options/commands are counted or accumulated into a\n  list.\n- 0.4.2 Bugfix release.\n- 0.4.0 Option descriptions become optional,\n  support for \"``--``\" and \"``-``\" commands.\n- 0.3.0 Support for (sub)commands like `git remote add`.\n  Introduce ``[options]`` shortcut for any options.\n  **Breaking changes**: ``docopt`` returns dictionary.\n- 0.2.0 Usage pattern matching. Positional arguments parsing based on\n  usage patterns.\n  **Breaking changes**: ``docopt`` returns namespace (for arguments),\n  not list. Usage pattern is formalized.\n- 0.1.0 Initial release. Options-parsing only (based on options\n  description).\n",
        "keywords": [
          "option",
          "arguments",
          "parsing",
          "optparse",
          "argparse",
          "getopt"
        ],
        "home_page": "http://docopt.org",
        "author": "Vladimir Keleshev",
        "author_email": "vladimir@keleshev.com",
        "license": "MIT",
        "license_file": [
          "LICENSE-MIT"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Topic :: Utilities",
          "Programming Language :: Python :: 2.5",
          "Programming Language :: Python :: 2.6",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3.2",
          "Programming Language :: Python :: 3.3",
          "License :: OSI Approved :: MIT License"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\docopt-0.6.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "doxypypy",
        "version": "0.8.8.7",
        "summary": "A Doxygen filter for Python",
        "description": "doxypypy\n========\n\n*A more Pythonic version of doxypy, a Doxygen filter for Python.*\n\nIntent\n------\n\nFor now Doxygen_ has limited support for Python.  It recognizes Python comments,\nbut otherwise treats the language as being more or less like Java.  It doesn't\nunderstand basic Python syntax constructs like docstrings, keyword arguments,\ngenerators, nested functions, decorators, or lambda expressions.  It likewise\ndoesn't understand conventional constructs like doctests or ZOPE-style\ninterfaces.  It does however support inline filters that can be used to make\ninput source code a little more like what it's expecting.\n\nThe excellent doxypy_ makes it possible to embed Doxygen commands in Python\ndocstrings, and have those docstrings converted to Doxygen-recognized comments\non the fly per Doxygen's regular input filtering process.  It however does not\naddress any of the other previously mentioned areas of difficulty.\n\nThis project started off as a fork of doxypy but quickly became quite distinct.\nIt shares little (if any) of the same code at this point (but maintains the\noriginal license just in case).  It is meant to support all the same command\nline options as doxypy, but handle additional Python syntax beyond docstrings.\n\nAdditional Syntax Supported\n---------------------------\n\nPython can have functions and classes within both functions and classes.\nDoxygen best understands this concept via its notion of namespaces.  This filter\nthus can supply Doxygen tags marking namespaces on every function and class.\nThis addresses the issue of Doxygen merging inner functions' documentation with\nthe documentation of the parent.\n\nPython class members whose names begin with a double-underscore are mangled\nand kept private by the language.  Doxygen does not understand this natively\nyet, so this filter additionally provides Doxygen tags to label such variables\nas private.\n\nPython frequently embeds doctests within docstrings.  This filter makes it\ntrivial to mark off such sections of the docstring so they get displayed as\ncode.\n\nZOPE-style interfaces overload class definitions to be interface definitions,\nuse embedded variable assignments to identify attributes, and use specific\nfunction calls to indicate interface adherence.  Furthermore, they frequently\ndon't have any code beyond their docstrings, so naively removing docstrings\nwould result in broken Python.  This filter has basic understanding of these\ninterfaces and treats them accordingly, supplying Doxygen tags as appropriate.\n\nFundamentally Python docstrings are meant for humans and not machines, and ought\nnot to have special mark-up beyond conventional structured text.  This filter\nheuristically examines Python docstrings, and ones like the sample for complex\nin `PEP 257`_ or that generally follow the stricter `Google Python Style Guide`_\nwill get appropriate Doxygen tags automatically added.\n\nHow It Works\n------------\n\nThis project takes a radically different approach than doxypy.  Rather than use\nregular expressions tied to a state machine to figure out syntax, Python's own\nAbstract Syntax Tree module is used to extract items of interest.  If the\n`autobrief` option is enabled, docstrings are parsed via a set of regular\nexpressions and a producer / consumer pair of coroutines.\n\nExample\n-------\n\nThis filter will correctly process code like the following working (albeit\ncontrived) example:\n\n.. code-block:: python\n\n    def myfunction(arg1, arg2, kwarg='whatever.'):\n        \"\"\"\n        Does nothing more than demonstrate syntax.\n\n        This is an example of how a Pythonic human-readable docstring can\n        get parsed by doxypypy and marked up with Doxygen commands as a\n        regular input filter to Doxygen.\n\n        Args:\n            arg1:   A positional argument.\n            arg2:   Another positional argument.\n\n        Kwargs:\n            kwarg:  A keyword argument.\n\n        Returns:\n            A string holding the result.\n\n        Raises:\n            ZeroDivisionError, AssertionError, & ValueError.\n\n        Examples:\n            >>> myfunction(2, 3)\n            '5 - 0, whatever.'\n            >>> myfunction(5, 0, 'oops.')\n            Traceback (most recent call last):\n                ...\n            ZeroDivisionError: integer division or modulo by zero\n            >>> myfunction(4, 1, 'got it.')\n            '5 - 4, got it.'\n            >>> myfunction(23.5, 23, 'oh well.')\n            Traceback (most recent call last):\n                ...\n            AssertionError\n            >>> myfunction(5, 50, 'too big.')\n            Traceback (most recent call last):\n                ...\n            ValueError\n        \"\"\"\n        assert isinstance(arg1, int)\n        if arg2 > 23:\n            raise ValueError\n        return '{0} - {1}, {2}'.format(arg1 + arg2, arg1 / arg2, kwarg)\n\nThere are a few points to note:\n\n1.  No special tags are used.  Best practice human-readable section headers\nare enough.\n\n2.  Some flexibility is allowed.  Most common names for sections are accepted,\nand items and descriptions may be separated by either colons or dashes.\n\n3.  The brief must be the first item and be no longer than one\nline.\n\n4.  Everything thrown into an examples section will be treated as code, so it's\nthe perfect place for doctests.\n\nAdditional more comprehensive examples can be found in the test area.\n\nInstalling doxypypy\n-------------------\n\nOne can use either :code:`pip` or :code:`easy_install` for installation.\nRunning either:\n\n.. code-block:: shell\n\n    pip install doxypypy\n\nor:\n\n.. code-block:: shell\n\n    easy_install doxypypy\n\nwith administrator privileges should do the trick.\n\nMany Linux distributions have packages for doxypypy, so if you are\nusing Linux you may find it more convenient to use :code:`aptitude`,\n:code:`apt`, :code:`apt-get`, :code:`yum`, :code:`dnf`, etc. as\nappropriate for your system to install the version tested by the\ndistribution maintainer. It will often be available as separate\npackages for both Python 3 and Python 2.\n\n\nPreviewing doxypypy Output\n--------------------------\n\nAfter successful installation, doxypypy can be run from the command line to\npreview the filtered results with:\n\n.. code-block:: shell\n\n    doxypypy -a -c file.py\n\nTypically you'll want to redirect output to a file for viewing in a text editor:\n\n.. code-block:: shell\n\n    doxypypy -a -c file.py > file.py.out\n\nInvoking doxypypy from Doxygen\n------------------------------\n\nTo make Doxygen run your Python code through doxypypy, set the FILTER\\_PATTERNS\ntag in your Doxyfile as follows:\n\n.. code-block:: shell\n\n    FILTER_PATTERNS        = *.py=py_filter\n\n`py_filter` must be available in your path as a shell script (or Windows batch\nfile).  If you wish to run `py_filter` in a particular directory you can include\nthe full or relative path.\n\nFor Unix-like operating systems, `py_filter` should like something like this:\n\n.. code-block:: shell\n\n    #!/bin/bash\n    doxypypy -a -c $1\n\nIn Windows, the batch file should be named `py_filter.bat`, and need only\ncontain the one line:\n\n.. code-block:: shell\n\n    doxypypy -a -c %1\n\nRunning Doxygen as usual should now run all Python code through doxypypy.  Be\nsure to carefully browse the Doxygen output the first time to make sure that\nDoxygen properly found and executed doxypypy.\n\n.. _Doxygen: http://www.stack.nl/~dimitri/doxygen/\n.. _doxypy: https://github.com/Feneric/doxypy\n.. _PEP 257: http://www.python.org/dev/peps/pep-0257/\n.. _Google Python Style Guide: https://google.github.io/styleguide/pyguide.html?showone=Comments#Comments\n\n",
        "keywords": [
          "Doxygen",
          "filter",
          "Python",
          "documentation"
        ],
        "home_page": "https://github.com/Feneric/doxypypy",
        "author": "Eric W. Brown",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Environment :: Console",
          "Environment :: Plugins",
          "Intended Audience :: Developers",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: GNU General Public License v2 (GPLv2)",
          "Natural Language :: English",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: POSIX",
          "Operating System :: Unix",
          "Programming Language :: Python",
          "Topic :: Software Development :: Documentation"
        ],
        "requires_dist": [
          "chardet",
          "pytest ; extra == 'testing'",
          "tox ; extra == 'testing'"
        ],
        "provides_extra": [
          "testing"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\doxypypy-0.8.8.7.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "et-xmlfile",
        "version": "1.1.0",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "An implementation of lxml.xmlfile for the standard library",
        "description": "et_xmfile\n=========\n\net_xmlfile is a low memory library for creating large XML files.\n\nIt is based upon the `xmlfile module from lxml <http://lxml.de/api.html#incremental-xml-generation>`_ with the aim of allowing code to be developed that will work with both libraries. It was developed initially for the openpyxl project but is now a standalone module.\n\nThe code was written by Elias Rabel as part of the `Python DÃ¼sseldorf <http://pyddf.de>`_ openpyxl sprint in September 2014.\n\n\nNote on performance\n-------------------\n\nThe code was not developed with performance in mind but turned out to be faster than the existing SAX-based implementation but is significantly slower than lxml's xmlfile. There is one area where an optimisation for lxml will negatively affect the performance of et_xmfile and that is when using the `.element()` method on an xmlfile context manager. It is, therefore, recommended not to use this, though the method is provided for code compatibility.\n\n\n",
        "home_page": "https://foss.heptapod.net/openpyxl/et_xmlfile",
        "author": "See ATUHORS.txt",
        "author_email": "charlie.clark@clark-consulting.eu",
        "license": "MIT",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX",
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9"
        ],
        "requires_python": ">=3.6"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\et_xmlfile-1.1.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "executing",
        "version": "2.0.1",
        "summary": "Get the currently executing AST node of a frame, and other information",
        "description": "# executing\n\n[![Build Status](https://github.com/alexmojaki/executing/workflows/Tests/badge.svg?branch=master)](https://github.com/alexmojaki/executing/actions) [![Coverage Status](https://coveralls.io/repos/github/alexmojaki/executing/badge.svg?branch=master)](https://coveralls.io/github/alexmojaki/executing?branch=master) [![Supports Python versions 3.5+, including PyPy](https://img.shields.io/pypi/pyversions/executing.svg)](https://pypi.python.org/pypi/executing)\n\nThis mini-package lets you get information about what a frame is currently doing, particularly the AST node being executed.\n\n* [Usage](#usage)\n    * [Getting the AST node](#getting-the-ast-node)\n    * [Getting the source code of the node](#getting-the-source-code-of-the-node)\n    * [Getting the `__qualname__` of the current function](#getting-the-__qualname__-of-the-current-function)\n    * [The Source class](#the-source-class)\n* [Installation](#installation)\n* [How does it work?](#how-does-it-work)\n* [Is it reliable?](#is-it-reliable)\n* [Which nodes can it identify?](#which-nodes-can-it-identify)\n* [Libraries that use this](#libraries-that-use-this)\n\n## Usage\n\n### Getting the AST node\n\n```python\nimport executing\n\nnode = executing.Source.executing(frame).node\n```\n\nThen `node` will be an AST node (from the `ast` standard library module) or None if the node couldn't be identified (which may happen often and should always be checked).\n\n`node` will always be the same instance for multiple calls with frames at the same point of execution.\n\nIf you have a traceback object, pass it directly to `Source.executing()` rather than the `tb_frame` attribute to get the correct node.\n\n### Getting the source code of the node\n\nFor this you will need to separately install the [`asttokens`](https://github.com/gristlabs/asttokens) library, then obtain an `ASTTokens` object:\n\n```python\nexecuting.Source.executing(frame).source.asttokens()\n```\n\nor:\n\n```python\nexecuting.Source.for_frame(frame).asttokens()\n```\n\nor use one of the convenience methods:\n\n```python\nexecuting.Source.executing(frame).text()\nexecuting.Source.executing(frame).text_range()\n```\n\n### Getting the `__qualname__` of the current function\n\n```python\nexecuting.Source.executing(frame).code_qualname()\n```\n\nor:\n\n```python\nexecuting.Source.for_frame(frame).code_qualname(frame.f_code)\n```\n\n### The `Source` class\n\nEverything goes through the `Source` class. Only one instance of the class is created for each filename. Subclassing it to add more attributes on creation or methods is recommended. The classmethods such as `executing` will respect this. See the source code and docstrings for more detail.\n\n## Installation\n\n    pip install executing\n\nIf you don't like that you can just copy the file `executing.py`, there are no dependencies (but of course you won't get updates).\n\n## How does it work?\n\nSuppose the frame is executing this line:\n\n```python\nself.foo(bar.x)\n```\n\nand in particular it's currently obtaining the attribute `self.foo`. Looking at the bytecode, specifically `frame.f_code.co_code[frame.f_lasti]`, we can tell that it's loading an attribute, but it's not obvious which one. We can narrow down the statement being executed using `frame.f_lineno` and find the two `ast.Attribute` nodes representing `self.foo` and `bar.x`. How do we find out which one it is, without recreating the entire compiler in Python?\n\nThe trick is to modify the AST slightly for each candidate expression and observe the changes in the bytecode instructions. We change the AST to this:\n\n```python\n(self.foo ** 'longuniqueconstant')(bar.x)\n```\n    \nand compile it, and the bytecode will be almost the same but there will be two new instructions:\n\n    LOAD_CONST 'longuniqueconstant'\n    BINARY_POWER\n\nand just before that will be a `LOAD_ATTR` instruction corresponding to `self.foo`. Seeing that it's in the same position as the original instruction lets us know we've found our match.\n\n## Is it reliable?\n\nYes - if it identifies a node, you can trust that it's identified the correct one. The tests are very thorough - in addition to unit tests which check various situations directly, there are property tests against a large number of files (see the filenames printed in [this build](https://travis-ci.org/alexmojaki/executing/jobs/557970457)) with real code. Specifically, for each file, the tests:\n \n 1. Identify as many nodes as possible from all the bytecode instructions in the file, and assert that they are all distinct\n 2. Find all the nodes that should be identifiable, and assert that they were indeed identified somewhere\n\nIn other words, it shows that there is a one-to-one mapping between the nodes and the instructions that can be handled. This leaves very little room for a bug to creep in.\n\nFurthermore, `executing` checks that the instructions compiled from the modified AST exactly match the original code save for a few small known exceptions. This accounts for all the quirks and optimisations in the interpreter. \n\n## Which nodes can it identify?\n\nCurrently it works in almost all cases for the following `ast` nodes:\n \n - `Call`, e.g. `self.foo(bar)`\n - `Attribute`, e.g. `point.x`\n - `Subscript`, e.g. `lst[1]`\n - `BinOp`, e.g. `x + y` (doesn't include `and` and `or`)\n - `UnaryOp`, e.g. `-n` (includes `not` but only works sometimes)\n - `Compare` e.g. `a < b` (not for chains such as `0 < p < 1`)\n\nThe plan is to extend to more operations in the future.\n\n## Projects that use this\n\n### My Projects\n\n- **[`stack_data`](https://github.com/alexmojaki/stack_data)**: Extracts data from stack frames and tracebacks, particularly to display more useful tracebacks than the default. Also uses another related library of mine: **[`pure_eval`](https://github.com/alexmojaki/pure_eval)**.\n- **[`futurecoder`](https://futurecoder.io/)**: Highlights the executing node in tracebacks using `executing` via `stack_data`, and provides debugging with `snoop`.\n- **[`snoop`](https://github.com/alexmojaki/snoop)**: A feature-rich and convenient debugging library. Uses `executing` to show the operation which caused an exception and to allow the `pp` function to display the source of its arguments.\n- **[`heartrate`](https://github.com/alexmojaki/heartrate)**: A simple real time visualisation of the execution of a Python program. Uses `executing` to highlight currently executing operations, particularly in each frame of the stack trace.\n- **[`sorcery`](https://github.com/alexmojaki/sorcery)**: Dark magic delights in Python. Uses `executing` to let special callables called spells know where they're being called from.\n\n### Projects I've contributed to\n\n- **[`IPython`](https://github.com/ipython/ipython/pull/12150)**: Highlights the executing node in tracebacks using `executing` via [`stack_data`](https://github.com/alexmojaki/stack_data).\n- **[`icecream`](https://github.com/gruns/icecream)**: ðŸ¦ Sweet and creamy print debugging. Uses `executing` to identify where `ic` is called and print its arguments.\n- **[`friendly_traceback`](https://github.com/friendly-traceback/friendly-traceback)**: Uses `stack_data` and `executing` to pinpoint the cause of errors and provide helpful explanations.\n- **[`python-devtools`](https://github.com/samuelcolvin/python-devtools)**: Uses `executing` for print debugging similar to `icecream`.\n- **[`sentry_sdk`](https://github.com/getsentry/sentry-python)**: Add the integration `sentry_sdk.integrations.executingExecutingIntegration()` to show the function `__qualname__` in each frame in sentry events.\n- **[`varname`](https://github.com/pwwang/python-varname)**: Dark magics about variable names in python. Uses `executing` to find where its various magical functions like `varname` and `nameof` are called from.\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/alexmojaki/executing",
        "author": "Alex Hall",
        "author_email": "alex.mojaki@gmail.com",
        "license": "MIT",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12"
        ],
        "requires_dist": [
          "asttokens >=2.1.0 ; extra == 'tests'",
          "ipython ; extra == 'tests'",
          "pytest ; extra == 'tests'",
          "coverage ; extra == 'tests'",
          "coverage-enable-subprocess ; extra == 'tests'",
          "littleutils ; extra == 'tests'",
          "rich ; (python_version >= \"3.11\") and extra == 'tests'"
        ],
        "requires_python": ">=3.5",
        "provides_extra": [
          "tests"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\executing-2.0.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "fastjsonschema",
        "version": "2.20.0",
        "summary": "Fastest Python implementation of JSON schema",
        "description": "===========================\nFast JSON schema for Python\n===========================\n\n|PyPI| |Pythons|\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/fastjsonschema.svg\n   :alt: PyPI version\n   :target: https://pypi.python.org/pypi/fastjsonschema\n\n.. |Pythons| image:: https://img.shields.io/pypi/pyversions/fastjsonschema.svg\n   :alt: Supported Python versions\n   :target: https://pypi.python.org/pypi/fastjsonschema\n\nSee `documentation <https://horejsek.github.io/python-fastjsonschema/>`_.\n",
        "home_page": "https://github.com/horejsek/python-fastjsonschema",
        "author": "Michal Horejsek",
        "author_email": "fastjsonschema@horejsek.com",
        "license": "BSD",
        "license_file": [
          "LICENSE",
          "AUTHORS"
        ],
        "classifier": [
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "colorama ; extra == 'devel'",
          "jsonschema ; extra == 'devel'",
          "json-spec ; extra == 'devel'",
          "pylint ; extra == 'devel'",
          "pytest ; extra == 'devel'",
          "pytest-benchmark ; extra == 'devel'",
          "pytest-cache ; extra == 'devel'",
          "validictory ; extra == 'devel'"
        ],
        "provides_extra": [
          "devel"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\fastjsonschema-2.20.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "filelock",
        "version": "3.15.4",
        "summary": "A platform independent file lock.",
        "description": "# filelock\n\n[![PyPI](https://img.shields.io/pypi/v/filelock)](https://pypi.org/project/filelock/)\n[![Supported Python\nversions](https://img.shields.io/pypi/pyversions/filelock.svg)](https://pypi.org/project/filelock/)\n[![Documentation\nstatus](https://readthedocs.org/projects/py-filelock/badge/?version=latest)](https://py-filelock.readthedocs.io/en/latest/?badge=latest)\n[![Code style:\nblack](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![Downloads](https://static.pepy.tech/badge/filelock/month)](https://pepy.tech/project/filelock)\n[![check](https://github.com/tox-dev/py-filelock/actions/workflows/check.yml/badge.svg)](https://github.com/tox-dev/py-filelock/actions/workflows/check.yml)\n\nFor more information checkout the [official documentation](https://py-filelock.readthedocs.io/en/latest/index.html).\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "application",
          "cache",
          "directory",
          "log",
          "user"
        ],
        "maintainer_email": "BernÃ¡t GÃ¡bor <gaborjbernat@gmail.com>",
        "license_expression": "Unlicense",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: The Unlicense (Unlicense)",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Internet",
          "Topic :: Software Development :: Libraries",
          "Topic :: System"
        ],
        "requires_dist": [
          "furo>=2023.9.10; extra == 'docs'",
          "sphinx-autodoc-typehints!=1.23.4,>=1.25.2; extra == 'docs'",
          "sphinx>=7.2.6; extra == 'docs'",
          "covdefaults>=2.3; extra == 'testing'",
          "coverage>=7.3.2; extra == 'testing'",
          "diff-cover>=8.0.1; extra == 'testing'",
          "pytest-asyncio>=0.21; extra == 'testing'",
          "pytest-cov>=4.1; extra == 'testing'",
          "pytest-mock>=3.12; extra == 'testing'",
          "pytest-timeout>=2.2; extra == 'testing'",
          "pytest>=7.4.3; extra == 'testing'",
          "virtualenv>=20.26.2; extra == 'testing'",
          "typing-extensions>=4.8; (python_version < '3.11') and extra == 'typing'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://py-filelock.readthedocs.io",
          "Homepage, https://github.com/tox-dev/py-filelock",
          "Source, https://github.com/tox-dev/py-filelock",
          "Tracker, https://github.com/tox-dev/py-filelock/issues"
        ],
        "provides_extra": [
          "docs",
          "testing",
          "typing"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\filelock-3.15.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "Flask",
        "version": "3.1.0",
        "summary": "A simple framework for building complex web applications.",
        "description": "# Flask\n\nFlask is a lightweight [WSGI][] web application framework. It is designed\nto make getting started quick and easy, with the ability to scale up to\ncomplex applications. It began as a simple wrapper around [Werkzeug][]\nand [Jinja][], and has become one of the most popular Python web\napplication frameworks.\n\nFlask offers suggestions, but doesn't enforce any dependencies or\nproject layout. It is up to the developer to choose the tools and\nlibraries they want to use. There are many extensions provided by the\ncommunity that make adding new functionality easy.\n\n[WSGI]: https://wsgi.readthedocs.io/\n[Werkzeug]: https://werkzeug.palletsprojects.com/\n[Jinja]: https://jinja.palletsprojects.com/\n\n\n## A Simple Example\n\n```python\n# save this as app.py\nfrom flask import Flask\n\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    return \"Hello, World!\"\n```\n\n```\n$ flask run\n  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n```\n\n\n## Donate\n\nThe Pallets organization develops and supports Flask and the libraries\nit uses. In order to grow the community of contributors and users, and\nallow the maintainers to devote more time to the projects, [please\ndonate today][].\n\n[please donate today]: https://palletsprojects.com/donate\n\n",
        "description_content_type": "text/markdown",
        "maintainer_email": "Pallets <contact@palletsprojects.com>",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Framework :: Flask",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Topic :: Internet :: WWW/HTTP :: Dynamic Content",
          "Topic :: Internet :: WWW/HTTP :: WSGI",
          "Topic :: Internet :: WWW/HTTP :: WSGI :: Application",
          "Topic :: Software Development :: Libraries :: Application Frameworks",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "Werkzeug>=3.1",
          "Jinja2>=3.1.2",
          "itsdangerous>=2.2",
          "click>=8.1.3",
          "blinker>=1.9",
          "importlib-metadata>=3.6; python_version < '3.10'",
          "asgiref>=3.2 ; extra == \"async\"",
          "python-dotenv ; extra == \"dotenv\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Changes, https://flask.palletsprojects.com/changes/",
          "Chat, https://discord.gg/pallets",
          "Documentation, https://flask.palletsprojects.com/",
          "Donate, https://palletsprojects.com/donate",
          "Source, https://github.com/pallets/flask/"
        ],
        "provides_extra": [
          "async",
          "dotenv"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\flask-3.1.0.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.2",
        "name": "fonttools",
        "version": "4.55.4",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "home-page",
          "license",
          "maintainer",
          "maintainer-email",
          "platform",
          "provides-extra",
          "requires-python",
          "summary"
        ],
        "platform": [
          "Any"
        ],
        "summary": "Tools to manipulate font files",
        "description": "|CI Build Status| |Coverage Status| |PyPI| |Gitter Chat|\n\nWhat is this?\n~~~~~~~~~~~~~\n\n| fontTools is a library for manipulating fonts, written in Python. The\n  project includes the TTX tool, that can convert TrueType and OpenType\n  fonts to and from an XML text format, which is also called TTX. It\n  supports TrueType, OpenType, AFM and to an extent Type 1 and some\n  Mac-specific formats. The project has an `MIT open-source\n  licence <LICENSE>`__.\n| Among other things this means you can use it free of charge.\n\n`User documentation <https://fonttools.readthedocs.io/en/latest/>`_ and\n`developer documentation <https://fonttools.readthedocs.io/en/latest/developer.html>`_\nare available at `Read the Docs <https://fonttools.readthedocs.io/>`_.\n\nInstallation\n~~~~~~~~~~~~\n\nFontTools requires `Python <http://www.python.org/download/>`__ 3.8\nor later. We try to follow the same schedule of minimum Python version support as\nNumPy (see `NEP 29 <https://numpy.org/neps/nep-0029-deprecation_policy.html>`__).\n\nThe package is listed in the Python Package Index (PyPI), so you can\ninstall it with `pip <https://pip.pypa.io>`__:\n\n.. code:: sh\n\n    pip install fonttools\n\nIf you would like to contribute to its development, you can clone the\nrepository from GitHub, install the package in 'editable' mode and\nmodify the source code in place. We recommend creating a virtual\nenvironment, using `virtualenv <https://virtualenv.pypa.io>`__ or\nPython 3 `venv <https://docs.python.org/3/library/venv.html>`__ module.\n\n.. code:: sh\n\n    # download the source code to 'fonttools' folder\n    git clone https://github.com/fonttools/fonttools.git\n    cd fonttools\n\n    # create new virtual environment called e.g. 'fonttools-venv', or anything you like\n    python -m virtualenv fonttools-venv\n\n    # source the `activate` shell script to enter the environment (Unix-like); to exit, just type `deactivate`\n    . fonttools-venv/bin/activate\n\n    # to activate the virtual environment in Windows `cmd.exe`, do\n    fonttools-venv\\Scripts\\activate.bat\n\n    # install in 'editable' mode\n    pip install -e .\n\nOptional Requirements\n---------------------\n\nThe ``fontTools`` package currently has no (required) external dependencies\nbesides the modules included in the Python Standard Library.\nHowever, a few extra dependencies are required by some of its modules, which\nare needed to unlock optional features.\nThe ``fonttools`` PyPI distribution also supports so-called \"extras\", i.e. a\nset of keywords that describe a group of additional dependencies, which can be\nused when installing via pip, or when specifying a requirement.\nFor example:\n\n.. code:: sh\n\n    pip install fonttools[ufo,lxml,woff,unicode]\n\nThis command will install fonttools, as well as the optional dependencies that\nare required to unlock the extra features named \"ufo\", etc.\n\n- ``Lib/fontTools/misc/etree.py``\n\n  The module exports a ElementTree-like API for reading/writing XML files, and\n  allows to use as the backend either the built-in ``xml.etree`` module or\n  `lxml <https://lxml.de>`__. The latter is preferred whenever present,\n  as it is generally faster and more secure.\n\n  *Extra:* ``lxml``\n\n- ``Lib/fontTools/ufoLib``\n\n  Package for reading and writing UFO source files; it requires:\n\n  * `fs <https://pypi.org/pypi/fs>`__: (aka ``pyfilesystem2``) filesystem\n    abstraction layer.\n\n  * `enum34 <https://pypi.org/pypi/enum34>`__: backport for the built-in ``enum``\n    module (only required on Python < 3.4).\n\n  *Extra:* ``ufo``\n\n- ``Lib/fontTools/ttLib/woff2.py``\n\n  Module to compress/decompress WOFF 2.0 web fonts; it requires:\n\n  * `brotli <https://pypi.python.org/pypi/Brotli>`__: Python bindings of\n    the Brotli compression library.\n\n  *Extra:* ``woff``\n\n- ``Lib/fontTools/ttLib/sfnt.py``\n\n  To better compress WOFF 1.0 web fonts, the following module can be used\n  instead of the built-in ``zlib`` library:\n\n  * `zopfli <https://pypi.python.org/pypi/zopfli>`__: Python bindings of\n    the Zopfli compression library.\n\n  *Extra:* ``woff``\n\n- ``Lib/fontTools/unicode.py``\n\n  To display the Unicode character names when dumping the ``cmap`` table\n  with ``ttx`` we use the ``unicodedata`` module in the Standard Library.\n  TheÂ version included in there varies between different Python versions.\n  To use the latest available data, you can install:\n\n  * `unicodedata2 <https://pypi.python.org/pypi/unicodedata2>`__:\n    ``unicodedata`` backport for Python 3.x updated to the latest Unicode\n    version 15.0.\n\n  *Extra:* ``unicode``\n\n- ``Lib/fontTools/varLib/interpolatable.py``\n\n  Module for finding wrongÂ contour/component order between different masters.\n  It requires one of the following packages in order to solve the so-called\n  \"minimum weight perfect matching problem in bipartite graphs\", or\n  the Assignment problem:\n\n  * `scipy <https://pypi.python.org/pypi/scipy>`__: the Scientific Library\n    for Python, which internally uses `NumPy <https://pypi.python.org/pypi/numpy>`__\n    arrays and hence is very fast;\n  * `munkres <https://pypi.python.org/pypi/munkres>`__: a pure-Python\n    module that implements the Hungarian or Kuhn-Munkres algorithm.\n\n  To plot the results to a PDF or HTML format, you also need to install:\n\n  * `pycairo <https://pypi.org/project/pycairo/>`__: Python bindings for the\n    Cairo graphics library. Note that wheels are currently only available for\n    Windows, for other platforms see pycairo's `installation instructions\n    <https://pycairo.readthedocs.io/en/latest/getting_started.html>`__.\n\n  *Extra:* ``interpolatable``\n\n- ``Lib/fontTools/varLib/plot.py``\n\n  Module for visualizing DesignSpaceDocument and resulting VariationModel.\n\n  * `matplotlib <https://pypi.org/pypi/matplotlib>`__: 2D plotting library.\n\n  *Extra:* ``plot``\n\n- ``Lib/fontTools/misc/symfont.py``\n\n  Advanced module for symbolic font statistics analysis; it requires:\n\n  * `sympy <https://pypi.python.org/pypi/sympy>`__: the Python library for\n    symbolic mathematics.\n\n  *Extra:* ``symfont``\n\n- ``Lib/fontTools/t1Lib.py``\n\n  To get the file creatorÂ and type of Macintosh PostScript Type 1 fonts\n  on Python 3 you need to install the following module, as the old ``MacOS``\n  module is no longer included in Mac Python:\n\n  * `xattr <https://pypi.python.org/pypi/xattr>`__: Python wrapper for\n    extended filesystem attributes (macOS platform only).\n\n  *Extra:* ``type1``\n\n- ``Lib/fontTools/ttLib/removeOverlaps.py``\n\n  Simplify TrueType glyphs by merging overlapping contours and components.\n\n  * `skia-pathops <https://pypi.python.org/pypy/skia-pathops>`__: Python\n    bindings for the Skia library's PathOps module, performing boolean\n    operations on paths (union, intersection, etc.).\n\n  *Extra:* ``pathops``\n\n- ``Lib/fontTools/pens/cocoaPen.py`` and ``Lib/fontTools/pens/quartzPen.py``\n\n  Pens for drawing glyphs with Cocoa ``NSBezierPath`` or ``CGPath`` require:\n\n  * `PyObjC <https://pypi.python.org/pypi/pyobjc>`__: the bridge between\n    Python and the Objective-C runtime (macOS platform only).\n\n- ``Lib/fontTools/pens/qtPen.py``\n\n  Pen for drawing glyphs with Qt's ``QPainterPath``, requires:\n\n  * `PyQt5 <https://pypi.python.org/pypi/PyQt5>`__: Python bindings for\n    the QtÂ cross platform UI and application toolkit.\n\n- ``Lib/fontTools/pens/reportLabPen.py``\n\n  Pen to drawing glyphs as PNG images, requires:\n\n  * `reportlab <https://pypi.python.org/pypi/reportlab>`__: Python toolkit\n    for generating PDFs and graphics.\n\n- ``Lib/fontTools/pens/freetypePen.py``\n\n  Pen to drawing glyphs with FreeType as raster images, requires:\n\n  * `freetype-py <https://pypi.python.org/pypi/freetype-py>`__: Python binding\n    for the FreeType library.\n    \n- ``Lib/fontTools/ttLib/tables/otBase.py``\n\n  Use the Harfbuzz library to serialize GPOS/GSUB using ``hb_repack`` method, requires:\n  \n  * `uharfbuzz <https://pypi.python.org/pypi/uharfbuzz>`__: Streamlined Cython\n    bindings for the harfbuzz shaping engine\n    \n  *Extra:* ``repacker``\n\nHow to make a new release\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\n1) Update ``NEWS.rst`` with all the changes since the last release. Write a\n   changelog entry for each PR, with one or two short sentences summarizing it,\n   as well as links to the PR and relevant issues addressed by the PR. Do not\n   put a new title, the next command will do it for you.\n2) Use semantic versioning to decide whether the new release will be a 'major',\n   'minor' or 'patch' release. It's usually one of the latter two, depending on\n   whether new backward compatible APIs were added, or simply some bugs were fixed.\n3) From inside a venv, first do ``pip install -r dev-requirements.txt``, then run\n   the ``python setup.py release`` command from the tip of the ``main`` branch.\n   By default this bumps the third or 'patch' digit only, unless you pass ``--major``\n   or ``--minor`` to bump respectively the first or second digit.\n   This bumps the package version string, extracts the changes since the latest\n   version from ``NEWS.rst``, and uses that text to create an annotated git tag\n   (or a signed git tag if you pass the ``--sign`` option and your git and Github\n   account are configured for `signing commits <https://docs.github.com/en/github/authenticating-to-github/managing-commit-signature-verification/signing-commits>`__\n   using a GPG key).\n   It also commits an additional version bump which opens the main branch for\n   the subsequent developmental cycle\n4) Push both the tag and commit to the upstream repository, by running the command\n   ``git push --follow-tags``. Note: it may push other local tags as well, be\n   careful.\n5) Let the CI build the wheel and source distribution packages and verify both\n   get uploaded to the Python Package Index (PyPI).\n6) [Optional] Go to fonttools `Github Releases <https://github.com/fonttools/fonttools/releases>`__\n   page and create a new release, copy-pasting the content of the git tag\n   message. This way, the release notes are nicely formatted as markdown, and\n   users watching the repo will get an email notification. One day we shall\n   automate that too.\n\n\nAcknowledgements\n~~~~~~~~~~~~~~~~\n\nIn alphabetical order:\n\naschmitz, Olivier Berten, Samyak Bhuta, Erik van Blokland, Petr van Blokland,\nJelle Bosma, Sascha Brawer, Tom Byrer, Antonio Cavedoni, FrÃ©dÃ©ric Coiffier,\nVincent Connare, David Corbett, Simon Cozens, Dave Crossland, Simon Daniels,\nPeter Dekkers, Behdad Esfahbod, Behnam Esfahbod, Hannes Famira, Sam Fishman,\nMatt Fontaine, Takaaki Fuji, Rob Hagemans, Yannis Haralambous, Greg Hitchcock,\nJeremie Hornus, Khaled Hosny, John Hudson, Denis Moyogo Jacquerye, Jack Jansen,\nTom Kacvinsky, Jens Kutilek, Antoine Leca, Werner Lemberg, Tal Leming, Peter\nLofting, Cosimo Lupo, Olli Meier, Masaya Nakamura, Dave Opstad, Laurence Penney,\nRoozbeh Pournader, Garret Rieger, Read Roberts, Colin Rofls, Guido van Rossum,\nJust van Rossum, Andreas Seidel, Georg Seifert, Chris Simpkins, Miguel Sousa,\nAdam Twardoch, Adrien TÃ©tar, Vitaly Volkov, Paul Wise.\n\nCopyrights\n~~~~~~~~~~\n\n| Copyright (c) 1999-2004 Just van Rossum, LettError\n  (just@letterror.com)\n| See `LICENSE <LICENSE>`__ for the full license.\n\nCopyright (c) 2000 BeOpen.com. All Rights Reserved.\n\nCopyright (c) 1995-2001 Corporation for National Research Initiatives.\nAll Rights Reserved.\n\nCopyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam. All\nRights Reserved.\n\nHave fun!\n\n.. |CI Build Status| image:: https://github.com/fonttools/fonttools/workflows/Test/badge.svg\n   :target: https://github.com/fonttools/fonttools/actions?query=workflow%3ATest\n.. |Coverage Status| image:: https://codecov.io/gh/fonttools/fonttools/branch/main/graph/badge.svg\n   :target: https://codecov.io/gh/fonttools/fonttools\n.. |PyPI| image:: https://img.shields.io/pypi/v/fonttools.svg\n   :target: https://pypi.org/project/FontTools\n.. |Gitter Chat| image:: https://badges.gitter.im/fonttools-dev/Lobby.svg\n   :alt: Join the chat at https://gitter.im/fonttools-dev/Lobby\n   :target: https://gitter.im/fonttools-dev/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n\nChangelog\n~~~~~~~~~\n\n4.55.4 (released 2025-01-21)\n----------------------------\n\n- [bezierTools] Fixed ``splitCubicAtT`` sometimes not returning identical start/end points as result of numerical precision (#3742, #3743).\n- [feaLib/ast] Fixed docstring of ``AlternateSubstStatement`` (#3735).\n- [transform] Typing fixes (#3734).\n\n4.55.3 (released 2024-12-10)\n----------------------------\n\n- [Docs] fill out ttLib table section [#3716]\n- [feaLib] More efficient inline format 4 lookups [#3726]\n\n4.55.2 (released 2024-12-05)\n----------------------------\n\n- [Docs] update Sphinx config (#3712)\n- [designspaceLib] Allow axisOrdering to be set to zero (#3715)\n- [feaLib] Donâ€™t modify variable anchors in place (#3717)\n\n4.55.1 (released 2024-12-02)\n----------------------------\n\n- [ttGlyphSet] Support VARC CFF2 fonts (#3683)\n- [DecomposedTransform] Document and implement always skewY == 0 (#3697)\n- [varLib] \"Fix\" cython iup issue? (#3704)\n- Cython minor refactor (#3705)\n\n\n4.55.0 (released 2024-11-14)\n----------------------------\n\n- [cffLib.specializer] Adjust stack use calculation (#3689)\n- [varLib] Lets not add mac names if the rest of name doesn't have them (#3688)\n- [ttLib.reorderGlyphs] Update CFF table charstrings and charset (#3682)\n- [cffLib.specializer] Add cmdline to specialize a CFF2 font (#3675, #3679)\n- [CFF2] Lift uint16 VariationStore.length limitation (#3674)\n- [subset] consider variation selectors subsetting cmap14 (#3672)\n- [varLib.interpolatable] Support CFF2 fonts (#3670)\n- Set isfinal to true in XML parser for proper resource cleanup (#3669)\n- [removeOverlaps] Fix CFF CharString width (#3659)\n- [glyf] Add optimizeSize option (#3657)\n- Python 3.13 support (#3656)\n- [TupleVariation] Optimize for loading speed, not size (#3650, #3653)\n\n\n4.54.1 (released 2024-09-24)\n----------------------------\n\n- [unicodedata] Update to Unicode 16\n- [subset] Escape ``\\\\`` in doc string\n\n4.54.0 (released 2024-09-23)\n----------------------------\n\n- [Docs] Small docs cleanups by @n8willis (#3611)\n- [Docs] cleanup code blocks by @n8willis (#3627)\n- [Docs] fix Sphinx builds by @n8willis (#3625)\n- [merge] Minor fixes to documentation for merge by @drj11 (#3588)\n- [subset] Small tweaks to pyftsubset documentation by @RoelN (#3633)\n- [Tests] Do not require fonttools command to be available by @behdad (#3612)\n- [Tests] subset_test: add failing test to reproduce issue #3616 by @anthrotype (#3622)\n- [ttLib] NameRecordVisitor: include whole sequence of character variants' UI labels, not just the first by @anthrotype (#3617)\n- [varLib.avar] Reconstruct mappings from binary by @behdad (#3598)\n- [varLib.instancer] Fix visual artefacts with partial L2 instancing by @Hoolean (#3635)\n- [varLib.interpolatable] Support discrete axes in .designspace by @behdad (#3599)\n- [varLib.models] By default, assume OpenType-like normalized space by @behdad (#3601)\n\n4.53.1 (released 2024-07-05)\n----------------------------\n\n- [feaLib] Improve the sharing of inline chained lookups (#3559)\n- [otlLib] Correct the calculation of OS/2.usMaxContext with reversed chaining contextual single substitutions (#3569)\n- [misc.visitor] Visitors search the inheritance chain of objects they are visiting (#3581)\n\n4.53.0 (released 2024-05-31)\n----------------------------\n\n- [ttLib.removeOverlaps] Support CFF table to aid in downconverting CFF2 fonts (#3528)\n- [avar] Fix crash when accessing not-yet-existing attribute (#3550)\n- [docs] Add buildMathTable to otlLib.builder documentation (#3540)\n- [feaLib] Allow UTF-8 with BOM when reading features (#3495)\n- [SVGPathPen] Revert rounding coordinates to two decimal places by default (#3543)\n- [varLib.instancer] Refix output filename decision-making  (#3545, #3544, #3548)\n\n4.52.4 (released 2024-05-27)\n----------------------------\n\n- [varLib.cff] Restore and deprecate convertCFFtoCFF2 that was removed in 4.52.0\n  release as it is used by downstream projects (#3535).\n\n4.52.3 (released 2024-05-27)\n----------------------------\n\n- Fixed a small syntax error in the reStructuredText-formatted NEWS.rst file\n  which caused the upload to PyPI to fail for 4.52.2. No other code changes.\n\n4.52.2 (released 2024-05-27)\n----------------------------\n\n- [varLib.interpolatable] Ensure that scipy/numpy output is JSON-serializable\n  (#3522, #3526).\n- [housekeeping] Regenerate table lists, to fix pyinstaller packaging of the new\n  ``VARC`` table (#3531, #3529).\n- [cffLib] Make CFFToCFF2 and CFF2ToCFF more robust (#3521, #3525).\n\n4.52.1 (released 2024-05-24)\n----------------------------\n\n- Fixed a small syntax error in the reStructuredText-formatted NEWS.rst file\n  which caused the upload to PyPI to fail for 4.52.0. No other code changes.\n\n4.52.0 (released 2024-05-24)\n----------------------------\n\n- Added support for the new ``VARC`` (Variable Composite) table that is being\n  proposed to OpenType spec (#3395). For more info:\n  https://github.com/harfbuzz/boring-expansion-spec/blob/main/VARC.md\n- [ttLib.__main__] Fixed decompiling all tables (90fed08).\n- [feaLib] Don't reference the same lookup index multiple times within the same\n  feature record, it is only applied once anyway (#3520).\n- [cffLib] Moved methods to desubroutinize, remove hints and unused subroutines\n  from subset module to cffLib (#3517).\n- [varLib.instancer] Added support for partial-instancing CFF2 tables! Also, added\n  method to down-convert from CFF2 to CFF 1.0, and CLI entry points to convert\n  CFF<->CFF2 (#3506).\n- [subset] Prune unused user name IDs even with --name-IDs='*' (#3410).\n- [ttx] use GNU-style getopt to intermix options and positional arguments (#3509).\n- [feaLib.variableScalar] Fixed ``value_at_location()`` method (#3491)\n- [psCharStrings] Shorten output of ``encodeFloat`` (#3492).\n- [bezierTools] Fix infinite-recursion in ``calcCubicArcLength`` (#3502).\n- [avar2] Implement ``avar2`` support in ``TTFont.getGlyphSet()`` (#3473).\n\n4.51.0 (released 2024-04-05)\n----------------------------\n\n- [ttLib] Optimization on loading aux fields (#3464).\n- [ttFont] Add reorderGlyphs (#3468).\n\n4.50.0 (released 2024-03-15)\n----------------------------\n\n- [pens] Added decomposing filter pens that draw components as regular contours (#3460).\n- [instancer] Drop explicit no-op axes from TupleVariations (#3457).\n- [cu2qu/ufo] Return set of modified glyph names from fonts_to_quadratic (#3456).\n\n4.49.0 (released 2024-02-15)\n----------------------------\n\n- [otlLib] Add API for building ``MATH`` table (#3446)\n\n4.48.1 (released 2024-02-06)\n----------------------------\n\n- Fixed uploading wheels to PyPI, no code changes since v4.48.0.\n\n4.48.0 (released 2024-02-06)\n----------------------------\n\n- [varLib] Do not log when there are no OTL tables to be merged.\n- [setup.py] Do not restrict lxml<5 any more, tests pass just fine with lxml>=5.\n- [feaLib] Remove glyph and class names length restrictions in FEA (#3424).\n- [roundingPens] Added ``transformRoundFunc`` parameter to the rounding pens to allow\n  for custom rounding of the components' transforms (#3426).\n- [feaLib] Keep declaration order of ligature components within a ligature set, instead\n  of sorting by glyph name (#3429).\n- [feaLib] Fixed ordering of alternates in ``aalt`` lookups, following the declaration\n  order of feature references within the ``aalt`` feature block (#3430).\n- [varLib.instancer] Fixed a bug in the instancer's IUP optimization (#3432).\n- [sbix] Support sbix glyphs with new graphicType \"flip\" (#3433).\n- [svgPathPen] Added ``--glyphs`` option to dump the SVG paths for the named glyphs\n  in the font (0572f78).\n- [designspaceLib] Added \"description\" attribute to ``<mappings>`` and ``<mapping>``\n  elements, and allow multiple ``<mappings>`` elements to group ``<mapping>`` elements\n  that are logically related (#3435, #3437).\n- [otlLib] Correctly choose the most compact GSUB contextual lookup format (#3439).\n\n4.47.2 (released 2024-01-11)\n----------------------------\n\nMinor release to fix uploading wheels to PyPI.\n\n4.47.1 (released 2024-01-11)\n----------------------------\n\n- [merge] Improve help message and add standard command line options (#3408)\n- [otlLib] Pass ``ttFont`` to ``name.addName`` in ``buildStatTable`` (#3406)\n- [featureVars] Re-use ``FeatureVariationRecord``'s when possible (#3413)\n\n4.47.0 (released 2023-12-18)\n----------------------------\n\n- [varLib.models] New API for VariationModel: ``getMasterScalars`` and\n  ``interpolateFromValuesAndScalars``.\n- [varLib.interpolatable] Various bugfixes and rendering improvements. In particular,\n  add a Summary page in the front, and an Index and Table-of-Contents in the back.\n  Change the page size to Letter.\n- [Docs/designspaceLib] Defined a new ``public.fontInfo`` lib key, not used anywhere yet (#3358).\n\n4.46.0 (released 2023-12-02)\n----------------------------\n\n- [featureVars] Allow to register the same set of substitution rules to multiple features.\n  The ``addFeatureVariations`` function can now take a list of featureTags; similarly, the\n  lib key 'com.github.fonttools.varLib.featureVarsFeatureTag' can now take a\n  comma-separateed string of feature tags (e.g. \"salt,ss01\") instead of a single tag (#3360).\n- [featureVars] Don't overwrite GSUB FeatureVariations, but append new records to it\n  for features which are not already there. But raise ``VarLibError`` if the feature tag\n  already has feature variations associated with it (#3363).\n- [varLib] Added ``addGSUBFeatureVariations`` function to add GSUB Feature Variations\n  to an existing variable font from rules defined in a DesignSpace document (#3362).\n- [varLib.interpolatable] Various bugfixes and rendering improvements. In particular,\n  a new test for \"underweight\" glyphs. The new test reports quite a few false-positives\n  though. Please send feedback.\n\n4.45.1 (released 2023-11-23)\n----------------------------\n\n- [varLib.interpolatable] Various bugfixes and improvements, better reporting, reduced\n  false positives.\n- [ttGlyphSet] Added option to not recalculate glyf bounds (#3348).\n\n4.45.0 (released 2023-11-20)\n----------------------------\n\n- [varLib.interpolatable] Vastly improved algorithms. Also available now is ``--pdf``\n  and ``--html`` options to generate a PDF or HTML report of the interpolation issues.\n  The PDF/HTML report showcases the problematic masters, the interpolated broken\n  glyph, as well as the proposed fixed version.\n\n4.44.3 (released 2023-11-15)\n----------------------------\n\n- [subset] Only prune codepage ranges for OS/2.version >= 1, ignore otherwise (#3334).\n- [instancer] Ensure hhea vertical metrics stay in sync with OS/2 ones after instancing\n  MVAR table containing 'hasc', 'hdsc' or 'hlgp' tags (#3297).\n\n4.44.2 (released 2023-11-14)\n----------------------------\n\n- [glyf] Have ``Glyph.recalcBounds`` skip empty components (base glyph with no contours)\n  when computing the bounding box of composite glyphs. This simply restores the existing\n  behavior before some changes were introduced in fonttools 4.44.0 (#3333).\n\n4.44.1 (released 2023-11-14)\n----------------------------\n\n- [feaLib] Ensure variable mark anchors are deep-copied while building since they\n  get modified in-place and later reused (#3330).\n- [OS/2|subset] Added method to ``recalcCodePageRanges`` to OS/2 table class; added\n  ``--prune-codepage-ranges`` to `fonttools subset` command (#3328, #2607).\n\n4.44.0 (released 2023-11-03)\n----------------------------\n\n- [instancer] Recalc OS/2 AvgCharWidth after instancing if default changes (#3317).\n- [otlLib] Make ClassDefBuilder class order match varLib.merger's, i.e. large\n  classes first, then glyph lexicographic order (#3321, #3324).\n- [instancer] Allow not specifying any of min:default:max values and let be filled\n  up with fvar's values (#3322, #3323).\n- [instancer] When running --update-name-table ignore axes that have no STAT axis\n  values (#3318, #3319).\n- [Debg] When dumping to ttx, write the embedded JSON as multi-line string with\n  indentation (92cbfee0d).\n- [varStore] Handle > 65535 items per encoding by splitting VarData subtable (#3310).\n- [subset] Handle null-offsets in MarkLigPos subtables.\n- [subset] Keep East Asian spacing fatures vhal, halt, chws, vchw by default (#3305).\n- [instancer.solver] Fixed case where axisDef < lower and upper < axisMax (#3304).\n- [glyf] Speed up compilation, mostly around ``recalcBounds`` (#3301).\n- [varLib.interpolatable] Speed it up when working on variable fonts, plus various\n  micro-optimizations (#3300).\n- Require unicodedata2 >= 15.1.0 when installed with 'unicode' extra, contains UCD 15.1.\n\n4.43.1 (released 2023-10-06)\n----------------------------\n\n- [EBDT] Fixed TypeError exception in `_reverseBytes` method triggered when dumping\n  some bitmap fonts with `ttx -z bitwise` option (#3162).\n- [v/hhea] Fixed UnboundLocalError exception in ``recalc`` method when no vmtx or hmtx\n  tables are present (#3290).\n- [bezierTools] Fixed incorrectly typed cython local variable leading to TypeError when\n  calling ``calcQuadraticArcLength`` (#3288).\n- [feaLib/otlLib] Better error message when building Coverage table with missing glyph (#3286).\n\n4.43.0 (released 2023-09-29)\n----------------------------\n\n- [subset] Set up lxml ``XMLParser(resolve_entities=False)`` when parsing OT-SVG documents\n  to prevent XML External Entity (XXE) attacks (9f61271dc):\n  https://codeql.github.com/codeql-query-help/python/py-xxe/\n- [varLib.iup] Added workaround for a Cython bug in ``iup_delta_optimize`` that was\n  leading to IUP tolerance being incorrectly initialised, resulting in sub-optimal deltas\n  (60126435d, cython/cython#5732).\n- [varLib] Added new command-line entry point ``fonttools varLib.avar`` to add an\n  ``avar`` table to an existing VF from axes mappings in a .designspace file (0a3360e52).\n- [instancer] Fixed bug whereby no longer used variation regions were not correctly pruned\n  after VarData optimization (#3268).\n- Added support for Python 3.12 (#3283).\n\n4.42.1 (released 2023-08-20)\n----------------------------\n\n- [t1Lib] Fixed several Type 1 issues (#3238, #3240).\n- [otBase/packer] Allow sharing tables reached by different offset sizes (#3241, #3236).\n- [varLib/merger] Fix Cursive attachment merging error when all anchors are NULL (#3248, #3247).\n- [ttLib] Fixed warning when calling ``addMultilingualName`` and ``ttFont`` parameter was not\n  passed on to ``findMultilingualName`` (#3253).\n\n4.42.0 (released 2023-08-02)\n----------------------------\n\n- [varLib] Use sentinel value 0xFFFF to mark a glyph advance in hmtx/vmtx as non\n  participating, allowing sparse masters to contain glyphs for variation purposes other\n  than {H,V}VAR (#3235).\n- [varLib/cff] Treat empty glyphs in non-default masters as missing, thus not participating\n  in CFF2 delta computation, similarly to how varLib already treats them for gvar (#3234).\n- Added varLib.avarPlanner script to deduce 'correct' avar v1 axis mappings based on\n  glyph average weights (#3223).\n\n4.41.1 (released 2023-07-21)\n----------------------------\n\n- [subset] Fixed perf regression in v4.41.0 by making ``NameRecordVisitor`` only visit\n  tables that do contain nameID references (#3213, #3214).\n- [varLib.instancer] Support instancing fonts containing null ConditionSet offsets in\n  FeatureVariationRecords (#3211, #3212).\n- [statisticsPen] Report font glyph-average weight/width and font-wide slant.\n- [fontBuilder] Fixed head.created date incorrectly set to 0 instead of the current\n  timestamp, regression introduced in v4.40.0 (#3210).\n- [varLib.merger] Support sparse ``CursivePos`` masters (#3209).\n\n4.41.0 (released 2023-07-12)\n----------------------------\n\n- [fontBuilder] Fixed bug in setupOS2 with default panose attribute incorrectly being\n  set to a dict instead of a Panose object (#3201).\n- [name] Added method to ``removeUnusedNameRecords`` in the user range (#3185).\n- [varLib.instancer] Fixed issue with L4 instancing (moving default) (#3179).\n- [cffLib] Use latin1 so we can roundtrip non-ASCII in {Full,Font,Family}Name (#3202).\n- [designspaceLib] Mark <source name=\"...\"> as optional in docs (as it is in the code).\n- [glyf-1] Fixed drawPoints() bug whereby last cubic segment becomes quadratic (#3189, #3190).\n- [fontBuilder] Propagate the 'hidden' flag to the fvar Axis instance (#3184).\n- [fontBuilder] Update setupAvar() to also support avar 2, fixing ``_add_avar()`` call\n  site (#3183).\n- Added new ``voltLib.voltToFea`` submodule (originally Tiro Typeworks' \"Volto\") for\n  converting VOLT OpenType Layout sources to FEA format (#3164).\n\n4.40.0 (released 2023-06-12)\n----------------------------\n\n- Published native binary wheels to PyPI for all the python minor versions and platform\n  and architectures currently supported that would benefit from this. They will include\n  precompiled Cython-accelerated modules (e.g. cu2qu) without requiring to compile them\n  from source. The pure-python wheel and source distribution will continue to be\n  published as always (pip will automatically chose them when no binary wheel is\n  available for the given platform, e.g. pypy). Use ``pip install --no-binary=fonttools fonttools``\n  to expliclity request pip to install from the pure-python source.\n- [designspaceLib|varLib] Add initial support for specifying axis mappings and build\n  ``avar2`` table from those (#3123).\n- [feaLib] Support variable ligature caret position (#3130).\n- [varLib|glyf] Added option to --drop-implied-oncurves; test for impliable oncurve\n  points either before or after rounding (#3146, #3147, #3155, #3156).\n- [TTGlyphPointPen] Don't error with empty contours, simply ignore them (#3145).\n- [sfnt] Fixed str vs bytes remnant of py3 transition in code dealing with de/compiling\n  WOFF metadata (#3129).\n- [instancer-solver] Fixed bug when moving default instance with sparse masters (#3139, #3140).\n- [feaLib] Simplify variable scalars that donâ€™t vary (#3132).\n- [pens] Added filter pen that explicitly emits closing line when lastPt != movePt (#3100).\n- [varStore] Improve optimize algorithm and better document the algorithm (#3124, #3127).\n  Added ``quantization`` option (#3126).\n- Added CI workflow config file for building native binary wheels (#3121).\n- [fontBuilder] Added glyphDataFormat=0 option; raise error when glyphs contain cubic\n  outlines but glyphDataFormat was not explicitly set to 1 (#3113, #3119).\n- [subset] Prune emptied GDEF.MarkGlyphSetsDef and remap indices; ensure GDEF is\n  subsetted before GSUB and GPOS (#3114, #3118).\n- [xmlReader] Fixed issue whereby DSIG table data was incorrectly parsed (#3115, #2614).\n- [varLib/merger] Fixed merging of SinglePos with pos=0 (#3111, #3112).\n- [feaLib] Demote \"Feature has not been defined\" error to a warning when building aalt\n  and referenced feature is empty (#3110).\n- [feaLib] Dedupe multiple substitutions with classes (#3105).\n\n4.39.4 (released 2023-05-10)\n----------------------------\n\n- [varLib.interpolatable] Allow for sparse masters (#3075)\n- [merge] Handle differing default/nominalWidthX in CFF (#3070)\n- [ttLib] Add missing main.py file to ttLib package (#3088)\n- [ttx] Fix missing composite instructions in XML (#3092)\n- [ttx] Fix split tables option to work on filenames containing '%' (#3096)\n- [featureVars] Process lookups for features other than rvrn last (#3099)\n- [feaLib] support multiple substitution with classes (#3103)\n\n4.39.3 (released 2023-03-28)\n----------------------------\n\n- [sbix] Fixed TypeError when compiling empty glyphs whose imageData is None, regression\n  was introduced in v4.39 (#3059).\n- [ttFont] Fixed AttributeError on python <= 3.10 when opening a TTFont from a tempfile\n  SpooledTemporaryFile, seekable method only added on python 3.11 (#3052).\n\n4.39.2 (released 2023-03-16)\n----------------------------\n\n- [varLib] Fixed regression introduced in 4.39.1 whereby an incomplete 'STAT' table\n  would be built even though a DesignSpace v5 did contain 'STAT' definitions (#3045, #3046).\n\n4.39.1 (released 2023-03-16)\n----------------------------\n\n- [avar2] Added experimental support for reading/writing avar version 2 as specified in\n  this draft proposal: https://github.com/harfbuzz/boring-expansion-spec/blob/main/avar2.md\n- [glifLib] Wrap underlying XML library exceptions with GlifLibError when parsing GLIFs,\n  and also print the name and path of the glyph that fails to be parsed (#3042).\n- [feaLib] Consult avar for normalizing user-space values in ConditionSets and in\n  VariableScalars (#3042, #3043).\n- [ttProgram] Handle string input to Program.fromAssembly() (#3038).\n- [otlLib] Added a config option to emit GPOS 7 lookups, currently disabled by default\n  because of a macOS bug (#3034).\n- [COLRv1] Added method to automatically compute ClipBoxes (#3027).\n- [ttFont] Fixed getGlyphID to raise KeyError on missing glyphs instead of returning\n  None. The regression was introduced in v4.27.0 (#3032).\n- [sbix] Fixed UnboundLocalError: cannot access local variable 'rawdata' (#3031).\n- [varLib] When building VF, do not overwrite a pre-existing ``STAT`` table that was built\n  with feaLib from FEA feature file. Also, added support for building multiple VFs\n  defined in Designspace v5 from ``fonttools varLib`` script (#3024).\n- [mtiLib] Only add ``Debg`` table with lookup names when ``FONTTOOLS_LOOKUP_DEBUGGING``\n  env variable is set (#3023).\n\n4.39.0 (released 2023-03-06)\n----------------------------\n\n- [mtiLib] Optionally add `Debg` debug info for MTI feature builds (#3018).\n- [ttx] Support reading input file from standard input using special `-` character,\n  similar to existing `-o -` option to write output to standard output (#3020).\n- [cython] Prevent ``cython.compiled`` raise AttributeError if cython not installed\n  properly (#3017).\n- [OS/2] Guard against ZeroDivisionError when calculating xAvgCharWidth in the unlikely\n  scenario no glyph has non-zero advance (#3015).\n- [subset] Recompute xAvgCharWidth independently of --no-prune-unicode-ranges,\n  previously the two options were involuntarily bundled together (#3012).\n- [fontBuilder] Add ``debug`` parameter to addOpenTypeFeatures method to add source\n  debugging information to the font in the ``Debg`` private table (#3008).\n- [name] Make NameRecord `__lt__` comparison not fail on Unicode encoding errors (#3006).\n- [featureVars] Fixed bug in ``overlayBox`` (#3003, #3005).\n- [glyf] Added experimental support for cubic bezier curves in TrueType glyf table, as\n  outlined in glyf v1 proposal (#2988):\n  https://github.com/harfbuzz/boring-expansion-spec/blob/main/glyf1-cubicOutlines.md\n- Added new qu2cu module and related qu2cuPen, the reverse of cu2qu for converting\n  TrueType quadratic splines to cubic bezier curves (#2993).\n- [glyf] Added experimental support for reading and writing Variable Composites/Components\n  as defined in glyf v1 spec proposal (#2958):\n  https://github.com/harfbuzz/boring-expansion-spec/blob/main/glyf1-varComposites.md.\n- [pens]: Added `addVarComponent` method to pen protocols' base classes, which pens can implement\n  to handle varcomponents (by default they get decomposed) (#2958).\n- [misc.transform] Added DecomposedTransform class which implements an affine transformation\n  with separate translate, rotation, scale, skew, and transformation-center components (#2598)\n- [sbix] Ensure Glyph.referenceGlyphName is set; fixes error after dumping and\n  re-compiling sbix table with 'dupe' glyphs (#2984).\n- [feaLib] Be cleverer when merging chained single substitutions into same lookup\n  when they are specified using the inline notation (#2150, #2974).\n- [instancer] Clamp user-inputted axis ranges to those of fvar (#2959).\n- [otBase/subset] Define ``__getstate__`` for BaseTable so that a copied/pickled 'lazy'\n  object gets its own OTTableReader to read from; incidentally fixes a bug while\n  subsetting COLRv1 table containing ClipBoxes on python 3.11 (#2965, #2968).\n- [sbix] Handle glyphs with \"dupe\" graphic type on compile correctly (#2963).\n- [glyf] ``endPointsOfContours`` field should be unsigned! Kudos to behdad for\n  spotting one of the oldest bugs in FT. Probably nobody has ever dared to make\n  glyphs with more than 32767 points... (#2957).\n- [feaLib] Fixed handling of ``ignore`` statements with unmarked glyphs to match\n  makeotf behavior, which assumes the first glyph is marked (#2950).\n- Reformatted code with ``black`` and enforce new code style via CI check (#2925).\n- [feaLib] Sort name table entries following OT spec prescribed order in the builder (#2927).\n- [cu2quPen] Add Cu2QuMultiPen that converts multiple outlines at a time in\n  interpolation compatible way; its methods take a list of tuples arguments\n  that would normally be passed to individual segment pens, and at the end it\n  dispatches the converted outlines to each pen (#2912).\n- [reverseContourPen/ttGlyphPen] Add outputImpliedClosingLine option (#2913, #2914,\n  #2921, #2922, #2995).\n- [gvar] Avoid expanding all glyphs unnecessarily upon compile (#2918).\n- [scaleUpem] Fixed bug whereby CFF2 vsindex was scaled; it should not (#2893, #2894).\n- [designspaceLib] Add DS.getAxisByTag and refactor getAxis (#2891).\n- [unicodedata] map Zmth<->math in ot_tag_{to,from}_script (#1737, #2889).\n- [woff2] Support encoding/decoding OVERLAP_SIMPLE glyf flags (#2576, #2884).\n- [instancer] Update OS/2 class and post.italicAngle when default moved (L4)\n- Dropped support for Python 3.7 which reached EOL, fontTools requires 3.8+.\n- [instancer] Fixed instantiateFeatureVariations logic when a rule range becomes\n  default-applicable (#2737, #2880).\n- [ttLib] Add main to ttFont and ttCollection that just decompile and re-compile the\n  input font (#2869).\n- [featureVars] Insert 'rvrn' lookup at the beginning of LookupList, to work around bug\n  in Apple implementation of 'rvrn' feature which the spec says it should be processed\n  early whereas on macOS 10.15 it follows lookup order (#2140, #2867).\n- [instancer/mutator] Remove 'DSIG' table if present.\n- [svgPathPen] Don't close path in endPath(), assume open unless closePath() (#2089, #2865).\n\n4.38.0 (released 2022-10-21)\n----------------------------\n\n- [varLib.instancer] Added support for L4 instancing, i.e. moving the default value of\n  an axis while keeping it variable. Thanks Behdad! (#2728, #2861).\n  It's now also possible to restrict an axis min/max values beyond the current default\n  value, e.g. a font wght has min=100, def=400, max=900 and you want a partial VF that\n  only varies between 500 and 700, you can now do that.\n  You can either specify two min/max values (wght=500:700), and the new default will be\n  set to either the minimum or maximum, depending on which one is closer to the current\n  default (e.g. 500 in this case). Or you can specify three values (e.g. wght=500:600:700)\n  to specify the new default value explicitly.\n- [otlLib/featureVars] Set a few Count values so one doesn't need to compile the font\n  to update them (#2860).\n- [varLib.models] Make extrapolation work for 2-master models as well where one master\n  is at the default location (#2843, #2846).\n  Add optional extrapolate=False to normalizeLocation() (#2847, #2849).\n- [varLib.cff] Fixed sub-optimal packing of CFF2 deltas by no longer rounding them to\n  integer (#2838).\n- [scaleUpem] Calculate numShorts in VarData after scale; handle CFF hintmasks (#2840).\n\n4.37.4 (released 2022-09-30)\n----------------------------\n\n- [subset] Keep nameIDs used by CPAL palette entry labels (#2837).\n- [varLib] Avoid negative hmtx values when creating font from variable CFF2 font (#2827).\n- [instancer] Don't prune stat.ElidedFallbackNameID (#2828).\n- [unicodedata] Update Scripts/Blocks to Unicode 15.0 (#2833).\n\n4.37.3 (released 2022-09-20)\n----------------------------\n\n- Fix arguments in calls to (glyf) glyph.draw() and drawPoints(), whereby offset wasn't\n  correctly passed down; this fix also exposed a second bug, where lsb and tsb were not\n  set (#2824, #2825, adobe-type-tools/afdko#1560).\n\n4.37.2 (released 2022-09-15)\n----------------------------\n\n- [subset] Keep CPAL table and don't attempt to prune unused color indices if OT-SVG\n  table is present even if COLR table was subsetted away; OT-SVG may be referencing the\n  CPAL table; for now we assume that's the case (#2814, #2815).\n- [varLib.instancer] Downgrade GPOS/GSUB version if there are no more FeatureVariations\n  after instancing (#2812).\n- [subset] Added ``--no-lazy`` to optionally load fonts eagerly (mostly to ease\n  debugging of table lazy loading, no practical effects) (#2807).\n- [varLib] Avoid building empty COLR.DeltaSetIndexMap with only identity mappings (#2803).\n- [feaLib] Allow multiple value record types (by promoting to the most general format)\n  within the same PairPos subtable; e.g. this allows variable and non variable kerning\n  rules to share the same subtable. This also fixes a bug whereby some kerning pairs\n  would become unreachable while shapiong because of premature subtable splitting (#2772, #2776).\n- [feaLib] Speed up ``VarScalar`` by caching models for recurring master locations (#2798).\n- [feaLib] Optionally cythonize ``feaLib.lexer``, speeds up parsing FEA a bit (#2799).\n- [designspaceLib] Avoid crash when handling unbounded rule conditions (#2797).\n- [post] Don't crash if ``post`` legacy format 1 is malformed/improperly used (#2786)\n- [gvar] Don't be \"lazy\" (load all glyph variations up front) when TTFont.lazy=False (#2771).\n- [TTFont] Added ``normalizeLocation`` method to normalize a location dict from the\n  font's defined axes space (also known as \"user space\") into the normalized (-1..+1)\n  space. It applies ``avar`` mapping if the font contains an ``avar`` table (#2789).\n- [TTVarGlyphSet] Support drawing glyph instances from CFF2 variable glyph set (#2784).\n- [fontBuilder] Do not error when building cmap if there are zero code points (#2785).\n- [varLib.plot] Added ability to plot a variation model and set of accompaning master\n  values corresponding to the model's master locations into a pyplot figure (#2767).\n- [Snippets] Added ``statShape.py`` script to draw statistical shape of a glyph as an\n  ellips (requires pycairo) (baecd88).\n- [TTVarGlyphSet] implement drawPoints natively, avoiding going through\n  SegmentToPointPen (#2778).\n- [TTVarGlyphSet] Fixed bug whereby drawing a composite glyph multiple times, its\n  components would shif; needed an extra copy (#2774).\n\n4.37.1 (released 2022-08-24)\n----------------------------\n\n- [subset] Fixed regression introduced with v4.37.0 while subsetting the VarStore of\n  ``HVAR`` and ``VVAR`` tables, whereby an ``AttributeError: subset_varidxes`` was\n  thrown because an apparently unused import statement (with the side-effect of\n  dynamically binding that ``subset_varidxes`` method to the VarStore class) had been\n  accidentally deleted in an unrelated PR (#2679, #2773).\n- [pens] Added ``cairoPen`` (#2678).\n- [gvar] Read ``gvar`` more lazily by not parsing all of the ``glyf`` table (#2771).\n- [ttGlyphSet] Make ``drawPoints(pointPen)`` method work for CFF fonts as well via\n  adapter pen (#2770).\n\n4.37.0 (released 2022-08-23)\n----------------------------\n\n- [varLib.models] Reverted PR #2717 which added support for \"narrow tents\" in v4.36.0,\n  as it introduced a regression (#2764, #2765). It will be restored in upcoming release\n  once we found a solution to the bug.\n- [cff.specializer] Fixed issue in charstring generalizer with the ``blend`` operator\n  (#2750, #1975).\n- [varLib.models] Added support for extrapolation (#2757).\n- [ttGlyphSet] Ensure the newly added ``_TTVarGlyphSet`` inherits from ``_TTGlyphSet``\n  to keep backward compatibility with existing API (#2762).\n- [kern] Allow compiling legacy kern tables with more than 64k entries (d21cfdede).\n- [visitor] Added new visitor API to traverse tree of objects and dispatch based\n  on the attribute type: cf. ``fontTools.misc.visitor`` and ``fontTools.ttLib.ttVisitor``. Added ``fontTools.ttLib.scaleUpem`` module that uses the latter to\n  change a font's units-per-em and scale all the related fields accordingly (#2718,\n  #2755).\n\n4.36.0 (released 2022-08-17)\n----------------------------\n\n- [varLib.models] Use a simpler model that generates narrower \"tents\" (regions, master\n  supports) whenever possible: specifically when any two axes that actively \"cooperate\"\n  (have masters at non-zero positions for both axes) have a complete set of intermediates.\n  The simpler algorithm produces fewer overlapping regions and behaves better with\n  respect to rounding at the peak positions than the generic solver, always matching\n  intermediate masters exactly, instead of maximally 0.5 units off. This may be useful\n  when 100% metrics compatibility is desired (#2218, #2717).\n- [feaLib] Remove warning when about ``GDEF`` not being built when explicitly not\n  requested; don't build one unconditonally even when not requested (#2744, also works\n  around #2747).\n- [ttFont] ``TTFont.getGlyphSet`` method now supports selecting a location that\n  represents an instance of a variable font (supports both user-scale and normalized\n  axes coordinates via the ``normalized=False`` parameter). Currently this only works\n  for TrueType-flavored variable fonts (#2738).\n\n4.35.0 (released 2022-08-15)\n----------------------------\n\n- [otData/otConverters] Added support for 'biased' PaintSweepGradient start/end angles\n  to match latest COLRv1 spec (#2743).\n- [varLib.instancer] Fixed bug in ``_instantiateFeatureVariations`` when at the same\n  time pinning one axis and restricting the range of a subsequent axis; the wrong axis\n  tag was being used in the latter step (as the records' axisIdx was updated in the\n  preceding step but looked up using the old axes order in the following step) (#2733,\n  #2734).\n- [mtiLib] Pad script tags with space when less than 4 char long (#1727).\n- [merge] Use ``'.'`` instead of ``'#'`` in duplicate glyph names (#2742).\n- [gvar] Added support for lazily loading glyph variations (#2741).\n- [varLib] In ``build_many``, we forgot to pass on ``colr_layer_reuse`` parameter to\n  the ``build`` method (#2730).\n- [svgPathPen] Add a main that prints SVG for input text (6df779fd).\n- [cffLib.width] Fixed off-by-one in optimized values; previous code didn't match the\n  code block above it (2963fa50).\n- [varLib.interpolatable] Support reading .designspace and .glyphs files (via optional\n  ``glyphsLib``).\n- Compile some modules with Cython when available and building/installing fonttools\n  from source: ``varLib.iup`` (35% faster), ``pens.momentsPen`` (makes\n  ``varLib.interpolatable`` 3x faster).\n- [feaLib] Allow features to be built for VF without also building a GDEF table (e.g.\n  only build GSUB); warn when GDEF would be needed but isn't requested (#2705, 2694).\n- [otBase] Fixed ``AttributeError`` when uharfbuzz < 0.23.0 and 'repack' method is\n  missing (32aa8eaf). Use new ``uharfbuzz.repack_with_tag`` when available (since\n  uharfbuzz>=0.30.0), enables table-specific optimizations to be performed during\n  repacking (#2724).\n- [statisticsPen] By default report all glyphs (4139d891). Avoid division-by-zero\n  (52b28f90).\n- [feaLib] Added missing required argument to FeatureLibError exception (#2693)\n- [varLib.merge] Fixed error during error reporting (#2689). Fixed undefined\n  ``NotANone`` variable (#2714).\n\n4.34.4 (released 2022-07-07)\n----------------------------\n\n- Fixed typo in varLib/merger.py that causes NameError merging COLR glyphs\n  containing more than 255 layers (#2685).\n\n4.34.3 (released 2022-07-07)\n----------------------------\n\n- [designspaceLib] Don't make up bad PS names when no STAT data (#2684)\n\n4.34.2 (released 2022-07-06)\n----------------------------\n\n- [varStore/subset] fixed KeyError exception to do with NO_VARIATION_INDEX while\n  subsetting varidxes in GPOS/GDEF (a08140d).\n\n4.34.1 (released 2022-07-06)\n----------------------------\n\n- [instancer] When optimizing HVAR/VVAR VarStore, use_NO_VARIATION_INDEX=False to avoid\n  including NO_VARIATION_INDEX in AdvWidthMap, RsbMap, LsbMap mappings, which would\n  push the VarIdx width to maximum (4bytes), which is not desirable. This also fixes\n  a hard crash when attempting to subset a varfont after it had been partially instanced\n  with use_NO_VARIATION_INDEX=True.\n\n4.34.0 (released 2022-07-06)\n----------------------------\n\n- [instancer] Set RIBBI bits in head and OS/2 table when cutting instances and the\n  subfamily nameID=2 contains strings like 'Italic' or 'Bold' (#2673).\n- [otTraverse] Addded module containing methods for traversing trees of otData tables\n  (#2660).\n- [otTables] Made DeltaSetIndexMap TTX dump less verbose by omitting no-op entries\n  (#2660).\n- [colorLib.builder] Added option to disable PaintColrLayers's reuse of layers from\n  LayerList (#2660).\n- [varLib] Added support for merging multiple master COLRv1 tables into a variable\n  COLR table (#2660, #2328). Base color glyphs of same name in different masters must have\n  identical paint graph structure (incl. number of layers, palette indices, number\n  of color line stops, corresponding paint formats at each level of the graph),\n  but can differ in the variable fields (e.g. PaintSolid.Alpha). PaintVar* tables\n  are produced when this happens and a VarStore/DeltaSetIndexMap is added to the\n  variable COLR table. It is possible for non-default masters to be 'sparse', i.e.\n  omit some of the color glyphs present in the default master.\n- [feaLib] Let the Parser set nameIDs 1 through 6 that were previously reserved (#2675).\n- [varLib.varStore] Support NO_VARIATION_INDEX in optimizer and instancer.\n- [feaLib] Show all missing glyphs at once at end of parsing (#2665).\n- [varLib.iup] Rewrite force-set conditions and limit DP loopback length (#2651).\n  For Noto Sans, IUP time drops from 23s down to 9s, with only a slight size increase\n  in the final font. This basically turns the algorithm from O(n^3) into O(n).\n- [featureVars] Report about missing glyphs in substitution rules (#2654).\n- [mutator/instancer] Added CLI flag to --no-recalc-timestamp (#2649).\n- [SVG] Allow individual SVG documents in SVG OT table to be compressed on uncompressed,\n  and remember that when roundtripping to/from ttx. The SVG.docList is now a list\n  of SVGDocument namedtuple-like dataclass containing an extra ``compressed`` field,\n  and no longer a bare 3-tuple (#2645).\n- [designspaceLib] Check for descriptor types with hasattr() to allow custom classes\n  that don't inherit the default descriptors (#2634).\n- [subset] Enable sharing across subtables of extension lookups for harfbuzz packing\n  (#2626). Updated how table packing falls back to fontTools from harfbuzz (#2668).\n- [subset] Updated default feature tags following current Harfbuzz (#2637).\n- [svgLib] Fixed regex for real number to support e.g. 1e-4 in addition to 1.0e-4.\n  Support parsing negative rx, ry on arc commands (#2596, #2611).\n- [subset] Fixed subsetting SinglePosFormat2 when ValueFormat=0 (#2603).\n\n4.33.3 (released 2022-04-26)\n----------------------------\n\n- [designspaceLib] Fixed typo in ``deepcopyExceptFonts`` method, preventing font\n  references to be transferred (#2600). Fixed another typo in the name of ``Range``\n  dataclass's ``__post_init__`` magic method (#2597).\n\n4.33.2 (released 2022-04-22)\n----------------------------\n\n- [otBase] Make logging less verbose when harfbuzz fails to serialize. Do not exit\n  at the first failure but continue attempting to fix offset overflow error using\n  the pure-python serializer even when the ``USE_HARFBUZZ_REPACKER`` option was\n  explicitly set to ``True``. This is normal with fonts with relatively large\n  tables, at least until hb.repack implements proper table splitting.\n\n4.33.1 (released 2022-04-22)\n----------------------------\n\n- [otlLib] Put back the ``FONTTOOLS_GPOS_COMPACT_MODE`` environment variable to fix\n  regression in ufo2ft (and thus fontmake) introduced with v4.33.0 (#2592, #2593).\n  This is deprecated and will be removed one ufo2ft gets updated to use the new\n  config setup.\n\n4.33.0 (released 2022-04-21)\n----------------------------\n\n- [OS/2 / merge] Automatically recalculate ``OS/2.xAvgCharWidth`` after merging\n  fonts with ``fontTools.merge`` (#2591, #2538).\n- [misc/config] Added ``fontTools.misc.configTools`` module, a generic configuration\n  system (#2416, #2439).\n  Added ``fontTools.config`` module, a fontTools-specific configuration\n  system using ``configTools`` above.\n  Attached a ``Config`` object to ``TTFont``.\n- [otlLib] Replaced environment variable for GPOS compression level with an\n  equivalent option using the new config system.\n- [designspaceLib] Incremented format version to 5.0 (#2436).\n  Added discrete axes, variable fonts, STAT information, either design- or\n  user-space location on instances.\n  Added ``fontTools.designspaceLib.split`` module to split a designspace\n  into sub-spaces that interpolate and that represent the variable fonts\n  listed in the document.\n  Made instance names optional and allow computing them from STAT data instead.\n  Added ``fontTools.designspaceLib.statNames`` module.\n  Allow instances to have the same location as a previously defined STAT label.\n  Deprecated some attributes:\n  ``SourceDescriptor``: ``copyLib``, ``copyInfo``, ``copyGroups``, ``copyFeatures``.\n  ``InstanceDescriptor``: ``kerning``, ``info``; ``glyphs``: use rules or sparse\n  sources.\n  For both, ``location``: use the more explicit designLocation.\n  Note: all are soft deprecations and existing code should keep working.\n  Updated documentation for Python methods and the XML format.\n- [varLib] Added ``build_many`` to build several variable fonts from a single\n  designspace document (#2436).\n  Added ``fontTools.varLib.stat`` module to build STAT tables from a designspace\n  document.\n- [otBase] Try to use the Harfbuzz Repacker for packing GSUB/GPOS tables when\n  ``uharfbuzz`` python bindings are available (#2552). Disable it by setting the\n  \"fontTools.ttLib.tables.otBase:USE_HARFBUZZ_REPACKER\" config option to ``False``.\n  If the option is set explicitly to ``True`` but ``uharfbuzz`` can't be imported\n  or fails to serialize for any reasons, an error will be raised (ImportError or\n  uharfbuzz errors).\n- [CFF/T2] Ensure that ``pen.closePath()`` gets called for CFF2 charstrings (#2577).\n  Handle implicit CFF2 closePath within ``T2OutlineExtractor`` (#2580).\n\n4.32.0 (released 2022-04-08)\n----------------------------\n\n- [otlLib] Disable GPOS7 optimization to work around bug in Apple CoreText.\n  Always force Chaining GPOS8 for now (#2540).\n- [glifLib] Added ``outputImpliedClosingLine=False`` parameter to ``Glyph.draw()``,\n  to control behaviour of ``PointToSegmentPen`` (6b4e2e7).\n- [varLib.interpolatable] Check for wrong contour starting point (#2571).\n- [cffLib] Remove leftover ``GlobalState`` class and fix calls to ``TopDictIndex()``\n  (#2569, #2570).\n- [instancer] Clear ``AxisValueArray`` if it is empty after instantiating (#2563).\n\n4.31.2 (released 2022-03-22)\n----------------------------\n\n- [varLib] fix instantiation of GPOS SinglePos values (#2555).\n\n4.31.1 (released 2022-03-18)\n----------------------------\n\n- [subset] fix subsetting OT-SVG when glyph id attribute is on the root ``<svg>``\n  element (#2553).\n\n4.31.0 (released 2022-03-18)\n----------------------------\n\n- [ttCollection] Fixed 'ResourceWarning: unclosed file' warning (#2549).\n- [varLib.merger] Handle merging SinglePos with valueformat=0 (#2550).\n- [ttFont] Update glyf's glyphOrder when calling TTFont.setGlyphOrder() (#2544).\n- [ttFont] Added ``ensureDecompiled`` method to load all tables irrespective\n  of the ``lazy`` attribute (#2551).\n- [otBase] Added ``iterSubTable`` method to iterate over BaseTable's children of\n  type BaseTable; useful for traversing a tree of otTables (#2551).\n\n4.30.0 (released 2022-03-10)\n----------------------------\n\n- [varLib] Added debug logger showing the glyph name for which ``gvar`` is built (#2542).\n- [varLib.errors] Fixed undefined names in ``FoundANone`` and ``UnsupportedFormat``\n  exceptions (ac4d5611).\n- [otlLib.builder] Added ``windowsNames`` and ``macNames`` (bool) parameters to the\n  ``buildStatTabe`` function, so that one can select whether to only add one or both\n  of the two sets (#2528).\n- [t1Lib] Added the ability to recreate PostScript stream (#2504).\n- [name] Added ``getFirstDebugName``, ``getBest{Family,SubFamily,Full}Name`` methods (#2526).\n\n4.29.1 (released 2022-02-01)\n----------------------------\n\n- [colorLib] Fixed rounding issue with radial gradient's start/end circles inside\n  one another (#2521).\n- [freetypePen] Handle rotate/skew transform when auto-computing width/height of the\n  buffer; raise PenError wen missing moveTo (#2517)\n\n4.29.0 (released 2022-01-24)\n----------------------------\n\n- [ufoLib] Fixed illegal characters and expanded reserved filenames (#2506).\n- [COLRv1] Don't emit useless PaintColrLayers of lenght=1 in LayerListBuilder (#2513).\n- [ttx] Removed legacy ``waitForKeyPress`` method on Windows (#2509).\n- [pens] Added FreeTypePen that uses ``freetype-py`` and the pen protocol for\n  rasterizating outline paths (#2494).\n- [unicodedata] Updated the script direction list to Unicode 14.0 (#2484).\n  Bumped unicodedata2 dependency to 14.0 (#2499).\n- [psLib] Fixed type of ``fontName`` in ``suckfont`` (#2496).\n\n4.28.5 (released 2021-12-19)\n----------------------------\n\n- [svgPathPen] Continuation of #2471: make sure all occurrences of ``str()`` are now\n  replaced with user-defined ``ntos`` callable.\n- [merge] Refactored code into submodules, plus several bugfixes and improvements:\n  fixed duplicate-glyph-resolution GSUB-lookup generation code; use tolerance in glyph\n  comparison for empty glyph's width; ignore space of default ignorable glyphs;\n  downgrade duplicates-resolution missing-GSUB from assert to warn; added --drop-tables\n  option (#2473, #2475, #2476).\n\n4.28.4 (released 2021-12-15)\n----------------------------\n\n- [merge] Merge GDEF marksets in Lookups properly (#2474).\n- [feaLib] Have ``fontTools feaLib`` script exit with error code when build fails (#2459)\n- [svgPathPen] Added ``ntos`` option to customize number formatting (e.g. rounding) (#2471).\n- [subset] Speed up subsetting of large CFF fonts (#2467).\n- [otTables] Speculatively promote lookups to extension to speed up compilation. If the\n  offset to lookup N is too big to fit in a ushort, the offset to lookup N+1 is going to\n  be too big as well, so we promote to extension all lookups from lookup N onwards (#2465).\n\n4.28.3 (released 2021-12-03)\n----------------------------\n\n- [subset] Fixed bug while subsetting ``COLR`` table, whereby incomplete layer records\n  pointing to missing glyphs were being retained leading to ``struct.error`` upon\n  compiling. Make it so that ``glyf`` glyph closure, which follows the ``COLR`` glyph\n  closure, does not influence the ``COLR`` table subsetting (#2461, #2462).\n- [docs] Fully document the ``cmap`` and ``glyf`` tables (#2454, #2457).\n- [colorLib.unbuilder] Fixed CLI by deleting no longer existing parameter (180bb1867).\n\n4.28.2 (released 2021-11-22)\n----------------------------\n\n- [otlLib] Remove duplicates when building coverage (#2433).\n- [docs] Add interrogate configuration (#2443).\n- [docs] Remove comment about missing â€œstartâ€ optional argument to ``calcChecksum`` (#2448).\n- [cu2qu/cli] Adapt to the latest ufoLib2.\n- [subset] Support subsetting SVG table and remove it from the list of  drop by default tables (#534).\n- [subset] add ``--pretty-svg`` option to pretty print SVG table contents (#2452).\n- [merge] Support merging ``CFF`` tables (CID-keyed ``CFF`` is still not supported) (#2447).\n- [merge] Support ``--output-file`` (#2447).\n- [docs] Split table docs into individual pages (#2444).\n- [feaLib] Forbid empty classes (#2446).\n- [docs] Improve documentation for ``fontTools.ttLib.ttFont`` (#2442).\n\n4.28.1 (released 2021-11-08)\n----------------------------\n\n- [subset] Fixed AttributeError while traversing a color glyph's Paint graph when there is no\n  LayerList, which is optional (#2441).\n\n4.28.0 (released 2021-11-05)\n----------------------------\n\n- Dropped support for EOL Python 3.6, require Python 3.7 (#2417).\n- [ufoLib/glifLib] Make filename-clash checks faster by using a set instead of a list (#2422).\n- [subset] Don't crash if optional ClipList and LayerList are ``None`` (empty) (#2424, 2439).\n- [OT-SVG] Removed support for old deprecated version 1 and embedded color palettes,\n  which were never officially part of the OpenType SVG spec. Upon compile, reuse offsets\n  to SVG documents that are identical (#2430).\n- [feaLib] Added support for Variable Feature File syntax. This is experimental and subject\n  to change until it is finalized in the Adobe FEA spec (#2432).\n- [unicodedata] Update Scripts/ScriptExtensions/Blocks to UnicodeData 14.0 (#2437).\n\n4.27.1 (released 2021-09-23)\n----------------------------\n\n- [otlLib] Fixed error when chained contextual lookup builder overflows (#2404, #2411).\n- [bezierTools] Fixed two floating-point bugs: one when computing `t` for a point\n  lying on an almost horizontal/vertical line; another when computing the intersection\n  point between a curve and a line (#2413).\n\n4.27.0 (released 2021-09-14)\n----------------------------\n\n- [ttLib/otTables] Cleaned up virtual GID handling: allow virtual GIDs in ``Coverage``\n  and ``ClassDef`` readers; removed unused ``allowVID`` argument from ``TTFont``\n  constructor, and ``requireReal`` argument in ``TTFont.getGlyphID`` method.\n  Make ``TTFont.setGlyphOrder`` clear reverse glyphOrder map, and assume ``glyphOrder``\n  internal attribute is never modified outside setGlyphOrder; added ``TTFont.getGlyphNameMany``\n  and ``getGlyphIDMany`` (#1536, #1654, #2334, #2398).\n- [py23] Dropped internal use of ``fontTools.py23`` module to fix deprecation warnings\n  in client code that imports from fontTools (#2234, #2399, #2400).\n- [subset] Fix subsetting COLRv1 clip boxes when font is loaded lazily (#2408).\n\n4.26.2 (released 2021-08-09)\n----------------------------\n\n- [otTables] Added missing ``CompositeMode.PLUS`` operator (#2390).\n\n4.26.1 (released 2021-08-03)\n----------------------------\n\n- [transform] Added ``transformVector`` and ``transformVectors`` methods to the\n  ``Transform`` class. Similar to ``transformPoint`` but ignore the translation\n  part (#2386).\n\n4.26.0 (released 2021-08-03)\n----------------------------\n\n- [xmlWriter] Default to ``\"\\n\"`` for ``newlinestr`` instead of platform-specific\n  ``os.linesep`` (#2384).\n- [otData] Define COLRv1 ClipList and ClipBox (#2379).\n- [removeOverlaps/instancer] Added --ignore-overlap-errors option to work around\n  Skia PathOps.Simplify bug (#2382, #2363, google/fonts#3365).\n- NOTE: This will be the last version to support Python 3.6. FontTools will require\n  Python 3.7 or above from the next release (#2350)\n\n4.25.2 (released 2021-07-26)\n----------------------------\n\n- [COLRv1] Various changes to sync with the latest CORLv1 draft spec. In particular:\n  define COLR.VarIndexMap, remove/inline ColorIndex struct, add VarIndexBase to ``PaintVar*`` tables (#2372);\n  add reduced-precicion specialized transform Paints;\n  define Angle as fraction of half circle encoded as F2Dot14;\n  use FWORD (int16) for all Paint center coordinates;\n  change PaintTransform to have an offset to Affine2x3;\n- [ttLib] when importing XML, only set sfntVersion if the font has no reader and is empty (#2376)\n\n4.25.1 (released 2021-07-16)\n----------------------------\n\n- [ttGlyphPen] Fixed bug in ``TTGlyphPointPen``, whereby open contours (i.e. starting\n  with segmentType \"move\") would throw ``NotImplementedError``. They are now treated\n  as if they are closed, like with the ``TTGlyphPen`` (#2364, #2366).\n\n4.25.0 (released 2021-07-05)\n----------------------------\n\n- [tfmLib] Added new library for parsing TeX Font Metric (TFM) files (#2354).\n- [TupleVariation] Make shared tuples order deterministic on python < 3.7 where\n  Counter (subclass of dict) doesn't remember insertion order (#2351, #2353).\n- [otData] Renamed COLRv1 structs to remove 'v1' suffix and match the updated draft\n  spec: 'LayerV1List' -> 'LayerList', 'BaseGlyphV1List' -> 'BaseGlyphList',\n  'BaseGlyphV1Record' -> 'BaseGlyphPaintRecord' (#2346).\n  Added 8 new ``PaintScale*`` tables: with/without centers, uniform vs non-uniform.\n  Added ``*AroundCenter`` variants to ``PaintRotate`` and ``PaintSkew``: the default\n  versions no longer have centerX/Y, but default to origin.\n  ``PaintRotate``, ``PaintSkew`` and ``PaintComposite`` formats were re-numbered.\n  NOTE: these are breaking changes; clients using the experimental COLRv1 API will\n  have to be updated (#2348).\n- [pointPens] Allow ``GuessSmoothPointPen`` to accept a tolerance. Fixed call to\n  ``math.atan2`` with x/y parameters inverted. Sync the code with fontPens (#2344).\n- [post] Fixed parsing ``post`` table format 2.0 when it contains extra garbage\n  at the end of the stringData array (#2314).\n- [subset] drop empty features unless 'size' with FeatureParams table (#2324).\n- [otlLib] Added ``otlLib.optimize`` module; added GPOS compaction algorithm.\n  The compaction can be run on existing fonts with ``fonttools otlLib.optimize``\n  or using the snippet ``compact_gpos.py``. There's experimental support for\n  compacting fonts at compilation time using an environment variable, but that\n  might be removed later (#2326).\n\n4.24.4 (released 2021-05-25)\n----------------------------\n\n- [subset/instancer] Fixed ``AttributeError`` when instantiating a VF that\n  contains GPOS ValueRecords with ``Device`` tables but without the respective\n  non-Device values (e.g. ``XAdvDevice`` without ``XAdvance``). When not\n  explicitly set, the latter are assumed to be 0 (#2323).\n\n4.24.3 (released 2021-05-20)\n----------------------------\n\n- [otTables] Fixed ``AttributeError`` in methods that split LigatureSubst,\n  MultipleSubst and AlternateSubst subtables when an offset overflow occurs.\n  The ``Format`` attribute was removed in v4.22.0 (#2319).\n\n4.24.2 (released 2021-05-20)\n----------------------------\n\n- [ttGlyphPen] Fixed typing annotation of TTGlyphPen glyphSet parameter (#2315).\n- Fixed two instances of DeprecationWarning: invalid escape sequence (#2311).\n\n4.24.1 (released 2021-05-20)\n----------------------------\n\n- [subset] Fixed AttributeError when SinglePos subtable has None Value (ValueFormat 0)\n  (#2312, #2313).\n\n4.24.0 (released 2021-05-17)\n----------------------------\n\n- [pens] Add ``ttGlyphPen.TTGlyphPointPen`` similar to ``TTGlyphPen`` (#2205).\n\n4.23.1 (released 2021-05-14)\n----------------------------\n\n- [subset] Fix ``KeyError`` after subsetting ``COLR`` table that initially contains\n  both v0 and v1 color glyphs when the subset only requested v1 glyphs; we were\n  not pruning the v0 portion of the table (#2308).\n- [colorLib] Set ``LayerV1List`` attribute to ``None`` when empty, it's optional\n  in CORLv1 (#2308).\n\n4.23.0 (released 2021-05-13)\n----------------------------\n\n- [designspaceLib] Allow to use ``\\\\UNC`` absolute paths on Windows (#2299, #2306).\n- [varLib.merger] Fixed bug where ``VarLibMergeError`` was raised with incorrect\n  parameters (#2300).\n- [feaLib] Allow substituting a glyph class with ``NULL`` to delete multiple glyphs\n  (#2303).\n- [glyf] Fixed ``NameError`` exception in ``getPhantomPoints`` (#2295, #2305).\n- [removeOverlaps] Retry pathops.simplify after rounding path coordinates to integers\n  if it fails the first time using floats, to work around a rare and hard to debug\n  Skia bug (#2288).\n- [varLib] Added support for building, reading, writing and optimizing 32-bit\n  ``ItemVariationStore`` as used in COLRv1 table (#2285).\n- [otBase/otConverters] Add array readers/writers for int types (#2285).\n- [feaLib] Allow more than one lookahead glyph/class in contextual positioning with\n  \"value at end\" (#2293, #2294).\n- [COLRv1] Default varIdx should be 0xFFFFFFFF (#2297, #2298).\n- [pens] Make RecordingPointPen actually pass on identifiers; replace asserts with\n  explicit ``PenError`` exception (#2284).\n- [mutator] Round lsb for CF2 fonts as well (#2286).\n\n4.22.1 (released 2021-04-26)\n----------------------------\n\n- [feaLib] Skip references to named lookups if the lookup block definition\n  is empty, similarly to makeotf. This also fixes an ``AttributeError`` while\n  generating ``aalt`` feature (#2276, #2277).\n- [subset] Fixed bug with ``--no-hinting`` implementation for Device tables (#2272,\n  #2275). The previous code was alwyas dropping Device tables if no-hinting was\n  requested, but some Device tables (DeltaFormat=0x8000) are also used to encode\n  variation indices and need to be retained.\n- [otBase] Fixed bug in getting the ValueRecordSize when decompiling ``MVAR``\n  table with ``lazy=True`` (#2273, #2274).\n- [varLib/glyf/gvar] Optimized and simplified ``GlyphCoordinates`` and\n  ``TupleVariation`` classes, use ``bytearray`` where possible, refactored\n  phantom-points calculations. We measured about 30% speedup in total time\n  of loading master ttfs, building gvar, and saving (#2261, #2266).\n- [subset] Fixed ``AssertionError`` while pruning unused CPAL palettes when\n  ``0xFFFF`` is present (#2257, #2259).\n\n4.22.0 (released 2021-04-01)\n----------------------------\n\n- [ttLib] Remove .Format from Coverage, ClassDef, SingleSubst, LigatureSubst,\n  AlternateSubst, MultipleSubst (#2238).\n  ATTENTION: This will change your TTX dumps!\n- [misc.arrayTools] move Vector to its own submodule, and rewrite as a tuple\n  subclass (#2201).\n- [docs] Added a terminology section for varLib (#2209).\n- [varLib] Move rounding to VariationModel, to avoid error accumulation from\n  multiple deltas (#2214)\n- [varLib] Explain merge errors in more human-friendly terms (#2223, #2226)\n- [otlLib] Correct some documentation (#2225)\n- [varLib/otlLib] Allow merging into VariationFont without first saving GPOS\n  PairPos2 (#2229)\n- [subset] Improve PairPosFormat2 subsetting (#2221)\n- [ttLib] TTFont.save: create file on disk as late as possible (#2253)\n- [cffLib] Add missing CFF2 dict operators LanguageGroup and ExpansionFactor\n  (#2249)\n  ATTENTION: This will change your TTX dumps!\n\n4.21.1 (released 2021-02-26)\n----------------------------\n\n- [pens] Reverted breaking change that turned ``AbstractPen`` and ``AbstractPointPen``\n  into abstract base classes (#2164, #2198).\n\n4.21.0 (released 2021-02-26)\n----------------------------\n\n- [feaLib] Indent anchor statements in ``asFea()`` to make them more legible and\n  diff-able (#2193).\n- [pens] Turn ``AbstractPen`` and ``AbstractPointPen`` into abstract base classes\n  (#2164).\n- [feaLib] Added support for parsing and building ``STAT`` table from AFDKO feature\n  files (#2039).\n- [instancer] Added option to update name table of generated instance using ``STAT``\n  table's axis values (#2189).\n- [bezierTools] Added functions to compute bezier point-at-time, as well as line-line,\n  curve-line and curve-curve intersections (#2192).\n\n4.20.0 (released 2021-02-15)\n----------------------------\n\n- [COLRv1] Added ``unbuildColrV1`` to deconstruct COLRv1 otTables to raw json-able\n  data structure; it does the reverse of ``buildColrV1`` (#2171).\n- [feaLib] Allow ``sub X by NULL`` sequence to delete a glyph (#2170).\n- [arrayTools] Fixed ``Vector`` division (#2173).\n- [COLRv1] Define new ``PaintSweepGradient`` (#2172).\n- [otTables] Moved ``Paint.Format`` enum class outside of ``Paint`` class definition,\n  now named ``PaintFormat``. It was clashing with paint instance ``Format`` attribute\n  and thus was breaking lazy load of COLR table which relies on magic ``__getattr__``\n  (#2175).\n- [COLRv1] Replace hand-coded builder functions with otData-driven dynamic\n  implementation (#2181).\n- [COLRv1] Define additional static (non-variable) Paint formats (#2181).\n- [subset] Added support for subsetting COLR v1 and CPAL tables (#2174, #2177).\n- [fontBuilder] Allow ``setupFvar`` to optionally take ``designspaceLib.AxisDescriptor``\n  objects. Added new ``setupAvar`` method. Support localised names for axes and\n  named instances (#2185).\n\n4.19.1 (released 2021-01-28)\n----------------------------\n\n- [woff2] An initial off-curve point with an overlap flag now stays an off-curve\n  point after compression.\n\n4.19.0 (released 2021-01-25)\n----------------------------\n\n- [codecs] Handle ``errors`` parameter different from 'strict' for the custom\n  extended mac encodings (#2137, #2132).\n- [featureVars] Raise better error message when a script is missing the required\n  default language system (#2154).\n- [COLRv1] Avoid abrupt change caused by rounding ``PaintRadialGradient.c0`` when\n  the start circle almost touches the end circle's perimeter (#2148).\n- [COLRv1] Support building unlimited lists of paints as 255-ary trees of\n  ``PaintColrLayers`` tables (#2153).\n- [subset] Prune redundant format-12 cmap subtables when all non-BMP characters\n  are dropped (#2146).\n- [basePen] Raise ``MissingComponentError`` instead of bare ``KeyError`` when a\n  referenced component is missing (#2145).\n\n4.18.2 (released 2020-12-16)\n----------------------------\n\n- [COLRv1] Implemented ``PaintTranslate`` paint format (#2129).\n- [varLib.cff] Fixed unbound local variable error (#1787).\n- [otlLib] Don't crash when creating OpenType class definitions if some glyphs\n  occur more than once (#2125).\n\n4.18.1 (released 2020-12-09)\n----------------------------\n\n- [colorLib] Speed optimization for ``LayerV1ListBuilder`` (#2119).\n- [mutator] Fixed missing tab in ``interpolate_cff2_metrics`` (0957dc7a).\n\n4.18.0 (released 2020-12-04)\n----------------------------\n\n- [COLRv1] Update to latest draft: added ``PaintRotate`` and ``PaintSkew`` (#2118).\n- [woff2] Support new ``brotlicffi`` bindings for PyPy (#2117).\n- [glifLib] Added ``expectContentsFile`` parameter to ``GlyphSet``, for use when\n  reading existing UFOs, to comply with the specification stating that a\n  ``contents.plist`` file must exist in a glyph set (#2114).\n- [subset] Allow ``LangSys`` tags in ``--layout-scripts`` option (#2112). For example:\n  ``--layout-scripts=arab.dflt,arab.URD,latn``; this will keep ``DefaultLangSys``\n  and ``URD`` language for ``arab`` script, and all languages for ``latn`` script.\n- [varLib.interpolatable] Allow UFOs to be checked; report open paths, non existant\n  glyphs; add a ``--json`` option to produce a machine-readable list of\n  incompatibilities\n- [pens] Added ``QuartzPen`` to create ``CGPath`` from glyph outlines on macOS.\n  Requires pyobjc (#2107).\n- [feaLib] You can export ``FONTTOOLS_LOOKUP_DEBUGGING=1`` to enable feature file\n  debugging info stored in ``Debg`` table (#2106).\n- [otlLib] Build more efficient format 1 and format 2 contextual lookups whenever\n  possible (#2101).\n\n4.17.1 (released 2020-11-16)\n----------------------------\n\n- [colorLib] Fixed regression in 4.17.0 when building COLR v0 table; when color\n  layers are stored in UFO lib plist, we can't distinguish tuples from lists so\n  we need to accept either types (e5439eb9, googlefonts/ufo2ft/issues#426).\n\n4.17.0 (released 2020-11-12)\n----------------------------\n\n- [colorLib/otData] Updated to latest draft ``COLR`` v1 spec (#2092).\n- [svgLib] Fixed parsing error when arc commands' boolean flags are not separated\n  by space or comma (#2094).\n- [varLib] Interpret empty non-default glyphs as 'missing', if the default glyph is\n  not empty (#2082).\n- [feaLib.builder] Only stash lookup location for ``Debg`` if ``Builder.buildLookups_``\n  has cooperated (#2065, #2067).\n- [varLib] Fixed bug in VarStore optimizer (#2073, #2083).\n- [varLib] Add designspace lib key for custom feavar feature tag (#2080).\n- Add HashPointPen adapted from psautohint. With this pen, a hash value of a glyph\n  can be computed, which can later be used to detect glyph changes (#2005).\n\n4.16.1 (released 2020-10-05)\n----------------------------\n\n- [varLib.instancer] Fixed ``TypeError`` exception when instantiating a VF with\n  a GSUB table 1.1 in which ``FeatureVariations`` attribute is present but set to\n  ``None`` -- indicating that optional ``FeatureVariations`` is missing (#2077).\n- [glifLib] Make ``x`` and ``y`` attributes of the ``point`` element required\n  even when validation is turned off, and raise a meaningful ``GlifLibError``\n  message when that happens (#2075).\n\n4.16.0 (released 2020-09-30)\n----------------------------\n\n- [removeOverlaps] Added new module and ``removeOverlaps`` function that merges\n  overlapping contours and components in TrueType glyphs. It requires the\n  `skia-pathops <https://github.com/fonttools/skia-pathops>`__ module.\n  Note that removing overlaps invalidates the TrueType hinting (#2068).\n- [varLib.instancer] Added ``--remove-overlaps`` command-line option.\n  The ``overlap`` option in ``instantiateVariableFont`` now takes an ``OverlapMode``\n  enum: 0: KEEP_AND_DONT_SET_FLAGS, 1: KEEP_AND_SET_FLAGS (default), and 2: REMOVE.\n  The latter is equivalent to calling ``removeOverlaps`` on the generated static\n  instance. The option continues to accept ``bool`` value for backward compatibility.\n\n\n4.15.0 (released 2020-09-21)\n----------------------------\n\n- [plistlib] Added typing annotations to plistlib module. Set up mypy static\n  typechecker to run automatically on CI (#2061).\n- [ttLib] Implement private ``Debg`` table, a reverse-DNS namespaced JSON dict.\n- [feaLib] Optionally add an entry into the ``Debg`` table with the original\n  lookup name (if any), feature name / script / language combination (if any),\n  and original source filename and line location. Annotate the ttx output for\n  a lookup with the information from the Debg table (#2052).\n- [sfnt] Disabled checksum checking by default in ``SFNTReader`` (#2058).\n- [Docs] Document ``mtiLib`` module (#2027).\n- [varLib.interpolatable] Added checks for contour node count and operation type\n  of each node (#2054).\n- [ttLib] Added API to register custom table packer/unpacker classes (#2055).\n\n4.14.0 (released 2020-08-19)\n----------------------------\n\n- [feaLib] Allow anonymous classes in LookupFlags definitions (#2037).\n- [Docs] Better document DesignSpace rules processing order (#2041).\n- [ttLib] Fixed 21-year old bug in ``maxp.maxComponentDepth`` calculation (#2044,\n  #2045).\n- [varLib.models] Fixed misspelled argument name in CLI entry point (81d0042a).\n- [subset] When subsetting GSUB v1.1, fixed TypeError by checking whether the\n  optional FeatureVariations table is present (e63ecc5b).\n- [Snippets] Added snippet to show how to decompose glyphs in a TTF (#2030).\n- [otlLib] Generate GSUB type 5 and GPOS type 7 contextual lookups where appropriate\n  (#2016).\n\n4.13.0 (released 2020-07-10)\n----------------------------\n\n- [feaLib/otlLib] Moved lookup subtable builders from feaLib to otlLib; refactored\n  some common code (#2004, #2007).\n- [docs] Document otlLib module (#2009).\n- [glifLib] Fixed bug with some UFO .glif filenames clashing on case-insensitive\n  filesystems (#2001, #2002).\n- [colorLib] Updated COLRv1 implementation following changes in the draft spec:\n  (#2008, googlefonts/colr-gradients-spec#24).\n\n4.12.1 (released 2020-06-16)\n----------------------------\n\n- [_n_a_m_e] Fixed error in ``addMultilingualName`` with one-character names.\n  Only attempt to recovered malformed UTF-16 data from a ``bytes`` string,\n  not from unicode ``str`` (#1997, #1998).\n\n4.12.0 (released 2020-06-09)\n----------------------------\n\n- [otlLib/varLib] Ensure that the ``AxisNameID`` in the ``STAT`` and ``fvar``\n  tables is grater than 255 as per OpenType spec (#1985, #1986).\n- [docs] Document more modules in ``fontTools.misc`` package: ``filenames``,\n  ``fixedTools``, ``intTools``, ``loggingTools``, ``macCreatorType``, ``macRes``,\n  ``plistlib`` (#1981).\n- [OS/2] Don't calculate whole sets of unicode codepoints, use faster and more memory\n  efficient ranges and bisect lookups (#1984).\n- [voltLib] Support writing back abstract syntax tree as VOLT data (#1983).\n- [voltLib] Accept DO_NOT_TOUCH_CMAP keyword (#1987).\n- [subset/merge] Fixed a namespace clash involving a private helper class (#1955).\n\n4.11.0 (released 2020-05-28)\n----------------------------\n\n- [feaLib] Introduced ``includeDir`` parameter on Parser and IncludingLexer to\n  explicitly specify the directory to search when ``include()`` statements are\n  encountered (#1973).\n- [ufoLib] Silently delete duplicate glyphs within the same kerning group when reading\n  groups (#1970).\n- [ttLib] Set version of COLR table when decompiling COLRv1 (commit 9d8a7e2).\n\n4.10.2 (released 2020-05-20)\n----------------------------\n\n- [sfnt] Fixed ``NameError: SimpleNamespace`` while reading TTC header. The regression\n  was introduced with 4.10.1 after removing ``py23`` star import.\n\n4.10.1 (released 2020-05-19)\n----------------------------\n\n- [sfnt] Make ``SFNTReader`` pickleable even when TTFont is loaded with lazy=True\n  option and thus keeps a reference to an external file (#1962, #1967).\n- [feaLib.ast] Restore backward compatibility (broken in 4.10 with #1905) for\n  ``ChainContextPosStatement`` and ``ChainContextSubstStatement`` classes.\n  Make them accept either list of lookups or list of lists of lookups (#1961).\n- [docs] Document some modules in ``fontTools.misc`` package: ``arrayTools``,\n  ``bezierTools`` ``cliTools`` and ``eexec`` (#1956).\n- [ttLib._n_a_m_e] Fixed ``findMultilingualName()`` when name record's ``string`` is\n  encoded as bytes sequence (#1963).\n\n4.10.0 (released 2020-05-15)\n----------------------------\n\n- [varLib] Allow feature variations to be active across the entire space (#1957).\n- [ufoLib] Added support for ``formatVersionMinor`` in UFO's ``fontinfo.plist`` and for\n  ``formatMinor`` attribute in GLIF file as discussed in unified-font-object/ufo-spec#78.\n  No changes in reading or writing UFOs until an upcoming (non-0) minor update of the\n  UFO specification is published (#1786).\n- [merge] Fixed merging fonts with different versions of ``OS/2`` table (#1865, #1952).\n- [subset] Fixed ``AttributeError`` while subsetting ``ContextSubst`` and ``ContextPos``\n  Format 3 subtable (#1879, #1944).\n- [ttLib.table._m_e_t_a] if data happens to be ascii, emit comment in TTX (#1938).\n- [feaLib] Support multiple lookups per glyph position (#1905).\n- [psCharStrings] Use inheritance to avoid repeated code in initializer (#1932).\n- [Doc] Improved documentation for the following modules: ``afmLib`` (#1933), ``agl``\n  (#1934), ``cffLib`` (#1935), ``cu2qu`` (#1937), ``encodings`` (#1940), ``feaLib``\n  (#1941), ``merge`` (#1949).\n- [Doc] Split off developer-centric info to new page, making front page of docs more\n  user-focused. List all utilities and sub-modules with brief descriptions.\n  Make README more concise and focused (#1914).\n- [otlLib] Add function to build STAT table from high-level description (#1926).\n- [ttLib._n_a_m_e] Add ``findMultilingualName()`` method (#1921).\n- [unicodedata] Update ``RTL_SCRIPTS`` for Unicode 13.0 (#1925).\n- [gvar] Sort ``gvar`` XML output by glyph name, not glyph order (#1907, #1908).\n- [Doc] Added help options to ``fonttools`` command line tool (#1913, #1920).\n  Ensure all fonttools CLI tools have help documentation (#1948).\n- [ufoLib] Only write fontinfo.plist when there actually is content (#1911).\n\n4.9.0 (released 2020-04-29)\n---------------------------\n\n- [subset] Fixed subsetting of FeatureVariations table. The subsetter no longer drops\n  FeatureVariationRecords that have empty substitutions as that will keep the search\n  going and thus change the logic. It will only drop empty records that occur at the\n  end of the FeatureVariationRecords array (#1881).\n- [subset] Remove FeatureVariations table and downgrade GSUB/GPOS to version 0x10000\n  when FeatureVariations contain no FeatureVariationRecords after subsetting (#1903).\n- [agl] Add support for legacy Adobe Glyph List of glyph names in ``fontTools.agl``\n  (#1895).\n- [feaLib] Ignore superfluous script statements (#1883).\n- [feaLib] Hide traceback by default on ``fonttools feaLib`` command line.\n  Use ``--traceback`` option to show (#1898).\n- [feaLib] Check lookup index in chaining sub/pos lookups and print better error\n  message (#1896, #1897).\n- [feaLib] Fix building chained alt substitutions (#1902).\n- [Doc] Included all fontTools modules in the sphinx-generated documentation, and\n  published it to ReadTheDocs for continuous documentation of the fontTools project\n  (#1333). Check it out at https://fonttools.readthedocs.io/. Thanks to Chris Simpkins!\n- [transform] The ``Transform`` class is now subclass of ``typing.NamedTuple``. No\n  change in functionality (#1904).\n\n\n4.8.1 (released 2020-04-17)\n---------------------------\n\n- [feaLib] Fixed ``AttributeError: 'NoneType' has no attribute 'getAlternateGlyphs'``\n  when ``aalt`` feature references a chain contextual substitution lookup\n  (googlefonts/fontmake#648, #1878).\n\n4.8.0 (released 2020-04-16)\n---------------------------\n\n- [feaLib] If Parser is initialized without a ``glyphNames`` parameter, it cannot\n  distinguish between a glyph name containing an hyphen, or a range of glyph names;\n  instead of raising an error, it now interprets them as literal glyph names, while\n  also outputting a logging warning to alert user about the ambiguity (#1768, #1870).\n- [feaLib] When serializing AST to string, emit spaces around hyphens that denote\n  ranges. Also, fixed an issue with CID ranges when round-tripping AST->string->AST\n  (#1872).\n- [Snippets/otf2ttf] In otf2ttf.py script update LSB in hmtx to match xMin (#1873).\n- [colorLib] Added experimental support for building ``COLR`` v1 tables as per\n  the `colr-gradients-spec <https://github.com/googlefonts/colr-gradients-spec/blob/main/colr-gradients-spec.md>`__\n  draft proposal. **NOTE**: both the API and the XML dump of ``COLR`` v1 are\n  susceptible to change while the proposal is being discussed and formalized (#1822).\n\n4.7.0 (released 2020-04-03)\n---------------------------\n\n- [cu2qu] Added ``fontTools.cu2qu`` package, imported from the original\n  `cu2qu <https://github.com/googlefonts/cu2qu>`__ project. The ``cu2qu.pens`` module\n  was moved to ``fontTools.pens.cu2quPen``. The optional cu2qu extension module\n  can be compiled by installing `Cython <https://cython.org/>`__ before installing\n  fonttools from source (i.e. git repo or sdist tarball). The wheel package that\n  is published on PyPI (i.e. the one ``pip`` downloads, unless ``--no-binary``\n  option is used), will continue to be pure-Python for now (#1868).\n\n4.6.0 (released 2020-03-24)\n---------------------------\n\n- [varLib] Added support for building variable ``BASE`` table version 1.1 (#1858).\n- [CPAL] Added ``fromRGBA`` method to ``Color`` class (#1861).\n\n\n4.5.0 (released 2020-03-20)\n---------------------------\n\n- [designspaceLib] Added ``add{Axis,Source,Instance,Rule}Descriptor`` methods to\n  ``DesignSpaceDocument`` class, to initialize new descriptor objects using keyword\n  arguments, and at the same time append them to the current document (#1860).\n- [unicodedata] Update to Unicode 13.0 (#1859).\n\n4.4.3 (released 2020-03-13)\n---------------------------\n\n- [varLib] Always build ``gvar`` table for TrueType-flavored Variable Fonts,\n  even if it contains no variation data. The table is required according to\n  the OpenType spec (#1855, #1857).\n\n4.4.2 (released 2020-03-12)\n---------------------------\n\n- [ttx] Annotate ``LookupFlag`` in XML dump with comment explaining what bits\n  are set and what they mean (#1850).\n- [feaLib] Added more descriptive message to ``IncludedFeaNotFound`` error (#1842).\n\n4.4.1 (released 2020-02-26)\n---------------------------\n\n- [woff2] Skip normalizing ``glyf`` and ``loca`` tables if these are missing from\n  a font (e.g. in NotoColorEmoji using ``CBDT/CBLC`` tables).\n- [timeTools] Use non-localized date parsing in ``timestampFromString``, to fix\n  error when non-English ``LC_TIME`` locale is set (#1838, #1839).\n- [fontBuilder] Make sure the CFF table generated by fontBuilder can be used by varLib\n  without having to compile and decompile the table first. This was breaking in\n  converting the CFF table to CFF2 due to some unset attributes (#1836).\n\n4.4.0 (released 2020-02-18)\n---------------------------\n\n- [colorLib] Added ``fontTools.colorLib.builder`` module, initially with ``buildCOLR``\n  and ``buildCPAL`` public functions. More color font formats will follow (#1827).\n- [fontBuilder] Added ``setupCOLR`` and ``setupCPAL`` methods (#1826).\n- [ttGlyphPen] Quantize ``GlyphComponent.transform`` floats to ``F2Dot14`` to fix\n  round-trip issue when computing bounding boxes of transformed components (#1830).\n- [glyf] If a component uses reference points (``firstPt`` and ``secondPt``) for\n  alignment (instead of X and Y offsets), compute the effective translation offset\n  *after* having applied any transform (#1831).\n- [glyf] When all glyphs have zero contours, compile ``glyf`` table data as a single\n  null byte in order to pass validation by OTS and Windows (#1829).\n- [feaLib] Parsing feature code now ensures that referenced glyph names are part of\n  the known glyph set, unless a glyph set was not provided.\n- [varLib] When filling in the default axis value for a missing location of a source or\n  instance, correctly map the value forward.\n- [varLib] The avar table can now contain mapping output values that are greater than\n  OR EQUAL to the preceeding value, as the avar specification allows this.\n- [varLib] The errors of the module are now ordered hierarchically below VarLibError.\n  See #1821.\n\n4.3.0 (released 2020-02-03)\n---------------------------\n\n- [EBLC/CBLC] Fixed incorrect padding length calculation for Format 3 IndexSubTable\n  (#1817, #1818).\n- [varLib] Fixed error when merging OTL tables and TTFonts were loaded as ``lazy=True``\n  (#1808, #1809).\n- [varLib] Allow to use master fonts containing ``CFF2`` table when building VF (#1816).\n- [ttLib] Make ``recalcBBoxes`` option work also with ``CFF2`` table (#1816).\n- [feaLib] Don't reset ``lookupflag`` in lookups defined inside feature blocks.\n  They will now inherit the current ``lookupflag`` of the feature. This is what\n  Adobe ``makeotf`` also does in this case (#1815).\n- [feaLib] Fixed bug with mixed single/multiple substitutions. If a single substitution\n  involved a glyph class, we were incorrectly using only the first glyph in the class\n  (#1814).\n\n4.2.5 (released 2020-01-29)\n---------------------------\n\n- [feaLib] Do not fail on duplicate multiple substitutions, only warn (#1811).\n- [subset] Optimize SinglePos subtables to Format 1 if all ValueRecords are the same\n  (#1802).\n\n4.2.4 (released 2020-01-09)\n---------------------------\n\n- [unicodedata] Update RTL_SCRIPTS for Unicode 11 and 12.\n\n4.2.3 (released 2020-01-07)\n---------------------------\n\n- [otTables] Fixed bug when splitting `MarkBasePos` subtables as offsets overflow.\n  The mark class values in the split subtable were not being updated, leading to\n  invalid mark-base attachments (#1797, googlefonts/noto-source#145).\n- [feaLib] Only log a warning instead of error when features contain duplicate\n  substitutions (#1767).\n- [glifLib] Strip XML comments when parsing with lxml (#1784, #1785).\n\n4.2.2 (released 2019-12-12)\n---------------------------\n\n- [subset] Fixed issue with subsetting FeatureVariations table when the index\n  of features changes as features get dropped. The feature index need to be\n  remapped to point to index of the remaining features (#1777, #1782).\n- [fontBuilder] Added `addFeatureVariations` method to `FontBuilder` class. This\n  is a shorthand for calling `featureVars.addFeatureVariations` on the builder's\n  TTFont object (#1781).\n- [glyf] Fixed the flags bug in glyph.drawPoints() like we did for glyph.draw()\n  (#1771, #1774).\n\n4.2.1 (released 2019-12-06)\n---------------------------\n\n- [glyf] Use the ``flagOnCurve`` bit mask in ``glyph.draw()``, so that we ignore\n  the ``overlap`` flag that may be set when instantiating variable fonts (#1771).\n\n4.2.0 (released 2019-11-28)\n---------------------------\n\n- [pens] Added the following pens:\n\n  * ``roundingPen.RoundingPen``: filter pen that rounds coordinates and components'\n    offsets to integer;\n  * ``roundingPen.RoundingPointPen``: like the above, but using PointPen protocol.\n  * ``filterPen.FilterPointPen``: base class for filter point pens;\n  * ``transformPen.TransformPointPen``: filter point pen to apply affine transform;\n  * ``recordingPen.RecordingPointPen``: records and replays point-pen commands.\n\n- [ttGlyphPen] Always round float coordinates and component offsets to integers\n  (#1763).\n- [ufoLib] When converting kerning groups from UFO2 to UFO3, avoid confusing\n  groups with the same name as one of the glyphs (#1761, #1762,\n  unified-font-object/ufo-spec#98).\n\n4.1.0 (released 2019-11-18)\n---------------------------\n\n- [instancer] Implemented restricting axis ranges (level 3 partial instancing).\n  You can now pass ``{axis_tag: (min, max)}`` tuples as input to the\n  ``instantiateVariableFont`` function. Note that changing the default axis\n  position is not supported yet. The command-line script also accepts axis ranges\n  in the form of colon-separated float values, e.g. ``wght=400:700`` (#1753, #1537).\n- [instancer] Never drop STAT ``DesignAxis`` records, but only prune out-of-range\n  ``AxisValue`` records.\n- [otBase/otTables] Enforce that VarStore.RegionAxisCount == fvar.axisCount, even\n  when regions list is empty to appease OTS < v8.0 (#1752).\n- [designspaceLib] Defined new ``processing`` attribute for ``<rules>`` element,\n  with values \"first\" or \"last\", plus other editorial changes to DesignSpace\n  specification. Bumped format version to 4.1 (#1750).\n- [varLib] Improved error message when masters' glyph orders do not match (#1758,\n  #1759).\n- [featureVars] Allow to specify custom feature tag in ``addFeatureVariations``;\n  allow said feature to already exist, in which case we append new lookup indices\n  to existing features. Implemented ``<rules>`` attribute ``processing`` according to\n  DesignSpace specification update in #1750. Depending on this flag, we generate\n  either an 'rvrn' (always processed first) or a 'rclt' feature (follows lookup order,\n  therefore last) (#1747, #1625, #1371).\n- [ttCollection] Added support for context manager auto-closing via ``with`` statement\n  like with ``TTFont`` (#1751).\n- [unicodedata] Require unicodedata2 >= 12.1.0.\n- [py2.py3] Removed yet more PY2 vestiges (#1743).\n- [_n_a_m_e] Fixed issue when comparing NameRecords with different string types (#1742).\n- [fixedTools] Changed ``fixedToFloat`` to not do any rounding but simply return\n  ``value / (1 << precisionBits)``. Added ``floatToFixedToStr`` and\n  ``strToFixedToFloat`` functions to be used when loading from or dumping to XML.\n  Fixed values (e.g. fvar axes and instance coordinates, avar mappings, etc.) are\n  are now stored as un-rounded decimal floats upon decompiling (#1740, #737).\n- [feaLib] Fixed handling of multiple ``LigatureCaret`` statements for the same glyph.\n  Only the first rule per glyph is used, additional ones are ignored (#1733).\n\n4.0.2 (released 2019-09-26)\n---------------------------\n\n- [voltLib] Added support for ``ALL`` and ``NONE`` in ``PROCESS_MARKS`` (#1732).\n- [Silf] Fixed issue in ``Silf`` table compilation and decompilation regarding str vs\n  bytes in python3 (#1728).\n- [merge] Handle duplicate glyph names better: instead of appending font index to\n  all glyph names, use similar code like we use in ``post`` and ``CFF`` tables (#1729).\n\n4.0.1 (released 2019-09-11)\n---------------------------\n\n- [otTables] Support fixing offset overflows in ``MultipleSubst`` lookup subtables\n  (#1706).\n- [subset] Prune empty strikes in ``EBDT`` and ``CBDT`` table data (#1698, #1633).\n- [pens] Fixed issue in ``PointToSegmentPen`` when last point of closed contour has\n  same coordinates as the starting point and was incorrectly dropped (#1720).\n- [Graphite] Fixed ``Sill`` table output to pass OTS (#1705).\n- [name] Added ``removeNames`` method to ``table__n_a_m_e`` class (#1719).\n- [ttLib] Added aliases for renamed entries ``ascender`` and ``descender`` in\n  ``hhea`` table (#1715).\n\n4.0.0 (released 2019-08-22)\n---------------------------\n\n- NOTE: The v4.x version series only supports Python 3.6 or greater. You can keep\n  using fonttools 3.x if you need support for Python 2.\n- [py23] Removed all the python2-only code since it is no longer reachable, thus\n  unused; only the Python3 symbols were kept, but these are no-op. The module is now\n  DEPRECATED and will removed in the future.\n- [ttLib] Fixed UnboundLocalError for empty loca/glyph tables (#1680). Also, allow\n  the glyf table to be incomplete when dumping to XML (#1681).\n- [varLib.models] Fixed KeyError while sorting masters and there are no on-axis for\n  a given axis (38a8eb0e).\n- [cffLib] Make sure glyph names are unique (#1699).\n- [feaLib] Fix feature parser to correctly handle octal numbers (#1700).\n\n3.44.0 (released 2019-08-02)\n----------------------------\n\n- NOTE: This is the last scheduled release to support Python 2.7. The upcoming fonttools\n  v4.x series is going to require Python 3.6 or greater.\n- [varLib] Added new ``varLib.instancer`` module for partially instantiating variable\n  fonts. This extends (and will eventually replace) ``varLib.mutator`` module, as\n  it allows to create not just full static instances from a variable font, but also\n  \"partial\" or \"less variable\" fonts where some of the axes are dropped or\n  instantiated at a particular value.\n  Also available from the command-line as `fonttools varLib.instancer --help`\n  (#1537, #1628).\n- [cffLib] Added support for ``FDSelect`` format 4 (#1677).\n- [subset] Added support for subsetting ``sbix`` (Apple bitmap color font) table.\n- [t1Lib] Fixed issue parsing ``eexec`` section in Type1 fonts when whitespace\n  characters are interspersed among the trailing zeros (#1676).\n- [cffLib.specializer] Fixed bug in ``programToCommands`` with CFF2 charstrings (#1669).\n\n3.43.2 (released 2019-07-10)\n----------------------------\n\n- [featureVars] Fixed region-merging code on python3 (#1659).\n- [varLib.cff] Fixed merging of sparse PrivateDict items (#1653).\n\n3.43.1 (released 2019-06-19)\n----------------------------\n\n- [subset] Fixed regression when passing ``--flavor=woff2`` option with an input font\n  that was already compressed as WOFF 1.0 (#1650).\n\n3.43.0 (released 2019-06-18)\n----------------------------\n\n- [woff2] Added support for compressing/decompressing WOFF2 fonts with non-transformed\n  ``glyf`` and ``loca`` tables, as well as with transformed ``hmtx`` table.\n  Removed ``Snippets/woff2_compress.py`` and ``Snippets/woff2_decompress.py`` scripts,\n  and replaced them with a new console entry point ``fonttools ttLib.woff2``\n  that provides two sub-commands ``compress`` and ``decompress``.\n- [varLib.cff] Fixed bug when merging CFF2 ``PrivateDicts``. The ``PrivateDict``\n  data from the first region font was incorrecty used for all subsequent fonts.\n  The bug would only affect variable CFF2 fonts with hinting (#1643, #1644).\n  Also, fixed a merging bug when VF masters have no blends or marking glyphs (#1632,\n  #1642).\n- [loggingTools] Removed unused backport of ``LastResortLogger`` class.\n- [subset] Gracefully handle partial MATH table (#1635).\n- [featureVars] Avoid duplicate references to ``rvrn`` feature record in\n  ``DefaultLangSys`` tables when calling ``addFeatureVariations`` on a font that\n  does not already have a ``GSUB`` table (aa8a5bc6).\n- [varLib] Fixed merging of class-based kerning. Before, the process could introduce\n  rogue kerning values and variations for random classes against class zero (everything\n  not otherwise classed).\n- [varLib] Fixed merging GPOS tables from master fonts with different number of\n  ``SinglePos`` subtables (#1621, #1641).\n- [unicodedata] Updated Blocks, Scripts and ScriptExtensions to Unicode 12.1.\n\n3.42.0 (released 2019-05-28)\n----------------------------\n\n- [OS/2] Fixed sign of ``fsType``: it should be ``uint16``, not ``int16`` (#1619).\n- [subset] Skip out-of-range class values in mark attachment (#1478).\n- [fontBuilder] Add an empty ``DSIG`` table with ``setupDummyDSIG`` method (#1621).\n- [varLib.merger] Fixed bug whereby ``GDEF.GlyphClassDef`` were being dropped\n  when generating instance via ``varLib.mutator`` (#1614).\n- [varLib] Added command-line options ``-v`` and ``-q`` to configure logging (#1613).\n- [subset] Update font extents in head table (#1612).\n- [subset] Make --retain-gids truncate empty glyphs after the last non-empty glyph\n  (#1611).\n- [requirements] Updated ``unicodedata2`` backport for Unicode 12.0.\n\n3.41.2 (released 2019-05-13)\n----------------------------\n\n- [cffLib] Fixed issue when importing a ``CFF2`` variable font from XML, whereby\n  the VarStore state was not propagated to PrivateDict (#1598).\n- [varLib] Don't drop ``post`` glyph names when building CFF2 variable font (#1609).\n\n\n3.41.1 (released 2019-05-13)\n----------------------------\n\n- [designspaceLib] Added ``loadSourceFonts`` method to load source fonts using\n  custom opener function (#1606).\n- [head] Round font bounding box coordinates to integers to fix compile error\n  if CFF font has float coordinates (#1604, #1605).\n- [feaLib] Don't write ``None`` in ``ast.ValueRecord.asFea()`` (#1599).\n- [subset] Fixed issue ``AssertionError`` when using ``--desubroutinize`` option\n  (#1590, #1594).\n- [graphite] Fixed bug in ``Silf`` table's ``decompile`` method unmasked by\n  previous typo fix (#1597). Decode languange code as UTF-8 in ``Sill`` table's\n  ``decompile`` method (#1600).\n\n3.41.0 (released 2019-04-29)\n----------------------------\n\n- [varLib/cffLib] Added support for building ``CFF2`` variable font from sparse\n  masters, or masters with more than one model (multiple ``VarStore.VarData``).\n  In ``cffLib.specializer``, added support for ``CFF2`` CharStrings with\n  ``blend`` operators (#1547, #1591).\n- [subset] Fixed subsetting ``HVAR`` and ``VVAR`` with ``--retain-gids`` option,\n  and when advances mapping is null while sidebearings mappings are non-null\n  (#1587, #1588).\n- Added ``otlLib.maxContextCalc`` module to compute ``OS/2.usMaxContext`` value.\n  Calculate it automatically when compiling features with feaLib. Added option\n  ``--recalc-max-context`` to ``subset`` module (#1582).\n- [otBase/otTables] Fixed ``AttributeError`` on missing OT table fields after\n  importing font from TTX (#1584).\n- [graphite] Fixed typo ``Silf`` table's ``decompile`` method (#1586).\n- [otlLib] Better compress ``GPOS`` SinglePos (LookupType 1) subtables (#1539).\n\n3.40.0 (released 2019-04-08)\n----------------------------\n\n- [subset] Fixed error while subsetting ``VVAR`` with ``--retain-gids``\n  option (#1552).\n- [designspaceLib] Use up-to-date default location in ``findDefault`` method\n  (#1554).\n- [voltLib] Allow passing file-like object to Parser.\n- [arrayTools/glyf] ``calcIntBounds`` (used to compute bounding boxes of glyf\n  table's glyphs) now uses ``otRound`` instead of ``round3`` (#1566).\n- [svgLib] Added support for converting more SVG shapes to path ``d`` strings\n  (ellipse, line, polyline), as well as support for ``transform`` attributes.\n  Only ``matrix`` transformations are currently supported (#1564, #1564).\n- [varLib] Added support for building ``VVAR`` table from ``vmtx`` and ``VORG``\n  tables (#1551).\n- [fontBuilder] Enable making CFF2 fonts with ``post`` table format 2 (#1557).\n- Fixed ``DeprecationWarning`` on invalid escape sequences (#1562).\n\n3.39.0 (released 2019-03-19)\n----------------------------\n\n- [ttLib/glyf] Raise more specific error when encountering recursive\n  component references (#1545, #1546).\n- [Doc/designspaceLib] Defined new ``public.skipExportGlyphs`` lib key (#1534,\n  unified-font-object/ufo-spec#84).\n- [varLib] Use ``vmtx`` to compute vertical phantom points; or ``hhea.ascent``\n  and ``head.unitsPerEM`` if ``vmtx`` is missing (#1528).\n- [gvar/cvar] Sort XML element's min/value/max attributes in TupleVariation\n  toXML to improve readability of TTX dump (#1527).\n- [varLib.plot] Added support for 2D plots with only 1 variation axis (#1522).\n- [designspaceLib] Use axes maps when normalizing locations in\n  DesignSpaceDocument (#1226, #1521), and when finding default source (#1535).\n- [mutator] Set ``OVERLAP_SIMPLE`` and ``OVERLAP_COMPOUND`` glyf flags by\n  default in ``instantiateVariableFont``. Added ``--no-overlap`` cli option\n  to disable this (#1518).\n- [subset] Fixed subsetting ``VVAR`` table (#1516, #1517).\n  Fixed subsetting an ``HVAR`` table that has an ``AdvanceWidthMap`` when the\n  option ``--retain-gids`` is used.\n- [feaLib] Added ``forceChained`` in MultipleSubstStatement (#1511).\n  Fixed double indentation of ``subtable`` statement (#1512).\n  Added support for ``subtable`` statement in more places than just PairPos\n  lookups (#1520).\n  Handle lookupflag 0 and lookupflag without a value (#1540).\n- [varLib] In ``load_designspace``, provide a default English name for the\n  ``ital`` axis tag.\n- Remove pyftinspect because it is unmaintained and bitrotted.\n\n3.38.0 (released 2019-02-18)\n----------------------------\n\n- [cffLib] Fixed RecursionError when unpickling or deepcopying TTFont with\n  CFF table (#1488, 649dc49).\n- [subset] Fixed AttributeError when using --desubroutinize option (#1490).\n  Also, fixed desubroutinizing bug when subrs contain hints (#1499).\n- [CPAL] Make Color a subclass of namedtuple (173a0f5).\n- [feaLib] Allow hyphen in glyph class names.\n- [feaLib] Added 'tables' option to __main__.py (#1497).\n- [feaLib] Add support for special-case contextual positioning formatting\n  (#1501).\n- [svgLib] Support converting SVG basic shapes (rect, circle, etc.) into\n  equivalent SVG paths (#1500, #1508).\n- [Snippets] Added name-viewer.ipynb Jupyter notebook.\n\n\n3.37.3 (released 2019-02-05)\n----------------------------\n\n- The previous release accidentally changed several files from Unix to DOS\n  line-endings. Fix that.\n\n3.37.2 (released 2019-02-05)\n----------------------------\n\n- [varLib] Temporarily revert the fix to ``load_masters()``, which caused a\n  crash in ``interpolate_layout()`` when ``deepcopy``-ing OTFs.\n\n3.37.1 (released 2019-02-05)\n----------------------------\n\n- [varLib] ``load_masters()`` now actually assigns the fonts it loads to the\n  source.font attributes.\n- [varLib] Fixed an MVAR table generation crash when sparse masters were\n  involved.\n- [voltLib] ``parse_coverage_()`` returns a tuple instead of an ast.Enum.\n- [feaLib] A MarkClassDefinition inside a block is no longer doubly indented\n  compared to the rest of the block.\n\n3.37.0 (released 2019-01-28)\n----------------------------\n\n- [svgLib] Added support for converting elliptical arcs to cubic bezier curves\n  (#1464).\n- [py23] Added backport for ``math.isfinite``.\n- [varLib] Apply HIDDEN flag to fvar axis if designspace axis has attribute\n  ``hidden=1``.\n- Fixed \"DeprecationWarning: invalid escape sequence\" in Python 3.7.\n- [voltLib] Fixed parsing glyph groups. Distinguish different PROCESS_MARKS.\n  Accept COMPONENT glyph type.\n- [feaLib] Distinguish missing value and explicit ``<NULL>`` for PairPos2\n  format A (#1459). Round-trip ``useExtension`` keyword. Implemented\n  ``ValueRecord.asFea`` method.\n- [subset] Insert empty widths into hdmx when retaining gids (#1458).\n\n3.36.0 (released 2019-01-17)\n----------------------------\n\n- [ttx] Added ``--no-recalc-timestamp`` option to keep the original font's\n  ``head.modified`` timestamp (#1455, #46).\n- [ttx/psCharStrings] Fixed issues while dumping and round-tripping CFF2 table\n  with ttx (#1451, #1452, #1456).\n- [voltLib] Fixed check for duplicate anchors (#1450). Don't try to read past\n  the ``END`` operator in .vtp file (#1453).\n- [varLib] Use sentinel value -0x8000 (-32768) to ignore post.underlineThickness\n  and post.underlinePosition when generating MVAR deltas (#1449,\n  googlei18n/ufo2ft#308).\n- [subset] Added ``--retain-gids`` option to subset font without modifying the\n  current glyph indices (#1443, #1447).\n- [ufoLib] Replace deprecated calls to ``getbytes`` and ``setbytes`` with new\n  equivalent ``readbytes`` and ``writebytes`` calls. ``fs`` >= 2.2 no required.\n- [varLib] Allow loading masters from TTX files as well (#1441).\n\n3.35.2 (released 2019-01-14)\n----------------------------\n\n- [hmtx/vmtx]: Allow to compile/decompile ``hmtx`` and ``vmtx`` tables even\n  without the corresponding (required) metrics header tables, ``hhea`` and\n  ``vhea`` (#1439).\n- [varLib] Added support for localized axes' ``labelname`` and named instances'\n  ``stylename`` (#1438).\n\n3.35.1 (released 2019-01-09)\n----------------------------\n\n- [_m_a_x_p] Include ``maxComponentElements`` in ``maxp`` table's recalculation.\n\n3.35.0 (released 2019-01-07)\n----------------------------\n\n- [psCharStrings] In ``encodeFloat`` function, use float's \"general format\" with\n  8 digits of precision (i.e. ``%8g``) instead of ``str()``. This works around\n  a macOS rendering issue when real numbers in CFF table are too long, and\n  also makes sure that floats are encoded with the same precision in python 2.7\n  and 3.x (#1430, googlei18n/ufo2ft#306).\n- [_n_a_m_e/fontBuilder] Make ``_n_a_m_e_table.addMultilingualName`` also add\n  Macintosh (platformID=1) names by default. Added options to ``FontBuilder``\n  ``setupNameTable`` method to optionally disable Macintosh or Windows names.\n  (#1359, #1431).\n- [varLib] Make ``build`` optionally accept a ``DesignSpaceDocument`` object,\n  instead of a designspace file path. The caller can now set the ``font``\n  attribute of designspace's sources to a TTFont object, thus allowing to\n  skip filenames manipulation altogether (#1416, #1425).\n- [sfnt] Allow SFNTReader objects to be deep-copied.\n- Require typing>=3.6.4 on py27 to fix issue with singledispatch (#1423).\n- [designspaceLib/t1Lib/macRes] Fixed some cases where pathlib.Path objects were\n  not accepted (#1421).\n- [varLib] Fixed merging of multiple PairPosFormat2 subtables (#1411).\n- [varLib] The default STAT table version is now set to 1.1, to improve\n  compatibility with legacy applications (#1413).\n\n3.34.2 (released 2018-12-17)\n----------------------------\n\n- [merge] Fixed AssertionError when none of the script tables in GPOS/GSUB have\n  a DefaultLangSys record (#1408, 135a4a1).\n\n3.34.1 (released 2018-12-17)\n----------------------------\n\n- [varLib] Work around macOS rendering issue for composites without gvar entry (#1381).\n\n3.34.0 (released 2018-12-14)\n----------------------------\n\n- [varLib] Support generation of CFF2 variable fonts. ``model.reorderMasters()``\n  now supports arbitrary mapping. Fix handling of overlapping ranges for feature\n  variations (#1400).\n- [cffLib, subset] Code clean-up and fixing related to CFF2 support.\n- [ttLib.tables.ttProgram] Use raw strings for regex patterns (#1389).\n- [fontbuilder] Initial support for building CFF2 fonts. Set CFF's\n  ``FontMatrix`` automatically from unitsPerEm.\n- [plistLib] Accept the more general ``collections.Mapping`` instead of the\n  specific ``dict`` class to support custom data classes that should serialize\n  to dictionaries.\n\n3.33.0 (released 2018-11-30)\n----------------------------\n- [subset] subsetter bug fix with variable fonts.\n- [varLib.featureVar] Improve FeatureVariations generation with many rules.\n- [varLib] Enable sparse masters when building variable fonts:\n  https://github.com/fonttools/fonttools/pull/1368#issuecomment-437257368\n- [varLib.mutator] Add IDEF for GETVARIATION opcode, for handling hints in an\n  instance.\n- [ttLib] Ignore the length of kern table subtable format 0\n\n3.32.0 (released 2018-11-01)\n----------------------------\n\n- [ufoLib] Make ``UFOWriter`` a subclass of ``UFOReader``, and use mixins\n  for shared methods (#1344).\n- [featureVars] Fixed normalization error when a condition's minimum/maximum\n  attributes are missing in designspace ``<rule>`` (#1366).\n- [setup.py] Added ``[plot]`` to extras, to optionally install ``matplotlib``,\n  needed to use the ``fonTools.varLib.plot`` module.\n- [varLib] Take total bounding box into account when resolving model (7ee81c8).\n  If multiple axes have the same range ratio, cut across both (62003f4).\n- [subset] Don't error if ``STAT`` has no ``AxisValue`` tables.\n- [fontBuilder] Added a new submodule which contains a ``FontBuilder`` wrapper\n  class around ``TTFont`` that makes it easier to create a working TTF or OTF\n  font from scratch with code. NOTE: the API is still experimental and may\n  change in future versions.\n\n3.31.0 (released 2018-10-21)\n----------------------------\n\n- [ufoLib] Merged the `ufoLib <https://github.com/unified-font-objects/ufoLib>`__\n  master branch into a new ``fontTools.ufoLib`` package (#1335, #1095).\n  Moved ``ufoLib.pointPen`` module to ``fontTools.pens.pointPen``.\n  Moved ``ufoLib.etree`` module to ``fontTools.misc.etree``.\n  Moved ``ufoLib.plistlib`` module to ``fontTools.misc.plistlib``.\n  To use the new ``fontTools.ufoLib`` module you need to install fonttools\n  with the ``[ufo]`` extra, or you can manually install the required additional\n  dependencies (cf. README.rst).\n- [morx] Support AAT action type to insert glyphs and clean up compilation\n  of AAT action tables (4a1871f, 2011ccf).\n- [subset] The ``--no-hinting`` on a CFF font now also drops the optional\n  hinting keys in Private dict: ``ForceBold``, ``LanguageGroup``, and\n  ``ExpansionFactor`` (#1322).\n- [subset] Include nameIDs referenced by STAT table (#1327).\n- [loggingTools] Added ``msg=None`` argument to\n  ``CapturingLogHandler.assertRegex`` (0245f2c).\n- [varLib.mutator] Implemented ``FeatureVariations`` instantiation (#1244).\n- [g_l_y_f] Added PointPen support to ``_TTGlyph`` objects (#1334).\n\n3.30.0 (released 2018-09-18)\n----------------------------\n\n- [feaLib] Skip building noop class PairPos subtables when Coverage is NULL\n  (#1318).\n- [ttx] Expose the previously reserved bit flag ``OVERLAP_SIMPLE`` of\n  glyf table's contour points in the TTX dump. This is used in some\n  implementations to specify a non-zero fill with overlapping contours (#1316).\n- [ttLib] Added support for decompiling/compiling ``TS1C`` tables containing\n  VTT sources for ``cvar`` variation table (#1310).\n- [varLib] Use ``fontTools.designspaceLib`` to read DesignSpaceDocument. The\n  ``fontTools.varLib.designspace`` module is now deprecated and will be removed\n  in future versions. The presence of an explicit ``axes`` element is now\n  required in order to build a variable font (#1224, #1313).\n- [varLib] Implemented building GSUB FeatureVariations table from the ``rules``\n  element of DesignSpace document (#1240, #713, #1314).\n- [subset] Added ``--no-layout-closure`` option to not expand the subset with\n  the glyphs produced by OpenType layout features. Instead, OpenType features\n  will be subset to only rules that are relevant to the otherwise-specified\n  glyph set (#43, #1121).\n\n3.29.1 (released 2018-09-10)\n----------------------------\n\n- [feaLib] Fixed issue whereby lookups from DFLT/dflt were not included in the\n  DFLT/non-dflt language systems (#1307).\n- [graphite] Fixed issue on big-endian architectures (e.g. ppc64) (#1311).\n- [subset] Added ``--layout-scripts`` option to add/exclude set of OpenType\n  layout scripts that will be preserved. By default all scripts are retained\n  (``'*'``) (#1303).\n\n3.29.0 (released 2018-07-26)\n----------------------------\n\n- [feaLib] In the OTL table builder, when the ``name`` table is excluded\n  from the list of tables to be build, skip compiling ``featureNames`` blocks,\n  as the records referenced in ``FeatureParams`` table don't exist (68951b7).\n- [otBase] Try ``ExtensionLookup`` if other offset-overflow methods fail\n  (05f95f0).\n- [feaLib] Added support for explicit ``subtable;`` break statements in\n  PairPos lookups; previously these were ignored (#1279, #1300, #1302).\n- [cffLib.specializer] Make sure the stack depth does not exceed maxstack - 1,\n  so that a subroutinizer can insert subroutine calls (#1301,\n  https://github.com/googlei18n/ufo2ft/issues/266).\n- [otTables] Added support for fixing offset overflow errors occurring inside\n  ``MarkBasePos`` subtables (#1297).\n- [subset] Write the default output file extension based on ``--flavor`` option,\n  or the value of ``TTFont.sfntVersion`` (d7ac0ad).\n- [unicodedata] Updated Blocks, Scripts and ScriptExtensions for Unicode 11\n  (452c85e).\n- [xmlWriter] Added context manager to XMLWriter class to autoclose file\n  descriptor on exit (#1290).\n- [psCharStrings] Optimize the charstring's bytecode by encoding as integers\n  all float values that have no decimal portion (8d7774a).\n- [ttFont] Fixed missing import of ``TTLibError`` exception (#1285).\n- [feaLib] Allow any languages other than ``dflt`` under ``DFLT`` script\n  (#1278, #1292).\n\n3.28.0 (released 2018-06-19)\n----------------------------\n\n- [featureVars] Added experimental module to build ``FeatureVariations``\n  tables. Still needs to be hooked up to ``varLib.build`` (#1240).\n- [fixedTools] Added ``otRound`` to round floats to nearest integer towards\n  positive Infinity. This is now used where we deal with visual data like X/Y\n  coordinates, advance widths/heights, variation deltas, and similar (#1274,\n  #1248).\n- [subset] Improved GSUB closure memoize algorithm.\n- [varLib.models] Fixed regression in model resolution (180124, #1269).\n- [feaLib.ast] Fixed error when converting ``SubtableStatement`` to string\n  (#1275).\n- [varLib.mutator] Set ``OS/2.usWeightClass`` and ``usWidthClass``, and\n  ``post.italicAngle`` based on the 'wght', 'wdth' and 'slnt' axis values\n  (#1276, #1264).\n- [py23/loggingTools] Don't automatically set ``logging.lastResort`` handler\n  on py27. Moved ``LastResortLogger`` to the ``loggingTools`` module (#1277).\n\n3.27.1 (released 2018-06-11)\n----------------------------\n\n- [ttGlyphPen] Issue a warning and skip building non-existing components\n  (https://github.com/googlei18n/fontmake/issues/411).\n- [tests] Fixed issue running ttx_test.py from a tagged commit.\n\n3.27.0 (released 2018-06-11)\n----------------------------\n\n- [designspaceLib] Added new ``conditionSet`` element to ``rule`` element in\n  designspace document. Bumped ``format`` attribute to ``4.0`` (previously,\n  it was formatted as an integer). Removed ``checkDefault``, ``checkAxes``\n  methods, and any kind of guessing about the axes when the ``<axes>`` element\n  is missing. The default master is expected at the intersection of all default\n  values for each axis (#1254, #1255, #1267).\n- [cffLib] Fixed issues when compiling CFF2 or converting from CFF when the\n  font has an FDArray (#1211, #1271).\n- [varLib] Avoid attempting to build ``cvar`` table when ``glyf`` table is not\n  present, as is the case for CFF2 fonts.\n- [subset] Handle None coverages in MarkGlyphSets; revert commit 02616ab that\n  sets empty Coverage tables in MarkGlyphSets to None, to make OTS happy.\n- [ttFont] Allow to build glyph order from ``maxp.numGlyphs`` when ``post`` or\n  ``cmap`` are missing.\n- [ttFont] Added ``__len__`` method to ``_TTGlyphSet``.\n- [glyf] Ensure ``GlyphCoordinates`` never overflow signed shorts (#1230).\n- [py23] Added alias for ``itertools.izip`` shadowing the built-in ``zip``.\n- [loggingTools] Memoize ``log`` property of ``LogMixin`` class (fbab12).\n- [ttx] Impoved test coverage (#1261).\n- [Snippets] Addded script to append a suffix to all family names in a font.\n- [varLib.plot] Make it work with matplotlib >= 2.1 (b38e2b).\n\n3.26.0 (released 2018-05-03)\n----------------------------\n\n- [designspace] Added a new optional ``layer`` attribute to the source element,\n  and a corresponding ``layerName`` attribute to the ``SourceDescriptor``\n  object (#1253).\n  Added ``conditionset`` element to the ``rule`` element to the spec, but not\n  implemented in designspace reader/writer yet (#1254).\n- [varLib.models] Refine modeling one last time (0ecf5c5).\n- [otBase] Fixed sharing of tables referred to by different offset sizes\n  (795f2f9).\n- [subset] Don't drop a GDEF that only has VarStore (fc819d6). Set to None\n  empty Coverage tables in MarkGlyphSets (02616ab).\n- [varLib]: Added ``--master-finder`` command-line option (#1249).\n- [varLib.mutator] Prune fvar nameIDs from instance's name table (#1245).\n- [otTables] Allow decompiling bad ClassDef tables with invalid format, with\n  warning (#1236).\n- [varLib] Make STAT v1.2 and reuse nameIDs from fvar table (#1242).\n- [varLib.plot] Show master locations. Set axis limits to -1, +1.\n- [subset] Handle HVAR direct mapping. Passthrough 'cvar'.\n  Added ``--font-number`` command-line option for collections.\n- [t1Lib] Allow a text encoding to be specified when parsing a Type 1 font\n  (#1234). Added ``kind`` argument to T1Font constructor (c5c161c).\n- [ttLib] Added context manager API to ``TTFont`` class, so it can be used in\n  ``with`` statements to auto-close the file when exiting the context (#1232).\n\n3.25.0 (released 2018-04-03)\n----------------------------\n\n- [varLib] Improved support-resolution algorithm. Previously, the on-axis\n  masters would always cut the space. They don't anymore. That's more\n  consistent, and fixes the main issue Erik showed at TYPO Labs 2017.\n  Any varfont built that had an unusual master configuration will change\n  when rebuilt (42bef17, a523a697,\n  https://github.com/googlei18n/fontmake/issues/264).\n- [varLib.models] Added a ``main()`` entry point, that takes positions and\n  prints model results.\n- [varLib.plot] Added new module to plot a designspace's\n  VariationModel. Requires ``matplotlib``.\n- [varLib.mutator] Added -o option to specify output file path (2ef60fa).\n- [otTables] Fixed IndexError while pruning of HVAR pre-write (6b6c34a).\n- [varLib.models] Convert delta array to floats if values overflows signed\n  short integer (0055f94).\n\n3.24.2 (released 2018-03-26)\n----------------------------\n\n- [otBase] Don't fail during ``ValueRecord`` copy if src has more items.\n  We drop hinting in the subsetter by simply changing ValueFormat, without\n  cleaning up the actual ValueRecords. This was causing assertion error if\n  a variable font was subsetted without hinting and then passed directly to\n  the mutator for instantiation without first it saving to disk.\n\n3.24.1 (released 2018-03-06)\n----------------------------\n\n- [varLib] Don't remap the same ``DeviceTable`` twice in VarStore optimizer\n  (#1206).\n- [varLib] Add ``--disable-iup`` option to ``fonttools varLib`` script,\n  and a ``optimize=True`` keyword argument to ``varLib.build`` function,\n  to optionally disable IUP optimization while building varfonts.\n- [ttCollection] Fixed issue while decompiling ttc with python3 (#1207).\n\n3.24.0 (released 2018-03-01)\n----------------------------\n\n- [ttGlyphPen] Decompose composite glyphs if any components' transform is too\n  large to fit a ``F2Dot14`` value, or clamp transform values that are\n  (almost) equal to +2.0 to make them fit and avoid decomposing (#1200,\n  #1204, #1205).\n- [ttx] Added new ``-g`` option to dump glyphs from the ``glyf`` table\n  splitted as individual ttx files (#153, #1035, #1132, #1202).\n- Copied ``ufoLib.filenames`` module to ``fontTools.misc.filenames``, used\n  for the ttx split-glyphs option (#1202).\n- [feaLib] Added support for ``cvParameters`` blocks in Character Variant\n  feautures ``cv01-cv99`` (#860, #1169).\n- [Snippets] Added ``checksum.py`` script to generate/check SHA1 hash of\n  ttx files (#1197).\n- [varLib.mutator] Fixed issue while instantiating some variable fonts\n  whereby the horizontal advance width computed from ``gvar`` phantom points\n  could turn up to be negative (#1198).\n- [varLib/subset] Fixed issue with subsetting GPOS variation data not\n  picking up ``ValueRecord`` ``Device`` objects (54fd71f).\n- [feaLib/voltLib] In all AST elements, the ``location`` is no longer a\n  required positional argument, but an optional kewyord argument (defaults\n  to ``None``). This will make it easier to construct feature AST from\n  code (#1201).\n\n\n3.23.0 (released 2018-02-26)\n----------------------------\n\n- [designspaceLib] Added an optional ``lib`` element to the designspace as a\n  whole, as well as to the instance elements, to store arbitrary data in a\n  property list dictionary, similar to the UFO's ``lib``. Added an optional\n  ``font`` attribute to the ``SourceDescriptor``, to allow operating on\n  in-memory font objects (#1175).\n- [cffLib] Fixed issue with lazy-loading of attributes when attempting to\n  set the CFF TopDict.Encoding (#1177, #1187).\n- [ttx] Fixed regression introduced in 3.22.0 that affected the split tables\n  ``-s`` option (#1188).\n- [feaLib] Added ``IncludedFeaNotFound`` custom exception subclass, raised\n  when an included feature file cannot be found (#1186).\n- [otTables] Changed ``VarIdxMap`` to use glyph names internally instead of\n  glyph indexes. The old ttx dumps of HVAR/VVAR tables that contain indexes\n  can still be imported (21cbab8, 38a0ffb).\n- [varLib] Implemented VarStore optimizer (#1184).\n- [subset] Implemented pruning of GDEF VarStore, HVAR and MVAR (#1179).\n- [sfnt] Restore backward compatiblity with ``numFonts`` attribute of\n  ``SFNTReader`` object (#1181).\n- [merge] Initial support for merging ``LangSysRecords`` (#1180).\n- [ttCollection] don't seek(0) when writing to possibly unseekable strems.\n- [subset] Keep all ``--name-IDs`` from 0 to 6 by default (#1170, #605, #114).\n- [cffLib] Added ``width`` module to calculate optimal CFF default and\n  nominal glyph widths.\n- [varLib] Donâ€™t fail if STAT already in the master fonts (#1166).\n\n3.22.0 (released 2018-02-04)\n----------------------------\n\n- [subset] Support subsetting ``endchar`` acting as ``seac``-like components\n  in ``CFF`` (fixes #1162).\n- [feaLib] Allow to build from pre-parsed ``ast.FeatureFile`` object.\n  Added ``tables`` argument to only build some tables instead of all (#1159,\n  #1163).\n- [textTools] Replaced ``safeEval`` with ``ast.literal_eval`` (#1139).\n- [feaLib] Added option to the parser to not resolve ``include`` statements\n  (#1154).\n- [ttLib] Added new ``ttCollection`` module to read/write TrueType and\n  OpenType Collections. Exports a ``TTCollection`` class with a ``fonts``\n  attribute containing a list of ``TTFont`` instances, the methods ``save``\n  and ``saveXML``, plus some list-like methods. The ``importXML`` method is\n  not implemented yet (#17).\n- [unicodeadata] Added ``ot_tag_to_script`` function that converts from\n  OpenType script tag to Unicode script code.\n- Added new ``designspaceLib`` subpackage, originally from Erik Van Blokland's\n  ``designSpaceDocument``: https://github.com/LettError/designSpaceDocument\n  NOTE: this is not yet used internally by varLib, and the API may be subject\n  to changes (#911, #1110, LettError/designSpaceDocument#28).\n- Added new FontTools icon images (8ee7c32).\n- [unicodedata] Added ``script_horizontal_direction`` function that returns\n  either \"LTR\" or \"RTL\" given a unicode script code.\n- [otConverters] Don't write descriptive name string as XML comment if the\n  NameID value is 0 (== NULL) (#1151, #1152).\n- [unicodedata] Add ``ot_tags_from_script`` function to get the list of\n  OpenType script tags associated with unicode script code (#1150).\n- [feaLib] Don't error when \"enumerated\" kern pairs conflict with preceding\n  single pairs; emit warning and chose the first value (#1147, #1148).\n- [loggingTools] In ``CapturingLogHandler.assertRegex`` method, match the\n  fully formatted log message.\n- [sbix] Fixed TypeError when concatenating str and bytes (#1154).\n- [bezierTools] Implemented cusp support and removed ``approximate_fallback``\n  arg in ``calcQuadraticArcLength``. Added ``calcCubicArcLength`` (#1142).\n\n3.21.2 (released 2018-01-08)\n----------------------------\n\n- [varLib] Fixed merging PairPos Format1/2 with missing subtables (#1125).\n\n3.21.1 (released 2018-01-03)\n----------------------------\n\n- [feaLib] Allow mixed single/multiple substitutions (#612)\n- Added missing ``*.afm`` test assets to MAINFEST.in (#1137).\n- Fixed dumping ``SVG`` tables containing color palettes (#1124).\n\n3.21.0 (released 2017-12-18)\n----------------------------\n\n- [cmap] when compiling format6 subtable, don't assume gid0 is always called\n  '.notdef' (1e42224).\n- [ot] Allow decompiling fonts with bad Coverage format number (1aafae8).\n- Change FontTools licence to MIT (#1127).\n- [post] Prune extra names already in standard Mac set (df1e8c7).\n- [subset] Delete empty SubrsIndex after subsetting (#994, #1118).\n- [varLib] Don't share points in cvar by default, as it currently fails on\n  some browsers (#1113).\n- [afmLib] Make poor old afmLib work on python3.\n\n3.20.1 (released 2017-11-22)\n----------------------------\n\n- [unicodedata] Fixed issue with ``script`` and ``script_extension`` functions\n  returning inconsistent short vs long names. They both return the short four-\n  letter script codes now. Added ``script_name`` and ``script_code`` functions\n  to look up the long human-readable script name from the script code, and\n  viceversa (#1109, #1111).\n\n3.20.0 (released 2017-11-21)\n----------------------------\n\n- [unicodedata] Addded new module ``fontTools.unicodedata`` which exports the\n  same interface as the built-in ``unicodedata`` module, with the addition of\n  a few functions that are missing from the latter, such as ``script``,\n  ``script_extension`` and ``block``. Added a ``MetaTools/buildUCD.py`` script\n  to download and parse data files from the Unicode Character Database and\n  generate python modules containing lists of ranges and property values.\n- [feaLib] Added ``__str__`` method to all ``ast`` elements (delegates to the\n  ``asFea`` method).\n- [feaLib] ``Parser`` constructor now accepts a ``glyphNames`` iterable\n  instead of ``glyphMap`` dict. The latter still works but with a pending\n  deprecation warning (#1104).\n- [bezierTools] Added arc length calculation functions originally from\n  ``pens.perimeterPen`` module (#1101).\n- [varLib] Started generating STAT table (8af4309). Right now it just reflects\n  the axes, and even that with certain limitations:\n  * AxisOrdering is set to the order axes are defined,\n  * Name-table entries are not shared with fvar.\n- [py23] Added backports for ``redirect_stdout`` and ``redirect_stderr``\n  context managers (#1097).\n- [Graphite] Fixed some round-trip bugs (#1093).\n\n3.19.0 (released 2017-11-06)\n----------------------------\n\n- [varLib] Try set of used points instead of all points when testing whether to\n  share points between tuples (#1090).\n- [CFF2] Fixed issue with reading/writing PrivateDict BlueValues to TTX file.\n  Read the commit message 8b02b5a and issue #1030 for more details.\n  NOTE: this change invalidates all the TTX files containing CFF2 tables\n  that where dumped with previous verisons of fonttools.\n  CFF2 Subr items can have values on the stack after the last operator, thus\n  a ``CFF2Subr`` class was added to accommodate this (#1091).\n- [_k_e_r_n] Fixed compilation of AAT kern version=1.0 tables (#1089, #1094)\n- [ttLib] Added getBestCmap() convenience method to TTFont class and cmap table\n  class that returns a preferred Unicode cmap subtable given a list of options\n  (#1092).\n- [morx] Emit more meaningful subtable flags. Implement InsertionMorphAction\n\n3.18.0 (released 2017-10-30)\n----------------------------\n\n- [feaLib] Fixed writing back nested glyph classes (#1086).\n- [TupleVariation] Reactivated shared points logic, bugfixes (#1009).\n- [AAT] Implemented ``morx`` ligature subtables (#1082).\n- [reverseContourPen] Keep duplicate lineTo following a moveTo (#1080,\n  https://github.com/googlei18n/cu2qu/issues/51).\n- [varLib.mutator] Suport instantiation of GPOS, GDEF and MVAR (#1079).\n- [sstruct] Fixed issue with ``unicode_literals`` and ``struct`` module in\n  old versions of python 2.7 (#993).\n\n3.17.0 (released 2017-10-16)\n----------------------------\n\n- [svgPathPen] Added an ``SVGPathPen`` that translates segment pen commands\n  into SVG path descriptions. Copied from Tal Leming's ``ufo2svg.svgPathPen``\n  https://github.com/typesupply/ufo2svg/blob/d69f992/Lib/ufo2svg/svgPathPen.py\n- [reverseContourPen] Added ``ReverseContourPen``, a filter pen that draws\n  contours with the winding direction reversed, while keeping the starting\n  point (#1071).\n- [filterPen] Added ``ContourFilterPen`` to manipulate contours as a whole\n  rather than segment by segment.\n- [arrayTools] Added ``Vector`` class to apply math operations on an array\n  of numbers, and ``pairwise`` function to loop over pairs of items in an\n  iterable.\n- [varLib] Added support for building and interpolation of ``cvar`` table\n  (f874cf6, a25a401).\n\n3.16.0 (released 2017-10-03)\n----------------------------\n\n- [head] Try using ``SOURCE_DATE_EPOCH`` environment variable when setting\n  the ``head`` modified timestamp to ensure reproducible builds (#1063).\n  See https://reproducible-builds.org/specs/source-date-epoch/\n- [VTT] Decode VTT's ``TSI*`` tables text as UTF-8 (#1060).\n- Added support for Graphite font tables: Feat, Glat, Gloc, Silf and Sill.\n  Thanks @mhosken! (#1054).\n- [varLib] Default to using axis \"name\" attribute if \"labelname\" element\n  is missing (588f524).\n- [merge] Added support for merging Script records. Remove unused features\n  and lookups after merge (d802580, 556508b).\n- Added ``fontTools.svgLib`` package. Includes a parser for SVG Paths that\n  supports the Pen protocol (#1051). Also, added a snippet to convert SVG\n  outlines to UFO GLIF (#1053).\n- [AAT] Added support for ``ankr``, ``bsln``, ``mort``, ``morx``, ``gcid``,\n  and ``cidg``.\n- [subset] Implemented subsetting of ``prop``, ``opbd``, ``bsln``, ``lcar``.\n\n3.15.1 (released 2017-08-18)\n----------------------------\n\n- [otConverters] Implemented ``__add__`` and ``__radd__`` methods on\n  ``otConverters._LazyList`` that decompile a lazy list before adding\n  it to another list or ``_LazyList`` instance. Fixes an ``AttributeError``\n  in the ``subset`` module when attempting to sum ``_LazyList`` objects\n  (6ef48bd2, 1aef1683).\n- [AAT] Support the `opbd` table with optical bounds (a47f6588).\n- [AAT] Support `prop` table with glyph properties (d05617b4).\n\n\n3.15.0 (released 2017-08-17)\n----------------------------\n\n- [AAT] Added support for AAT lookups. The ``lcar`` table can be decompiled\n  and recompiled; futher work needed to handle ``morx`` table (#1025).\n- [subset] Keep (empty) DefaultLangSys for Script 'DFLT' (6eb807b5).\n- [subset] Support GSUB/GPOS.FeatureVariations (fe01d87b).\n- [varLib] In ``models.supportScalars``, ignore an axis when its peak value\n  is 0 (fixes #1020).\n- [varLib] Add default mappings to all axes in avar to fix rendering issue\n  in some rasterizers (19c4b377, 04eacf13).\n- [varLib] Flatten multiple tail PairPosFormat2 subtables before merging\n  (c55ef525).\n- [ttLib] Added support for recalculating font bounding box in ``CFF`` and\n  ``head`` tables, and min/max values in ``hhea`` and ``vhea`` tables (#970).\n\n3.14.0 (released 2017-07-31)\n----------------------------\n\n- [varLib.merger] Remove Extensions subtables before merging (f7c20cf8).\n- [varLib] Initialize the avar segment map with required default entries\n  (#1014).\n- [varLib] Implemented optimal IUP optmiziation (#1019).\n- [otData] Add ``AxisValueFormat4`` for STAT table v1.2 from OT v1.8.2\n  (#1015).\n- [name] Fixed BCP46 language tag for Mac langID=9: 'si' -> 'sl'.\n- [subset] Return value from ``_DehintingT2Decompiler.op_hintmask``\n  (c0d672ba).\n- [cffLib] Allow to get TopDict by index as well as by name (dca96c9c).\n- [cffLib] Removed global ``isCFF2`` state; use one set of classes for\n  both CFF and CFF2, maintaining backward compatibility existing codeÂ (#1007).\n- [cffLib] Deprecated maxstack operator, per OpenType spec update 1.8.1.\n- [cffLib] Added missing default (-100) for UnderlinePosition (#983).\n- [feaLib] Enable setting nameIDs greater than 255 (#1003).\n- [varLib] Recalculate ValueFormat when merging SinglePos (#996).\n- [varLib] Do not emit MVAR if there are no entries in the variation store\n  (#987).\n- [ttx] For ``-x`` option, pad with space if table tag length is < 4.\n\n3.13.1 (released 2017-05-30)\n----------------------------\n\n- [feaLib.builder] Removed duplicate lookups optimization. The original\n  lookup order and semantics of the feature file are preserved (#976).\n\n3.13.0 (released 2017-05-24)\n----------------------------\n\n- [varLib.mutator] Implement IUP optimization (#969).\n- [_g_l_y_f.GlyphCoordinates] Changed ``__bool__()`` semantics to match those\n  of other iterables (e46f949). Removed ``__abs__()`` (3db5be2).\n- [varLib.interpolate_layout] Added ``mapped`` keyword argument to\n  ``interpolate_layout`` to allow disabling avar mapping: if False (default),\n  the location is mapped using the map element of the axes in designspace file;\n  if True, it is assumed that location is in designspace's internal space and\n  no mapping is performed (#950, #975).\n- [varLib.interpolate_layout] Import designspace-loading logic from varLib.\n- [varLib] Fixed bug with recombining PairPosClass2 subtables (81498e5, #914).\n- [cffLib.specializer] When copying iterables, cast to list (462b7f86).\n\n3.12.1 (released 2017-05-18)\n----------------------------\n\n- [pens.t2CharStringPen] Fixed AttributeError when calling addComponent in\n  T2CharStringPen (#965).\n\n3.12.0 (released 2017-05-17)\n----------------------------\n\n- [cffLib.specializer] Added new ``specializer`` module to optimize CFF\n  charstrings, used by the T2CharStringPen (#948).\n- [varLib.mutator] Sort glyphs by component depth before calculating composite\n  glyphs' bounding boxes to ensure deltas are correctly caclulated (#945).\n- [_g_l_y_f] Fixed loss of precision in GlyphCoordinates by using 'd' (double)\n  instead of 'f' (float) as ``array.array`` typecode (#963, #964).\n\n3.11.0 (released 2017-05-03)\n----------------------------\n\n- [t2CharStringPen] Initial support for specialized Type2 path operators:\n  vmoveto, hmoveto, vlineto, hlineto, vvcurveto, hhcurveto, vhcurveto and\n  hvcurveto. This should produce more compact charstrings (#940, #403).\n- [Doc] Added Sphinx sources for the documentation. Thanks @gferreira (#935).\n- [fvar] Expose flags in XML (#932)\n- [name] Add helper function for building multi-lingual names (#921)\n- [varLib] Fixed kern merging when a PairPosFormat2 has ClassDef1 with glyphs\n  that are NOT present in the Coverage (1b5e1c4, #939).\n- [varLib] Fixed non-deterministic ClassDef order with PY3 (f056c12, #927).\n- [feLib] Throw an error when the same glyph is defined in multiple mark\n  classes within the same lookup (3e3ff00, #453).\n\n3.10.0 (released 2017-04-14)\n----------------------------\n\n- [varLib] Added support for building ``avar`` table, using the designspace\n  ``<map>`` elements.\n- [varLib] Removed unused ``build(..., axisMap)`` argument. Axis map should\n  be specified in designspace file now. We do not accept nonstandard axes\n  if ``<axes>`` element is not present.\n- [varLib] Removed \"custom\" axis from the ``standard_axis_map``. This was\n  added before when glyphsLib was always exporting the (unused) custom axis.\n- [varLib] Added partial support for building ``MVAR`` table; does not\n  implement ``gasp`` table variations yet.\n- [pens] Added FilterPen base class, for pens that control another pen;\n  factored out ``addComponent`` method from BasePen into a separate abstract\n  DecomposingPen class; added DecomposingRecordingPen, which records\n  components decomposed as regular contours.\n- [TSI1] Fixed computation of the textLength of VTT private tables (#913).\n- [loggingTools] Added ``LogMixin`` class providing a ``log`` property to\n  subclasses, which returns a ``logging.Logger`` named after the latter.\n- [loggingTools] Added ``assertRegex`` method to ``CapturingLogHandler``.\n- [py23] Added backport for python 3's ``types.SimpleNamespace`` class.\n- [EBLC] Fixed issue with python 3 ``zip`` iterator.\n\n3.9.2 (released 2017-04-08)\n---------------------------\n\n- [pens] Added pen to draw glyphs using WxPython ``GraphicsPath`` class:\n  https://wxpython.org/docs/api/wx.GraphicsPath-class.html\n- [varLib.merger] Fixed issue with recombining multiple PairPosFormat2\n  subtables (#888)\n- [varLib] Do not encode gvar deltas that are all zeroes, or if all values\n  are smaller than tolerance.\n- [ttLib] _TTGlyphSet glyphs now also have ``height`` and ``tsb`` (top\n  side bearing) attributes from the ``vmtx`` table, if present.\n- [glyf] In ``GlyphCoordintes`` class, added ``__bool__`` / ``__nonzero__``\n  methods, and ``array`` property to get raw array.\n- [ttx] Support reading TTX files with BOM (#896)\n- [CFF2] Fixed the reporting of the number of regions in the font.\n\n3.9.1 (released 2017-03-20)\n---------------------------\n\n- [varLib.merger] Fixed issue while recombining multiple PairPosFormat2\n  subtables if they were split because of offset overflows (9798c30).\n- [varLib.merger] Only merge multiple PairPosFormat1 subtables if there is\n  at least one of the fonts with a non-empty Format1 subtable (0f5a46b).\n- [varLib.merger] Fixed IndexError with empty ClassDef1 in PairPosFormat2\n  (aad0d46).\n- [varLib.merger] Avoid reusing Class2Record (mutable) objects (e6125b3).\n- [varLib.merger] Calculate ClassDef1 and ClassDef2's Format when merging\n  PairPosFormat2 (23511fd).\n- [macUtils] Added missing ttLib import (b05f203).\n\n3.9.0 (released 2017-03-13)\n---------------------------\n\n- [feaLib] Added (partial) support for parsing feature file comments ``# ...``\n  appearing in between statements (#879).\n- [feaLib] Cleaned up syntax tree for FeatureNames.\n- [ttLib] Added support for reading/writing ``CFF2`` table (thanks to\n  @readroberts at Adobe), and ``TTFA`` (ttfautohint) table.\n- [varLib] Fixed regression introduced with 3.8.0 in the calculation of\n  ``NumShorts``, i.e. the number of deltas in ItemVariationData's delta sets\n  that use a 16-bitÂ representation (b2825ff).\n\n3.8.0 (released 2017-03-05)\n---------------------------\n\n- New pens: MomentsPen, StatisticsPen, RecordingPen, and TeePen.\n- [misc] Added new ``fontTools.misc.symfont`` module, for symbolic font\n  statistical analysis; requires ``sympy`` (http://www.sympy.org/en/index.html)\n- [varLib] Added experimental ``fontTools.varLib.interpolatable`` module for\n  finding wrong contour order between different masters\n- [varLib] designspace.load() now returns a dictionary, instead of a tuple,\n  and supports <axes> element (#864); the 'masters' item was renamed 'sources',\n  like the <sources> element in the designspace document\n- [ttLib] Fixed issue with recalculating ``head`` modified timestamp when\n  saving CFF fonts\n- [ttLib] In TupleVariation, round deltas before compiling (#861, fixed #592)\n- [feaLib] Ignore duplicate glyphs in classes used as MarkFilteringSet and\n  MarkAttachmentType (#863)\n- [merge] Changed the ``gasp`` table merge logic so that only the one from\n  the first font is retained, similar to other hinting tables (#862)\n- [Tests] Added tests for the ``varLib`` package, as well as test fonts\n  from the \"Annotated OpenType Specification\" (AOTS) to exercise ``ttLib``'s\n  table readers/writers (<https://github.com/adobe-type-tools/aots>)\n\n3.7.2 (released 2017-02-17)\n---------------------------\n\n- [subset] Keep advance widths when stripping \".notdef\" glyph outline in\n  CID-keyed CFF fonts (#845)\n- [feaLib] Zero values now produce the same results as makeotf (#633, #848)\n- [feaLib] More compact encoding for â€œContextual positioning with in-line\n  single positioning rulesâ€ (#514)\n\n3.7.1 (released 2017-02-15)\n---------------------------\n\n- [subset] Fixed issue with ``--no-hinting`` option whereby advance widths in\n  Type 2 charstrings were also being stripped (#709, #343)\n- [feaLib] include statements now resolve relative paths like makeotf (#838)\n- [feaLib] table ``name`` now handles Unicode codepoints beyond the Basic\n  Multilingual Plane, also supports old-style MacOS platform encodings (#842)\n- [feaLib] correctly escape string literals when emitting feature syntax (#780)\n\n3.7.0 (released 2017-02-11)\n---------------------------\n\n- [ttx, mtiLib] Preserve ordering of glyph alternates in GSUB type 3 (#833).\n- [feaLib] Glyph names can have dashes, as per new AFDKO syntax v1.20 (#559).\n- [feaLib] feaLib.Parser now needs the font's glyph map for parsing.\n- [varLib] Fix regression where GPOS values were stored as 0.\n- [varLib] Allow merging of class-based kerning when ClassDefs are different\n\n3.6.3 (released 2017-02-06)\n---------------------------\n\n- [varLib] Fix building variation of PairPosFormat2 (b5c34ce).\n- Populate defaults even for otTables that have postRead (e45297b).\n- Fix compiling of MultipleSubstFormat1 with zero 'out' glyphs (b887860).\n\n3.6.2 (released 2017-01-30)\n---------------------------\n\n- [varLib.merger] Fixed \"TypeError: reduce() of empty sequence with no\n  initial value\" (3717dc6).\n\n3.6.1 (released 2017-01-28)\n---------------------------\n\n-  [py23] Fixed unhandled exception occurring at interpreter shutdown in\n   the \"lastÂ resort\" logging handler (972b3e6).\n-  [agl] Ensure all glyph names are of native 'str' type; avoid mixing\n   'str' and 'unicode' in TTFont.glyphOrder (d8c4058).\n-  Fixed inconsistent title levels in README.rst that caused PyPI to\n   incorrectly render the reStructuredText page.\n\n3.6.0 (released 2017-01-26)\n---------------------------\n\n-  [varLib] Refactored and improved the variation-font-building process.\n-  Assembly code in the fpgm, prep, and glyf tables is now indented in\n   XML output for improved readability. The ``instruction`` element is\n   written as a simple tag if empty (#819).\n-  [ttx] Fixed 'I/O operation on closed file' error when dumping\n   multiple TTXs to standard output with the '-o -' option.\n-  The unit test modules (``*_test.py``) have been moved outside of the\n   fontTools package to the Tests folder, thus they are no longer\n   installed (#811).\n\n3.5.0 (released 2017-01-14)\n---------------------------\n\n-  Font tables read from XML can now be written back to XML with no\n   loss.\n-  GSUB/GPOS LookupType is written out in XML as an element, not\n   comment. (#792)\n-  When parsing cmap table, do not store items mapped to glyph id 0.\n   (#790)\n-  [otlLib] Make ClassDef sorting deterministic. Fixes #766 (7d1ddb2)\n-  [mtiLib] Added unit tests (#787)\n-  [cvar] Implemented cvar table\n-  [gvar] Renamed GlyphVariation to TupleVariation to match OpenType\n   terminology.\n-  [otTables] Handle gracefully empty VarData.Item array when compiling\n   XML. (#797)\n-  [varLib] Re-enabled generation of ``HVAR`` table for fonts with\n   TrueType outlines; removed ``--build-HVAR`` command-line option.\n-  [feaLib] The parser can now be extended to support non-standard\n   statements in FEA code by using a customized Abstract Syntax Tree.\n   See, for example, ``feaLib.builder_test.test_extensions`` and\n   baseClass.feax (#794, fixes #773).\n-  [feaLib] Added ``feaLib`` command to the 'fonttools' command-line\n   tool; applies a feature file to a font. ``fonttools feaLib -h`` for\n   help.\n-  [pens] The ``T2CharStringPen`` now takes an optional\n   ``roundTolerance`` argument to control the rounding of coordinates\n   (#804, fixes #769).\n-  [ci] Measure test coverage on all supported python versions and OSes,\n   combine coverage data and upload to\n   https://codecov.io/gh/fonttools/fonttools (#786)\n-  [ci] Configured Travis and Appveyor for running tests on Python 3.6\n   (#785, 55c03bc)\n-  The manual pages installation directory can be customized through\n   ``FONTTOOLS_MANPATH`` environment variable (#799, fixes #84).\n-  [Snippets] Added otf2ttf.py, for converting fonts from CFF to\n   TrueType using the googlei18n/cu2qu module (#802)\n\n3.4.0 (released 2016-12-21)\n---------------------------\n\n-  [feaLib] Added support for generating FEA text from abstract syntax\n   tree (AST) objects (#776). Thanks @mhosken\n-  Added ``agl.toUnicode`` function to convert AGL-compliant glyph names\n   to Unicode strings (#774)\n-  Implemented MVAR table (b4d5381)\n\n3.3.1 (released 2016-12-15)\n---------------------------\n\n-  [setup] We no longer use versioneer.py to compute fonttools version\n   from git metadata, as this has caused issues for some users (#767).\n   Now we bump the version strings manually with a custom ``release``\n   command of setup.py script.\n\n3.3.0 (released 2016-12-06)\n---------------------------\n\n-  [ttLib] Implemented STAT table from OpenType 1.8 (#758)\n-  [cffLib] Fixed decompilation of CFF fonts containing non-standard\n   key/value pairs in FontDict (issue #740; PR #744)\n-  [py23] minor: in ``round3`` function, allow the second argument to be\n   ``None`` (#757)\n-  The standalone ``sstruct`` and ``xmlWriter`` modules, deprecated\n   since vesion 3.2.0, have been removed. They can be imported from the\n   ``fontTools.misc`` package.\n\n3.2.3 (released 2016-12-02)\n---------------------------\n\n-  [py23] optimized performance of round3 function; added backport for\n   py35 math.isclose() (9d8dacb)\n-  [subset] fixed issue with 'narrow' (UCS-2) Python 2 builds and\n   ``--text``/``--text-file`` options containing non-BMP chararcters\n   (16d0e5e)\n-  [varLib] fixed issuewhen normalizing location values (8fa2ee1, #749)\n-  [inspect] Made it compatible with both python2 and python3 (167ee60,\n   #748). Thanks @pnemade\n\n3.2.2 (released 2016-11-24)\n---------------------------\n\n-  [varLib] Do not emit null axes in fvar (1bebcec). Thanks @robmck-ms\n-  [varLib] Handle fonts without GPOS (7915a45)\n-  [merge] Ignore LangSys if None (a11bc56)\n-  [subset] Fix subsetting MathVariants (78d3cbe)\n-  [OS/2] Fix \"Private Use (plane 15)\" range (08a0d55). Thanks @mashabow\n\n3.2.1 (released 2016-11-03)\n---------------------------\n\n-  [OS/2] fix checking ``fsSelection`` bits matching ``head.macStyle``\n   bits\n-  [varLib] added ``--build-HVAR`` option to generate ``HVAR`` table for\n   fonts with TrueType outlines. For ``CFF2``, it is enabled by default.\n\n3.2.0 (released 2016-11-02)\n---------------------------\n\n-  [varLib] Improve support for OpenType 1.8 Variable Fonts:\n-  Implement GDEF's VariationStore\n-  Implement HVAR/VVAR tables\n-  Partial support for loading MutatorMath .designspace files with\n   varLib.designspace module\n-  Add varLib.models with Variation fonts interpolation models\n-  Implement GSUB/GPOS FeatureVariations\n-  Initial support for interpolating and merging OpenType Layout tables\n   (see ``varLib.interpolate_layout`` and ``varLib.merger`` modules)\n-  [API change] Change version to be an integer instead of a float in\n   XML output for GSUB, GPOS, GDEF, MATH, BASE, JSTF, HVAR, VVAR, feat,\n   hhea and vhea tables. Scripts that set the Version for those to 1.0\n   or other float values also need fixing. A warning is emitted when\n   code or XML needs fix.\n-  several bug fixes to the cffLib module, contributed by Adobe's\n   @readroberts\n-  The XML output for CFF table now has a 'major' and 'minor' elements\n   for specifying whether it's version 1.0 or 2.0 (support for CFF2 is\n   coming soon)\n-  [setup.py] remove undocumented/deprecated ``extra_path`` Distutils\n   argument. This means that we no longer create a \"FontTools\" subfolder\n   in site-packages containing the actual fontTools package, as well as\n   the standalone xmlWriter and sstruct modules. The latter modules are\n   also deprecated, and scheduled for removal in upcoming releases.\n   Please change your import statements to point to from fontTools.misc\n   import xmlWriter and from fontTools.misc import sstruct.\n-  [scripts] Add a 'fonttools' command-line tool that simply runs\n   ``fontTools.*`` sub-modules: e.g. ``fonttools ttx``,\n   ``fonttools subset``, etc.\n-  [hmtx/vmts] Read advance width/heights as unsigned short (uint16);\n   automatically round float values to integers.\n-  [ttLib/xmlWriter] add 'newlinestr=None' keyword argument to\n   ``TTFont.saveXML`` for overriding os-specific line endings (passed on\n   to ``XMLWriter`` instances).\n-  [versioning] Use versioneer instead of ``setuptools_scm`` to\n   dynamically load version info from a git checkout at import time.\n-  [feaLib] Support backslash-prefixed glyph names.\n\n3.1.2 (released 2016-09-27)\n---------------------------\n\n-  restore Makefile as an alternative way to build/check/install\n-  README.md: update instructions for installing package from source,\n   and for running test suite\n-  NEWS: Change log was out of sync with tagged release\n\n3.1.1 (released 2016-09-27)\n---------------------------\n\n-  Fix ``ttLibVersion`` attribute in TTX files still showing '3.0'\n   instead of '3.1'.\n-  Use ``setuptools_scm`` to manage package versions.\n\n3.1.0 (released 2016-09-26)\n---------------------------\n\n-  [feaLib] New library to parse and compile Adobe FDK OpenType Feature\n   files.\n-  [mtiLib] New library to parse and compile Monotype 'FontDame'\n   OpenType Layout Tables files.\n-  [voltLib] New library to parse Microsoft VOLT project files.\n-  [otlLib] New library to work with OpenType Layout tables.\n-  [varLib] New library to work with OpenType Font Variations.\n-  [pens] Add ttGlyphPen to draw to TrueType glyphs, and t2CharStringPen\n   to draw to Type 2 Charstrings (CFF); add areaPen and perimeterPen.\n-  [ttLib.tables] Implement 'meta' and 'trak' tables.\n-  [ttx] Add --flavor option for compiling to 'woff' or 'woff2'; add\n   ``--with-zopfli`` option to use Zopfli to compress WOFF 1.0 fonts.\n-  [subset] Support subsetting 'COLR'/'CPAL' and 'CBDT'/'CBLC' color\n   fonts tables, and 'gvar' table for variation fonts.\n-  [Snippets] Add ``symfont.py``, for symbolic font statistics analysis;\n   interpolatable.py, a preliminary script for detecting interpolation\n   errors; ``{merge,dump}_woff_metadata.py``.\n-  [classifyTools] Helpers to classify things into classes.\n-  [CI] Run tests on Windows, Linux and macOS using Appveyor and Travis\n   CI; check unit test coverage with Coverage.py/Coveralls; automatic\n   deployment to PyPI on tags.\n-  [loggingTools] Use Python built-in logging module to print messages.\n-  [py23] Make round() behave like Python 3 built-in round(); define\n   round2() and round3().\n\n3.0 (released 2015-09-01)\n-------------------------\n\n-  Add Snippet scripts for cmap subtable format conversion, printing\n   GSUB/GPOS features, building a GX font from two masters\n-  TTX WOFF2 support and a ``-f`` option to overwrite output file(s)\n-  Support GX tables: ``avar``, ``gvar``, ``fvar``, ``meta``\n-  Support ``feat`` and gzip-compressed SVG tables\n-  Upgrade Mac East Asian encodings to native implementation if\n   available\n-  Add Roman Croatian and Romanian encodings, codecs for mac-extended\n   East Asian encodings\n-  Implement optimal GLYF glyph outline packing; disabled by default\n\n2.5 (released 2014-09-24)\n-------------------------\n\n-  Add a Qt pen\n-  Add VDMX table converter\n-  Load all OpenType sub-structures lazily\n-  Add support for cmap format 13.\n-  Add pyftmerge tool\n-  Update to Unicode 6.3.0d3\n-  Add pyftinspect tool\n-  Add support for Google CBLC/CBDT color bitmaps, standard EBLC/EBDT\n   embedded bitmaps, and ``SVG`` table (thanks to Read Roberts at Adobe)\n-  Add support for loading, saving and ttx'ing WOFF file format\n-  Add support for Microsoft COLR/CPAL layered color glyphs\n-  Support PyPy\n-  Support Jython, by replacing numpy with array/lists modules and\n   removed it, pure-Python StringIO, not cStringIO\n-  Add pyftsubset and Subsetter object, supporting CFF and TTF\n-  Add to ttx args for -q for quiet mode, -z to choose a bitmap dump\n   format\n\n2.4 (released 2013-06-22)\n-------------------------\n\n-  Option to write to arbitrary files\n-  Better dump format for DSIG\n-  Better detection of OTF XML\n-  Fix issue with Apple's kern table format\n-  Fix mangling of TT glyph programs\n-  Fix issues related to mona.ttf\n-  Fix Windows Installer instructions\n-  Fix some modern MacOS issues\n-  Fix minor issues and typos\n\n2.3 (released 2009-11-08)\n-------------------------\n\n-  TrueType Collection (TTC) support\n-  Python 2.6 support\n-  Update Unicode data to 5.2.0\n-  Couple of bug fixes\n\n2.2 (released 2008-05-18)\n-------------------------\n\n-  ClearType support\n-  cmap format 1 support\n-  PFA font support\n-  Switched from Numeric to numpy\n-  Update Unicode data to 5.1.0\n-  Update AGLFN data to 1.6\n-  Many bug fixes\n\n2.1 (released 2008-01-28)\n-------------------------\n\n-  Many years worth of fixes and features\n\n2.0b2 (released 2002-??-??)\n---------------------------\n\n-  Be \"forgiving\" when interpreting the maxp table version field:\n   interpret any value as 1.0 if it's not 0.5. Fixes dumping of these\n   GPL fonts: http://www.freebsd.org/cgi/pds.cgi?ports/chinese/wangttf\n-  Fixed ttx -l: it turned out this part of the code didn't work with\n   Python 2.2.1 and earlier. My bad to do most of my testing with a\n   different version than I shipped TTX with :-(\n-  Fixed bug in ClassDef format 1 subtable (Andreas Seidel bumped into\n   this one).\n\n2.0b1 (released 2002-09-10)\n---------------------------\n\n-  Fixed embarrassing bug: the master checksum in the head table is now\n   calculated correctly even on little-endian platforms (such as Intel).\n-  Made the cmap format 4 compiler smarter: the binary data it creates\n   is now more or less as compact as possible. TTX now makes more\n   compact data than in any shipping font I've tested it with.\n-  Dump glyph names as a separate \"GlyphOrder\" pseudo table as opposed\n   to as part of the glyf table (obviously needed for CFF-OTF's).\n-  Added proper support for the CFF table.\n-  Don't barf on empty tables (questionable, but \"there are font out\n   there...\")\n-  When writing TT glyf data, align glyphs on 4-byte boundaries. This\n   seems to be the current recommendation by MS. Also: don't barf on\n   fonts which are already 4-byte aligned.\n-  Windows installer contributed bu Adam Twardoch! Yay!\n-  Changed the command line interface again, now by creating one new\n   tool replacing the old ones: ttx It dumps and compiles, depending on\n   input file types. The options have changed somewhat.\n-  The -d option is back (output dir)\n-  ttcompile's -i options is now called -m (as in \"merge\"), to avoid\n   clash with dump's -i.\n-  The -s option (\"split tables\") no longer creates a directory, but\n   instead outputs a small .ttx file containing references to the\n   individual table files. This is not a true link, it's a simple file\n   name, and the referenced file should be in the same directory so\n   ttcompile can find them.\n-  compile no longer accepts a directory as input argument. Instead it\n   can parse the new \"mini-ttx\" format as output by \"ttx -s\".\n-  all arguments are input files\n-  Renamed the command line programs and moved them to the Tools\n   subdirectory. They are now installed by the setup.py install script.\n-  Added OpenType support. BASE, GDEF, GPOS, GSUB and JSTF are (almost)\n   fully supported. The XML output is not yet final, as I'm still\n   considering to output certain subtables in a more human-friendly\n   manner.\n-  Fixed 'kern' table to correctly accept subtables it doesn't know\n   about, as well as interpreting Apple's definition of the 'kern' table\n   headers correctly.\n-  Fixed bug where glyphnames were not calculated from 'cmap' if it was\n   (one of the) first tables to be decompiled. More specifically: it\n   cmap was the first to ask for a glyphID -> glyphName mapping.\n-  Switched XML parsers: use expat instead of xmlproc. Should be faster.\n-  Removed my UnicodeString object: I now require Python 2.0 or up,\n   which has unicode support built in.\n-  Removed assert in glyf table: redundant data at the end of the table\n   is now ignored instead of raising an error. Should become a warning.\n-  Fixed bug in hmtx/vmtx code that only occured if all advances were\n   equal.\n-  Fixed subtle bug in TT instruction disassembler.\n-  Couple of fixes to the 'post' table.\n-  Updated OS/2 table to latest spec.\n\n1.0b1 (released 2001-08-10)\n---------------------------\n\n-  Reorganized the command line interface for ttDump.py and\n   ttCompile.py, they now behave more like \"normal\" command line tool,\n   in that they accept multiple input files for batch processing.\n-  ttDump.py and ttCompile.py don't silently override files anymore, but\n   ask before doing so. Can be overridden by -f.\n-  Added -d option to both ttDump.py and ttCompile.py.\n-  Installation is now done with distutils. (Needs work for environments\n   without compilers.)\n-  Updated installation instructions.\n-  Added some workarounds so as to handle certain buggy fonts more\n   gracefully.\n-  Updated Unicode table to Unicode 3.0 (Thanks Antoine!)\n-  Included a Python script by Adam Twardoch that adds some useful stuff\n   to the Windows registry.\n-  Moved the project to SourceForge.\n\n1.0a6 (released 2000-03-15)\n---------------------------\n\n-  Big reorganization: made ttLib a subpackage of the new fontTools\n   package, changed several module names. Called the entire suite\n   \"FontTools\"\n-  Added several submodules to fontTools, some new, some older.\n-  Added experimental CFF/GPOS/GSUB support to ttLib, read-only (but XML\n   dumping of GPOS/GSUB is for now disabled)\n-  Fixed hdmx endian bug\n-  Added -b option to ttCompile.py, it disables recalculation of\n   bounding boxes, as requested by Werner Lemberg.\n-  Renamed tt2xml.pt to ttDump.py and xml2tt.py to ttCompile.py\n-  Use \".ttx\" as file extension instead of \".xml\".\n-  TTX is now the name of the XML-based *format* for TT fonts, and not\n   just an application.\n\n1.0a5\n-----\n\nNever released\n\n-  More tables supported: hdmx, vhea, vmtx\n\n1.0a3 & 1.0a4\n-------------\n\nNever released\n\n-  fixed most portability issues\n-  retracted the \"Euro_or_currency\" change from 1.0a2: it was\n   nonsense!\n\n1.0a2 (released 1999-05-02)\n---------------------------\n\n-  binary release for MacOS\n-  genenates full FOND resources: including width table, PS font name\n   info and kern table if applicable.\n-  added cmap format 4 support. Extra: dumps Unicode char names as XML\n   comments!\n-  added cmap format 6 support\n-  now accepts true type files starting with \"true\" (instead of just\n   0x00010000 and \"OTTO\")\n-  'glyf' table support is now complete: I added support for composite\n   scale, xy-scale and two-by-two for the 'glyf' table. For now,\n   component offset scale behaviour defaults to Apple-style. This only\n   affects the (re)calculation of the glyph bounding box.\n-  changed \"Euro\" to \"Euro_or_currency\" in the Standard Apple Glyph\n   order list, since we cannot tell from the 'post' table which is\n   meant. I should probably doublecheck with a Unicode encoding if\n   available. (This does not affect the output!)\n\nFixed bugs: - 'hhea' table is now recalculated correctly - fixed wrong\nassumption about sfnt resource names\n\n1.0a1 (released 1999-04-27)\n---------------------------\n\n-  initial binary release for MacOS\n",
        "home_page": "http://github.com/fonttools/fonttools",
        "author": "Just van Rossum",
        "author_email": "just@letterror.com",
        "maintainer": "Behdad Esfahbod",
        "maintainer_email": "behdad@behdad.org",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Environment :: Other Environment",
          "Intended Audience :: Developers",
          "Intended Audience :: End Users/Desktop",
          "License :: OSI Approved :: MIT License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3",
          "Topic :: Text Processing :: Fonts",
          "Topic :: Multimedia :: Graphics",
          "Topic :: Multimedia :: Graphics :: Graphics Conversion"
        ],
        "requires_dist": [
          "fs<3,>=2.2.0; extra == \"ufo\"",
          "lxml>=4.0; extra == \"lxml\"",
          "brotli>=1.0.1; platform_python_implementation == \"CPython\" and extra == \"woff\"",
          "brotlicffi>=0.8.0; platform_python_implementation != \"CPython\" and extra == \"woff\"",
          "zopfli>=0.1.4; extra == \"woff\"",
          "unicodedata2>=15.1.0; python_version <= \"3.12\" and extra == \"unicode\"",
          "lz4>=1.7.4.2; extra == \"graphite\"",
          "scipy; platform_python_implementation != \"PyPy\" and extra == \"interpolatable\"",
          "munkres; platform_python_implementation == \"PyPy\" and extra == \"interpolatable\"",
          "pycairo; extra == \"interpolatable\"",
          "matplotlib; extra == \"plot\"",
          "sympy; extra == \"symfont\"",
          "xattr; sys_platform == \"darwin\" and extra == \"type1\"",
          "skia-pathops>=0.5.0; extra == \"pathops\"",
          "uharfbuzz>=0.23.0; extra == \"repacker\"",
          "fs<3,>=2.2.0; extra == \"all\"",
          "lxml>=4.0; extra == \"all\"",
          "brotli>=1.0.1; platform_python_implementation == \"CPython\" and extra == \"all\"",
          "brotlicffi>=0.8.0; platform_python_implementation != \"CPython\" and extra == \"all\"",
          "zopfli>=0.1.4; extra == \"all\"",
          "unicodedata2>=15.1.0; python_version <= \"3.12\" and extra == \"all\"",
          "lz4>=1.7.4.2; extra == \"all\"",
          "scipy; platform_python_implementation != \"PyPy\" and extra == \"all\"",
          "munkres; platform_python_implementation == \"PyPy\" and extra == \"all\"",
          "pycairo; extra == \"all\"",
          "matplotlib; extra == \"all\"",
          "sympy; extra == \"all\"",
          "xattr; sys_platform == \"darwin\" and extra == \"all\"",
          "skia-pathops>=0.5.0; extra == \"all\"",
          "uharfbuzz>=0.23.0; extra == \"all\""
        ],
        "requires_python": ">=3.8",
        "provides_extra": [
          "ufo",
          "lxml",
          "woff",
          "unicode",
          "graphite",
          "interpolatable",
          "plot",
          "symfont",
          "type1",
          "pathops",
          "repacker",
          "all"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\fonttools-4.55.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "fqdn",
        "version": "1.5.1",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "Validates fully-qualified domain names against RFC 1123, so that they are acceptable to modern bowsers",
        "description": "UNKNOWN\n\n\n",
        "keywords": [
          "fqdn",
          "domain",
          "hostname",
          "RFC3686",
          "dns"
        ],
        "home_page": "https://github.com/ypcrts/fqdn",
        "author": "ypcrts",
        "author_email": "ypcrts@users.noreply.github.com",
        "license": "MPL 2.0",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet :: Name Service (DNS)",
          "Topic :: Internet",
          "Topic :: System :: Systems Administration",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "cached-property (>=1.3.0) ; python_version < \"3.8\""
        ],
        "requires_python": ">=2.7, !=3.0, !=3.1, !=3.2, !=3.3, !=3.4, <4"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\fqdn-1.5.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "idna",
        "version": "3.8",
        "summary": "Internationalized Domain Names in Applications (IDNA)",
        "description": "Internationalized Domain Names in Applications (IDNA)\n=====================================================\n\nSupport for the Internationalized Domain Names in\nApplications (IDNA) protocol as specified in `RFC 5891\n<https://tools.ietf.org/html/rfc5891>`_. This is the latest version of\nthe protocol and is sometimes referred to as â€œIDNA 2008â€.\n\nThis library also provides support for Unicode Technical\nStandard 46, `Unicode IDNA Compatibility Processing\n<https://unicode.org/reports/tr46/>`_.\n\nThis acts as a suitable replacement for the â€œencodings.idnaâ€\nmodule that comes with the Python standard library, but which\nonly supports the older superseded IDNA specification (`RFC 3490\n<https://tools.ietf.org/html/rfc3490>`_).\n\nBasic functions are simply executed:\n\n.. code-block:: pycon\n\n    >>> import idna\n    >>> idna.encode('ãƒ‰ãƒ¡ã‚¤ãƒ³.ãƒ†ã‚¹ãƒˆ')\n    b'xn--eckwd4c7c.xn--zckzah'\n    >>> print(idna.decode('xn--eckwd4c7c.xn--zckzah'))\n    ãƒ‰ãƒ¡ã‚¤ãƒ³.ãƒ†ã‚¹ãƒˆ\n\n\nInstallation\n------------\n\nThis package is available for installation from PyPI:\n\n.. code-block:: bash\n\n    $ python3 -m pip install idna\n\n\nUsage\n-----\n\nFor typical usage, the ``encode`` and ``decode`` functions will take a\ndomain name argument and perform a conversion to A-labels or U-labels\nrespectively.\n\n.. code-block:: pycon\n\n    >>> import idna\n    >>> idna.encode('ãƒ‰ãƒ¡ã‚¤ãƒ³.ãƒ†ã‚¹ãƒˆ')\n    b'xn--eckwd4c7c.xn--zckzah'\n    >>> print(idna.decode('xn--eckwd4c7c.xn--zckzah'))\n    ãƒ‰ãƒ¡ã‚¤ãƒ³.ãƒ†ã‚¹ãƒˆ\n\nYou may use the codec encoding and decoding methods using the\n``idna.codec`` module:\n\n.. code-block:: pycon\n\n    >>> import idna.codec\n    >>> print('Ð´Ð¾Ð¼ÐµÐ½.Ð¸ÑÐ¿Ñ‹Ñ‚Ð°Ð½Ð¸Ðµ'.encode('idna2008'))\n    b'xn--d1acufc.xn--80akhbyknj4f'\n    >>> print(b'xn--d1acufc.xn--80akhbyknj4f'.decode('idna2008'))\n    Ð´Ð¾Ð¼ÐµÐ½.Ð¸ÑÐ¿Ñ‹Ñ‚Ð°Ð½Ð¸Ðµ\n\nConversions can be applied at a per-label basis using the ``ulabel`` or\n``alabel`` functions if necessary:\n\n.. code-block:: pycon\n\n    >>> idna.alabel('æµ‹è¯•')\n    b'xn--0zwm56d'\n\nCompatibility Mapping (UTS #46)\n+++++++++++++++++++++++++++++++\n\nAs described in `RFC 5895 <https://tools.ietf.org/html/rfc5895>`_, the\nIDNA specification does not normalize input from different potential\nways a user may input a domain name. This functionality, known as\na â€œmappingâ€, is considered by the specification to be a local\nuser-interface issue distinct from IDNA conversion functionality.\n\nThis library provides one such mapping that was developed by the\nUnicode Consortium. Known as `Unicode IDNA Compatibility Processing\n<https://unicode.org/reports/tr46/>`_, it provides for both a regular\nmapping for typical applications, as well as a transitional mapping to\nhelp migrate from older IDNA 2003 applications. Strings are\npreprocessed according to Section 4.4 â€œPreprocessing for IDNA2008â€\nprior to the IDNA operations.\n\nFor example, â€œKÃ¶nigsgÃ¤ÃŸchenâ€ is not a permissible label as *LATIN\nCAPITAL LETTER K* is not allowed (nor are capital letters in general).\nUTS 46 will convert this into lower case prior to applying the IDNA\nconversion.\n\n.. code-block:: pycon\n\n    >>> import idna\n    >>> idna.encode('KÃ¶nigsgÃ¤ÃŸchen')\n    ...\n    idna.core.InvalidCodepoint: Codepoint U+004B at position 1 of 'KÃ¶nigsgÃ¤ÃŸchen' not allowed\n    >>> idna.encode('KÃ¶nigsgÃ¤ÃŸchen', uts46=True)\n    b'xn--knigsgchen-b4a3dun'\n    >>> print(idna.decode('xn--knigsgchen-b4a3dun'))\n    kÃ¶nigsgÃ¤ÃŸchen\n\nTransitional processing provides conversions to help transition from\nthe older 2003 standard to the current standard. For example, in the\noriginal IDNA specification, the *LATIN SMALL LETTER SHARP S* (ÃŸ) was\nconverted into two *LATIN SMALL LETTER S* (ss), whereas in the current\nIDNA specification this conversion is not performed.\n\n.. code-block:: pycon\n\n    >>> idna.encode('KÃ¶nigsgÃ¤ÃŸchen', uts46=True, transitional=True)\n    'xn--knigsgsschen-lcb0w'\n\nImplementers should use transitional processing with caution, only in\nrare cases where conversion from legacy labels to current labels must be\nperformed (i.e. IDNA implementations that pre-date 2008). For typical\napplications that just need to convert labels, transitional processing\nis unlikely to be beneficial and could produce unexpected incompatible\nresults.\n\n``encodings.idna`` Compatibility\n++++++++++++++++++++++++++++++++\n\nFunction calls from the Python built-in ``encodings.idna`` module are\nmapped to their IDNA 2008 equivalents using the ``idna.compat`` module.\nSimply substitute the ``import`` clause in your code to refer to the new\nmodule name.\n\nExceptions\n----------\n\nAll errors raised during the conversion following the specification\nshould raise an exception derived from the ``idna.IDNAError`` base\nclass.\n\nMore specific exceptions that may be generated as ``idna.IDNABidiError``\nwhen the error reflects an illegal combination of left-to-right and\nright-to-left characters in a label; ``idna.InvalidCodepoint`` when\na specific codepoint is an illegal character in an IDN label (i.e.\nINVALID); and ``idna.InvalidCodepointContext`` when the codepoint is\nillegal based on its positional context (i.e. it is CONTEXTO or CONTEXTJ\nbut the contextual requirements are not satisfied.)\n\nBuilding and Diagnostics\n------------------------\n\nThe IDNA and UTS 46 functionality relies upon pre-calculated lookup\ntables for performance. These tables are derived from computing against\neligibility criteria in the respective standards. These tables are\ncomputed using the command-line script ``tools/idna-data``.\n\nThis tool will fetch relevant codepoint data from the Unicode repository\nand perform the required calculations to identify eligibility. There are\nthree main modes:\n\n* ``idna-data make-libdata``. Generates ``idnadata.py`` and\n  ``uts46data.py``, the pre-calculated lookup tables used for IDNA and\n  UTS 46 conversions. Implementers who wish to track this library against\n  a different Unicode version may use this tool to manually generate a\n  different version of the ``idnadata.py`` and ``uts46data.py`` files.\n\n* ``idna-data make-table``. Generate a table of the IDNA disposition\n  (e.g. PVALID, CONTEXTJ, CONTEXTO) in the format found in Appendix\n  B.1 of RFC 5892 and the pre-computed tables published by `IANA\n  <https://www.iana.org/>`_.\n\n* ``idna-data U+0061``. Prints debugging output on the various\n  properties associated with an individual Unicode codepoint (in this\n  case, U+0061), that are used to assess the IDNA and UTS 46 status of a\n  codepoint. This is helpful in debugging or analysis.\n\nThe tool accepts a number of arguments, described using ``idna-data\n-h``. Most notably, the ``--version`` argument allows the specification\nof the version of Unicode to be used in computing the table data. For\nexample, ``idna-data --version 9.0.0 make-libdata`` will generate\nlibrary data against Unicode 9.0.0.\n\n\nAdditional Notes\n----------------\n\n* **Packages**. The latest tagged release version is published in the\n  `Python Package Index <https://pypi.org/project/idna/>`_.\n\n* **Version support**. This library supports Python 3.6 and higher.\n  As this library serves as a low-level toolkit for a variety of\n  applications, many of which strive for broad compatibility with older\n  Python versions, there is no rush to remove older interpreter support.\n  Removing support for older versions should be well justified in that the\n  maintenance burden has become too high.\n\n* **Python 2**. Python 2 is supported by version 2.x of this library.\n  Use \"idna<3\" in your requirements file if you need this library for\n  a Python 2 application. Be advised that these versions are no longer\n  actively developed.\n\n* **Testing**. The library has a test suite based on each rule of the\n  IDNA specification, as well as tests that are provided as part of the\n  Unicode Technical Standard 46, `Unicode IDNA Compatibility Processing\n  <https://unicode.org/reports/tr46/>`_.\n\n* **Emoji**. It is an occasional request to support emoji domains in\n  this library. Encoding of symbols like emoji is expressly prohibited by\n  the technical standard IDNA 2008 and emoji domains are broadly phased\n  out across the domain industry due to associated security risks. For\n  now, applications that need to support these non-compliant labels\n  may wish to consider trying the encode/decode operation in this library\n  first, and then falling back to using `encodings.idna`. See `the Github\n  project <https://github.com/kjd/idna/issues/18>`_ for more discussion.\n\n",
        "description_content_type": "text/x-rst",
        "author_email": "Kim Davies <kim+pypi@gumleaf.org>",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet :: Name Service (DNS)",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Utilities"
        ],
        "requires_python": ">=3.6",
        "project_url": [
          "Changelog, https://github.com/kjd/idna/blob/master/HISTORY.rst",
          "Issue tracker, https://github.com/kjd/idna/issues",
          "Source, https://github.com/kjd/idna"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\idna-3.8.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "importlib-resources",
        "version": "5.13.0",
        "summary": "Read resources from Python packages",
        "description": ".. image:: https://img.shields.io/pypi/v/importlib_resources.svg\n   :target: https://pypi.org/project/importlib_resources\n\n.. image:: https://img.shields.io/pypi/pyversions/importlib_resources.svg\n\n.. image:: https://github.com/python/importlib_resources/workflows/tests/badge.svg\n   :target: https://github.com/python/importlib_resources/actions?query=workflow%3A%22tests%22\n   :alt: tests\n\n.. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v2.json\n    :target: https://github.com/astral-sh/ruff\n    :alt: Ruff\n\n.. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n   :target: https://github.com/psf/black\n   :alt: Code style: Black\n\n.. image:: https://readthedocs.org/projects/importlib-resources/badge/?version=latest\n   :target: https://importlib-resources.readthedocs.io/en/latest/?badge=latest\n\n.. image:: https://img.shields.io/badge/skeleton-2023-informational\n   :target: https://blog.jaraco.com/skeleton\n\n.. image:: https://tidelift.com/badges/package/pypi/importlib-resources\n   :target: https://tidelift.com/subscription/pkg/pypi-importlib-resources?utm_source=pypi-importlib-resources&utm_medium=readme\n\n``importlib_resources`` is a backport of Python standard library\n`importlib.resources\n<https://docs.python.org/3/library/importlib.html#module-importlib.resources>`_\nmodule for older Pythons.\n\nThe key goal of this module is to replace parts of `pkg_resources\n<https://setuptools.readthedocs.io/en/latest/pkg_resources.html>`_ with a\nsolution in Python's stdlib that relies on well-defined APIs.  This makes\nreading resources included in packages easier, with more stable and consistent\nsemantics.\n\nCompatibility\n=============\n\nNew features are introduced in this third-party library and later merged\ninto CPython. The following table indicates which versions of this library\nwere contributed to different versions in the standard library:\n\n.. list-table::\n   :header-rows: 1\n\n   * - importlib_resources\n     - stdlib\n   * - 5.9\n     - 3.12\n   * - 5.7\n     - 3.11\n   * - 5.0\n     - 3.10\n   * - 1.3\n     - 3.9\n   * - 0.5 (?)\n     - 3.7\n\nFor Enterprise\n==============\n\nAvailable as part of the Tidelift Subscription.\n\nThis project and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.\n\n`Learn more <https://tidelift.com/subscription/pkg/pypi-importlib-resources?utm_source=pypi-importlib-resources&utm_medium=referral&utm_campaign=github>`_.\n\nSecurity Contact\n================\n\nTo report a security vulnerability, please use the\n`Tidelift security contact <https://tidelift.com/security>`_.\nTidelift will coordinate the fix and disclosure.\n",
        "home_page": "https://github.com/python/importlib_resources",
        "author": "Barry Warsaw",
        "author_email": "barry@python.org",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only"
        ],
        "requires_dist": [
          "zipp (>=3.1.0) ; python_version < \"3.10\"",
          "sphinx (>=3.5) ; extra == 'docs'",
          "jaraco.packaging (>=9.3) ; extra == 'docs'",
          "rst.linker (>=1.9) ; extra == 'docs'",
          "furo ; extra == 'docs'",
          "sphinx-lint ; extra == 'docs'",
          "jaraco.tidelift (>=1.4) ; extra == 'docs'",
          "pytest (>=6) ; extra == 'testing'",
          "pytest-checkdocs (>=2.4) ; extra == 'testing'",
          "pytest-cov ; extra == 'testing'",
          "pytest-enabler (>=2.2) ; extra == 'testing'",
          "pytest-ruff ; extra == 'testing'",
          "pytest-black (>=0.3.7) ; (platform_python_implementation != \"PyPy\") and extra == 'testing'",
          "pytest-mypy (>=0.9.1) ; (platform_python_implementation != \"PyPy\") and extra == 'testing'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://importlib-resources.readthedocs.io/"
        ],
        "provides_extra": [
          "docs",
          "testing"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\importlib_resources-5.13.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "ipython",
        "version": "8.12.3",
        "platform": [
          "Linux",
          "Mac OSX",
          "Windows"
        ],
        "summary": "IPython: Productive Interactive Computing",
        "description": "IPython provides a rich toolkit to help you make the most out of using Python\ninteractively.  Its main components are:\n\n * A powerful interactive Python shell\n * A `Jupyter <https://jupyter.org/>`_ kernel to work with Python code in Jupyter\n   notebooks and other interactive frontends.\n\nThe enhanced interactive Python shells have the following main features:\n\n * Comprehensive object introspection.\n\n * Input history, persistent across sessions.\n\n * Caching of output results during a session with automatically generated\n   references.\n\n * Extensible tab completion, with support by default for completion of python\n   variables and keywords, filenames and function keywords.\n\n * Extensible system of 'magic' commands for controlling the environment and\n   performing many tasks related either to IPython or the operating system.\n\n * A rich configuration system with easy switching between different setups\n   (simpler than changing $PYTHONSTARTUP environment variables every time).\n\n * Session logging and reloading.\n\n * Extensible syntax processing for special purpose situations.\n\n * Access to the system shell with user-extensible alias system.\n\n * Easily embeddable in other Python programs and GUIs.\n\n * Integrated access to the pdb debugger and the Python profiler.\n\nThe latest development version is always available from IPython's `GitHub\nsite <http://github.com/ipython>`_.\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "Interactive",
          "Interpreter",
          "Shell",
          "Embedding"
        ],
        "home_page": "https://ipython.org",
        "author": "The IPython Development Team",
        "author_email": "ipython-dev@python.org",
        "license": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Framework :: IPython",
          "Framework :: Jupyter",
          "Intended Audience :: Developers",
          "Intended Audience :: Science/Research",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Topic :: System :: Shells"
        ],
        "requires_dist": [
          "backcall",
          "decorator",
          "jedi >=0.16",
          "matplotlib-inline",
          "pickleshare",
          "prompt-toolkit !=3.0.37,<3.1.0,>=3.0.30",
          "pygments >=2.4.0",
          "stack-data",
          "traitlets >=5",
          "typing-extensions ; python_version < \"3.10\"",
          "pexpect >4.3 ; sys_platform != \"win32\"",
          "appnope ; sys_platform == \"darwin\"",
          "colorama ; sys_platform == \"win32\"",
          "black ; extra == 'all'",
          "ipykernel ; extra == 'all'",
          "setuptools >=18.5 ; extra == 'all'",
          "sphinx >=1.3 ; extra == 'all'",
          "sphinx-rtd-theme ; extra == 'all'",
          "docrepr ; extra == 'all'",
          "matplotlib ; extra == 'all'",
          "stack-data ; extra == 'all'",
          "pytest <7 ; extra == 'all'",
          "typing-extensions ; extra == 'all'",
          "pytest <7.1 ; extra == 'all'",
          "pytest-asyncio ; extra == 'all'",
          "testpath ; extra == 'all'",
          "nbconvert ; extra == 'all'",
          "nbformat ; extra == 'all'",
          "ipywidgets ; extra == 'all'",
          "notebook ; extra == 'all'",
          "ipyparallel ; extra == 'all'",
          "qtconsole ; extra == 'all'",
          "curio ; extra == 'all'",
          "matplotlib !=3.2.0 ; extra == 'all'",
          "numpy >=1.21 ; extra == 'all'",
          "pandas ; extra == 'all'",
          "trio ; extra == 'all'",
          "black ; extra == 'black'",
          "ipykernel ; extra == 'doc'",
          "setuptools >=18.5 ; extra == 'doc'",
          "sphinx >=1.3 ; extra == 'doc'",
          "sphinx-rtd-theme ; extra == 'doc'",
          "docrepr ; extra == 'doc'",
          "matplotlib ; extra == 'doc'",
          "stack-data ; extra == 'doc'",
          "pytest <7 ; extra == 'doc'",
          "typing-extensions ; extra == 'doc'",
          "pytest <7.1 ; extra == 'doc'",
          "pytest-asyncio ; extra == 'doc'",
          "testpath ; extra == 'doc'",
          "ipykernel ; extra == 'kernel'",
          "nbconvert ; extra == 'nbconvert'",
          "nbformat ; extra == 'nbformat'",
          "ipywidgets ; extra == 'notebook'",
          "notebook ; extra == 'notebook'",
          "ipyparallel ; extra == 'parallel'",
          "qtconsole ; extra == 'qtconsole'",
          "pytest <7.1 ; extra == 'test'",
          "pytest-asyncio ; extra == 'test'",
          "testpath ; extra == 'test'",
          "pytest <7.1 ; extra == 'test_extra'",
          "pytest-asyncio ; extra == 'test_extra'",
          "testpath ; extra == 'test_extra'",
          "curio ; extra == 'test_extra'",
          "matplotlib !=3.2.0 ; extra == 'test_extra'",
          "nbformat ; extra == 'test_extra'",
          "numpy >=1.21 ; extra == 'test_extra'",
          "pandas ; extra == 'test_extra'",
          "trio ; extra == 'test_extra'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://ipython.readthedocs.io/",
          "Funding, https://numfocus.org/",
          "Source, https://github.com/ipython/ipython",
          "Tracker, https://github.com/ipython/ipython/issues"
        ],
        "provides_extra": [
          "all",
          "black",
          "doc",
          "kernel",
          "nbconvert",
          "nbformat",
          "notebook",
          "parallel",
          "qtconsole",
          "terminal",
          "test",
          "test_extra"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\ipython-8.12.3.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "isoduration",
        "version": "20.11.0",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "Operations with ISO 8601 durations",
        "description": "# isoduration: Operations with ISO 8601 durations.\n\n[![PyPI Package](https://img.shields.io/pypi/v/isoduration?style=flat-square)](https://pypi.org/project/isoduration/)\n\n## What is this.\n\nISO 8601 is most commonly known as a way to exchange datetimes in textual format. A\nlesser known aspect of the standard is the representation of durations. They have a\nshape similar to this:\n\n```\nP3Y6M4DT12H30M5S\n```\n\nThis string represents a duration of 3 years, 6 months, 4 days, 12 hours, 30 minutes,\nand 5 seconds.\n\nThe state of the art of ISO 8601 duration handling in Python is more or less limited to\nwhat's offered by [`isodate`](https://pypi.org/project/isodate/). What we are trying to\nachieve here is to address the shortcomings of `isodate` (as described in their own\n[_Limitations_](https://github.com/gweis/isodate/#limitations) section), and a few of\nour own annoyances with their interface, such as the lack of uniformity in their\nhandling of types, and the use of regular expressions for parsing.\n\n## How to use it.\n\nThis package revolves around the [`Duration`](src/isoduration/types.py) type.\n\nGiven a ISO duration string we can produce such a type by using the `parse_duration()`\nfunction:\n\n```py\n>>> from isoduration import parse_duration\n>>> duration = parse_duration(\"P3Y6M4DT12H30M5S\")\n>>> duration.date\nDateDuration(years=Decimal('3'), months=Decimal('6'), days=Decimal('4'), weeks=Decimal('0'))\n>>> duration.time\nTimeDuration(hours=Decimal('12'), minutes=Decimal('30'), seconds=Decimal('5'))\n```\n\nThe `date` and `time` portions of the parsed duration are just regular\n[dataclasses](https://docs.python.org/3/library/dataclasses.html), so their members can\nbe accessed in a non-surprising way.\n\nBesides just parsing them, a number of additional operations are available:\n\n- Durations can be compared and negated:\n  ```py\n  >>> parse_duration(\"P3Y4D\") == parse_duration(\"P3Y4DT0H\")\n  True\n  >>> -parse_duration(\"P3Y4D\")\n  Duration(DateDuration(years=Decimal('-3'), months=Decimal('0'), days=Decimal('-4'), weeks=Decimal('0')), TimeDuration(hours=Decimal('0'), minutes=Decimal('0'), seconds=Decimal('0')))\n  ```\n- Durations can be added to, or subtracted from, Python datetimes:\n  ```py\n  >>> from datetime import datetime\n  >>> datetime(2020, 3, 15) + parse_duration(\"P2Y\")\n  datetime.datetime(2022, 3, 15, 0, 0)\n  >>> datetime(2020, 3, 15) - parse_duration(\"P33Y1M4D\")\n  datetime.datetime(1987, 2, 11, 0, 0)\n  ```\n- Durations are hashable, so they can be used as dictionary keys or as part of sets.\n- Durations can be formatted back to a ISO 8601-compliant duration string:\n  ```py\n  >>> from isoduration import parse_duration, format_duration\n  >>> format_duration(parse_duration(\"P11YT2H\"))\n  'P11YT2H'\n  >>> str(parse_duration(\"P11YT2H\"))\n  'P11YT2H'\n  ```\n\n## How to improve it.\n\nThese steps, in this order, should land you in a development environment:\n\n```sh\ngit clone git@github.com:bolsote/isoduration.git\ncd isoduration/\npython -m venv ve\n. ve/bin/activate\npip install -U pip\npip install -e .\npip install -r requirements/dev.txt\n```\n\nAdapt to your own likings and/or needs.\n\nTesting is driven by [tox](https://tox.readthedocs.io). The output of `tox -l` and a\ncareful read of [tox.ini](tox.ini) should get you there.\n\n## FAQs.\n\n### How come `P1Y != P365D`?\nSome years have 366 days. If it's not always the same, then it's not the same.\n\n### Why do you create your own types, instead of somewhat shoehorning a `timedelta`?\n`timedelta` cannot represent certain durations, such as those involving years or months.\nSince it cannot represent all possible durations without dangerous arithmetic, then it\nmust not be the right type.\n\n### Why don't you use regular expressions to parse duration strings?\n[Regular expressions should only be used to parse regular languages.](https://stackoverflow.com/a/1732454)\n\n### Why is parsing the inverse of formatting, but the converse is not true?\nBecause this wonderful representation is not unique.\n\n### Why do you support `<insert here a weird case>`?\nProbably because the standard made me to.\n\n### Why do you not support `<insert here a weird case>`?\nProbably because the standard doesn't allow me to.\n\n### Why is it not possible to subtract a datetime from a duration?\nI'm confused.\n\n### Why should I use this over some other thing?\nYou shouldn't do what people on the Internet tell you to do.\n\n### Why are ISO standards so strange?\nYes.\n\n## References.\n\n- [XML Schema Part 2: Datatypes, Appendix D](https://www.w3.org/TR/xmlschema-2/#isoformats):\n  This excitingly named document contains more details about ISO 8601 than any human\n  should be allowed to understand.\n- [`isodate`](https://pypi.org/project/isodate/): The original implementation of ISO\n  durations in Python. Worth a look. But ours is cooler.\n\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "datetime",
          "date",
          "time",
          "duration",
          "duration-parsing",
          "duration-string",
          "iso8601",
          "iso8601-duration"
        ],
        "home_page": "https://github.com/bolsote/isoduration",
        "author": "VÃ­ctor MuÃ±oz",
        "author_email": "victorm@marshland.es",
        "license": "UNKNOWN",
        "classifier": [
          "Programming Language :: Python :: 3",
          "Operating System :: OS Independent",
          "License :: OSI Approved :: ISC License (ISCL)",
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "arrow (>=0.15.0)"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Repository, https://github.com/bolsote/isoduration",
          "Bug Reports, https://github.com/bolsote/isoduration/issues",
          "Changelog, https://github.com/bolsote/isoduration/blob/master/CHANGELOG"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\isoduration-20.11.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "isort",
        "version": "5.13.2",
        "summary": "A Python utility / library to sort Python imports.",
        "description": "[![isort - isort your imports, so you don't have to.](https://raw.githubusercontent.com/pycqa/isort/main/art/logo_large.png)](https://pycqa.github.io/isort/)\n\n------------------------------------------------------------------------\n\n[![PyPI version](https://badge.fury.io/py/isort.svg)](https://badge.fury.io/py/isort)\n[![Test Status](https://github.com/pycqa/isort/workflows/Test/badge.svg?branch=develop)](https://github.com/pycqa/isort/actions?query=workflow%3ATest)\n[![Lint Status](https://github.com/pycqa/isort/workflows/Lint/badge.svg?branch=develop)](https://github.com/pycqa/isort/actions?query=workflow%3ALint)\n[![Code coverage Status](https://codecov.io/gh/pycqa/isort/branch/main/graph/badge.svg)](https://codecov.io/gh/pycqa/isort)\n[![License](https://img.shields.io/github/license/mashape/apistatus.svg)](https://pypi.org/project/isort/)\n[![Join the chat at https://gitter.im/timothycrosley/isort](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/timothycrosley/isort?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![Downloads](https://pepy.tech/badge/isort)](https://pepy.tech/project/isort)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)\n[![DeepSource](https://static.deepsource.io/deepsource-badge-light-mini.svg)](https://deepsource.io/gh/pycqa/isort/?ref=repository-badge)\n_________________\n\n[Read Latest Documentation](https://pycqa.github.io/isort/) - [Browse GitHub Code Repository](https://github.com/pycqa/isort/)\n_________________\n\nisort your imports, so you don't have to.\n\nisort is a Python utility / library to sort imports alphabetically and\nautomatically separate into sections and by type. It provides a command line\nutility, Python library and [plugins for various\neditors](https://github.com/pycqa/isort/wiki/isort-Plugins) to\nquickly sort all your imports. It requires Python 3.8+ to run but\nsupports formatting Python 2 code too.\n\n- [Try isort now from your browser!](https://pycqa.github.io/isort/docs/quick_start/0.-try.html)\n- [Using black? See the isort and black compatibility guide.](https://pycqa.github.io/isort/docs/configuration/black_compatibility.html)\n- [isort has official support for pre-commit!](https://pycqa.github.io/isort/docs/configuration/pre-commit.html)\n\n![Example Usage](https://raw.github.com/pycqa/isort/main/example.gif)\n\nBefore isort:\n\n```python\nfrom my_lib import Object\n\nimport os\n\nfrom my_lib import Object3\n\nfrom my_lib import Object2\n\nimport sys\n\nfrom third_party import lib15, lib1, lib2, lib3, lib4, lib5, lib6, lib7, lib8, lib9, lib10, lib11, lib12, lib13, lib14\n\nimport sys\n\nfrom __future__ import absolute_import\n\nfrom third_party import lib3\n\nprint(\"Hey\")\nprint(\"yo\")\n```\n\nAfter isort:\n\n```python\nfrom __future__ import absolute_import\n\nimport os\nimport sys\n\nfrom third_party import (lib1, lib2, lib3, lib4, lib5, lib6, lib7, lib8,\n                         lib9, lib10, lib11, lib12, lib13, lib14, lib15)\n\nfrom my_lib import Object, Object2, Object3\n\nprint(\"Hey\")\nprint(\"yo\")\n```\n\n## Installing isort\n\nInstalling isort is as simple as:\n\n```bash\npip install isort\n```\n\n## Using isort\n\n**From the command line**:\n\nTo run on specific files:\n\n```bash\nisort mypythonfile.py mypythonfile2.py\n```\n\nTo apply recursively:\n\n```bash\nisort .\n```\n\nIf [globstar](https://www.gnu.org/software/bash/manual/html_node/The-Shopt-Builtin.html)\nis enabled, `isort .` is equivalent to:\n\n```bash\nisort **/*.py\n```\n\nTo view proposed changes without applying them:\n\n```bash\nisort mypythonfile.py --diff\n```\n\nFinally, to atomically run isort against a project, only applying\nchanges if they don't introduce syntax errors:\n\n```bash\nisort --atomic .\n```\n\n(Note: this is disabled by default, as it prevents isort from\nrunning against code written using a different version of Python.)\n\n**From within Python**:\n\n```python\nimport isort\n\nisort.file(\"pythonfile.py\")\n```\n\nor:\n\n```python\nimport isort\n\nsorted_code = isort.code(\"import b\\nimport a\\n\")\n```\n\n## Installing isort's for your preferred text editor\n\nSeveral plugins have been written that enable to use isort from within a\nvariety of text-editors. You can find a full list of them [on the isort\nwiki](https://github.com/pycqa/isort/wiki/isort-Plugins).\nAdditionally, I will enthusiastically accept pull requests that include\nplugins for other text editors and add documentation for them as I am\nnotified.\n\n## Multi line output modes\n\nYou will notice above the \\\"multi\\_line\\_output\\\" setting. This setting\ndefines how from imports wrap when they extend past the line\\_length\nlimit and has [12 possible settings](https://pycqa.github.io/isort/docs/configuration/multi_line_output_modes.html).\n\n## Indentation\n\nTo change the how constant indents appear - simply change the\nindent property with the following accepted formats:\n\n-   Number of spaces you would like. For example: 4 would cause standard\n    4 space indentation.\n-   Tab\n-   A verbatim string with quotes around it.\n\nFor example:\n\n```python\n\"    \"\n```\n\nis equivalent to 4.\n\nFor the import styles that use parentheses, you can control whether or\nnot to include a trailing comma after the last import with the\n`include_trailing_comma` option (defaults to `False`).\n\n## Intelligently Balanced Multi-line Imports\n\nAs of isort 3.1.0 support for balanced multi-line imports has been\nadded. With this enabled isort will dynamically change the import length\nto the one that produces the most balanced grid, while staying below the\nmaximum import length defined.\n\nExample:\n\n```python\nfrom __future__ import (absolute_import, division,\n                        print_function, unicode_literals)\n```\n\nWill be produced instead of:\n\n```python\nfrom __future__ import (absolute_import, division, print_function,\n                        unicode_literals)\n```\n\nTo enable this set `balanced_wrapping` to `True` in your config or pass\nthe `-e` option into the command line utility.\n\n## Custom Sections and Ordering\n\nisort provides configuration options to change almost every aspect of how\nimports are organized, ordered, or grouped together in sections.\n\n[Click here](https://pycqa.github.io/isort/docs/configuration/custom_sections_and_ordering.html) for an overview of all these options.\n\n## Skip processing of imports (outside of configuration)\n\nTo make isort ignore a single import simply add a comment at the end of\nthe import line containing the text `isort:skip`:\n\n```python\nimport module  # isort:skip\n```\n\nor:\n\n```python\nfrom xyz import (abc,  # isort:skip\n                 yo,\n                 hey)\n```\n\nTo make isort skip an entire file simply add `isort:skip_file` to the\nmodule's doc string:\n\n```python\n\"\"\" my_module.py\n    Best module ever\n\n   isort:skip_file\n\"\"\"\n\nimport b\nimport a\n```\n\n## Adding or removing an import from multiple files\n\nisort can be ran or configured to add / remove imports automatically.\n\n[See a complete guide here.](https://pycqa.github.io/isort/docs/configuration/add_or_remove_imports.html)\n\n## Using isort to verify code\n\nThe `--check-only` option\n-------------------------\n\nisort can also be used to verify that code is correctly formatted\nby running it with `-c`. Any files that contain incorrectly sorted\nand/or formatted imports will be outputted to `stderr`.\n\n```bash\nisort **/*.py -c -v\n\nSUCCESS: /home/timothy/Projects/Open_Source/isort/isort_kate_plugin.py Everything Looks Good!\nERROR: /home/timothy/Projects/Open_Source/isort/isort/isort.py Imports are incorrectly sorted.\n```\n\nOne great place this can be used is with a pre-commit git hook, such as\nthis one by \\@acdha:\n\n<https://gist.github.com/acdha/8717683>\n\nThis can help to ensure a certain level of code quality throughout a\nproject.\n\n## Git hook\n\nisort provides a hook function that can be integrated into your Git\npre-commit script to check Python code before committing.\n\n[More info here.](https://pycqa.github.io/isort/docs/configuration/git_hook.html)\n\n## Setuptools integration\n\nUpon installation, isort enables a `setuptools` command that checks\nPython files declared by your project.\n\n[More info here.](https://pycqa.github.io/isort/docs/configuration/setuptools_integration.html)\n\n## Spread the word\n\n[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)\n\nPlace this badge at the top of your repository to let others know your project uses isort.\n\nFor README.md:\n\n```markdown\n[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)\n```\n\nOr README.rst:\n\n```rst\n.. image:: https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336\n    :target: https://pycqa.github.io/isort/\n```\n\n## Security contact information\n\nTo report a security vulnerability, please use the [Tidelift security\ncontact](https://tidelift.com/security). Tidelift will coordinate the\nfix and disclosure.\n\n## Why isort?\n\nisort simply stands for import sort. It was originally called\n\"sortImports\" however I got tired of typing the extra characters and\ncame to the realization camelCase is not pythonic.\n\nI wrote isort because in an organization I used to work in the manager\ncame in one day and decided all code must have alphabetically sorted\nimports. The code base was huge - and he meant for us to do it by hand.\nHowever, being a programmer - I\\'m too lazy to spend 8 hours mindlessly\nperforming a function, but not too lazy to spend 16 hours automating it.\nI was given permission to open source sortImports and here we are :)\n\n------------------------------------------------------------------------\n\n[Get professionally supported isort with the Tidelift\nSubscription](https://tidelift.com/subscription/pkg/pypi-isort?utm_source=pypi-isort&utm_medium=referral&utm_campaign=readme)\n\nProfessional support for isort is available as part of the [Tidelift\nSubscription](https://tidelift.com/subscription/pkg/pypi-isort?utm_source=pypi-isort&utm_medium=referral&utm_campaign=readme).\nTidelift gives software development teams a single source for purchasing\nand maintaining their software, with professional grade assurances from\nthe experts who know it best, while seamlessly integrating with existing\ntools.\n\n------------------------------------------------------------------------\n\nThanks and I hope you find isort useful!\n\n~Timothy Crosley\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "Refactor",
          "Lint",
          "Imports",
          "Sort",
          "Clean"
        ],
        "home_page": "https://pycqa.github.io/isort/",
        "author": "Timothy Crosley",
        "author_email": "timothy.crosley@gmail.com",
        "license": "MIT",
        "classifier": [
          "Development Status :: 6 - Mature",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Natural Language :: English",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "colorama (>=0.4.6) ; extra == \"colors\""
        ],
        "requires_python": ">=3.8.0",
        "project_url": [
          "Changelog, https://github.com/pycqa/isort/blob/main/CHANGELOG.md",
          "Documentation, https://pycqa.github.io/isort/",
          "Repository, https://github.com/pycqa/isort"
        ],
        "provides_extra": [
          "colors",
          "plugins"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\isort-5.13.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "jedi",
        "version": "0.19.1",
        "platform": [
          "any"
        ],
        "summary": "An autocompletion tool for Python that can be used for text editors.",
        "description": "####################################################################################\nJedi - an awesome autocompletion, static analysis and refactoring library for Python\n####################################################################################\n\n.. image:: http://isitmaintained.com/badge/open/davidhalter/jedi.svg\n    :target: https://github.com/davidhalter/jedi/issues\n    :alt: The percentage of open issues and pull requests\n\n.. image:: http://isitmaintained.com/badge/resolution/davidhalter/jedi.svg\n    :target: https://github.com/davidhalter/jedi/issues\n    :alt: The resolution time is the median time an issue or pull request stays open.\n\n.. image:: https://github.com/davidhalter/jedi/workflows/ci/badge.svg?branch=master\n    :target: https://github.com/davidhalter/jedi/actions\n    :alt: Tests\n\n.. image:: https://pepy.tech/badge/jedi\n    :target: https://pepy.tech/project/jedi\n    :alt: PyPI Downloads\n\n\nJedi is a static analysis tool for Python that is typically used in\nIDEs/editors plugins. Jedi has a focus on autocompletion and goto\nfunctionality. Other features include refactoring, code search and finding\nreferences.\n\nJedi has a simple API to work with. There is a reference implementation as a\n`VIM-Plugin <https://github.com/davidhalter/jedi-vim>`_. Autocompletion in your\nREPL is also possible, IPython uses it natively and for the CPython REPL you\ncan install it. Jedi is well tested and bugs should be rare.\n\nJedi can currently be used with the following editors/projects:\n\n- Vim (jedi-vim_, YouCompleteMe_, deoplete-jedi_, completor.vim_)\n- `Visual Studio Code`_ (via `Python Extension <https://marketplace.visualstudio.com/items?itemName=ms-python.python>`_)\n- Emacs (Jedi.el_, company-mode_, elpy_, anaconda-mode_, ycmd_)\n- Sublime Text (SublimeJEDI_ [ST2 + ST3], anaconda_ [only ST3])\n- TextMate_ (Not sure if it's actually working)\n- Kate_ version 4.13+ supports it natively, you have to enable it, though.  [`see\n  <https://projects.kde.org/projects/kde/applications/kate/repository/show?rev=KDE%2F4.13>`_]\n- Atom_ (autocomplete-python-jedi_)\n- `GNOME Builder`_ (with support for GObject Introspection)\n- Gedit (gedi_)\n- wdb_ - Web Debugger\n- `Eric IDE`_\n- `IPython 6.0.0+ <https://ipython.readthedocs.io/en/stable/whatsnew/version6.html>`_\n- `xonsh shell <https://xon.sh/contents.html>`_ has `jedi extension <https://xon.sh/xontribs.html#jedi>`_\n\nand many more!\n\nThere are a few language servers that use Jedi:\n\n- `jedi-language-server <https://github.com/pappasam/jedi-language-server>`_\n- `python-language-server <https://github.com/palantir/python-language-server>`_ (currently unmaintained)\n- `python-lsp-server <https://github.com/python-lsp/python-lsp-server>`_ (fork from python-language-server)\n- `anakin-language-server <https://github.com/muffinmad/anakin-language-server>`_\n\nHere are some pictures taken from jedi-vim_:\n\n.. image:: https://github.com/davidhalter/jedi/raw/master/docs/_screenshots/screenshot_complete.png\n\nCompletion for almost anything:\n\n.. image:: https://github.com/davidhalter/jedi/raw/master/docs/_screenshots/screenshot_function.png\n\nDocumentation:\n\n.. image:: https://github.com/davidhalter/jedi/raw/master/docs/_screenshots/screenshot_pydoc.png\n\n\nGet the latest version from `github <https://github.com/davidhalter/jedi>`_\n(master branch should always be kind of stable/working).\n\nDocs are available at `https://jedi.readthedocs.org/en/latest/\n<https://jedi.readthedocs.org/en/latest/>`_. Pull requests with enhancements\nand/or fixes are awesome and most welcome. Jedi uses `semantic versioning\n<https://semver.org/>`_.\n\nIf you want to stay **up-to-date** with releases, please **subscribe** to this\nmailing list: https://groups.google.com/g/jedi-announce. To subscribe you can\nsimply send an empty email to ``jedi-announce+subscribe@googlegroups.com``.\n\nIssues & Questions\n==================\n\nYou can file issues and questions in the `issue tracker\n<https://github.com/davidhalter/jedi/>`. Alternatively you can also ask on\n`Stack Overflow <https://stackoverflow.com/questions/tagged/python-jedi>`_ with\nthe label ``python-jedi``.\n\nInstallation\n============\n\n`Check out the docs <https://jedi.readthedocs.org/en/latest/docs/installation.html>`_.\n\nFeatures and Limitations\n========================\n\nJedi's features are listed here:\n`Features <https://jedi.readthedocs.org/en/latest/docs/features.html>`_.\n\nYou can run Jedi on Python 3.6+ but it should also\nunderstand code that is older than those versions. Additionally you should be\nable to use `Virtualenvs <https://jedi.readthedocs.org/en/latest/docs/api.html#environments>`_\nvery well.\n\nTips on how to use Jedi efficiently can be found `here\n<https://jedi.readthedocs.org/en/latest/docs/features.html#recipes>`_.\n\nAPI\n---\n\nYou can find a comprehensive documentation for the\n`API here <https://jedi.readthedocs.org/en/latest/docs/api.html>`_.\n\nAutocompletion / Goto / Documentation\n-------------------------------------\n\nThere are the following commands:\n\n- ``jedi.Script.goto``\n- ``jedi.Script.infer``\n- ``jedi.Script.help``\n- ``jedi.Script.complete``\n- ``jedi.Script.get_references``\n- ``jedi.Script.get_signatures``\n- ``jedi.Script.get_context``\n\nThe returned objects are very powerful and are really all you might need.\n\nAutocompletion in your REPL (IPython, etc.)\n-------------------------------------------\n\nJedi is a dependency of IPython. Autocompletion in IPython with Jedi is\ntherefore possible without additional configuration.\n\nHere is an `example video <https://vimeo.com/122332037>`_ how REPL completion\ncan look like.\nFor the ``python`` shell you can enable tab completion in a `REPL\n<https://jedi.readthedocs.org/en/latest/docs/usage.html#tab-completion-in-the-python-shell>`_.\n\nStatic Analysis\n---------------\n\nFor a lot of forms of static analysis, you can try to use\n``jedi.Script(...).get_names``. It will return a list of names that you can\nthen filter and work with. There is also a way to list the syntax errors in a\nfile: ``jedi.Script.get_syntax_errors``.\n\n\nRefactoring\n-----------\n\nJedi supports the following refactorings:\n\n- ``jedi.Script.inline``\n- ``jedi.Script.rename``\n- ``jedi.Script.extract_function``\n- ``jedi.Script.extract_variable``\n\nCode Search\n-----------\n\nThere is support for module search with ``jedi.Script.search``, and project\nsearch for ``jedi.Project.search``. The way to search is either by providing a\nname like ``foo`` or by using dotted syntax like ``foo.bar``. Additionally you\ncan provide the API type like ``class foo.bar.Bar``. There are also the\nfunctions ``jedi.Script.complete_search`` and ``jedi.Project.complete_search``.\n\nDevelopment\n===========\n\nThere's a pretty good and extensive `development documentation\n<https://jedi.readthedocs.org/en/latest/docs/development.html>`_.\n\nTesting\n=======\n\nThe test suite uses ``pytest``::\n\n    pip install pytest\n\nIf you want to test only a specific Python version (e.g. Python 3.8), it is as\neasy as::\n\n    python3.8 -m pytest\n\nFor more detailed information visit the `testing documentation\n<https://jedi.readthedocs.org/en/latest/docs/testing.html>`_.\n\nAcknowledgements\n================\n\nThanks a lot to all the\n`contributors <https://jedi.readthedocs.org/en/latest/docs/acknowledgements.html>`_!\n\n\n.. _jedi-vim: https://github.com/davidhalter/jedi-vim\n.. _youcompleteme: https://github.com/ycm-core/YouCompleteMe\n.. _deoplete-jedi: https://github.com/zchee/deoplete-jedi\n.. _completor.vim: https://github.com/maralla/completor.vim\n.. _Jedi.el: https://github.com/tkf/emacs-jedi\n.. _company-mode: https://github.com/syohex/emacs-company-jedi\n.. _elpy: https://github.com/jorgenschaefer/elpy\n.. _anaconda-mode: https://github.com/proofit404/anaconda-mode\n.. _ycmd: https://github.com/abingham/emacs-ycmd\n.. _sublimejedi: https://github.com/srusskih/SublimeJEDI\n.. _anaconda: https://github.com/DamnWidget/anaconda\n.. _wdb: https://github.com/Kozea/wdb\n.. _TextMate: https://github.com/lawrenceakka/python-jedi.tmbundle\n.. _Kate: https://kate-editor.org\n.. _Atom: https://atom.io/\n.. _autocomplete-python-jedi: https://atom.io/packages/autocomplete-python-jedi\n.. _GNOME Builder: https://wiki.gnome.org/Apps/Builder\n.. _Visual Studio Code: https://code.visualstudio.com/\n.. _gedi: https://github.com/isamert/gedi\n.. _Eric IDE: https://eric-ide.python-projects.org\n\n\n.. :changelog:\n\nChangelog\n---------\n\nUnreleased\n++++++++++\n\n0.19.1 (2023-10-02)\n+++++++++++++++++++\n\n- Python 3.12 support (Thanks Peter!)\n\n0.19.0 (2023-07-29)\n+++++++++++++++++++\n\n- Python 3.11 support\n- Massive improvements in performance for ``Interpreter`` (e.g. IPython) users.\n  This especially affects ``pandas`` users with large datasets.\n- Add ``jedi.settings.allow_unsafe_interpreter_executions`` to make it easier\n  for IPython users to avoid unsafe executions.\n\n0.18.2 (2022-11-21)\n+++++++++++++++++++\n\n- Added dataclass-equivalent for attrs.define\n- Find fixtures from Pytest entrypoints; Examples of pytest plugins installed\n  like this are pytest-django, pytest-sugar and Faker.\n- Fixed Project.search, when a venv was involved, which is why for example\n  `:Pyimport django.db` did not work in some cases in jedi-vim.\n- And many smaller bugfixes\n\n0.18.1 (2021-11-17)\n+++++++++++++++++++\n\n- Implict namespaces are now a separate types in ``Name().type``\n- Python 3.10 support\n- Mostly bugfixes\n\n0.18.0 (2020-12-25)\n+++++++++++++++++++\n\n- Dropped Python 2 and Python 3.5\n- Using ``pathlib.Path()`` as an output instead of ``str`` in most places:\n  - ``Project.path``\n  - ``Script.path``\n  - ``Definition.module_path``\n  - ``Refactoring.get_renames``\n  - ``Refactoring.get_changed_files``\n- Functions with ``@property`` now return ``property`` instead of ``function``\n  in ``Name().type``\n- Started using annotations\n- Better support for the walrus operator\n- Project attributes are now read accessible\n- Removed all deprecations\n\nThis is likely going to be the last minor release before 1.0.\n\n0.17.2 (2020-07-17)\n+++++++++++++++++++\n\n- Added an option to pass environment variables to ``Environment``\n- ``Project(...).path`` exists now\n- Support for Python 3.9\n- A few bugfixes\n\nThis will be the last release that supports Python 2 and Python 3.5.\n``0.18.0`` will be Python 3.6+.\n\n0.17.1 (2020-06-20)\n+++++++++++++++++++\n\n- Django ``Model`` meta class support\n- Django Manager support (completion on Managers/QuerySets)\n- Added Django Stubs to Jedi, thanks to all contributors of the\n  `Django Stubs <https://github.com/typeddjango/django-stubs>`_ project\n- Added ``SyntaxError.get_message``\n- Python 3.9 support\n- Bugfixes (mostly towards Generics)\n\n0.17.0 (2020-04-14)\n+++++++++++++++++++\n\n- Added ``Project`` support. This allows a user to specify which folders Jedi\n  should work with.\n- Added support for Refactoring. The following refactorings have been\n  implemented: ``Script.rename``, ``Script.inline``,\n  ``Script.extract_variable`` and ``Script.extract_function``.\n- Added ``Script.get_syntax_errors`` to display syntax errors in the current\n  script.\n- Added code search capabilities both for individual files and projects. The\n  new functions are ``Project.search``, ``Project.complete_search``,\n  ``Script.search`` and ``Script.complete_search``.\n- Added ``Script.help`` to make it easier to display a help window to people.\n  Now returns pydoc information as well for Python keywords/operators.  This\n  means that on the class keyword it will now return the docstring of Python's\n  builtin function ``help('class')``.\n- The API documentation is now way more readable and complete. Check it out\n  under https://jedi.readthedocs.io. A lot of it has been rewritten.\n- Removed Python 3.4 support\n- Many bugfixes\n\nThis is likely going to be the last minor version that supports Python 2 and\nPython3.5. Bugfixes will be provided in 0.17.1+. The next minor/major version\nwill probably be Jedi 1.0.0.\n\n0.16.0 (2020-01-26)\n+++++++++++++++++++\n\n- **Added** ``Script.get_context`` to get information where you currently are.\n- Completions/type inference of **Pytest fixtures**.\n- Tensorflow, Numpy and Pandas completions should now be about **4-10x faster**\n  after the first time they are used.\n- Dict key completions are working now. e.g. ``d = {1000: 3}; d[10`` will\n  expand to ``1000``.\n- Completion for \"proxies\" works now. These are classes that have a\n  ``__getattr__(self, name)`` method that does a ``return getattr(x, name)``.\n  after loading them initially.\n- Goto on a function/attribute in a class now goes to the definition in its\n  super class.\n- Big **Script API Changes**:\n    - The line and column parameters of ``jedi.Script`` are now deprecated\n    - ``completions`` deprecated, use ``complete`` instead\n    - ``goto_assignments`` deprecated, use ``goto`` instead\n    - ``goto_definitions`` deprecated, use ``infer`` instead\n    - ``call_signatures`` deprecated, use ``get_signatures`` instead\n    - ``usages`` deprecated, use ``get_references`` instead\n    - ``jedi.names`` deprecated, use ``jedi.Script(...).get_names()``\n- ``BaseName.goto_assignments`` renamed to ``BaseName.goto``\n- Add follow_imports to ``Name.goto``. Now its signature matches\n  ``Script.goto``.\n- **Python 2 support deprecated**. For this release it is best effort. Python 2\n  has reached the end of its life and now it's just about a smooth transition.\n  Bugs for Python 2 will not be fixed anymore and a third of the tests are\n  already skipped.\n- Removed ``settings.no_completion_duplicates``. It wasn't tested and nobody\n  was probably using it anyway.\n- Removed ``settings.use_filesystem_cache`` and\n  ``settings.additional_dynamic_modules``, they have no usage anymore. Pretty\n  much nobody was probably using them.\n\n0.15.2 (2019-12-20)\n+++++++++++++++++++\n\n- Signatures are now detected a lot better\n- Add fuzzy completions with ``Script(...).completions(fuzzy=True)``\n- Files bigger than one MB (about 20kLOC) get cropped to avoid getting\n  stuck completely.\n- Many small Bugfixes\n- A big refactoring around contexts/values\n\n0.15.1 (2019-08-13)\n+++++++++++++++++++\n\n- Small bugfix and removal of a print statement\n\n0.15.0 (2019-08-11)\n+++++++++++++++++++\n\n- Added file path completions, there's a **new** ``Completion.type`` now:\n  ``path``. Example: ``'/ho`` -> ``'/home/``\n- ``*args``/``**kwargs`` resolving. If possible Jedi replaces the parameters\n  with the actual alternatives.\n- Better support for enums/dataclasses\n- When using Interpreter, properties are now executed, since a lot of people\n  have complained about this. Discussion in #1299, #1347.\n\nNew APIs:\n\n- ``Name.get_signatures() -> List[Signature]``. Signatures are similar to\n  ``CallSignature``. ``Name.params`` is therefore deprecated.\n- ``Signature.to_string()`` to format signatures.\n- ``Signature.params -> List[ParamName]``, ParamName has the\n  following additional attributes ``infer_default()``, ``infer_annotation()``,\n  ``to_string()``, and ``kind``.\n- ``Name.execute() -> List[Name]``, makes it possible to infer\n  return values of functions.\n\n\n0.14.1 (2019-07-13)\n+++++++++++++++++++\n\n- CallSignature.index should now be working a lot better\n- A couple of smaller bugfixes\n\n0.14.0 (2019-06-20)\n+++++++++++++++++++\n\n- Added ``goto_*(prefer_stubs=True)`` as well as ``goto_*(prefer_stubs=True)``\n- Stubs are used now for type inference\n- Typeshed is used for better type inference\n- Reworked Name.full_name, should have more correct return values\n\n0.13.3 (2019-02-24)\n+++++++++++++++++++\n\n- Fixed an issue with embedded Python, see https://github.com/davidhalter/jedi-vim/issues/870\n\n0.13.2 (2018-12-15)\n+++++++++++++++++++\n\n- Fixed a bug that led to Jedi spawning a lot of subprocesses.\n\n0.13.1 (2018-10-02)\n+++++++++++++++++++\n\n- Bugfixes, because tensorflow completions were still slow.\n\n0.13.0 (2018-10-02)\n+++++++++++++++++++\n\n- A small release. Some bug fixes.\n- Remove Python 3.3 support. Python 3.3 support has been dropped by the Python\n  foundation.\n- Default environments are now using the same Python version as the Python\n  process. In 0.12.x, we used to load the latest Python version on the system.\n- Added ``include_builtins`` as a parameter to usages.\n- ``goto_assignments`` has a new ``follow_builtin_imports`` parameter that\n  changes the previous behavior slightly.\n\n0.12.1 (2018-06-30)\n+++++++++++++++++++\n\n- This release forces you to upgrade parso. If you don't, nothing will work\n  anymore. Otherwise changes should be limited to bug fixes. Unfortunately Jedi\n  still uses a few internals of parso that make it hard to keep compatibility\n  over multiple releases. Parso >=0.3.0 is going to be needed.\n\n0.12.0 (2018-04-15)\n+++++++++++++++++++\n\n- Virtualenv/Environment support\n- F-String Completion/Goto Support\n- Cannot crash with segfaults anymore\n- Cleaned up import logic\n- Understand async/await and autocomplete it (including async generators)\n- Better namespace completions\n- Passing tests for Windows (including CI for Windows)\n- Remove Python 2.6 support\n\n0.11.1 (2017-12-14)\n+++++++++++++++++++\n\n- Parso update - the caching layer was broken\n- Better usages - a lot of internal code was ripped out and improved.\n\n0.11.0 (2017-09-20)\n+++++++++++++++++++\n\n- Split Jedi's parser into a separate project called ``parso``.\n- Avoiding side effects in REPL completion.\n- Numpy docstring support should be much better.\n- Moved the `settings.*recursion*` away, they are no longer usable.\n\n0.10.2 (2017-04-05)\n+++++++++++++++++++\n\n- Python Packaging sucks. Some files were not included in 0.10.1.\n\n0.10.1 (2017-04-05)\n+++++++++++++++++++\n\n- Fixed a few very annoying bugs.\n- Prepared the parser to be factored out of Jedi.\n\n0.10.0 (2017-02-03)\n+++++++++++++++++++\n\n- Actual semantic completions for the complete Python syntax.\n- Basic type inference for ``yield from`` PEP 380.\n- PEP 484 support (most of the important features of it). Thanks Claude! (@reinhrst)\n- Added ``get_line_code`` to ``Name`` and ``Completion`` objects.\n- Completely rewritten the type inference engine.\n- A new and better parser for (fast) parsing diffs of Python code.\n\n0.9.0 (2015-04-10)\n++++++++++++++++++\n\n- The import logic has been rewritten to look more like Python's. There is now\n  an ``InferState.modules`` import cache, which resembles ``sys.modules``.\n- Integrated the parser of 2to3. This will make refactoring possible. It will\n  also be possible to check for error messages (like compiling an AST would give)\n  in the future.\n- With the new parser, the type inference also completely changed. It's now\n  simpler and more readable.\n- Completely rewritten REPL completion.\n- Added ``jedi.names``, a command to do static analysis. Thanks to that\n  sourcegraph guys for sponsoring this!\n- Alpha version of the linter.\n\n\n0.8.1 (2014-07-23)\n+++++++++++++++++++\n\n- Bugfix release, the last release forgot to include files that improve\n  autocompletion for builtin libraries. Fixed.\n\n0.8.0 (2014-05-05)\n+++++++++++++++++++\n\n- Memory Consumption for compiled modules (e.g. builtins, sys) has been reduced\n  drastically. Loading times are down as well (it takes basically as long as an\n  import).\n- REPL completion is starting to become usable.\n- Various small API changes. Generally this release focuses on stability and\n  refactoring of internal APIs.\n- Introducing operator precedence, which makes calculating correct Array\n  indices and ``__getattr__`` strings possible.\n\n0.7.0 (2013-08-09)\n++++++++++++++++++\n\n- Switched from LGPL to MIT license.\n- Added an Interpreter class to the API to make autocompletion in REPL\n  possible.\n- Added autocompletion support for namespace packages.\n- Add sith.py, a new random testing method.\n\n0.6.0 (2013-05-14)\n++++++++++++++++++\n\n- Much faster parser with builtin part caching.\n- A test suite, thanks @tkf.\n\n0.5 versions (2012)\n+++++++++++++++++++\n\n- Initial development.\n\n\n",
        "keywords": [
          "python",
          "completion",
          "refactoring",
          "vim"
        ],
        "home_page": "https://github.com/davidhalter/jedi",
        "author": "David Halter",
        "author_email": "davidhalter88@gmail.com",
        "maintainer": "David Halter",
        "maintainer_email": "davidhalter88@gmail.com",
        "license": "MIT",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Environment :: Plugins",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Text Editors :: Integrated Development Environments (IDE)",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "parso (<0.9.0,>=0.8.3)",
          "Jinja2 (==2.11.3) ; extra == 'docs'",
          "MarkupSafe (==1.1.1) ; extra == 'docs'",
          "Pygments (==2.8.1) ; extra == 'docs'",
          "alabaster (==0.7.12) ; extra == 'docs'",
          "babel (==2.9.1) ; extra == 'docs'",
          "chardet (==4.0.0) ; extra == 'docs'",
          "commonmark (==0.8.1) ; extra == 'docs'",
          "docutils (==0.17.1) ; extra == 'docs'",
          "future (==0.18.2) ; extra == 'docs'",
          "idna (==2.10) ; extra == 'docs'",
          "imagesize (==1.2.0) ; extra == 'docs'",
          "mock (==1.0.1) ; extra == 'docs'",
          "packaging (==20.9) ; extra == 'docs'",
          "pyparsing (==2.4.7) ; extra == 'docs'",
          "pytz (==2021.1) ; extra == 'docs'",
          "readthedocs-sphinx-ext (==2.1.4) ; extra == 'docs'",
          "recommonmark (==0.5.0) ; extra == 'docs'",
          "requests (==2.25.1) ; extra == 'docs'",
          "six (==1.15.0) ; extra == 'docs'",
          "snowballstemmer (==2.1.0) ; extra == 'docs'",
          "sphinx-rtd-theme (==0.4.3) ; extra == 'docs'",
          "sphinx (==1.8.5) ; extra == 'docs'",
          "sphinxcontrib-serializinghtml (==1.1.4) ; extra == 'docs'",
          "sphinxcontrib-websupport (==1.2.4) ; extra == 'docs'",
          "urllib3 (==1.26.4) ; extra == 'docs'",
          "flake8 (==5.0.4) ; extra == 'qa'",
          "mypy (==0.971) ; extra == 'qa'",
          "types-setuptools (==67.2.0.1) ; extra == 'qa'",
          "Django ; extra == 'testing'",
          "attrs ; extra == 'testing'",
          "colorama ; extra == 'testing'",
          "docopt ; extra == 'testing'",
          "pytest (<7.0.0) ; extra == 'testing'"
        ],
        "requires_python": ">=3.6",
        "project_url": [
          "Documentation, https://jedi.readthedocs.io/en/latest/"
        ],
        "provides_extra": [
          "docs",
          "qa",
          "testing"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\jedi-0.19.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "Jinja2",
        "version": "3.1.4",
        "summary": "A very fast and expressive template engine.",
        "description": "# Jinja\n\nJinja is a fast, expressive, extensible templating engine. Special\nplaceholders in the template allow writing code similar to Python\nsyntax. Then the template is passed data to render the final document.\n\nIt includes:\n\n-   Template inheritance and inclusion.\n-   Define and import macros within templates.\n-   HTML templates can use autoescaping to prevent XSS from untrusted\n    user input.\n-   A sandboxed environment can safely render untrusted templates.\n-   AsyncIO support for generating templates and calling async\n    functions.\n-   I18N support with Babel.\n-   Templates are compiled to optimized Python code just-in-time and\n    cached, or can be compiled ahead-of-time.\n-   Exceptions point to the correct line in templates to make debugging\n    easier.\n-   Extensible filters, tests, functions, and even syntax.\n\nJinja's philosophy is that while application logic belongs in Python if\npossible, it shouldn't make the template designer's job difficult by\nrestricting functionality too much.\n\n\n## In A Nutshell\n\n.. code-block:: jinja\n\n    {% extends \"base.html\" %}\n    {% block title %}Members{% endblock %}\n    {% block content %}\n      <ul>\n      {% for user in users %}\n        <li><a href=\"{{ user.url }}\">{{ user.username }}</a></li>\n      {% endfor %}\n      </ul>\n    {% endblock %}\n\n\n## Donate\n\nThe Pallets organization develops and supports Jinja and other popular\npackages. In order to grow the community of contributors and users, and\nallow the maintainers to devote more time to the projects, [please\ndonate today][].\n\n[please donate today]: https://palletsprojects.com/donate\n\n",
        "description_content_type": "text/markdown",
        "maintainer_email": "Pallets <contact@palletsprojects.com>",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Topic :: Internet :: WWW/HTTP :: Dynamic Content",
          "Topic :: Text Processing :: Markup :: HTML",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "MarkupSafe>=2.0",
          "Babel>=2.7 ; extra == \"i18n\""
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Changes, https://jinja.palletsprojects.com/changes/",
          "Chat, https://discord.gg/pallets",
          "Documentation, https://jinja.palletsprojects.com/",
          "Donate, https://palletsprojects.com/donate",
          "Source, https://github.com/pallets/jinja/"
        ],
        "provides_extra": [
          "i18n"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\jinja2-3.1.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "jmespath",
        "version": "1.0.1",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "JSON Matching Expressions",
        "description": "JMESPath\n========\n\n\n.. image:: https://badges.gitter.im/Join Chat.svg\n   :target: https://gitter.im/jmespath/chat\n\n\nJMESPath (pronounced \"james path\") allows you to declaratively specify how to\nextract elements from a JSON document.\n\nFor example, given this document::\n\n    {\"foo\": {\"bar\": \"baz\"}}\n\nThe jmespath expression ``foo.bar`` will return \"baz\".\n\nJMESPath also supports:\n\nReferencing elements in a list.  Given the data::\n\n    {\"foo\": {\"bar\": [\"one\", \"two\"]}}\n\nThe expression: ``foo.bar[0]`` will return \"one\".\nYou can also reference all the items in a list using the ``*``\nsyntax::\n\n   {\"foo\": {\"bar\": [{\"name\": \"one\"}, {\"name\": \"two\"}]}}\n\nThe expression: ``foo.bar[*].name`` will return [\"one\", \"two\"].\nNegative indexing is also supported (-1 refers to the last element\nin the list).  Given the data above, the expression\n``foo.bar[-1].name`` will return \"two\".\n\nThe ``*`` can also be used for hash types::\n\n   {\"foo\": {\"bar\": {\"name\": \"one\"}, \"baz\": {\"name\": \"two\"}}}\n\nThe expression: ``foo.*.name`` will return [\"one\", \"two\"].\n\n\nInstallation\n============\n\nYou can install JMESPath from pypi with:\n\n.. code:: bash\n\n    pip install jmespath\n\n\nAPI\n===\n\nThe ``jmespath.py`` library has two functions\nthat operate on python data structures.  You can use ``search``\nand give it the jmespath expression and the data:\n\n.. code:: python\n\n    >>> import jmespath\n    >>> path = jmespath.search('foo.bar', {'foo': {'bar': 'baz'}})\n    'baz'\n\nSimilar to the ``re`` module, you can use the ``compile`` function\nto compile the JMESPath expression and use this parsed expression\nto perform repeated searches:\n\n.. code:: python\n\n    >>> import jmespath\n    >>> expression = jmespath.compile('foo.bar')\n    >>> expression.search({'foo': {'bar': 'baz'}})\n    'baz'\n    >>> expression.search({'foo': {'bar': 'other'}})\n    'other'\n\nThis is useful if you're going to use the same jmespath expression to\nsearch multiple documents.  This avoids having to reparse the\nJMESPath expression each time you search a new document.\n\nOptions\n-------\n\nYou can provide an instance of ``jmespath.Options`` to control how\na JMESPath expression is evaluated.  The most common scenario for\nusing an ``Options`` instance is if you want to have ordered output\nof your dict keys.  To do this you can use either of these options:\n\n.. code:: python\n\n    >>> import jmespath\n    >>> jmespath.search('{a: a, b: b}',\n    ...                 mydata,\n    ...                 jmespath.Options(dict_cls=collections.OrderedDict))\n\n\n    >>> import jmespath\n    >>> parsed = jmespath.compile('{a: a, b: b}')\n    >>> parsed.search(mydata,\n    ...               jmespath.Options(dict_cls=collections.OrderedDict))\n\n\nCustom Functions\n~~~~~~~~~~~~~~~~\n\nThe JMESPath language has numerous\n`built-in functions\n<http://jmespath.org/specification.html#built-in-functions>`__, but it is\nalso possible to add your own custom functions.  Keep in mind that\ncustom function support in jmespath.py is experimental and the API may\nchange based on feedback.\n\n**If you have a custom function that you've found useful, consider submitting\nit to jmespath.site and propose that it be added to the JMESPath language.**\nYou can submit proposals\n`here <https://github.com/jmespath/jmespath.site/issues>`__.\n\nTo create custom functions:\n\n* Create a subclass of ``jmespath.functions.Functions``.\n* Create a method with the name ``_func_<your function name>``.\n* Apply the ``jmespath.functions.signature`` decorator that indicates\n  the expected types of the function arguments.\n* Provide an instance of your subclass in a ``jmespath.Options`` object.\n\nBelow are a few examples:\n\n.. code:: python\n\n    import jmespath\n    from jmespath import functions\n\n    # 1. Create a subclass of functions.Functions.\n    #    The function.Functions base class has logic\n    #    that introspects all of its methods and automatically\n    #    registers your custom functions in its function table.\n    class CustomFunctions(functions.Functions):\n\n        # 2 and 3.  Create a function that starts with _func_\n        # and decorate it with @signature which indicates its\n        # expected types.\n        # In this example, we're creating a jmespath function\n        # called \"unique_letters\" that accepts a single argument\n        # with an expected type \"string\".\n        @functions.signature({'types': ['string']})\n        def _func_unique_letters(self, s):\n            # Given a string s, return a sorted\n            # string of unique letters: 'ccbbadd' ->  'abcd'\n            return ''.join(sorted(set(s)))\n\n        # Here's another example.  This is creating\n        # a jmespath function called \"my_add\" that expects\n        # two arguments, both of which should be of type number.\n        @functions.signature({'types': ['number']}, {'types': ['number']})\n        def _func_my_add(self, x, y):\n            return x + y\n\n    # 4. Provide an instance of your subclass in a Options object.\n    options = jmespath.Options(custom_functions=CustomFunctions())\n\n    # Provide this value to jmespath.search:\n    # This will print 3\n    print(\n        jmespath.search(\n            'my_add(`1`, `2`)', {}, options=options)\n    )\n\n    # This will print \"abcd\"\n    print(\n        jmespath.search(\n            'foo.bar | unique_letters(@)',\n            {'foo': {'bar': 'ccbbadd'}},\n            options=options)\n    )\n\nAgain, if you come up with useful functions that you think make\nsense in the JMESPath language (and make sense to implement in all\nJMESPath libraries, not just python), please let us know at\n`jmespath.site <https://github.com/jmespath/jmespath.site/issues>`__.\n\n\nSpecification\n=============\n\nIf you'd like to learn more about the JMESPath language, you can check out\nthe `JMESPath tutorial <http://jmespath.org/tutorial.html>`__.  Also check\nout the `JMESPath examples page <http://jmespath.org/examples.html>`__ for\nexamples of more complex jmespath queries.\n\nThe grammar is specified using ABNF, as described in\n`RFC4234 <http://www.ietf.org/rfc/rfc4234.txt>`_.\nYou can find the most up to date\n`grammar for JMESPath here <http://jmespath.org/specification.html#grammar>`__.\n\nYou can read the full\n`JMESPath specification here <http://jmespath.org/specification.html>`__.\n\n\nTesting\n=======\n\nIn addition to the unit tests for the jmespath modules,\nthere is a ``tests/compliance`` directory that contains\n.json files with test cases.  This allows other implementations\nto verify they are producing the correct output.  Each json\nfile is grouped by feature.\n\n\nDiscuss\n=======\n\nJoin us on our `Gitter channel <https://gitter.im/jmespath/chat>`__\nif you want to chat or if you have any questions.\n\n\n",
        "home_page": "https://github.com/jmespath/jmespath.py",
        "author": "James Saryerwinnie",
        "author_email": "js@jamesls.com",
        "license": "MIT",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_python": ">=3.7"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\jmespath-1.0.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "jsonpointer",
        "version": "3.0.0",
        "summary": "Identify specific nodes in a JSON document (RFC 6901) ",
        "description": "python-json-pointer\n===================\n\n[![PyPI version](https://img.shields.io/pypi/v/jsonpointer.svg)](https://pypi.python.org/pypi/jsonpointer/)\n[![Supported Python versions](https://img.shields.io/pypi/pyversions/jsonpointer.svg)](https://pypi.python.org/pypi/jsonpointer/)\n[![Coverage Status](https://coveralls.io/repos/stefankoegl/python-json-pointer/badge.svg?branch=master)](https://coveralls.io/r/stefankoegl/python-json-pointer?branch=master)\n\n\nResolve JSON Pointers in Python\n-------------------------------\n\nLibrary to resolve JSON Pointers according to\n[RFC 6901](http://tools.ietf.org/html/rfc6901)\n\nSee source code for examples\n* Website: https://github.com/stefankoegl/python-json-pointer\n* Repository: https://github.com/stefankoegl/python-json-pointer.git\n* Documentation: https://python-json-pointer.readthedocs.org/\n* PyPI: https://pypi.python.org/pypi/jsonpointer\n* Travis CI: https://travis-ci.org/stefankoegl/python-json-pointer\n* Coveralls: https://coveralls.io/r/stefankoegl/python-json-pointer\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/stefankoegl/python-json-pointer",
        "author": "Stefan KÃ¶gl",
        "author_email": "stefan@skoegl.net",
        "license": "Modified BSD License",
        "license_file": [
          "LICENSE.txt",
          "AUTHORS"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries",
          "Topic :: Utilities"
        ],
        "requires_python": ">=3.7"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\jsonpointer-3.0.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "jsonschema",
        "version": "4.23.0",
        "summary": "An implementation of JSON Schema validation for Python",
        "description": "==========\njsonschema\n==========\n\n|PyPI| |Pythons| |CI| |ReadTheDocs| |Precommit| |Zenodo|\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/jsonschema.svg\n   :alt: PyPI version\n   :target: https://pypi.org/project/jsonschema/\n\n.. |Pythons| image:: https://img.shields.io/pypi/pyversions/jsonschema.svg\n   :alt: Supported Python versions\n   :target: https://pypi.org/project/jsonschema/\n\n.. |CI| image:: https://github.com/python-jsonschema/jsonschema/workflows/CI/badge.svg\n  :alt: Build status\n  :target: https://github.com/python-jsonschema/jsonschema/actions?query=workflow%3ACI\n\n.. |ReadTheDocs| image:: https://readthedocs.org/projects/python-jsonschema/badge/?version=stable&style=flat\n   :alt: ReadTheDocs status\n   :target: https://python-jsonschema.readthedocs.io/en/stable/\n\n.. |Precommit| image:: https://results.pre-commit.ci/badge/github/python-jsonschema/jsonschema/main.svg\n   :alt: pre-commit.ci status\n   :target: https://results.pre-commit.ci/latest/github/python-jsonschema/jsonschema/main\n\n.. |Zenodo| image:: https://zenodo.org/badge/3072629.svg\n   :alt: Zenodo DOI\n   :target: https://zenodo.org/badge/latestdoi/3072629\n\n\n``jsonschema`` is an implementation of the `JSON Schema <https://json-schema.org>`_ specification for Python.\n\n.. code:: python\n\n    >>> from jsonschema import validate\n\n    >>> # A sample schema, like what we'd get from json.load()\n    >>> schema = {\n    ...     \"type\" : \"object\",\n    ...     \"properties\" : {\n    ...         \"price\" : {\"type\" : \"number\"},\n    ...         \"name\" : {\"type\" : \"string\"},\n    ...     },\n    ... }\n\n    >>> # If no exception is raised by validate(), the instance is valid.\n    >>> validate(instance={\"name\" : \"Eggs\", \"price\" : 34.99}, schema=schema)\n\n    >>> validate(\n    ...     instance={\"name\" : \"Eggs\", \"price\" : \"Invalid\"}, schema=schema,\n    ... )                                   # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n        ...\n    ValidationError: 'Invalid' is not of type 'number'\n\nIt can also be used from the command line by installing `check-jsonschema <https://github.com/python-jsonschema/check-jsonschema>`_.\n\nFeatures\n--------\n\n* Full support for `Draft 2020-12 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft202012Validator>`_, `Draft 2019-09 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft201909Validator>`_, `Draft 7 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft7Validator>`_, `Draft 6 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft6Validator>`_, `Draft 4 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft4Validator>`_ and `Draft 3 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft3Validator>`_\n\n* `Lazy validation <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/protocols/#jsonschema.protocols.Validator.iter_errors>`_ that can iteratively report *all* validation errors.\n\n* `Programmatic querying <https://python-jsonschema.readthedocs.io/en/latest/errors/>`_ of which properties or items failed validation.\n\n\nInstallation\n------------\n\n``jsonschema`` is available on `PyPI <https://pypi.org/project/jsonschema/>`_. You can install using `pip <https://pip.pypa.io/en/stable/>`_:\n\n.. code:: bash\n\n    $ pip install jsonschema\n\n\nExtras\n======\n\nTwo extras are available when installing the package, both currently related to ``format`` validation:\n\n    * ``format``\n    * ``format-nongpl``\n\nThey can be used when installing in order to include additional dependencies, e.g.:\n\n.. code:: bash\n\n    $ pip install jsonschema'[format]'\n\nBe aware that the mere presence of these dependencies â€“ or even the specification of ``format`` checks in a schema â€“ do *not* activate format checks (as per the specification).\nPlease read the `format validation documentation <https://python-jsonschema.readthedocs.io/en/latest/validate/#validating-formats>`_ for further details.\n\nAbout\n-----\n\nI'm Julian Berman.\n\n``jsonschema`` is on `GitHub <https://github.com/python-jsonschema/jsonschema>`_.\n\nGet in touch, via GitHub or otherwise, if you've got something to contribute, it'd be most welcome!\n\nYou can also generally find me on Libera (nick: ``Julian``) in various channels, including ``#python``.\n\nIf you feel overwhelmingly grateful, you can also `sponsor me <https://github.com/sponsors/Julian/>`_.\n\nAnd for companies who appreciate ``jsonschema`` and its continued support and growth, ``jsonschema`` is also now supportable via `TideLift <https://tidelift.com/subscription/pkg/pypi-jsonschema?utm_source=pypi-jsonschema&utm_medium=referral&utm_campaign=readme>`_.\n\n\nRelease Information\n-------------------\n\nv4.23.0\n=======\n\n* Do not reorder dictionaries (schemas, instances) that are printed as part of validation errors.\n* Declare support for Py3.13\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "data validation",
          "json",
          "json schema",
          "jsonschema",
          "validation"
        ],
        "author_email": "Julian Berman <Julian+jsonschema@GrayVines.com>",
        "license": "MIT",
        "license_file": [
          "COPYING"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: File Formats :: JSON",
          "Topic :: File Formats :: JSON :: JSON Schema"
        ],
        "requires_dist": [
          "attrs>=22.2.0",
          "importlib-resources>=1.4.0; python_version < '3.9'",
          "jsonschema-specifications>=2023.03.6",
          "pkgutil-resolve-name>=1.3.10; python_version < '3.9'",
          "referencing>=0.28.4",
          "rpds-py>=0.7.1",
          "fqdn; extra == 'format'",
          "idna; extra == 'format'",
          "isoduration; extra == 'format'",
          "jsonpointer>1.13; extra == 'format'",
          "rfc3339-validator; extra == 'format'",
          "rfc3987; extra == 'format'",
          "uri-template; extra == 'format'",
          "webcolors>=1.11; extra == 'format'",
          "fqdn; extra == 'format-nongpl'",
          "idna; extra == 'format-nongpl'",
          "isoduration; extra == 'format-nongpl'",
          "jsonpointer>1.13; extra == 'format-nongpl'",
          "rfc3339-validator; extra == 'format-nongpl'",
          "rfc3986-validator>0.1.0; extra == 'format-nongpl'",
          "uri-template; extra == 'format-nongpl'",
          "webcolors>=24.6.0; extra == 'format-nongpl'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://github.com/python-jsonschema/jsonschema",
          "Documentation, https://python-jsonschema.readthedocs.io/",
          "Issues, https://github.com/python-jsonschema/jsonschema/issues/",
          "Funding, https://github.com/sponsors/Julian",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-jsonschema?utm_source=pypi-jsonschema&utm_medium=referral&utm_campaign=pypi-link",
          "Changelog, https://github.com/python-jsonschema/jsonschema/blob/main/CHANGELOG.rst",
          "Source, https://github.com/python-jsonschema/jsonschema"
        ],
        "provides_extra": [
          "format",
          "format-nongpl"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\jsonschema-4.23.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "jsonschema-specifications",
        "version": "2023.12.1",
        "summary": "The JSON Schema meta-schemas and vocabularies, exposed as a Registry",
        "description": "=============================\n``jsonschema-specifications``\n=============================\n\n|PyPI| |Pythons| |CI| |ReadTheDocs|\n\nJSON support files from the `JSON Schema Specifications <https://json-schema.org/specification.html>`_ (metaschemas, vocabularies, etc.), packaged for runtime access from Python as a `referencing-based Schema Registry <https://referencing.readthedocs.io/en/stable/api/#referencing.Registry>`_.\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/jsonschema-specifications.svg\n  :alt: PyPI version\n  :target: https://pypi.org/project/jsonschema-specifications/\n\n.. |Pythons| image:: https://img.shields.io/pypi/pyversions/jsonschema-specifications.svg\n  :alt: Supported Python versions\n  :target: https://pypi.org/project/jsonschema-specifications/\n\n.. |CI| image:: https://github.com/python-jsonschema/jsonschema-specifications/workflows/CI/badge.svg\n  :alt: Build status\n  :target: https://github.com/python-jsonschema/jsonschema-specifications/actions?query=workflow%3ACI\n\n.. |ReadTheDocs| image:: https://readthedocs.org/projects/jsonschema-specifications/badge/?version=stable&style=flat\n  :alt: ReadTheDocs status\n  :target: https://jsonschema-specifications.readthedocs.io/en/stable/\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "data validation",
          "json",
          "json schema",
          "jsonschema",
          "validation"
        ],
        "author": "Julian Berman",
        "author_email": "Julian+jsonschema-specifications@GrayVines.com",
        "license": "MIT",
        "license_file": [
          "COPYING"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: File Formats :: JSON :: JSON Schema"
        ],
        "requires_dist": [
          "importlib-resources>=1.4.0; python_version < '3.9'",
          "referencing>=0.31.0"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://jsonschema-specifications.readthedocs.io/",
          "Homepage, https://github.com/python-jsonschema/jsonschema-specifications",
          "Issues, https://github.com/python-jsonschema/jsonschema-specifications/issues/",
          "Funding, https://github.com/sponsors/Julian",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-jsonschema-specifications?utm_source=pypi-jsonschema-specifications&utm_medium=referral&utm_campaign=pypi-link",
          "Source, https://github.com/python-jsonschema/jsonschema-specifications"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\jsonschema_specifications-2023.12.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "jupyterlab_pygments",
        "version": "0.3.0",
        "summary": "Pygments theme using JupyterLab CSS variables",
        "description": "# JupyterLab Pygments Theme\n\nThis package contains a syntax coloring theme for [pygments](http://pygments.org/) making use of\nthe JupyterLab CSS variables.\n\nThe goal is to enable the use of JupyterLab's themes with pygments-generated HTML.\n\n## Screencast\n\nIn the following screencast, we demonstrate how Pygments-highlighted code can make use of the JupyterLab theme.\n\n![pygments screencast](pygments.gif)\n\n## Installation\n\n`jupyterlab_pygments` can be installed with the conda package manager\n\n```\nconda install -c conda-forge jupyterlab_pygments\n```\n\nor from pypi\n\n```\npip install jupyterlab_pygments\n```\n\n## Dependencies\n\n- `jupyterlab_pygments` requires [pygments](http://pygments.org) version `2.4.1`.\n- The CSS variables used by the theme correspond to the CodeMirror syntex coloring\n  theme defined in the NPM package [@jupyterlab/codemirror](https://www.npmjs.com/package/@jupyterlab/codemirror). Supported versions for `@jupyterlab/codemirror`'s CSS include `0.19.1`, `^1.0`, and, `^2.0`.\n\n## Limitations\n\nPygments-generated HTML and CSS classes are not granular enough to reproduce\nall of the details of codemirror (the JavaScript text editor used by JupyterLab).\n\nThis includes the ability to differentiate properties from general names.\n\n## License\n\n`jupyterlab_pygments` uses a shared copyright model that enables all contributors to maintain the\ncopyright on their contributions. All code is licensed under the terms of the revised [BSD license](LICENSE).\n",
        "description_content_type": "text/markdown",
        "author_email": "Jupyter Development Team <jupyter@googlegroups.com>",
        "license": "Copyright (c) 2015 Project Jupyter Contributors\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Framework :: Jupyter",
          "Framework :: Jupyter :: JupyterLab",
          "Framework :: Jupyter :: JupyterLab :: 4",
          "Framework :: Jupyter :: JupyterLab :: Extensions",
          "Framework :: Jupyter :: JupyterLab :: Extensions :: Prebuilt",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://github.com/jupyterlab/jupyterlab_pygments",
          "Bug Tracker, https://github.com/jupyterlab/jupyterlab_pygments/issues",
          "Repository, https://github.com/jupyterlab/jupyterlab_pygments.git"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\jupyterlab_pygments-0.3.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "jupyter_client",
        "version": "8.6.2",
        "summary": "Jupyter protocol implementation and client libraries",
        "description": "# Jupyter Client\n\n[![Build Status](https://github.com/jupyter/jupyter_client/workflows/CI/badge.svg)](https://github.com/jupyter/jupyter_client/actions)\n[![Documentation Status](https://readthedocs.org/projects/jupyter-client/badge/?version=latest)](http://jupyter-client.readthedocs.io/en/latest/?badge=latest)\n\n`jupyter_client` contains the reference implementation of the [Jupyter protocol].\nIt also provides client and kernel management APIs for working with kernels.\n\nIt also provides the `jupyter kernelspec` entrypoint\nfor installing kernelspecs for use with Jupyter frontends.\n\n## Development Setup\n\nThe [Jupyter Contributor Guides](https://jupyter.readthedocs.io/en/latest/contributing/content-contributor.html) provide extensive information on contributing code or documentation to Jupyter projects. The limited instructions below for setting up a development environment are for your convenience.\n\n## Coding\n\nYou'll need Python and `pip` on the search path. Clone the Jupyter Client git repository to your computer, for example in `/my/project/jupyter_client`\n\n```bash\ncd /my/projects/\ngit clone git@github.com:jupyter/jupyter_client.git\n```\n\nNow create an [editable install](https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs)\nand download the dependencies of code and test suite by executing:\n\n```bash\ncd /my/projects/jupyter_client/\npip install -e \".[test]\"\npytest\n```\n\nThe last command runs the test suite to verify the setup. During development, you can pass filenames to `pytest`, and it will execute only those tests.\n\n## Documentation\n\nThe documentation of Jupyter Client is generated from the files in `docs/` using Sphinx. Instructions for setting up Sphinx with a selection of optional modules are in the [Documentation Guide](https://jupyter.readthedocs.io/en/latest/contributing/docs-contributions/index.html). You'll also need the `make` command.\nFor a minimal Sphinx installation to process the Jupyter Client docs, execute:\n\n```bash\npip install \".[doc]\"\n```\n\nThe following commands build the documentation in HTML format and check for broken links:\n\n```bash\ncd /my/projects/jupyter_client/docs/\nmake html linkcheck\n```\n\nPoint your browser to the following URL to access the generated documentation:\n\n_file:///my/projects/jupyter_client/docs/\\_build/html/index.html_\n\n## Contributing\n\n`jupyter-client` has adopted automatic code formatting so you shouldn't\nneed to worry too much about your code style.\nAs long as your code is valid,\nthe pre-commit hook should take care of how it should look.\nYou can invoke the pre-commit hook by hand at any time with:\n\n```bash\npre-commit run\n```\n\nwhich should run any autoformatting on your code\nand tell you about any errors it couldn't fix automatically.\nYou may also install [black integration](https://black.readthedocs.io/en/stable/integrations/editors.html)\ninto your text editor to format code automatically.\n\nIf you have already committed files before setting up the pre-commit\nhook with `pre-commit install`, you can fix everything up using\n`pre-commit run --all-files`. You need to make the fixing commit\nyourself after that.\n\nSome of the hooks only run on CI by default, but you can invoke them by\nrunning with the `--hook-stage manual` argument.\n\n## About the Jupyter Development Team\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project.\nThis includes all of the Jupyter subprojects.\n\nThe core team that coordinates development on GitHub can be found here:\nhttps://github.com/jupyter/.\n\n## Our Copyright Policy\n\nJupyter uses a shared copyright model. Each contributor maintains copyright\nover their contributions to Jupyter. But, it is important to note that these\ncontributions are typically only changes to the repositories. Thus, the Jupyter\nsource code, in its entirety is not the copyright of any single person or\ninstitution. Instead, it is the collective copyright of the entire Jupyter\nDevelopment Team. If individual contributors want to maintain a record of what\nchanges/contributions they have specific copyright on, they should indicate\ntheir copyright in the commit message of the change, when they commit the\nchange to one of the Jupyter repositories.\n\nWith this in mind, the following banner should be used in any source code file\nto indicate the copyright and license terms:\n\n```\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License.\n```\n\n[jupyter protocol]: https://jupyter-client.readthedocs.io/en/latest/messaging.html\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "Interactive",
          "Interpreter",
          "Shell",
          "Web"
        ],
        "author_email": "Jupyter Development Team <jupyter@googlegroups.com>",
        "license": "BSD 3-Clause License\n\n- Copyright (c) 2001-2015, IPython Development Team\n- Copyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Framework :: Jupyter",
          "Intended Audience :: Developers",
          "Intended Audience :: Education",
          "Intended Audience :: Science/Research",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3"
        ],
        "requires_dist": [
          "importlib-metadata>=4.8.3; python_version < '3.10'",
          "jupyter-core!=5.0.*,>=4.12",
          "python-dateutil>=2.8.2",
          "pyzmq>=23.0",
          "tornado>=6.2",
          "traitlets>=5.3",
          "ipykernel; extra == 'docs'",
          "myst-parser; extra == 'docs'",
          "pydata-sphinx-theme; extra == 'docs'",
          "sphinx-autodoc-typehints; extra == 'docs'",
          "sphinx>=4; extra == 'docs'",
          "sphinxcontrib-github-alt; extra == 'docs'",
          "sphinxcontrib-spelling; extra == 'docs'",
          "coverage; extra == 'test'",
          "ipykernel>=6.14; extra == 'test'",
          "mypy; extra == 'test'",
          "paramiko; (sys_platform == 'win32') and extra == 'test'",
          "pre-commit; extra == 'test'",
          "pytest-cov; extra == 'test'",
          "pytest-jupyter[client]>=0.4.1; extra == 'test'",
          "pytest-timeout; extra == 'test'",
          "pytest<8.2.0; extra == 'test'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://jupyter.org",
          "Documentation, https://jupyter-client.readthedocs.io/",
          "Source, https://github.com/jupyter/jupyter_client"
        ],
        "provides_extra": [
          "docs",
          "test"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\jupyter_client-8.6.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "jupyter_core",
        "version": "5.7.2",
        "summary": "Jupyter core package. A base package on which Jupyter projects rely.",
        "description": "There is no reason to install this package on its own.",
        "description_content_type": "text/plain",
        "author_email": "Jupyter Development Team <jupyter@googlegroups.org>",
        "license": "BSD 3-Clause License\n\n- Copyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Framework :: Jupyter",
          "Intended Audience :: Developers",
          "Intended Audience :: Science/Research",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3"
        ],
        "requires_dist": [
          "platformdirs>=2.5",
          "pywin32>=300; sys_platform == 'win32' and platform_python_implementation != 'PyPy'",
          "traitlets>=5.3",
          "myst-parser; extra == 'docs'",
          "pydata-sphinx-theme; extra == 'docs'",
          "sphinx-autodoc-typehints; extra == 'docs'",
          "sphinxcontrib-github-alt; extra == 'docs'",
          "sphinxcontrib-spelling; extra == 'docs'",
          "traitlets; extra == 'docs'",
          "ipykernel; extra == 'test'",
          "pre-commit; extra == 'test'",
          "pytest-cov; extra == 'test'",
          "pytest-timeout; extra == 'test'",
          "pytest<8; extra == 'test'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://jupyter.org",
          "Documentation, https://jupyter-core.readthedocs.io/",
          "Funding, https://numfocus.org/",
          "Source, https://github.com/jupyter/jupyter_core",
          "Tracker, https://github.com/jupyter/jupyter_core/issues"
        ],
        "provides_extra": [
          "docs",
          "test"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\jupyter_core-5.7.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "kiwisolver",
        "version": "1.4.8",
        "summary": "A fast implementation of the Cassowary constraint solver",
        "description": "Welcome to Kiwi\n===============\n\n.. image:: https://github.com/nucleic/kiwi/workflows/Continuous%20Integration/badge.svg\n    :target: https://github.com/nucleic/kiwi/actions\n.. image:: https://github.com/nucleic/kiwi/workflows/Documentation%20building/badge.svg\n    :target: https://github.com/nucleic/kiwi/actions\n.. image:: https://codecov.io/gh/nucleic/kiwi/branch/main/graph/badge.svg\n  :target: https://codecov.io/gh/nucleic/kiwi\n.. image:: https://readthedocs.org/projects/kiwisolver/badge/?version=latest\n    :target: https://kiwisolver.readthedocs.io/en/latest/?badge=latest\n    :alt: Documentation Status\n\nKiwi is an efficient C++ implementation of the Cassowary constraint solving\nalgorithm. Kiwi is an implementation of the algorithm based on the\n`seminal Cassowary paper <https://constraints.cs.washington.edu/solvers/cassowary-tochi.pdf>`_.\nIt is *not* a refactoring of the original C++ solver. Kiwi has been designed\nfrom the ground up to be lightweight and fast. Kiwi ranges from 10x to 500x\nfaster than the original Cassowary solver with typical use cases gaining a 40x\nimprovement. Memory savings are consistently > 5x.\n\nIn addition to the C++ solver, Kiwi ships with hand-rolled Python bindings for\nPython 3.7+.\n",
        "description_content_type": "text/x-rst",
        "author_email": "The Nucleic Development Team <sccolbert@gmail.com>",
        "maintainer_email": "\"Matthieu C. Dartiailh\" <m.dartiailh@gmail.com>",
        "license": "=========================\n The Kiwi licensing terms\n=========================\nKiwi is licensed under the terms of the Modified BSD License (also known as\nNew or Revised BSD), as follows:\n\nCopyright (c) 2013-2024, Nucleic Development Team\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this\nlist of conditions and the following disclaimer.\n\nRedistributions in binary form must reproduce the above copyright notice, this\nlist of conditions and the following disclaimer in the documentation and/or\nother materials provided with the distribution.\n\nNeither the name of the Nucleic Development Team nor the names of its\ncontributors may be used to endorse or promote products derived from this\nsoftware without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nAbout Kiwi\n----------\nChris Colbert began the Kiwi project in December 2013 in an effort to\ncreate a blisteringly fast UI constraint solver. Chris is still the\nproject lead.\n\nThe Nucleic Development Team is the set of all contributors to the Nucleic\nproject and its subprojects.\n\nThe core team that coordinates development on GitHub can be found here:\nhttp://github.com/nucleic. The current team consists of:\n\n* Chris Colbert\n\nOur Copyright Policy\n--------------------\nNucleic uses a shared copyright model. Each contributor maintains copyright\nover their contributions to Nucleic. But, it is important to note that these\ncontributions are typically only changes to the repositories. Thus, the Nucleic\nsource code, in its entirety is not the copyright of any single person or\ninstitution. Instead, it is the collective copyright of the entire Nucleic\nDevelopment Team. If individual contributors want to maintain a record of what\nchanges/contributions they have specific copyright on, they should indicate\ntheir copyright in the commit message of the change, when they commit the\nchange to one of the Nucleic repositories.\n\nWith this in mind, the following banner should be used in any source code file\nto indicate the copyright and license terms:\n\n#------------------------------------------------------------------------------\n# Copyright (c) 2013-2024, Nucleic Development Team.\n#\n# Distributed under the terms of the Modified BSD License.\n#\n# The full license is in the file LICENSE, distributed with this software.\n#------------------------------------------------------------------------------\n",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "homepage, https://github.com/nucleic/kiwi",
          "documentation, https://kiwisolver.readthedocs.io/en/latest/",
          "repository, https://github.com/nucleic/kiwi",
          "changelog, https://github.com/nucleic/kiwi/blob/main/releasenotes.rst"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\kiwisolver-1.4.8.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "lib4sbom",
        "version": "0.7.5",
        "summary": "Software Bill of Material (SBOM) generator and consumer library",
        "description": "# Lib4SBOM\n\nLib4SBOM is a library to parse and generate Software Bill of Materials (SBOMs). It supports SBOMs created in both\n[SPDX](https://www.spdx.org) and [CycloneDX](https://www.cyclonedx.org) formats.\n\nIt has been developed on the assumption that having a generic abstraction of SBOM regardless of the underlying format will be useful to developers.\n\nThe following facilities are provided:\n\n- Generate SPDX SBOM in TagValue, JSON and YAML formats\n- Generate CycloneDX SBOM in JSON format\n- Parse SPDX SBOM in TagValue, JSON, YAML, XML and RDF formats\n- Parse CycloneDX SBOM in JSON and XMLformat\n- Create and manipulate a SBOM file object\n- Create and manipulate a SBOM package object\n- Create and manipulate a SBOM dependency relationship object\n- Create and manipulate a Vulnerability object\n- Create and manipulate a Software Service object\n- Generated SBOM can be output to a file or to the console\n\n## Installation\n\nTo install use the following command:\n\n`pip install lib4sbom`\n\nAlternatively, just clone the repo and install dependencies using the following command:\n\n`pip install -U -r requirements.txt`\n\nThe tool requires Python 3 (3.7+). It is recommended to use a virtual python environment especially\nif you are using different versions of python. `virtualenv` is a tool for setting up virtual python environments which\nallows you to have all the dependencies for the tool set up in a single environment, or have different environments set\nup for testing using different versions of Python.\n\n## API\n\n### SBOMParser\n\nThe SBOMParser module provides methods for parsing a SBOM in either SPDX or CycloneDX format and\nreturns the file, package and relationship information from within the SBOM.\n\nThe focus of the implementation is on providing a common set of SBOM data regardless of the SBOM format.\n\nSBOMs are supported in the following formats\n\n| SBOM Type | Version | Format   |\n| --------- |---------|----------|\n| SPDX      | 2.2     | TagValue |\n| SPDX      | 2.2     | JSON     |\n| SPDX      | 2.2     | YAML     |\n| SPDX      | 2.2     | RDF      |\n| SPDX      | 2.2     | XML      |\n| SPDX      | 2.3     | TagValue |\n| SPDX      | 2.3     | JSON     |\n| SPDX      | 2.3     | YAML     |\n| SPDX      | 2.3     | RDF       |\n| SPDX      | 2.3     | XML      |\n| CycloneDX | 1.4     | JSON     |\n| CycloneDX | 1.4     | XML      |\n| CycloneDX | 1.5     | JSON     |\n| CycloneDX | 1.5     | XML      |\n| CycloneDX | 1.6     | JSON     |\n| CycloneDX | 1.6     | XML      |\n\n**Note** that support for SPDX RDF and XML formats is limited to a few package attributes.\n\n_class_ **SBOMParser**(_sbom_type='auto_')\n\nThis creates a simple SBOM Parser object. A single optional parameter, _sbom_type_, can be specified\nwhich represents the type of SBOM (either spdx, cyclonedx or auto). The default is auto in\nwhich case the parser will automatically work out the SBOM type using the\nfollowing filename conventions.\n\n| SBOM      | Format   | Filename extension |\n| --------- |----------|--------------------|\n| SPDX      | TagValue | .spdx              |\n| SPDX      | JSON     | .spdx.json         |\n| SPDX      | YAML     | .spdx.yaml         |\n| SPDX      | YAML     | .spdx.yml          |\n| SPDX      | RDF      | .spdx.rdf          |\n| SPDX      | XML      | .spdx.xml          |\n| CycloneDX | JSON     | .json              |\n| CycloneDX | XML      | .xml               |\n\nThe parser will check that the correct JSON files is being processed by the correct parser.\nA SPDX JSON file submitted to the CycloneDX parser will result in no data being processed.\n\n**Methods**\n\nparse_file(filename)\nParses the SBOM file. If the file does not exist, a FileNotFoundError exception is raised.\n\nget_files()\nReturns a list of file elements from within a parsed SBOM\n\nget_packages()\nReturns a list of packages elements from within a parsed SBOM\n\nget_relationships()\nReturns the relationship elements from within a parsed SBOM\n\nget_vulnerabilities()\nReturns the vulnerability elements from within a parsed SBOM\n\nget_services()\nReturns the software service elements from within a parsed SBOM\n\nget_type()\nReturns the type of SBOM (either spdx or cyclonedx)\n\n**Example**\n\nA test SBOM file (test_sbom.spdx) is used in the following example.\n\n```bash\nSPDXVersion: SPDX-2.2\nDataLicense: CC0-1.0\nSPDXID: SPDXRef-DOCUMENT\nDocumentName: virtualenv\nDocumentNamespace: http://spdx.org/spdxdocs/virtualenv-b7ac9cce-efe8-4fe7-a544-100e6a5664e6\nLicenseListVersion: 3.18\nCreator: Tool: sbom4python-0.4.0\nCreated: 2022-11-16T10:14:26Z\nCreatorComment: <text>This document has been automatically generated.</text>\n##### \n\nPackageName: virtualenv\nSPDXID: SPDXRef-Package-1-virtualenv\nPackageSupplier: Person: Bernat_Gabor\nPackageVersion: 20.16.7\nPackageDownloadLocation: NOASSERTION\nFilesAnalyzed: false\nPackageLicenseConcluded: MIT\nPackageLicenseDeclared: MIT\nPackageCopyrightText: NOASSERTION\nExternalRef: PACKAGE-MANAGER purl pkg:pypi/virtualenv@20.16.7\n##### \n\nPackageName: distlib\nSPDXID: SPDXRef-Package-2-distlib\nPackageSupplier: Person: Vinay_Sajip\nPackageVersion: 0.3.6\nPackageDownloadLocation: NOASSERTION\nFilesAnalyzed: false\nPackageLicenseConcluded: NOASSERTION\nPackageLicenseDeclared: NOASSERTION\nPackageCopyrightText: NOASSERTION\nExternalRef: PACKAGE-MANAGER purl pkg:pypi/distlib@0.3.6\n##### \n\nPackageName: filelock\nSPDXID: SPDXRef-Package-3-filelock\nPackageSupplier: Person: Benedikt_Schmitt\nPackageVersion: 3.8.0\nPackageDownloadLocation: NOASSERTION\nFilesAnalyzed: false\nPackageLicenseConcluded: Unlicense\nPackageLicenseDeclared: Unlicense\nPackageCopyrightText: NOASSERTION\nExternalRef: PACKAGE-MANAGER purl pkg:pypi/filelock@3.8.0\n##### \n\nPackageName: platformdirs\nSPDXID: SPDXRef-Package-4-platformdirs\nPackageSupplier: NOASSERTION\nPackageVersion: 2.5.4\nPackageDownloadLocation: NOASSERTION\nFilesAnalyzed: false\nPackageLicenseConcluded: NOASSERTION\nPackageLicenseDeclared: NOASSERTION\nPackageCopyrightText: NOASSERTION\nExternalRef: PACKAGE-MANAGER purl pkg:pypi/platformdirs@2.5.4\n\nRelationship: SPDXRef-DOCUMENT DESCRIBES SPDXRef-Package-1-virtualenv\nRelationship: SPDXRef-Package-1-virtualenv CONTAINS SPDXRef-Package-2-distlib\nRelationship: SPDXRef-Package-1-virtualenv CONTAINS SPDXRef-Package-3-filelock\nRelationship: SPDXRef-Package-1-virtualenv CONTAINS SPDXRef-Package-4-platformdirs\n```\n\nThe following code sample shows the use of the SBOMParser module.\n\n```python\n>>> from lib4sbom.parser import SBOMParser\n>>> test_parser = SBOMParser()\n>>> print (f\"SBOM type {test_parser.get_type()}\")                                                                                                                                             \nSBOM type auto                                                                                                                                                                                \n>>> test_parser.parse_file(\"test_sbom.spdx\")                                                                                                                                                                                                                                                                                            \n>>> print (f\"SBOM type {test_parser.get_type()}\")                                                                                                                                             \nSBOM type spdx                                                                                                                                                                                \n>>> sbom_files = test_parser.get_files()\n>>> print (sbom_files)                                                                                                                                                                        \n[]                                                                                                                                                                                            \n>>> sbom_packages = test_parser.get_packages()\n>>> print (sbom_packages)\n[{'name': 'virtualenv', 'type': 'library', 'id': 'SPDXRef-Package-1-virtualenv', 'supplier_type': 'Person', 'supplier': 'Bernat_Gabor', 'version': '20.16.7', 'downloadlocation': 'NOASSERTION', 'filesanalysis': 'false', 'licenseconcluded': 'MIT', 'licensedeclared': 'MIT', 'externalreference': [['PACKAGE-MANAGER', 'purl', 'pkg:pypi/virtualenv@20.16.7']]}, {'name': 'distlib', 'type': 'library', 'id': 'SPDXRef-Package-2-distlib', 'supplier_type': 'Person', 'supplier': 'Vinay_Sajip', 'version': '0.3.6', 'downloadlocation': 'NOASSERTION', 'filesanalysis': 'false', 'licenseconcluded': 'NOASSERTION', 'licensedeclared': 'NOASSERTION', 'externalreference': [['PACKAGE-MANAGER', 'purl', 'pkg:pypi/distlib@0.3.6']]}, {'name': 'filelock', 'type': 'library', 'id': 'SPDXRef-Package-3-filelock', 'supplier_type': 'Person', 'supplier': 'Benedikt_Schmitt', 'version': '3.8.0', 'downloadlocation': 'NOASSERTION', 'filesanalysis': 'false', 'licenseconcluded': 'Unlicense', 'licensedeclared': 'Unlicense', 'externalreference': [['PACKAGE-MANAGER', 'purl', 'pkg:pypi/filelock@3.8.0']]}, {'name': 'platformdirs', 'type': 'library', 'id': 'SPDXRef-Package-4-platformdirs', 'supplier_type': 'Organization', 'supplier': 'Unknown', 'version': '2.5.4', 'downloadlocation': 'NOASSERTION', 'filesanalysis': 'false', 'licenseconcluded': 'NOASSERTION', 'licensedeclared': 'NOASSERTION', 'externalreference': [['PACKAGE-MANAGER', 'purl', 'pkg:pypi/platformdirs@2.5.4']]}]\n>>> print (len(sbom_packages))\n4\n>>> sbom_packages[0]\n{'name': 'virtualenv', 'type': 'library', 'id': 'SPDXRef-Package-1-virtualenv', 'supplier_type': 'Person', 'supplier': 'Bernat_Gabor', 'version': '20.16.7', 'downloadlocation': 'NOASSERTION', 'filesanalysis': 'false', 'licenseconcluded': 'MIT', 'licensedeclared': 'MIT', 'externalreference': [['PACKAGE-MANAGER', 'purl', 'pkg:pypi/virtualenv@20.16.7']]}\n>>> sbom_relationships = test_parser.get_relationships()\n>>> print (sbom_relationships)\n[{'source': 'TestDocument', 'type': 'DESCRIBES', 'target': 'virtualenv', 'source_id': 'SPDXRef-DOCUMENT', 'target_id': 'SPDXRef-Package-1-virtualenv'}, {'source': 'virtualenv', 'type': 'CONTAINS', 'target': 'distlib', 'source_id': 'SPDXRef-Package-1-virtualenv', 'target_id': 'SPDXRef-Package-2-distlib'}, {'source': 'virtualenv', 'type': 'CONTAINS', 'target': 'filelock', 'source_id': 'SPDXRef-Package-1-virtualenv', 'target_id': 'SPDXRef-Package-3-filelock'}, {'source': 'virtualenv', 'type': 'CONTAINS', 'target': 'platformdirs', 'source_id': 'SPDXRef-Package-1-virtualenv', 'target_id': 'SPDXRef-Package-4-platformdirs'}]\n>>> sbom_relationships[2]\n{'source': 'virtualenv', 'type': 'CONTAINS', 'target': 'filelock', 'source_id': 'SPDXRef-Package-1-virtualenv', 'target_id': 'SPDXRef-Package-3-filelock'}\n>>> \n```\n\n### SBOMGenerator\n\nThe SBOMGenerator module provides methods for generating a SBOM in either SPDX or CycloneDX format.\n\nThe focus of the implementation is on providing a single interface regardless of the SBOM type and format.\n\nSBOMs can be generated in the following formats\n\n| SBOM Type | Version | Format    |\n| --------- |---------| ----------|\n| SPDX      | 2.2     | Tag       |\n| SPDX      | 2.2     | JSON      |\n| SPDX      | 2.2     | YAML      |\n| SPDX      | 2.3     | Tag       |\n| SPDX      | 2.3     | JSON      |\n| SPDX      | 2.3     | YAML      |\n| CycloneDX | 1.4     | JSON      |\n| CycloneDX | 1.5     | JSON      |\n| CycloneDX | 1.6     | JSON      |\n\nThe default version for CycloneDX is version 1.6. However, the version can be overridden by setting the environment variable LIB4SBOM_CYCLONEDX_VERSION to \"1.4\" if required.\n\nThe default version for SPDX is version 2.3. However, the version can be overridden by setting the environment variable LIB4SBOM_SPDX_VERSION to \"SPDX-2.2\" if required.\n\n_class_ **SBOMGenerator**(_validate_license: True, sbom_type=\"spdx\", format=\"tag\", application=\"lib4sbom\", version=\"0.1\"_)\n\nThis creates a simple SBOM Generator object. The following optional parameters can be specified:\n\n_validate_license_ indicates if license information is validated against the set of [SPDX license identifiers](https://spdx.org/licenses/). This option only applies for SPDX SBOMs\nas this is mandatory for CycloneDX SBOMs.\n\n_sbom_type_ indicates the type of SBOM to be generated. Valid options are spdx or cyclonedx\n\n_format_ indicates the format that the SBOM is to be generated in. Valid options are Tag, JSON or YAML. If an invalid format is specified,\na default format of JSON will be assumed. If an unsupported format is specified for the type of SBOM (e.g. Tag or YAML for CycloneDX), a default\nformat is assumed (Tag for SPDX, JSON for CycloneDX)\n\n_application_ and _version_ specify the name and version of the tool which created the SBOM. If these are not specified, the application name is 'lib4sbom' and the version is '0.1'\n\n**Methods**\n\n_generate(project_name, sbom_data, filename = \"\", send_to_output = True)_\n\nThe method generates the SBOM file. The parameters are\n\n_project_name_ specifies the name of the project\n\n_sbom_data_ contain the SBOM data to be used in the generation. It contains details of the packages, files and relationships to be included in the SBOM.\n\n_filename_ is the name of the file to be generated. The default is for the output to be generated to a console.\n\n_send_to_output_ indicates if the output is to be sent to the filename.\n\nget_sbom()\nReturns the generated SBOM in the requested format\n\nget_type()\nReturns the type of the generated SBOM (either spdx or cyclonedx)\n\nget_format()\nReturns the format of the generated SBOM (one of tag, json or yaml)\n\n**Example**\n\nThe following code sample shows the use of the SBOMGenerator module being used\nin the conversion of a SBOM from the Tag Value format to YAML format. The output is sent ot the console.\n\n```python\n>>> from lib4sbom.parser import SBOMParser\n>>> test_parser = SBOMParser()\n>>> test_parser.parse_file(\"test_sbom.spdx\")\n>>> from lib4sbom.generator import SBOMGenerator\n>>> test_generator = SBOMGenerator(format=\"yaml\")\n>>> test_generator.get_type()\n'spdx'\n>>> test_generator.get_format()\n'yaml'\n>>> test_generator.generate(\"TestApp\",test_parser.get_sbom())\nSPDXID: SPDXRef-DOCUMENT\ncreationInfo:\n  comment: This document has been automatically generated.\n  created: '2023-01-24T13:51:36Z'\n  creators:\n  - 'Tool: lib4sbom-0.1.0'\n  licenseListVersion: '3.18'\ndataLicense: CC0-1.0\ndocumentNamespace: http://spdx.org/spdxdocs/TestDocument-817c4e4c-eac4-49d9-bc41-65f0972edce8\nname: TestDocument\n...\n- relatedSpdxElement: SPDXRef-Package-4-platformdirs\n  relationshipType: DESCRIBES\n  spdxElementId: SPDXRef-DOCUMENT\n- relatedSpdxElement: SPDXRef-Package-2-distlib\n  relationshipType: CONTAINS\n  spdxElementId: SPDXRef-Package-1-virtualenv\n- relatedSpdxElement: SPDXRef-Package-3-filelock\n  relationshipType: CONTAINS\n  spdxElementId: SPDXRef-Package-1-virtualenv\n- relatedSpdxElement: SPDXRef-Package-4-platformdirs\n  relationshipType: CONTAINS\n  spdxElementId: SPDXRef-Package-1-virtualenv\nspdxVersion: SPDX-2.3\n>>> test_generator.get_sbom()\n{'SPDXID': 'SPDXRef-DOCUMENT', 'spdxVersion': 'SPDX-2.3', 'creationInfo': {'comment': 'This document has been automatically generated.', 'creators': ['Tool: lib4sbom-0.1.0'], 'created': '2023-01-24T13:51:36Z', 'licenseListVersion': '3.18'}, 'name': 'TestDocument', 'dataLicense': 'CC0-1.0', 'documentNamespace': 'http://spdx.org/spdxdocs/TestDocument-817c4e4c-eac4-49d9-bc41-65f0972edce8', 'packages': [{'SPDXID': 'SPDXRef-Package-1-virtualenv', 'name': 'virtualenv', 'versionInfo': '20.16.7', 'supplier': 'Person: Bernat_Gabor', 'downloadLocation': 'NONE', 'filesAnalyzed': 'false', 'licenseConcluded': 'MIT', 'licenseDeclared': 'MIT', 'copyrightText': 'NOASSERTION', 'externalRefs': [{'referenceCategory': 'PACKAGE-MANAGER', 'referenceType': 'purl', 'referenceLocator': 'pkg:pypi/virtualenv@20.16.7'}]}, {'SPDXID': 'SPDXRef-Package-2-distlib', 'name': 'distlib', 'versionInfo': '0.3.6', 'supplier': 'Person: Vinay_Sajip', 'downloadLocation': 'NONE', 'filesAnalyzed': 'false', 'licenseConcluded': 'NOASSERTION', 'licenseDeclared': 'NOASSERTION', 'copyrightText': 'NOASSERTION', 'externalRefs': [{'referenceCategory': 'PACKAGE-MANAGER', 'referenceType': 'purl', 'referenceLocator': 'pkg:pypi/distlib@0.3.6'}]}, {'SPDXID': 'SPDXRef-Package-3-filelock', 'name': 'filelock', 'versionInfo': '3.8.0', 'supplier': 'Person: Benedikt_Schmitt', 'downloadLocation': 'NONE', 'filesAnalyzed': 'false', 'licenseConcluded': 'Unlicense', 'licenseDeclared': 'Unlicense', 'copyrightText': 'NOASSERTION', 'externalRefs': [{'referenceCategory': 'PACKAGE-MANAGER', 'referenceType': 'purl', 'referenceLocator': 'pkg:pypi/filelock@3.8.0'}]}, {'SPDXID': 'SPDXRef-Package-4-platformdirs', 'name': 'platformdirs', 'versionInfo': '2.5.4', 'supplier': 'Organization: Unknown', 'downloadLocation': 'NONE', 'filesAnalyzed': 'false', 'licenseConcluded': 'NOASSERTION', 'licenseDeclared': 'NOASSERTION', 'copyrightText': 'NOASSERTION', 'externalRefs': [{'referenceCategory': 'PACKAGE-MANAGER', 'referenceType': 'purl', 'referenceLocator': 'pkg:pypi/platformdirs@2.5.4'}]}], 'relationships': [{'spdxElementId': 'SPDXRef-DOCUMENT', 'relatedSpdxElement': 'SPDXRef-Package-1-virtualenv', 'relationshipType': 'DESCRIBES'}, {'spdxElementId': 'SPDXRef-DOCUMENT', 'relatedSpdxElement': 'SPDXRef-Package-2-distlib', 'relationshipType': 'DESCRIBES'}, {'spdxElementId': 'SPDXRef-DOCUMENT', 'relatedSpdxElement': 'SPDXRef-Package-3-filelock', 'relationshipType': 'DESCRIBES'}, {'spdxElementId': 'SPDXRef-DOCUMENT', 'relatedSpdxElement': 'SPDXRef-Package-4-platformdirs', 'relationshipType': 'DESCRIBES'}, {'spdxElementId': 'SPDXRef-Package-1-virtualenv', 'relatedSpdxElement': 'SPDXRef-Package-2-distlib', 'relationshipType': 'CONTAINS'}, {'spdxElementId': 'SPDXRef-Package-1-virtualenv', 'relatedSpdxElement': 'SPDXRef-Package-3-filelock', 'relationshipType': 'CONTAINS'}, {'spdxElementId': 'SPDXRef-Package-1-virtualenv', 'relatedSpdxElement': 'SPDXRef-Package-4-platformdirs', 'relationshipType': 'CONTAINS'}]}\n>>> \n```\n\n### SBOMOutput\n\n_class_ **SBOMOutput**(_filename=\"\", output_format=\"tag\"_)\n\nThis creates a simple SBOM Output object. The following optional parameters can be specified:\n\n_filename_ indicates the output destination of the SBOM to be generated. If a valid filename path is provided and a file can be created, then the output will be to a file otherwise\nit will be output to the console.\n\n_output_format_ indicates the format that the SBOM is to be generated in. Valid options are Tag, JSON or YAML. If an invalid format is specified,\na default format of Tag will be assumed.\n\n**Methods**\n\ngenerate_output(dataset) Outputs a SBOM file. The parameters are\n\n_dataset_ contains SBOM data in the output format. If the SBOM data is NOT in the format specified by the output_format parameter, no output will be generated.\n\n**NOTE A valid dataset will normally be generated by the SBOMGenerator class and obtained by a call to the get_sbom() method.**\n\nget_type()\nReturn the destination of the generated SBOM. Either file or console\n\nget_format()\nReturn the format of the generated SBOM. One of Tag, JSON or YAML.\n\n**Example**\n\nThe following code sample shows the use of the SBOMOutput module.\n\n```python\n>>> from lib4sbom.parser import SBOMParser\n>>> test_parser = SBOMParser()\n>>> test_parser.parse_file(\"test_sbom.spdx\")\n>>> from lib4sbom.generator import SBOMGenerator\n>>> test_generator = SBOMGenerator(format=\"json\")\n>>> test_generator.generate(\"TestApp\",test_parser.get_sbom())\n>>> from lib4sbom.output import SBOMOutput\n>>> sbom_output = SBOMOutput(filename=\"testapp.json\", output_format=\"json\")\n>>> sbom_output.generate_output(test_generator.get_sbom())\n>>> \n```\n\n### SBOM Object \n\n_class_ **SBOM**()\n\nThis creates a simple SBOM object. This object contains all the items to be contained within the SBOM including\ncomponents and relationships. It is left to the application manipulating the SBOM object to apply validation as appropriate\nfor the presence of each attribute.\n\n**Methods**\n\n**_Setter Methods_**\n\nFor the following attributes, a method **_set_attribute(value)_** is provided. Note that the attribute name is always in _lowercase_.\ne.g. set_type(). Unless indicated, the method just takes a single parameter for the value. Where indicated, multiple instances of the attribute may be defined.\n\n| Attribute         | Multiple | Note |\n|-------------------|----------|------|\n| Version           | No       | (1)  |\n| Type              | No       | (2)  |\n| Uuid              | No       | (3)  |\n| Bom_Version       | No       |      |\n\n**Note**\n\n1. This relates to the version of the specification of SBOM specified by the type atrribute. e.g. 1.4 for CycloneDX, SPDX-2.3 for SPDX.\n\n2. This refers to the type of SBOM either SPDX or CycloneDX.\n\n3. This relates to the unique identifier for the SBOM.\n\n**_Getter Methods_**\n\nget_sbom()\nReturns the SBOM object as a dictionary.\n\n**Example**\n\n```python\n>>> from lib4sbom.sbom import SBOM\n>>> sbom = SBOM()\n>>> sbom.set_type(sbom_type='cyclonedx')\n>>> sbom.set_version(\"1.4\")\n>>> sbom.set_uuid(\"urn:uuid:My_uuid_1234\")\n>>> sbom.set_bom_version(\"2\")\n>>> sbom.get_type()\n'cyclonedx'\n>>> from lib4sbom.data.document import SBOMDocument\n>>> my_doc = SBOMDocument()\n>>> my_doc.set_metadata_type(\"firmware\")\n>>> sbom.add_document(my_doc.get_document())\n```\n\n### SBOMDocument Object \n\n_class_ **SBOMDocument**()\n\nThis creates a simple SBOMDocument object. This object contains the values of the attributes\nthat can be associated with a SBOM. This includes attributes such as name, identifier, type of file,\nchecksum and licence information. As each of the attributes are optional, it is left to the application manipulating the\nSBOMFile object to apply validation as appropriate for the presence of each attribute.\n\n**Methods**\n\n**_Setter Methods_**\n\nFor the following attributes, a method **_set_attribute(value)_** is provided. Note that the attribute name is always in _lowercase_.\ne.g. set_filetype(). The attribute names are aligned with the attributes of the File Object in the SPDX Specification. Unless\nindicated, the method just takes a single parameter for the value. Where indicated, multiple instances of the attribute may be defined.\n\n| Attribute         | Multiple | Note |\n|-------------------|----------|------|\n| Name              | No       |      |\n| Id                | No       |      |\n| DataLicense       | No       |      |\n| Metadata_Type     | No       | (1)  |\n| Metadata_Supplier | No       |      |\n| Metadata_Version  | No       |      |\n| Bom_Version       | No       |      |\n\n**Note**\n\n1. This relates to the type of component which the SBOM is describing. This is attribute is only used for CycloneDX SBOMs.\n\nThere is an additional setter method, **set_value**(_attribute, value_) which allows the setting of any attribute.\n\n`set_value(\"language\", \"Rust\")`\n\n**_Getter Methods_**\n\nget_document()\nReturns the SBOMDocument object as a list.\n\nget_name()\nReturns the name of the SBOMDocument object or a default value if the attribute does not exist within the instance of the SBOMDocument object.\n\nget_value(attribute)\nReturns the value of the attribute. A default value is returned if the attribute does not exist within the instance of the SBOMDocument object.\n\n**Example**\n\n```python\n>>> from lib4sbom.data.document import SBOMDocument\n>>> sbom_document = SBOMDocument()\n>>> sbom_document.set_name(\"test_file\")\n>>> sbom_document.set_metadata_type(\"firmware\")\n>>> sbom_document.get_name()\n'test_file'\n>>> from lib4sbom.sbom import SBOM\n>>> my_sbom = SBOM()\n>>> my_sbom.add_document(sbom_document.get_document())\n```\n\n### SBOMFile Object\n\n_class_ **SBOMFile**()\n\nThis creates a simple SBOM File object. This object contains the values of the attributes\nthat can be associated with a file artefact within an SBOM. This includes attributes such as name, identifier, type of file,\nchecksum and licence information. As each of the attributes are optional, it is left to the application manipulating the\nSBOMFile object to apply validation as appropriate for the presence of each attribute.\n\n**Methods**\n\n**_Setter Methods_**\n\nFor the following attributes, a method **_set_attribute(value)_** is provided. Note that the attribute name is always in _lowercase_.\ne.g. set_filetype(). The attribute names are aligned with the attributes of the File Object in the SPDX Specification. Unless\nindicated, the method just takes a single parameter for the value. Where indicated, multiple instances of the attribute may be defined.\n\n| Attribute         | Multiple | Note |\n|-------------------|----------|------|\n| Name              | No       |      |\n| Id                | No       |      |\n| FileType          | Yes      |      |\n| Checksum          | Yes      | (1)  |\n| LicenseConcluded  | No       |      |\n| LicenceInfoInFile | Yes      |      |\n| LicenceComment    | No       |      |\n| CopyrightText     | No       |      |\n| Comment           | No       |      |\n| Notice            | No       |      |\n| Contributor       | Yes      |      |\n| Attribution       | No       |      |\n\n**Note**\n\n1. The set_checksum method takes two parameters, the checksum algorithm (e.g. SHA256) and the actual checksum value (as a string)\n\nThere is an additional setter method, **set_value**(_attribute, value_) which allows the setting of any attribute.\n\n`set_value(\"language\", \"Rust\")`\n\n**_Getter Methods_**\n\nget_file()\nReturns the SBOMFile object as a dictionary. The value of an attribute is returned as a string except where multiple instances of an attribute are allowed in which\ncase the value of the attribute is returned as a List.\n\nget_name()\nReturns the name of the SBOMFile object or None if the 'name' attribute does not exist within the instance of the SBOMFile object.\n\nget_value(attribute)\nReturns the value of the attribute. A default value is returned if the attribute does not exist within the instance of the SBOMFile object.\n\n_**Utility Methods**_\n\ninitialise() Reinitialises a SBOMFile Object. All data associated with the object is deleted.\n\n**Example**\n\n```python\n>>> from lib4sbom.data.file import SBOMFile\n>>> sbom_file = SBOMFile()\n>>> sbom_files = {}\n>>> sbom_file.initialise()\n>>> sbom_file.set_name(\"test_file.c\")\n>>> sbom_file.set_licenseconcluded(\"MIT\")\n>>> file_hash = <<< some calculation >>>\n>>> sbom_file.set_checksum(\"SHA1\", file_hash)\n>>> sbom_file.set_id(\"SPDXRef-File-0001\")\n>>> sbom_files[sbom_file.get_name()] = sbom_file.get_file()\n>>> sbom_file.initialise()                                  \n>>> sbom_file.set_name(\"makefile\")                       \n>>> sbom_file.set_licenseconcluded(\"NOASSERTION\")                    \n>>> sbom_file.set_id(\"SPDXRef-File-0002\")                   \n>>> sbom_files[sbom_file.get_name()] = sbom_file.get_file()\n>>> from lib4sbom.sbom import SBOM\n>>> my_sbom = SBOM()\n>>> my_sbom.add_files(sbom_files)\n```\n\n### SBOMPackage Object\n                \n_class_ **SBOMPackage**()\n\nThis creates a simple SBOM Package object. This object contains the values of the attributes\nthat can be associated with a package or component artefact within an SBOM. This includes attributes such as name, identifier, supplier,\nversion and licence information. As each of the attributes are optional, it is left to the application manipulating the\nSBOMPackage object to apply validation as appropriate for the presence of each attribute.\n\n**_Setter Methods_**\n\nFor the following attributes, a method **_set_attribute(value)_** is provided. Note that the attribute name is always in _lowercase_.\ne.g. set_version(). The attribute names are aligned with the attributes of the Package Object in the SPDX Specification. Unless\nindicated, the method just takes a single parameter for the value. Where indicated, multiple instances of the attribute may be defined.\n\n| Attribute         | Multiple | Note |\n|-------------------|----------|------|\n| Name              | No       |      |\n| Id                | No       |      |\n| Type              | No       | (1)  |\n| Checksum          | Yes      | (2)  |\n| LicenseConcluded  | No       |      |\n| LicenseDeclared   | No       | (3)  |\n| LicenceInfoInFile | Yes      |      |\n| LicenceComments   | No       |      |\n| FilesAnalysis     | No       |      |\n| CopyrightText     | No       |      |\n| Comment           | No       |      |\n| Originator        | No       |      |\n| Supplier          | No       |      |\n| Version           | No       |      |\n| Homepage          | No       |      |\n| Property          | Yes      | (4)  |\n| DownloadLocation  | No       |      |\n| Description       | No       |      |\n| ExternalReference | Yes      | (5)  |\n| Cpe               | No       |      |\n| Purl              | No       | (6)  |\n| Summary           | No       |      |\n| SourceInfo        | No       |      |\n| Filename          | No       |      |\n\n**Note**\n\n1. The set_type method is used to indicate the purpose of the package (e.g. Application, Library, Operating-System).\n\n2. The set_checksum method takes two parameters, the checksum algorithm (e.g. SHA256) and the actual checksum value (as a string)\n\n3. The set_licensedeclared method takes an optional second parameter which is the license name. In this case the first parameter, license, is assumed to be the license text rather than the license identity.\n\n4. The set_property method takes two parameters which are the property name and value.\n\n5. The set_externalreference method takes three parameters which are the category (SECURITY or PACKAGE_MANAGER), type (cpe22Type, cpe23Type or purl) and the element corresponding to the tyoe.\n\n6. The set_cpe takes an optional second parameter which is the CPE type (default is cpeType23).\n\nThere is an additional setter method, **set_value**(_attribute, value_) which allows the setting of any attribute.\n\n`set_value(\"language\", \"Rust\")`\n\n**_Getter Methods_**\n\nget_package()\nReturns the SBOMPackage object as a dictionary. The value of an attribute is returned as a string except where multiple instances of an attribute are allowed in which\ncase the value of the attribute is returned as a List.\n\nget_name()\nReturns the name of the SBOMPackage object or None if the 'name' attribute does not exist within the instance of the SBOMPackage object.\n\nget_value(attribute)\nReturns the value of the attribute. A default value is returned if the attribute does not exist within the instance of the SBOMPackage object.\n\nget_purl()\nReturns the PURL identifier as a string for the package or None if no PURL element is defined.\n\nget_cpe()\nReturns the CPE identifier as a string for the package or None if no CPE element is defined.\n\n**_Utility Methods_**\n\ninitialise() Reinitialises a SBOMPackage Object. All data associated with the object is deleted.\n\n**Example**\n\n```python\n>>> from lib4sbom.data.package import SBOMPackage\n>>> sbom_packages = {}\n>>> my_package = SBOMPackage()\n>>> my_package.set_name(\"glibc\")\n>>> my_package.set_version(\"2.15\")\n>>> my_package.set_supplier(\"organisation\",\"gnu\")\n>>> my_package.set_licensedeclared(\"GPL3\")\n>>> sbom_packages[(my_package.get_name(), my_package.get_value('version'))] = my_package.get_package()\n>>> my_package.initialise()\n>>> my_package.set_name(\"tomcat\")\n>>> my_package.set_version(\"9.0.46\")\n>>> my_package.set_supplier(\"organisation\",\"apache\")\n>>> my_package.set_licensedeclared(\"Apache-2.0\")\n>>> sbom_packages[(my_package.get_name(), my_package.get_value('version'))] = my_package.get_package()\n>>> from lib4sbom.sbom import SBOM\n>>> my_sbom = SBOM()\n>>> my_sbom.add_packages(sbom_packages)\n```\n\n### SBOMRelationship Object\n\n_class_ **SBOMRelationship**()\n\nThis creates a simple SBOMRelationship object which is used to show the relationship between two items within an SBOM.\nAs there are multiple types of relationships, it is left to the application manipulating the\nSBOMRelationship object to apply validation as appropriate to ensure the semantics of the relationship are correct.\n\n**_Setter Methods_**\n\nset_relationship (source, type, target)\n\n_source_ and _target_ are the unique identifiers of the components for which the relationship is being defined.\n\n_type_ is the type of relationship being defined.\n\n**_Getter Methods_**\n\nget_relationship()\nReturns the SBOMRelationship object as a dictionary.\n\n**Example**\n\n```python\n>>> from lib4sbom.data.relationship import SBOMRelationship\n>>> sbom_relationships = []\n>>> my_relationship = SBOMRelationship()\n>>> my_relationship.set_relationship(\"Package-1\",\"CONTAINS\", \"Package-2\")\n>>> sbom_relationships.append(my_relationship)\n>>> from lib4sbom.sbom import SBOM\n>>> my_sbom = SBOM()\n>>> my_sbom.add_relationships(sbom_relationships)\n```\n\n### Vulnerability Object\n\n_class_ **Vulnerability**(validation = None)\n\nThis creates a simple vulnerability object which is used to define the details of a vulnerability typically for a component\nspecified within an SBOM. As there are multiple ways of specifying the status of a vulnerability, it is left to the\napplication manipulating the Vulnerability object to apply validation as appropriate to ensure the semantics of the vulnerability are correct.\n\nThe following optional parameter can be specified:\n\n_validation_ indicates that the status field is to be validated against the [OpenVEX](https://openvex.dev), [CycloneDX](https://www.cyclonedx.org) or [CSAF](https://docs.oasis-open.org/csaf/csaf/v2.0/csaf-v2.0.html) specifcaitions.\n\n**NOTE** Vulnerability objects are only included in CyclonedDX SBOMs\n\n**_Setter Methods_**\n\nFor the following attributes, a method **_set_attribute(value)_** is provided. Note that the attribute name is always in _lowercase_.\ne.g. set_release(). Each method takes a single parameter for the value. Multiple instances of the attribute are not allowed.\n\n\n| Attribute         | Multiple | Note |\n|-------------------|----------|------|\n| Name              | No       |      |\n| Id                | No       | (1)  |\n| Release           | No       |      |\n| Status            | No       | (2)  |\n| Comment           | No       | (3)  |\n| Description       | No       | (4)  |\n\n\n**Note**\n\n1. The set_id method is used to indicate the identity of the vulnerability e.g. CVE-2021-44228\n\n2. The set_status is used to indicate the status of the vulnerability. Validation of the value of status may be optionally performed as determined by\nthe optional parameter _validation_ specified in the creation of the Vulnerability object. An invalid status is indicated by a value of None.\n\n3. The set_comment method is used to provide additional information to support the status value e.g. a brief justification\n\n4. The set_description method is used to describe the vulnerability.\n\nThere is an additional setter method, **set_value**(_attribute, value_) which allows the setting of any attribute.\n\n`set_value(\"bom-ref\", \"rust@1.2.3\")`\n\n**_Getter Methods_**\n\nget_vulnerability()\nReturns the vulnerability object as a dictionary.\n\n**Example**\n\n```python\n>>> from lib4sbom.data.vulnerability import Vulnerability\n>>> vulnerabilities = []\n>>> vulnerability = Vulnerability(validation=\"cyclonedx\")\n>>> vulnerability.set_id(\"CVE-2023-1235\")\n>>> vulnerability.set_name(\"rust\")\n>>> vulnerability.set_release(\"1.2.3\")\n>>> vulnerability.set_value(\"bom-ref\", \"rust@1.2.3\")\n>>> vulnerability.set_status(\"in_triage\")\n>>> vulnerabilities.append(vulnerability.get_vulnerability())\n>>> from lib4sbom.sbom import SBOM\n>>> my_sbom = SBOM()\n>>> my_sbom.add_vulnerabilities(vulnerabilities)\n```\n\n### Services Object\n\n_class_ **SBOMService**(validation = None)\n\nThis creates a simple software service object which is used to define the details of a software service.\nAs there are multiple ways of specifying a service, it is left to the\napplication manipulating the service object to apply validation as appropriate to ensure the semantics of the service are correct.\n\n**NOTE** Services objects are only included in CyclonedDX SBOMs\n\n**_Setter Methods_**\n\nFor the following attributes, a method **_set_attribute(value)_** is provided. Note that the attribute name is always in _lowercase_.\ne.g. set_release(). Each method takes a single parameter for the value. Multiple instances of the attribute are not allowed.\n\n\n| Attribute        | Multiple | Note |\n|------------------|----------|------|\n| Name             | No       |      |\n| Id               | No       | (1)  |\n| Version          | No       |      |\n| Provider         | No       | (2)  |\n| Endpoint         | Yes      |      |\n| Data             | Yes      | (3)  |\n| Property         | Yes      | (4)  |\n| License          | Yes      |      |\n| Exernalreference | Yes      | (5)  |\n| Description      | No       |      |\n\n\n**Note**\n\n1. The set_id method is used to indicate the identity of the service. If this is not specified, an id will be automatically generated.\n\n2. The set_provider is used to specify details of the service provider. There are multiple parameters which can be specified (name, url, contactname, email address and phone) at least one must be specified.\n\n3. The set_data method is used to provide additional information to describe the data being exhanged. There are two mandatatory parameters flow type (\"Inbound\", \"Outbound\", \"Bi-directional\" or \"Unknown\") and classification, and two optional paramters name and description.\n\n4. The set_property method takes two parameters which are the property name and value.\n\n5. The set_externalreference method takes three parameters, the URL, the type of information being referenced and an optional comment.\n\nThere is an additional setter method, **set_value**(_attribute, value_) which allows the setting of any attribute.\n\n`set_value(\"trustzone\", \"Data_DMZ\")`\n\n**_Getter Methods_**\n\nget_service()\nReturns the service object as a dictionary.\n\n**Example**\n\n```python\n>>> from lib4sbom.data.service import SBOMService\n>>> sbom_services = {}\n>>> my_service=SBOMService()\n>>> my_service.set_name(\"Microsoft 365\")\n>>> my_service.set_version(\"2022.04\")\n>>> my_service.set_provider(name=\"Microsoft Inc.\", contact=\"Fred Flintstone\", email=\"fred@micrsoft.com\")\n>>> my_service.set_description(\"Business productivity suite\")\n>>> my_service.set_value(\"authenticated\",True)\n>>> my_service.set_endpoint(\"www.microsoft.com\")\n>>> my_service.set_endpoint(\"www.microsoft.com/owa\")\n>>> my_service.set_data(\"Bi-directional\",\"None\",description=\"document\")\n>>> my_service.set_data(\"outbound\",\"PII\",name=\"User information\")\n>>> my_service.set_license(\"Apache-2.0\")\n>>> my_service.set_license(\"MIT\")\n>>> my_service.set_property(\"Data_Location\",\"EU\")\n>>> my_service.set_externalreference(\"https://www.microsoft.com\",\"Website\", \"Company website\")\n>>> sbom_services[(my_service.get_name(), my_service.get_value('version'))] = my_service.get_service()\n>>> from lib4sbom.sbom import SBOM\n>>> my_sbom = SBOM()\n>>> my_sbom.add_services(sbom_services)\n```\n\n## Examples\n\nA number of example scripts are included in the _examples_ subdirectory.\n\t\t\t\t\t\t\n## Implementation Notes\n\nThe following design decisions have been made in processing the SBOM files:\n\n1. It is assumed that the SBOM is valid and contains syntactically valid data.\n\n2. In SPDX format, the tool assumes that the name of a package preceeds the version and license of the package.\n\n3. In SPDX format, the current implementation does not currently handle multi-line elements.\n\n4. When processing and validating licenses, the application will use a set of synonyms to attempt to map some license identifiers to the correct [SPDX License Identifiers](https://spdx.org/licenses/). However, the\nuser of the tool is reminded that they should assert the quality of any data which is provided by the tool particularly where the license identifier has been modified.\n\n## Future Development\n\n1. Support later versions of SPDX (3.0).\n\n2. Enhance validation of SBOM data to check for all mandatory elements.\n\n3. Implement Python typing across modules.\n\n4. Migrate packaging infrastructure away from setup.py.\n\n5. Utilise third-party SPDX and CycloneDX parsers and generators\n\n6. Add further support for SPDX XML and RDF formats\n\n7. Add generator for CycloneDX XML documents.\n\n8. Implement test suite.\n\n## License\n\nLicensed under the Apache 2.0 Licence.\n\nThe tool uses a local copy of the [SPDX Licenses List](https://github.com/spdx/license-list-data) which is released under\n[Creative Commons Attribution 3.0 (CC-BY-3.0)](http://creativecommons.org/licenses/by/3.0/).\n\nThis tool uses information sourced from the [Blue Oak Council's License List](https://blueoakcouncil.org/list) which is released under\n[Creative Commons Attribution 1.0 (CC-BY-1.0)](https://creativecommons.org/licenses/by/1.0/).\n\n## Limitations\n\nThis tool is meant to support software development. The usefulness of the tool is dependent on the SBOM data\nwhich is provided to the tool. Unfortunately, the tool is unable to determine the validity or completeness of such a SBOM file; users of the tool\nare therefore reminded that they should assert the quality of any data which is provided to the tool.\n\n## Feedback and Contributions\n\nBugs and feature requests can be made via GitHub Issues.\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "security",
          "tools",
          "SBOM",
          "DevSecOps",
          "SPDX",
          "CycloneDX",
          "library"
        ],
        "home_page": "https://github.com/anthonyharrison/lib4sbom",
        "author": "Anthony Harrison",
        "author_email": "anthony.p.harrison@gmail.com",
        "maintainer": "Anthony Harrison",
        "maintainer_email": "anthony.p.harrison@gmail.com",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_dist": [
          "pyyaml (>=5.4)",
          "semantic-version",
          "defusedxml"
        ],
        "requires_python": ">=3.7"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\lib4sbom-0.7.5.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "license-expression",
        "version": "30.3.1",
        "summary": "license-expression is a comprehensive utility library to parse, compare, simplify and normalize license expressions (such as SPDX license expressions) using boolean logic.",
        "description": "==================\nlicense-expression\n==================\n\n``license-expression`` is a comprehensive utility library to parse, compare,\nsimplify and normalize license expressions (such as SPDX license expressions)\nusing boolean logic.\n\n- License: Apache-2.0\n- Python: 3.8+\n- Homepage: https://github.com/aboutcode-org/license-expression/\n- Install: `pip install license-expression` also available in most Linux distro.\n\nSoftware project licenses are often a combination of several free and open\nsource software licenses. License expressions -- as specified by SPDX -- provide\na concise and human readable way to express these licenses without having to\nread long license texts, while still being machine-readable.\n\nLicense expressions are used by key FOSS projects such as Linux; several\npackages ecosystem use them to document package licensing metadata such as\nnpm and Rubygems; they are important when exchanging software data (such as with\nSPDX and SBOM in general) as a way to express licensing precisely.\n\n``license-expression`` is a comprehensive utility library to parse, compare,\nsimplify and normalize these license expressions (such as SPDX license expressions)\nusing boolean logic like in: `GPL-2.0-or-later WITH Classpath-exception-2.0 AND MIT`.\n\nIt includes the license keys from SPDX https://spdx.org/licenses/ (version 3.23)\nand ScanCode license DB (version 32.0.8, last published on 2023-02-27).\nSee https://scancode-licensedb.aboutcode.org/ to get started quickly.\n\n``license-expression`` is both powerful and simple to use and is a used as the\nlicense expression engine in several projects and products such as:\n\n- AboutCode-toolkit https://github.com/aboutcode-org/aboutcode-toolkit\n- AlekSIS (School Information System) https://edugit.org/AlekSIS/official/AlekSIS-Core\n- Barista https://github.com/Optum/barista\n- Conda forge tools https://github.com/conda-forge/conda-smithy\n- DejaCode https://dejacode.com\n- DeltaCode https://github.com/nexB/deltacode\n- FenixscanX https://github.com/SmartsYoung/FenixscanX\n- FetchCode https://github.com/aboutcode-org/fetchcode\n- Flict https://github.com/vinland-technology/flict and https://github.com/vinland-technology\n- license.sh https://github.com/webscopeio/license.sh\n- liferay_inbound_checker https://github.com/carmenbianca/liferay_inbound_checker\n- REUSE https://reuse.software/ and https://github.com/fsfe/reuse-tool\n- ScanCode-io https://github.com/aboutcode-org/scancode.io\n- ScanCode-toolkit https://github.com/aboutcode-org/scancode-toolkit\n\nSee also for details:\n- https://spdx.github.io/spdx-spec/appendix-IV-SPDX-license-expressions/\n\n``license-expression`` is also packaged for most Linux distributions. See below.\n\nAlternative:\n\nThere is no known alternative library for Python, but there are several similar\nlibraries in other languages (but not as powerful of course!):\n\n- JavaScript https://github.com/jslicense/spdx-expression-parse.js\n- Rust https://github.com/ehuss/license-exprs\n- Haskell https://github.com/phadej/spdx\n- Go https://github.com/kyoh86/go-spdx\n- Ada https://github.com/Fabien-Chouteau/spdx_ada\n- Java https://github.com/spdx/tools and https://github.com/aschet/spdx-license-expression-tools\n\nBuild and tests status\n======================\n\n+--------------------------+------------------------+----------------------------------+\n|**Linux & macOS (Travis)**| **Windows (AppVeyor)** |**Linux, Windows & macOS (Azure)**|\n+==========================+========================+==================================+\n|                          |                        |                                  |\n| |travis-badge-icon|      | |appveyor-badge-icon|  |   |azure-badge-icon|             |\n|                          |                        |                                  |\n+--------------------------+------------------------+----------------------------------+\n\nSource code and download\n========================\n\n- GitHub https://github.com/aboutcode-org/license-expression.git\n- PyPI https://pypi.python.org/pypi/license-expression\n\nAlso available in several Linux distros:\n\n- Arch Linux https://archlinux.org/packages/extra/any/python-license-expression/\n- Debian https://packages.debian.org/unstable/source/license-expression\n- DragonFly BSD https://github.com/DragonFlyBSD/DPorts/tree/master/textproc/py-license-expression\n- Fedora https://src.fedoraproject.org/rpms/python-license-expression/\n- FreeBSD https://www.freshports.org/textproc/py-license-expression\n- NixOS https://github.com/NixOS/nixpkgs/blob/release-21.05/pkgs/development/python-modules/license-expression/default.nix\n- openSUSE https://build.opensuse.org/package/show/openSUSE:Factory/python-license-expression\n\n\nSupport\n=======\n\n- Submit bugs and questions at: https://github.com/aboutcode-org/license-expression/issues\n- Join the chat at: https://gitter.im/aboutcode-org/discuss\n\nDescription\n===========\n\nThis module defines a mini language to parse, validate, simplify, normalize and\ncompare license expressions using a boolean logic engine.\n\nThis supports SPDX license expressions and also accepts other license naming\nconventions and license identifiers aliases to resolve and normalize any license\nexpressions.\n\nUsing boolean logic, license expressions can be tested for equality, containment,\nequivalence and can be normalized or simplified.\n\nIt also bundles the SPDX License list (3.20 as of now) and the ScanCode license\nDB (based on latest ScanCode) to easily parse and validate expressions using\nthe license symbols.\n\n\nUsage examples\n==============\n\nThe main entry point is the ``Licensing`` object that you can use to parse,\nvalidate, compare, simplify and normalize license expressions.\n\nCreate an SPDX Licensing and parse expressions::\n\n\t>>> from license_expression import get_spdx_licensing\n\t>>> licensing = get_spdx_licensing()\n\t>>> expression = ' GPL-2.0 or LGPL-2.1 and mit '\n\t>>> parsed = licensing.parse(expression)\n\t>>> print(parsed.pretty())\n\tOR(\n\t  LicenseSymbol('GPL-2.0-only'),\n\t  AND(\n\t    LicenseSymbol('LGPL-2.1-only'),\n\t    LicenseSymbol('MIT')\n\t  )\n\t)\n\n\t>>> str(parsed)\n\t'GPL-2.0-only OR (LGPL-2.1-only AND MIT)'\n\n\t>>> licensing.parse('unknwon with foo', validate=True, strict=True)\n\tlicense_expression.ExpressionParseError: A plain license symbol cannot be used\n\tas an exception in a \"WITH symbol\" statement. for token: \"foo\" at position: 13\n\n\t>>> licensing.parse('unknwon with foo', validate=True)\n\tlicense_expression.ExpressionError: Unknown license key(s): unknwon, foo\n\n\t>>> licensing.validate('foo and MIT and GPL-2.0+')\n\tExpressionInfo(\n\t    original_expression='foo and MIT and GPL-2.0+',\n\t    normalized_expression=None,\n\t    errors=['Unknown license key(s): foo'],\n\t    invalid_symbols=['foo']\n\t)\n\n\nCreate a simple Licensing and parse expressions::\n\n    >>> from license_expression import Licensing, LicenseSymbol\n    >>> licensing = Licensing()\n    >>> expression = ' GPL-2.0 or LGPL-2.1 and mit '\n    >>> parsed = licensing.parse(expression)\n    >>> expression = ' GPL-2.0 or LGPL-2.1 and mit '\n    >>> expected = 'GPL-2.0-only OR (LGPL-2.1-only AND mit)'\n    >>> assert str(parsed) == expected\n    >>> assert parsed.render('{symbol.key}') == expected\n\n\nCreate a Licensing with your own license symbols::\n\n    >>> expected = [\n    ...   LicenseSymbol('GPL-2.0'),\n    ...   LicenseSymbol('LGPL-2.1'),\n    ...   LicenseSymbol('mit')\n    ... ]\n    >>> assert licensing.license_symbols(expression) == expected\n    >>> assert licensing.license_symbols(parsed) == expected\n\n    >>> symbols = ['GPL-2.0+', 'Classpath', 'BSD']\n    >>> licensing = Licensing(symbols)\n    >>> expression = 'GPL-2.0+ with Classpath or (bsd)'\n    >>> parsed = licensing.parse(expression)\n    >>> expected = 'GPL-2.0+ WITH Classpath OR BSD'\n    >>> assert parsed.render('{symbol.key}') == expected\n\n    >>> expected = [\n    ...   LicenseSymbol('GPL-2.0+'),\n    ...   LicenseSymbol('Classpath'),\n    ...   LicenseSymbol('BSD')\n    ... ]\n    >>> assert licensing.license_symbols(parsed) == expected\n    >>> assert licensing.license_symbols(expression) == expected\n\nAnd expression can be deduplicated, to remove duplicate license subexpressions\nwithout changing the order and without consider license choices as simplifiable::\n\n    >>> expression2 = ' GPL-2.0 or (mit and LGPL 2.1) or bsd Or GPL-2.0  or (mit and LGPL 2.1)'\n    >>> parsed2 = licensing.parse(expression2)\n    >>> str(parsed2)\n    'GPL-2.0 OR (mit AND LGPL 2.1) OR BSD OR GPL-2.0 OR (mit AND LGPL 2.1)'\n    >>> assert str(parsed2.simplify()) == 'BSD OR GPL-2.0 OR (LGPL 2.1 AND mit)'\n\nExpression can be simplified, treating them as boolean expressions::\n\n    >>> expression2 = ' GPL-2.0 or (mit and LGPL 2.1) or bsd Or GPL-2.0  or (mit and LGPL 2.1)'\n    >>> parsed2 = licensing.parse(expression2)\n    >>> str(parsed2)\n    'GPL-2.0 OR (mit AND LGPL 2.1) OR BSD OR GPL-2.0 OR (mit AND LGPL 2.1)'\n    >>> assert str(parsed2.simplify()) == 'BSD OR GPL-2.0 OR (LGPL 2.1 AND mit)'\n\nTwo expressions can be compared for equivalence and containment:\n\n    >>> expr1 = licensing.parse(' GPL-2.0 or (LGPL 2.1 and mit) ')\n    >>> expr2 = licensing.parse(' (mit and LGPL 2.1)  or GPL-2.0 ')\n    >>> licensing.is_equivalent(expr1, expr2)\n    True\n    >>> licensing.is_equivalent(' GPL-2.0 or (LGPL 2.1 and mit) ',\n    ...                         ' (mit and LGPL 2.1)  or GPL-2.0 ')\n    True\n    >>> expr1.simplify() == expr2.simplify()\n    True\n    >>> expr3 = licensing.parse(' GPL-2.0 or mit or LGPL 2.1')\n    >>> licensing.is_equivalent(expr2, expr3)\n    False\n    >>> expr4 = licensing.parse('mit and LGPL 2.1')\n    >>> expr4.simplify() in expr2.simplify()\n    True\n    >>> licensing.contains(expr2, expr4)\n    True\n\nDevelopment\n===========\n\n- Checkout a clone from https://github.com/aboutcode-org/license-expression.git\n\n- Then run ``./configure --dev`` and then ``source tmp/bin/activate`` on Linux and POSIX.\n  This will install all dependencies in a local virtualenv, including\n  development deps.\n\n- On Windows run  ``configure.bat --dev`` and then ``Scripts\\bin\\activate`` instead.\n\n- To run the tests, run ``pytest -vvs``\n\n\n.. |travis-badge-icon| image:: https://api.travis-ci.org/nexB/license-expression.png?branch=master\n    :target: https://travis-ci.org/nexB/license-expression\n    :alt: Travis tests status\n    :align: middle\n\n.. |appveyor-badge-icon| image:: https://ci.appveyor.com/api/projects/status/github/nexB/license-expression?svg=true\n    :target: https://ci.appveyor.com/project/nexB/license-expression\n    :alt: Appveyor tests status\n    :align: middle\n\n.. |azure-badge-icon| image:: https://dev.azure.com/nexB/license-expression/_apis/build/status/nexB.license-expression?branchName=master\n    :target: https://dev.azure.com/nexB/license-expression/_build/latest?definitionId=2&branchName=master\n    :alt: Azure pipelines tests status\n    :align: middle\n\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "open source",
          "license expression",
          "license",
          "spdx",
          "boolean",
          "parse expression",
          "normalize expression",
          "compare expression",
          "licence"
        ],
        "home_page": "https://github.com/aboutcode-org/license-expression",
        "author": "nexB. Inc. and others",
        "author_email": "info@aboutcode.org",
        "license": "Apache-2.0",
        "license_file": [
          "apache-2.0.LICENSE",
          "NOTICE",
          "AUTHORS.rst",
          "CHANGELOG.rst",
          "CODE_OF_CONDUCT.rst"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Topic :: Software Development",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "boolean.py>=4.0",
          "Sphinx>=5.0.2; extra == \"docs\"",
          "sphinx-rtd-theme>=1.0.0; extra == \"docs\"",
          "sphinxcontrib-apidoc>=0.4.0; extra == \"docs\"",
          "sphinx-reredirects>=0.1.2; extra == \"docs\"",
          "doc8>=0.11.2; extra == \"docs\"",
          "sphinx-autobuild; extra == \"docs\"",
          "sphinx-rtd-dark-mode>=1.3.0; extra == \"docs\"",
          "sphinx-copybutton; extra == \"docs\"",
          "pytest!=7.0.0,>=6; extra == \"testing\"",
          "pytest-xdist>=2; extra == \"testing\"",
          "twine; extra == \"testing\"",
          "black; extra == \"testing\"",
          "isort; extra == \"testing\""
        ],
        "requires_python": ">=3.8",
        "provides_extra": [
          "docs",
          "testing"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\license_expression-30.3.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "lxml",
        "version": "5.3.0",
        "summary": "Powerful and Pythonic XML processing library combining libxml2/libxslt with the ElementTree API.",
        "description": "lxml is a Pythonic, mature binding for the libxml2 and libxslt libraries.  It\nprovides safe and convenient access to these libraries using the ElementTree\nAPI.\n\nIt extends the ElementTree API significantly to offer support for XPath,\nRelaxNG, XML Schema, XSLT, C14N and much more.\n\nTo contact the project, go to the `project home page\n<https://lxml.de/>`_ or see our bug tracker at\nhttps://launchpad.net/lxml\n\nIn case you want to use the current in-development version of lxml,\nyou can get it from the github repository at\nhttps://github.com/lxml/lxml .  Note that this requires Cython to\nbuild the sources, see the build instructions on the project home\npage.  To the same end, running ``easy_install lxml==dev`` will\ninstall lxml from\nhttps://github.com/lxml/lxml/tarball/master#egg=lxml-dev if you have\nan appropriate version of Cython installed.\n\n\nAfter an official release of a new stable series, bug fixes may become\navailable at\nhttps://github.com/lxml/lxml/tree/lxml-5.3 .\nRunning ``easy_install lxml==5.3bugfix`` will install\nthe unreleased branch state from\nhttps://github.com/lxml/lxml/tarball/lxml-5.3#egg=lxml-5.3bugfix\nas soon as a maintenance branch has been established.  Note that this\nrequires Cython to be installed at an appropriate version for the build.\n\n5.3.0 (2024-08-10)\n==================\n\nFeatures added\n--------------\n\n* GH#421: Nested ``CDATA`` sections are no longer rejected but split on output\n  to represent ``]]>`` correctly.\n  Patch by Gertjan Klein.\n\nBugs fixed\n----------\n\n* LP#2060160: Attribute values serialised differently in ``xmlfile.element()`` and ``xmlfile.write()``.\n\n* LP#2058177: The ISO-Schematron implementation could fail on unknown prefixes.\n  Patch by David Lakin.\n\nOther changes\n-------------\n\n* LP#2067707: The ``strip_cdata`` option in ``HTMLParser()`` turned out to be useless and is now deprecated.\n\n* Binary wheels use the library versions libxml2 2.12.9 and libxslt 1.1.42.\n\n* Windows binary wheels use the library versions libxml2 2.11.8 and libxslt 1.1.39.\n\n* Built with Cython 3.0.11.\n\n\n",
        "home_page": "https://lxml.de/",
        "author": "lxml dev team",
        "author_email": "lxml-dev@lxml.de",
        "maintainer": "lxml dev team",
        "maintainer_email": "lxml-dev@lxml.de",
        "license": "BSD-3-Clause",
        "license_file": [
          "LICENSE.txt",
          "LICENSES.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Cython",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: C",
          "Operating System :: OS Independent",
          "Topic :: Text Processing :: Markup :: HTML",
          "Topic :: Text Processing :: Markup :: XML",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "cssselect>=0.7; extra == \"cssselect\"",
          "html5lib; extra == \"html5\"",
          "lxml-html-clean; extra == \"html-clean\"",
          "BeautifulSoup4; extra == \"htmlsoup\"",
          "Cython>=3.0.11; extra == \"source\""
        ],
        "requires_python": ">=3.6",
        "project_url": [
          "Source, https://github.com/lxml/lxml"
        ],
        "provides_extra": [
          "cssselect",
          "html5",
          "html_clean",
          "htmlsoup",
          "source"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\lxml-5.3.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "MarkupSafe",
        "version": "2.1.5",
        "summary": "Safely add untrusted strings to HTML/XML markup.",
        "description": "MarkupSafe\n==========\n\nMarkupSafe implements a text object that escapes characters so it is\nsafe to use in HTML and XML. Characters that have special meanings are\nreplaced so that they display as the actual characters. This mitigates\ninjection attacks, meaning untrusted user input can safely be displayed\non a page.\n\n\nInstalling\n----------\n\nInstall and update using `pip`_:\n\n.. code-block:: text\n\n    pip install -U MarkupSafe\n\n.. _pip: https://pip.pypa.io/en/stable/getting-started/\n\n\nExamples\n--------\n\n.. code-block:: pycon\n\n    >>> from markupsafe import Markup, escape\n\n    >>> # escape replaces special characters and wraps in Markup\n    >>> escape(\"<script>alert(document.cookie);</script>\")\n    Markup('&lt;script&gt;alert(document.cookie);&lt;/script&gt;')\n\n    >>> # wrap in Markup to mark text \"safe\" and prevent escaping\n    >>> Markup(\"<strong>Hello</strong>\")\n    Markup('<strong>hello</strong>')\n\n    >>> escape(Markup(\"<strong>Hello</strong>\"))\n    Markup('<strong>hello</strong>')\n\n    >>> # Markup is a str subclass\n    >>> # methods and operators escape their arguments\n    >>> template = Markup(\"Hello <em>{name}</em>\")\n    >>> template.format(name='\"World\"')\n    Markup('Hello <em>&#34;World&#34;</em>')\n\n\nDonate\n------\n\nThe Pallets organization develops and supports MarkupSafe and other\npopular packages. In order to grow the community of contributors and\nusers, and allow the maintainers to devote more time to the projects,\n`please donate today`_.\n\n.. _please donate today: https://palletsprojects.com/donate\n\n\nLinks\n-----\n\n-   Documentation: https://markupsafe.palletsprojects.com/\n-   Changes: https://markupsafe.palletsprojects.com/changes/\n-   PyPI Releases: https://pypi.org/project/MarkupSafe/\n-   Source Code: https://github.com/pallets/markupsafe/\n-   Issue Tracker: https://github.com/pallets/markupsafe/issues/\n-   Chat: https://discord.gg/pallets\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://palletsprojects.com/p/markupsafe/",
        "maintainer": "Pallets",
        "maintainer_email": "contact@palletsprojects.com",
        "license": "BSD-3-Clause",
        "license_file": [
          "LICENSE.rst"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Topic :: Internet :: WWW/HTTP :: Dynamic Content",
          "Topic :: Text Processing :: Markup :: HTML"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Donate, https://palletsprojects.com/donate",
          "Documentation, https://markupsafe.palletsprojects.com/",
          "Changes, https://markupsafe.palletsprojects.com/changes/",
          "Source Code, https://github.com/pallets/markupsafe/",
          "Issue Tracker, https://github.com/pallets/markupsafe/issues/",
          "Chat, https://discord.gg/pallets"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\MarkupSafe-2.1.5.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "matplotlib",
        "version": "3.10.0",
        "summary": "Python plotting package",
        "description": "[![PyPi](https://img.shields.io/pypi/v/matplotlib)](https://pypi.org/project/matplotlib/)\n[![Conda](https://img.shields.io/conda/vn/conda-forge/matplotlib)](https://anaconda.org/conda-forge/matplotlib)\n[![Downloads](https://img.shields.io/pypi/dm/matplotlib)](https://pypi.org/project/matplotlib)\n[![NUMFocus](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](https://numfocus.org)\n\n[![Discourse help forum](https://img.shields.io/badge/help_forum-discourse-blue.svg)](https://discourse.matplotlib.org)\n[![Gitter](https://badges.gitter.im/matplotlib/matplotlib.svg)](https://gitter.im/matplotlib/matplotlib)\n[![GitHub issues](https://img.shields.io/badge/issue_tracking-github-blue.svg)](https://github.com/matplotlib/matplotlib/issues)\n[![Contributing](https://img.shields.io/badge/PR-Welcome-%23FF8300.svg?)](https://matplotlib.org/stable/devel/index.html)\n\n[![GitHub actions status](https://github.com/matplotlib/matplotlib/workflows/Tests/badge.svg)](https://github.com/matplotlib/matplotlib/actions?query=workflow%3ATests)\n[![Azure pipelines status](https://dev.azure.com/matplotlib/matplotlib/_apis/build/status/matplotlib.matplotlib?branchName=main)](https://dev.azure.com/matplotlib/matplotlib/_build/latest?definitionId=1&branchName=main)\n[![AppVeyor status](https://ci.appveyor.com/api/projects/status/github/matplotlib/matplotlib?branch=main&svg=true)](https://ci.appveyor.com/project/matplotlib/matplotlib)\n[![Codecov status](https://codecov.io/github/matplotlib/matplotlib/badge.svg?branch=main&service=github)](https://app.codecov.io/gh/matplotlib/matplotlib)\n[![EffVer Versioning](https://img.shields.io/badge/version_scheme-EffVer-0097a7)](https://jacobtomlinson.dev/effver)\n\n![Matplotlib logotype](https://matplotlib.org/_static/logo2.svg)\n\nMatplotlib is a comprehensive library for creating static, animated, and\ninteractive visualizations in Python.\n\nCheck out our [home page](https://matplotlib.org/) for more information.\n\n![image](https://matplotlib.org/_static/readme_preview.png)\n\nMatplotlib produces publication-quality figures in a variety of hardcopy\nformats and interactive environments across platforms. Matplotlib can be\nused in Python scripts, Python/IPython shells, web application servers,\nand various graphical user interface toolkits.\n\n## Install\n\nSee the [install\ndocumentation](https://matplotlib.org/stable/users/installing/index.html),\nwhich is generated from `/doc/install/index.rst`\n\n## Contribute\n\nYou've discovered a bug or something else you want to change â€” excellent!\n\nYou've worked out a way to fix it â€” even better!\n\nYou want to tell us about it â€” best of all!\n\nStart at the [contributing\nguide](https://matplotlib.org/devdocs/devel/contribute.html)!\n\n## Contact\n\n[Discourse](https://discourse.matplotlib.org/) is the discussion forum\nfor general questions and discussions and our recommended starting\npoint.\n\nOur active mailing lists (which are mirrored on Discourse) are:\n\n-   [Users](https://mail.python.org/mailman/listinfo/matplotlib-users)\n    mailing list: <matplotlib-users@python.org>\n-   [Announcement](https://mail.python.org/mailman/listinfo/matplotlib-announce)\n    mailing list: <matplotlib-announce@python.org>\n-   [Development](https://mail.python.org/mailman/listinfo/matplotlib-devel)\n    mailing list: <matplotlib-devel@python.org>\n\n[Gitter](https://gitter.im/matplotlib/matplotlib) is for coordinating\ndevelopment and asking questions directly related to contributing to\nmatplotlib.\n\n## Citing Matplotlib\n\nIf Matplotlib contributes to a project that leads to publication, please\nacknowledge this by citing Matplotlib.\n\n[A ready-made citation\nentry](https://matplotlib.org/stable/users/project/citing.html) is\navailable.\n",
        "description_content_type": "text/markdown",
        "author": "John D. Hunter, Michael Droettboom",
        "author_email": "Unknown <matplotlib-users@python.org>",
        "license": "License agreement for matplotlib versions 1.3.0 and later\n =========================================================\n\n 1. This LICENSE AGREEMENT is between the Matplotlib Development Team\n (\"MDT\"), and the Individual or Organization (\"Licensee\") accessing and\n otherwise using matplotlib software in source or binary form and its\n associated documentation.\n\n 2. Subject to the terms and conditions of this License Agreement, MDT\n hereby grants Licensee a nonexclusive, royalty-free, world-wide license\n to reproduce, analyze, test, perform and/or display publicly, prepare\n derivative works, distribute, and otherwise use matplotlib\n alone or in any derivative version, provided, however, that MDT's\n License Agreement and MDT's notice of copyright, i.e., \"Copyright (c)\n 2012- Matplotlib Development Team; All Rights Reserved\" are retained in\n matplotlib  alone or in any derivative version prepared by\n Licensee.\n\n 3. In the event Licensee prepares a derivative work that is based on or\n incorporates matplotlib or any part thereof, and wants to\n make the derivative work available to others as provided herein, then\n Licensee hereby agrees to include in any such work a brief summary of\n the changes made to matplotlib .\n\n 4. MDT is making matplotlib available to Licensee on an \"AS\n IS\" basis.  MDT MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\n IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, MDT MAKES NO AND\n DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\n FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF MATPLOTLIB\n WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.\n\n 5. MDT SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF MATPLOTLIB\n  FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR\n LOSS AS A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING\n MATPLOTLIB , OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF\n THE POSSIBILITY THEREOF.\n\n 6. This License Agreement will automatically terminate upon a material\n breach of its terms and conditions.\n\n 7. Nothing in this License Agreement shall be deemed to create any\n relationship of agency, partnership, or joint venture between MDT and\n Licensee.  This License Agreement does not grant permission to use MDT\n trademarks or trade name in a trademark sense to endorse or promote\n products or services of Licensee, or any third party.\n\n 8. By copying, installing or otherwise using matplotlib ,\n Licensee agrees to be bound by the terms and conditions of this License\n Agreement.\n\n License agreement for matplotlib versions prior to 1.3.0\n ========================================================\n\n 1. This LICENSE AGREEMENT is between John D. Hunter (\"JDH\"), and the\n Individual or Organization (\"Licensee\") accessing and otherwise using\n matplotlib software in source or binary form and its associated\n documentation.\n\n 2. Subject to the terms and conditions of this License Agreement, JDH\n hereby grants Licensee a nonexclusive, royalty-free, world-wide license\n to reproduce, analyze, test, perform and/or display publicly, prepare\n derivative works, distribute, and otherwise use matplotlib\n alone or in any derivative version, provided, however, that JDH's\n License Agreement and JDH's notice of copyright, i.e., \"Copyright (c)\n 2002-2011 John D. Hunter; All Rights Reserved\" are retained in\n matplotlib  alone or in any derivative version prepared by\n Licensee.\n\n 3. In the event Licensee prepares a derivative work that is based on or\n incorporates matplotlib  or any part thereof, and wants to\n make the derivative work available to others as provided herein, then\n Licensee hereby agrees to include in any such work a brief summary of\n the changes made to matplotlib.\n\n 4. JDH is making matplotlib  available to Licensee on an \"AS\n IS\" basis.  JDH MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\n IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, JDH MAKES NO AND\n DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\n FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF MATPLOTLIB\n WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.\n\n 5. JDH SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF MATPLOTLIB\n  FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR\n LOSS AS A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING\n MATPLOTLIB , OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF\n THE POSSIBILITY THEREOF.\n\n 6. This License Agreement will automatically terminate upon a material\n breach of its terms and conditions.\n\n 7. Nothing in this License Agreement shall be deemed to create any\n relationship of agency, partnership, or joint venture between JDH and\n Licensee.  This License Agreement does not grant permission to use JDH\n trademarks or trade name in a trademark sense to endorse or promote\n products or services of Licensee, or any third party.\n\n 8. By copying, installing or otherwise using matplotlib,\n Licensee agrees to be bound by the terms and conditions of this License\n Agreement.",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Framework :: Matplotlib",
          "Intended Audience :: Science/Research",
          "Intended Audience :: Education",
          "License :: OSI Approved :: Python Software Foundation License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Scientific/Engineering :: Visualization"
        ],
        "requires_dist": [
          "contourpy>=1.0.1",
          "cycler>=0.10",
          "fonttools>=4.22.0",
          "kiwisolver>=1.3.1",
          "numpy>=1.23",
          "packaging>=20.0",
          "pillow>=8",
          "pyparsing>=2.3.1",
          "python-dateutil>=2.7",
          "meson-python<0.17.0,>=0.13.1; extra == \"dev\"",
          "pybind11!=2.13.3,>=2.13.2; extra == \"dev\"",
          "setuptools_scm>=7; extra == \"dev\"",
          "setuptools>=64; extra == \"dev\""
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Homepage, https://matplotlib.org",
          "Download, https://matplotlib.org/stable/install/index.html",
          "Documentation, https://matplotlib.org",
          "Source Code, https://github.com/matplotlib/matplotlib",
          "Bug Tracker, https://github.com/matplotlib/matplotlib/issues",
          "Forum, https://discourse.matplotlib.org/",
          "Donate, https://numfocus.org/donate-to-matplotlib"
        ],
        "provides_extra": [
          "dev"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\matplotlib-3.10.0.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "matplotlib-inline",
        "version": "0.1.7",
        "summary": "Inline Matplotlib backend for Jupyter",
        "description": "# Matplotlib Inline Back-end for IPython and Jupyter\n\nThis package provides support for matplotlib to display figures directly inline in the Jupyter notebook and related clients, as shown below.\n\n## Installation\n\nWith conda:\n\n```bash\nconda install -c conda-forge matplotlib-inline\n```\n\nWith pip:\n\n```bash\npip install matplotlib-inline\n```\n\n## Usage\n\nNote that in current versions of JupyterLab and Jupyter Notebook, the explicit use of the `%matplotlib inline` directive is not needed anymore, though other third-party clients may still require it.\n\nThis will produce a figure immediately below:\n\n```python\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0, 3*np.pi, 500)\nplt.plot(x, np.sin(x**2))\nplt.title('A simple chirp');\n```\n\n## License\n\nLicensed under the terms of the BSD 3-Clause License, by the IPython Development Team (see `LICENSE` file).\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "ipython",
          "jupyter",
          "matplotlib",
          "python"
        ],
        "author_email": "IPython Development Team <ipython-dev@python.org>",
        "license": "BSD 3-Clause License\n\nCopyright (c) 2019-2022, IPython Development Team.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Framework :: IPython",
          "Framework :: Jupyter",
          "Framework :: Jupyter :: JupyterLab",
          "Framework :: Jupyter :: JupyterLab :: 3",
          "Framework :: Jupyter :: JupyterLab :: 4",
          "Intended Audience :: Developers",
          "Intended Audience :: Science/Research",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Multimedia :: Graphics"
        ],
        "requires_dist": [
          "traitlets"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://github.com/ipython/matplotlib-inline"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\matplotlib_inline-0.1.7.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "mccabe",
        "version": "0.7.0",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "McCabe checker, plugin for flake8",
        "description": "McCabe complexity checker\n=========================\n\nNed's script to check McCabe complexity.\n\nThis module provides a plugin for ``flake8``, the Python code checker.\n\n\nInstallation\n------------\n\nYou can install, upgrade, or uninstall ``mccabe`` with these commands::\n\n  $ pip install mccabe\n  $ pip install --upgrade mccabe\n  $ pip uninstall mccabe\n\n\nStandalone script\n-----------------\n\nThe complexity checker can be used directly::\n\n  $ python -m mccabe --min 5 mccabe.py\n  (\"185:1: 'PathGraphingAstVisitor.visitIf'\", 5)\n  (\"71:1: 'PathGraph.to_dot'\", 5)\n  (\"245:1: 'McCabeChecker.run'\", 5)\n  (\"283:1: 'main'\", 7)\n  (\"203:1: 'PathGraphingAstVisitor.visitTryExcept'\", 5)\n  (\"257:1: 'get_code_complexity'\", 5)\n\n\nPlugin for Flake8\n-----------------\n\nWhen both ``flake8 2+`` and ``mccabe`` are installed, the plugin is\navailable in ``flake8``::\n\n  $ flake8 --version\n  2.0 (pep8: 1.4.2, pyflakes: 0.6.1, mccabe: 0.2)\n\nBy default the plugin is disabled.  Use the ``--max-complexity`` switch to\nenable it.  It will emit a warning if the McCabe complexity of a function is\nhigher than the provided value::\n\n    $ flake8 --max-complexity 10 coolproject\n    ...\n    coolproject/mod.py:1204:1: C901 'CoolFactory.prepare' is too complex (14)\n\nThis feature is quite useful for detecting over-complex code.  According to McCabe,\nanything that goes beyond 10 is too complex.\n\nFlake8 has many features that mccabe does not provide. Flake8 allows users to\nignore violations reported by plugins with ``# noqa``. Read more about this in\n`their documentation\n<http://flake8.pycqa.org/en/latest/user/violations.html#in-line-ignoring-errors>`__.\nTo silence violations reported by ``mccabe``, place your ``# noqa: C901`` on\nthe function definition line, where the error is reported for (possibly a\ndecorator).\n\n\nLinks\n-----\n\n* Feedback and ideas: http://mail.python.org/mailman/listinfo/code-quality\n\n* Cyclomatic complexity: http://en.wikipedia.org/wiki/Cyclomatic_complexity\n\n* Ned Batchelder's script:\n  http://nedbatchelder.com/blog/200803/python_code_complexity_microtool.html\n\n* McCabe complexity: http://en.wikipedia.org/wiki/Cyclomatic_complexity\n\n\nChanges\n-------\n\n0.7.0 - 2021-01-23\n``````````````````\n\n* Drop support for all versions of Python lower than 3.6\n\n* Add support for Python 3.8, 3.9, and 3.10\n\n* Fix option declaration for Flake8\n\n0.6.1 - 2017-01-26\n``````````````````\n\n* Fix signature for ``PathGraphingAstVisitor.default`` to match the signature\n  for ``ASTVisitor``\n\n0.6.0 - 2017-01-23\n``````````````````\n\n* Add support for Python 3.6\n\n* Fix handling for missing statement types\n\n0.5.3 - 2016-12-14\n``````````````````\n\n* Report actual column number of violation instead of the start of the line\n\n0.5.2 - 2016-07-31\n``````````````````\n\n* When opening files ourselves, make sure we always name the file variable\n\n0.5.1 - 2016-07-28\n``````````````````\n\n* Set default maximum complexity to -1 on the class itself\n\n0.5.0 - 2016-05-30\n``````````````````\n\n* PyCon 2016 PDX release\n\n* Add support for Flake8 3.0\n\n0.4.0 - 2016-01-27\n``````````````````\n\n* Stop testing on Python 3.2\n\n* Add support for async/await keywords on Python 3.5 from PEP 0492\n\n0.3.1 - 2015-06-14\n``````````````````\n\n* Include ``test_mccabe.py`` in releases.\n\n* Always coerce the ``max_complexity`` value from Flake8's entry-point to an\n  integer.\n\n0.3 - 2014-12-17\n````````````````\n\n* Computation was wrong: the mccabe complexity starts at 1, not 2.\n\n* The ``max-complexity`` value is now inclusive.  E.g.: if the\n  value is 10 and the reported complexity is 10, then it passes.\n\n* Add tests.\n\n\n0.2.1 - 2013-04-03\n``````````````````\n\n* Do not require ``setuptools`` in setup.py.  It works around an issue\n  with ``pip`` and Python 3.\n\n\n0.2 - 2013-02-22\n````````````````\n\n* Rename project to ``mccabe``.\n\n* Provide ``flake8.extension`` setuptools entry point.\n\n* Read ``max-complexity`` from the configuration file.\n\n* Rename argument ``min_complexity`` to ``threshold``.\n\n\n0.1 - 2013-02-11\n````````````````\n* First release\n\n\n",
        "keywords": [
          "flake8",
          "mccabe"
        ],
        "home_page": "https://github.com/pycqa/mccabe",
        "author": "Tarek Ziade",
        "author_email": "tarek@ziade.org",
        "maintainer": "Ian Stapleton Cordasco",
        "maintainer_email": "graffatcolmingov@gmail.com",
        "license": "Expat license",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Software Development :: Quality Assurance"
        ],
        "requires_python": ">=3.6"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\mccabe-0.7.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "mistune",
        "version": "3.0.2",
        "summary": "A sane and fast Markdown parser with useful plugins and renderers",
        "description": "Mistune v3\n==========\n\nA fast yet powerful Python Markdown parser with renderers and plugins.\n\nOverview\n--------\n\nConvert Markdown to HTML with ease:\n\n.. code-block:: python\n\n    import mistune\n    mistune.html(your_markdown_text)\n\nUseful Links\n------------\n\n1. GitHub: https://github.com/lepture/mistune\n2. Docs: https://mistune.lepture.com/\n\nLicense\n-------\n\nMistune is licensed under BSD. Please see LICENSE for licensing details.\n",
        "description_content_type": "text/x-rst",
        "author_email": "Hsiaoming Yang <me@lepture.com>",
        "license": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Environment :: Console",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Text Processing :: Markup"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Documentation, https://mistune.lepture.com/",
          "Source, https://github.com/lepture/mistune",
          "Donate, https://github.com/sponsors/lepture"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\mistune-3.0.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "nbclient",
        "version": "0.10.0",
        "summary": "A client library for executing notebooks. Formerly nbconvert's ExecutePreprocessor.",
        "description": "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jupyter/nbclient/main?filepath=binder%2Frun_nbclient.ipynb)\n[![Build Status](https://github.com/jupyter/nbclient/workflows/CI/badge.svg)](https://github.com/jupyter/nbclient/actions)\n[![Documentation Status](https://readthedocs.org/projects/nbclient/badge/?version=latest)](https://nbclient.readthedocs.io/en/latest/?badge=latest)\n[![Python 3.7](https://img.shields.io/badge/python-3.7-blue.svg)](https://www.python.org/downloads/release/python-370/)\n[![Python 3.8](https://img.shields.io/badge/python-3.8-blue.svg)](https://www.python.org/downloads/release/python-380/)\n[![Python 3.9](https://img.shields.io/badge/python-3.9-blue.svg)](https://www.python.org/downloads/release/python-390/)\n[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/release/python-3100/)\n[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3110/)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)\n\n# nbclient\n\n**NBClient** lets you **execute** notebooks.\n\nA client library for programmatic notebook execution, **NBClient** is a tool for running Jupyter Notebooks in\ndifferent execution contexts, including the command line.\n\n## Interactive Demo\n\nTo demo **NBClient** interactively, click this Binder badge to start the demo:\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jupyter/nbclient/main?filepath=binder%2Frun_nbclient.ipynb)\n\n## Installation\n\nIn a terminal, run:\n\n```\npython3 -m pip install nbclient\n```\n\n## Documentation\n\nSee [ReadTheDocs](https://nbclient.readthedocs.io/en/latest/) for more in-depth details about the project and the\n[API Reference](https://nbclient.readthedocs.io/en/latest/reference/index.html).\n\n## Python Version Support\n\nThis library currently supports Python 3.6+ versions. As minor Python\nversions are officially sunset by the Python org, nbclient will similarly\ndrop support in the future.\n\n## Origins\n\nThis library used to be part of the [nbconvert](https://nbconvert.readthedocs.io/en/latest/) project. NBClient extracted nbconvert's `ExecutePreprocessor`into its own library for easier updating and importing by downstream libraries and applications.\n\n## Relationship to JupyterClient\n\nNBClient and JupyterClient are distinct projects.\n\n`jupyter_client` is a client library for the jupyter protocol. Specifically, `jupyter_client` provides the Python API\nfor starting, managing and communicating with Jupyter kernels.\n\nWhile, nbclient allows notebooks to be run in different execution contexts.\n\n## About the Jupyter Development Team\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project.\nThis includes all of the Jupyter subprojects.\n\nThe core team that coordinates development on GitHub can be found here:\nhttps://github.com/jupyter/.\n\n## Our Copyright Policy\n\nJupyter uses a shared copyright model. Each contributor maintains copyright\nover their contributions to Jupyter. But, it is important to note that these\ncontributions are typically only changes to the repositories. Thus, the Jupyter\nsource code, in its entirety is not the copyright of any single person or\ninstitution.  Instead, it is the collective copyright of the entire Jupyter\nDevelopment Team.  If individual contributors want to maintain a record of what\nchanges/contributions they have specific copyright on, they should indicate\ntheir copyright in the commit message of the change, when they commit the\nchange to one of the Jupyter repositories.\n\nWith this in mind, the following banner should be used in any source code file\nto indicate the copyright and license terms:\n\n```\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License.\n```\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "executor",
          "jupyter",
          "notebook",
          "pipeline"
        ],
        "author_email": "Jupyter Development Team <jupyter@googlegroups.com>",
        "license": "BSD 3-Clause License\n\nCopyright (c) 2020-, Jupyter Development Team\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Intended Audience :: Developers",
          "Intended Audience :: Science/Research",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11"
        ],
        "requires_dist": [
          "jupyter-client>=6.1.12",
          "jupyter-core!=5.0.*,>=4.12",
          "nbformat>=5.1",
          "traitlets>=5.4",
          "pre-commit; extra == 'dev'",
          "autodoc-traits; extra == 'docs'",
          "mock; extra == 'docs'",
          "moto; extra == 'docs'",
          "myst-parser; extra == 'docs'",
          "nbclient[test]; extra == 'docs'",
          "sphinx-book-theme; extra == 'docs'",
          "sphinx>=1.7; extra == 'docs'",
          "sphinxcontrib-spelling; extra == 'docs'",
          "flaky; extra == 'test'",
          "ipykernel>=6.19.3; extra == 'test'",
          "ipython; extra == 'test'",
          "ipywidgets; extra == 'test'",
          "nbconvert>=7.0.0; extra == 'test'",
          "pytest-asyncio; extra == 'test'",
          "pytest-cov>=4.0; extra == 'test'",
          "pytest<8,>=7.0; extra == 'test'",
          "testpath; extra == 'test'",
          "xmltodict; extra == 'test'"
        ],
        "requires_python": ">=3.8.0",
        "project_url": [
          "Documentation, https://nbclient.readthedocs.io",
          "Funding, https://numfocus.org/",
          "Homepage, https://jupyter.org",
          "Source, https://github.com/jupyter/nbclient",
          "Tracker, https://github.com/jupyter/nbclient/issues"
        ],
        "provides_extra": [
          "dev",
          "docs",
          "test"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\nbclient-0.10.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "nbconvert",
        "version": "7.16.4",
        "summary": "Converting Jupyter Notebooks (.ipynb files) to other formats.  Output formats include asciidoc, html, latex, markdown, pdf, py, rst, script.  nbconvert can be used both as a Python library (`import nbconvert`) or as a command line tool (invoked as `jupyter nbconvert ...`).",
        "description": "# nbconvert\n\n### Jupyter Notebook Conversion\n\n[![Build Status](https://github.com/jupyter/nbconvert/actions/workflows/tests.yml/badge.svg?query=branch%3Amain++)](https://github.com/jupyter/nbconvert/actions/workflows/tests.yml/badge.svg?query=branch%3Amain++)\n[![Documentation Status](https://readthedocs.org/projects/nbconvert/badge/?version=latest)](https://nbconvert.readthedocs.io/en/latest/?badge=latest)\n\nThe **nbconvert** tool, `jupyter nbconvert`, converts notebooks to various other\nformats via [Jinja] templates. The nbconvert tool allows you to convert an\n`.ipynb` notebook file into various static formats including:\n\n- HTML\n- LaTeX\n- PDF\n- Reveal JS\n- Markdown (md)\n- ReStructured Text (rst)\n- executable script\n\n## Usage\n\nFrom the command line, use nbconvert to convert a Jupyter notebook (_input_) to a\na different format (_output_). The basic command structure is:\n\n```\n$ jupyter nbconvert --to <output format> <input notebook>\n```\n\nwhere `<output format>` is the desired output format and `<input notebook>` is the\nfilename of the Jupyter notebook.\n\n### Example: Convert a notebook to HTML\n\nConvert Jupyter notebook file, `mynotebook.ipynb`, to HTML using:\n\n```\n$ jupyter nbconvert --to html mynotebook.ipynb\n```\n\nThis command creates an HTML output file named `mynotebook.html`.\n\n## Dev Install\n\nCheck if pandoc is installed (`pandoc --version`); if needed, install:\n\n```\nsudo apt-get install pandoc\n```\n\nOr\n\n```\nbrew install pandoc\n```\n\nInstall nbconvert for development using:\n\n```\ngit clone https://github.com/jupyter/nbconvert.git\ncd nbconvert\npip install -e .\n```\n\nRunning the tests after a dev install above:\n\n```\npip install nbconvert[test]\npy.test --pyargs nbconvert\n```\n\n## Documentation\n\n- [Documentation for Jupyter nbconvert](https://nbconvert.readthedocs.io/en/latest/)\n- [nbconvert examples on GitHub](https://github.com/jupyter/nbconvert-examples)\n- [Documentation for Project Jupyter](https://jupyter.readthedocs.io/en/latest/index.html)\n\n## Technical Support\n\n- [Issues and Bug Reports](https://github.com/jupyter/nbconvert/issues): A place to report\n  bugs or regressions found for nbconvert\n- [Community Technical Support and Discussion - Discourse](https://discourse.jupyter.org/): A place for\n  installation, configuration, and troubleshooting assistannce by the Jupyter community.\n  As a non-profit project and maintainers who are primarily volunteers, we encourage you\n  to ask questions and share your knowledge on Discourse.\n\n## Jupyter Resources\n\n- [Jupyter mailing list](https://groups.google.com/forum/#!forum/jupyter)\n- [Project Jupyter website](https://jupyter.org)\n\n## About the Jupyter Development Team\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project.\nThis includes all of the Jupyter subprojects.\n\nThe core team that coordinates development on GitHub can be found here:\nhttps://github.com/jupyter/.\n\n## Our Copyright Policy\n\nJupyter uses a shared copyright model. Each contributor maintains copyright\nover their contributions to Jupyter. But, it is important to note that these\ncontributions are typically only changes to the repositories. Thus, the Jupyter\nsource code, in its entirety is not the copyright of any single person or\ninstitution.  Instead, it is the collective copyright of the entire Jupyter\nDevelopment Team.  If individual contributors want to maintain a record of what\nchanges/contributions they have specific copyright on, they should indicate\ntheir copyright in the commit message of the change, when they commit the\nchange to one of the Jupyter repositories.\n\nWith this in mind, the following banner should be used in any source code file\nto indicate the copyright and license terms:\n\n```\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License.\n```\n\n[jinja]: http://jinja.pocoo.org/\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "Interactive",
          "Interpreter",
          "Shell",
          "Web"
        ],
        "author_email": "Jupyter Development Team <jupyter@googlegroups.com>",
        "license": "BSD 3-Clause License\n\n- Copyright (c) 2001-2015, IPython Development Team\n- Copyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Intended Audience :: Developers",
          "Intended Audience :: Science/Research",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3"
        ],
        "requires_dist": [
          "beautifulsoup4",
          "bleach!=5.0.0",
          "defusedxml",
          "importlib-metadata>=3.6; python_version < '3.10'",
          "jinja2>=3.0",
          "jupyter-core>=4.7",
          "jupyterlab-pygments",
          "markupsafe>=2.0",
          "mistune<4,>=2.0.3",
          "nbclient>=0.5.0",
          "nbformat>=5.7",
          "packaging",
          "pandocfilters>=1.4.1",
          "pygments>=2.4.1",
          "tinycss2",
          "traitlets>=5.1",
          "flaky; extra == 'all'",
          "ipykernel; extra == 'all'",
          "ipython; extra == 'all'",
          "ipywidgets>=7.5; extra == 'all'",
          "myst-parser; extra == 'all'",
          "nbsphinx>=0.2.12; extra == 'all'",
          "playwright; extra == 'all'",
          "pydata-sphinx-theme; extra == 'all'",
          "pyqtwebengine>=5.15; extra == 'all'",
          "pytest>=7; extra == 'all'",
          "sphinx==5.0.2; extra == 'all'",
          "sphinxcontrib-spelling; extra == 'all'",
          "tornado>=6.1; extra == 'all'",
          "ipykernel; extra == 'docs'",
          "ipython; extra == 'docs'",
          "myst-parser; extra == 'docs'",
          "nbsphinx>=0.2.12; extra == 'docs'",
          "pydata-sphinx-theme; extra == 'docs'",
          "sphinx==5.0.2; extra == 'docs'",
          "sphinxcontrib-spelling; extra == 'docs'",
          "pyqtwebengine>=5.15; extra == 'qtpdf'",
          "pyqtwebengine>=5.15; extra == 'qtpng'",
          "tornado>=6.1; extra == 'serve'",
          "flaky; extra == 'test'",
          "ipykernel; extra == 'test'",
          "ipywidgets>=7.5; extra == 'test'",
          "pytest>=7; extra == 'test'",
          "playwright; extra == 'webpdf'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://jupyter.org"
        ],
        "provides_extra": [
          "all",
          "docs",
          "qtpdf",
          "qtpng",
          "serve",
          "test",
          "webpdf"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\nbconvert-7.16.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "nbformat",
        "version": "5.10.4",
        "summary": "The Jupyter Notebook format",
        "description": "This package contains the base implementation of the Jupyter Notebook format,\nand Python APIs for working with notebooks.",
        "description_content_type": "text/plain",
        "keywords": [
          "Interactive",
          "Interpreter",
          "Shell",
          "Web"
        ],
        "author_email": "Jupyter Development Team <jupyter@googlegroups.com>",
        "license": "BSD 3-Clause License\n\n- Copyright (c) 2001-2015, IPython Development Team\n- Copyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Intended Audience :: Developers",
          "Intended Audience :: Science/Research",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12"
        ],
        "requires_dist": [
          "fastjsonschema>=2.15",
          "jsonschema>=2.6",
          "jupyter-core!=5.0.*,>=4.12",
          "traitlets>=5.1",
          "myst-parser; extra == 'docs'",
          "pydata-sphinx-theme; extra == 'docs'",
          "sphinx; extra == 'docs'",
          "sphinxcontrib-github-alt; extra == 'docs'",
          "sphinxcontrib-spelling; extra == 'docs'",
          "pep440; extra == 'test'",
          "pre-commit; extra == 'test'",
          "pytest; extra == 'test'",
          "testpath; extra == 'test'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://jupyter.org",
          "Changelog, https://github.com/jupyter/nbformat/blob/main/CHANGELOG.md",
          "Documentation, https://nbformat.readthedocs.io/",
          "Repository, https://github.com/jupyter/nbformat.git"
        ],
        "provides_extra": [
          "docs",
          "test"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\nbformat-5.10.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "numpy",
        "version": "2.1.3",
        "summary": "Fundamental package for array computing in Python",
        "description": "<h1 align=\"center\">\n<img src=\"https://raw.githubusercontent.com/numpy/numpy/main/branding/logo/primary/numpylogo.svg\" width=\"300\">\n</h1><br>\n\n\n[![Powered by NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](\nhttps://numfocus.org)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/numpy.svg?label=PyPI%20downloads)](\nhttps://pypi.org/project/numpy/)\n[![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/numpy.svg?label=Conda%20downloads)](\nhttps://anaconda.org/conda-forge/numpy)\n[![Stack Overflow](https://img.shields.io/badge/stackoverflow-Ask%20questions-blue.svg)](\nhttps://stackoverflow.com/questions/tagged/numpy)\n[![Nature Paper](https://img.shields.io/badge/DOI-10.1038%2Fs41586--020--2649--2-blue)](\nhttps://doi.org/10.1038/s41586-020-2649-2)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/numpy/numpy/badge)](https://securityscorecards.dev/viewer/?uri=github.com/numpy/numpy)\n\n\nNumPy is the fundamental package for scientific computing with Python.\n\n- **Website:** https://www.numpy.org\n- **Documentation:** https://numpy.org/doc\n- **Mailing list:** https://mail.python.org/mailman/listinfo/numpy-discussion\n- **Source code:** https://github.com/numpy/numpy\n- **Contributing:** https://www.numpy.org/devdocs/dev/index.html\n- **Bug reports:** https://github.com/numpy/numpy/issues\n- **Report a security vulnerability:** https://tidelift.com/docs/security\n\nIt provides:\n\n- a powerful N-dimensional array object\n- sophisticated (broadcasting) functions\n- tools for integrating C/C++ and Fortran code\n- useful linear algebra, Fourier transform, and random number capabilities\n\nTesting:\n\nNumPy requires `pytest` and `hypothesis`.  Tests can then be run after installation with:\n\n    python -c \"import numpy, sys; sys.exit(numpy.test() is False)\"\n\nCode of Conduct\n----------------------\n\nNumPy is a community-driven open source project developed by a diverse group of\n[contributors](https://numpy.org/teams/). The NumPy leadership has made a strong\ncommitment to creating an open, inclusive, and positive community. Please read the\n[NumPy Code of Conduct](https://numpy.org/code-of-conduct/) for guidance on how to interact\nwith others in a way that makes our community thrive.\n\nCall for Contributions\n----------------------\n\nThe NumPy project welcomes your expertise and enthusiasm!\n\nSmall improvements or fixes are always appreciated. If you are considering larger contributions\nto the source code, please contact us through the [mailing\nlist](https://mail.python.org/mailman/listinfo/numpy-discussion) first.\n\nWriting code isnâ€™t the only way to contribute to NumPy. You can also:\n- review pull requests\n- help us stay on top of new and old issues\n- develop tutorials, presentations, and other educational materials\n- maintain and improve [our website](https://github.com/numpy/numpy.org)\n- develop graphic design for our brand assets and promotional materials\n- translate website content\n- help with outreach and onboard new contributors\n- write grant proposals and help with other fundraising efforts\n\nFor more information about the ways you can contribute to NumPy, visit [our website](https://numpy.org/contribute/). \nIf youâ€™re unsure where to start or how your skills fit in, reach out! You can\nask on the mailing list or here, on GitHub, by opening a new issue or leaving a\ncomment on a relevant issue that is already open.\n\nOur preferred channels of communication are all public, but if youâ€™d like to\nspeak to us in private first, contact our community coordinators at\nnumpy-team@googlegroups.com or on Slack (write numpy-team@googlegroups.com for\nan invitation).\n\nWe also have a biweekly community call, details of which are announced on the\nmailing list. You are very welcome to join.\n\nIf you are new to contributing to open source, [this\nguide](https://opensource.guide/how-to-contribute/) helps explain why, what,\nand how to successfully get involved.\n",
        "description_content_type": "text/markdown",
        "author": "Travis E. Oliphant et al.",
        "maintainer_email": "NumPy Developers <numpy-discussion@python.org>",
        "license": "Copyright (c) 2005-2024, NumPy Developers.\n All rights reserved.\n\n Redistribution and use in source and binary forms, with or without\n modification, are permitted provided that the following conditions are\n met:\n\n     * Redistributions of source code must retain the above copyright\n        notice, this list of conditions and the following disclaimer.\n\n     * Redistributions in binary form must reproduce the above\n        copyright notice, this list of conditions and the following\n        disclaimer in the documentation and/or other materials provided\n        with the distribution.\n\n     * Neither the name of the NumPy Developers nor the names of any\n        contributors may be used to endorse or promote products derived\n        from this software without specific prior written permission.\n\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n ----\n\n The NumPy repository and source distributions bundle several libraries that are\n compatibly licensed.  We list these here.\n\n Name: lapack-lite\n Files: numpy/linalg/lapack_lite/*\n License: BSD-3-Clause\n   For details, see numpy/linalg/lapack_lite/LICENSE.txt\n\n Name: dragon4\n Files: numpy/_core/src/multiarray/dragon4.c\n License: MIT\n   For license text, see numpy/_core/src/multiarray/dragon4.c\n\n Name: libdivide\n Files: numpy/_core/include/numpy/libdivide/*\n License: Zlib\n   For license text, see numpy/_core/include/numpy/libdivide/LICENSE.txt\n\n\n Note that the following files are vendored in the repository and sdist but not\n installed in built numpy packages:\n\n Name: Meson\n Files: vendored-meson/meson/*\n License: Apache 2.0\n   For license text, see vendored-meson/meson/COPYING\n\n Name: spin\n Files: .spin/cmds.py\n License: BSD-3\n   For license text, see .spin/LICENSE\n\n Name: tempita\n Files: numpy/_build_utils/tempita/*\n License: MIT\n   For details, see numpy/_build_utils/tempita/LICENCE.txt\n\n ----\n\n This binary distribution of NumPy also bundles the following software:\n\n\n Name: OpenBLAS\n Files: numpy.libs\\libscipy_openblas*.dll\n Description: bundled as a dynamically linked library\n Availability: https://github.com/OpenMathLib/OpenBLAS/\n License: BSD-3-Clause\n   Copyright (c) 2011-2014, The OpenBLAS Project\n   All rights reserved.\n\n   Redistribution and use in source and binary forms, with or without\n   modification, are permitted provided that the following conditions are\n   met:\n\n      1. Redistributions of source code must retain the above copyright\n         notice, this list of conditions and the following disclaimer.\n\n      2. Redistributions in binary form must reproduce the above copyright\n         notice, this list of conditions and the following disclaimer in\n         the documentation and/or other materials provided with the\n         distribution.\n      3. Neither the name of the OpenBLAS project nor the names of\n         its contributors may be used to endorse or promote products\n         derived from this software without specific prior written\n         permission.\n\n   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n   AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n   IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n   ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n   LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n   DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n   SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n   CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n   OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n   USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\n Name: LAPACK\n Files: numpy.libs\\libscipy_openblas*.dll\n Description: bundled in OpenBLAS\n Availability: https://github.com/OpenMathLib/OpenBLAS/\n License: BSD-3-Clause-Attribution\n   Copyright (c) 1992-2013 The University of Tennessee and The University\n                           of Tennessee Research Foundation.  All rights\n                           reserved.\n   Copyright (c) 2000-2013 The University of California Berkeley. All\n                           rights reserved.\n   Copyright (c) 2006-2013 The University of Colorado Denver.  All rights\n                           reserved.\n\n   $COPYRIGHT$\n\n   Additional copyrights may follow\n\n   $HEADER$\n\n   Redistribution and use in source and binary forms, with or without\n   modification, are permitted provided that the following conditions are\n   met:\n\n   - Redistributions of source code must retain the above copyright\n     notice, this list of conditions and the following disclaimer.\n\n   - Redistributions in binary form must reproduce the above copyright\n     notice, this list of conditions and the following disclaimer listed\n     in this license in the documentation and/or other materials\n     provided with the distribution.\n\n   - Neither the name of the copyright holders nor the names of its\n     contributors may be used to endorse or promote products derived from\n     this software without specific prior written permission.\n\n   The copyright holders provide no reassurances that the source code\n   provided does not infringe any patent, copyright, or any other\n   intellectual property rights of third parties.  The copyright holders\n   disclaim any liability to any recipient for claims brought against\n   recipient by any third party for infringement of that parties\n   intellectual property rights.\n\n   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n   \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\n Name: GCC runtime library\n Files: numpy.libs\\libscipy_openblas*.dll\n Description: statically linked to files compiled with gcc\n Availability: https://gcc.gnu.org/git/?p=gcc.git;a=tree;f=libgfortran\n License: GPL-3.0-with-GCC-exception\n   Copyright (C) 2002-2017 Free Software Foundation, Inc.\n\n   Libgfortran is free software; you can redistribute it and/or modify\n   it under the terms of the GNU General Public License as published by\n   the Free Software Foundation; either version 3, or (at your option)\n   any later version.\n\n   Libgfortran is distributed in the hope that it will be useful,\n   but WITHOUT ANY WARRANTY; without even the implied warranty of\n   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n   GNU General Public License for more details.\n\n   Under Section 7 of GPL version 3, you are granted additional\n   permissions described in the GCC Runtime Library Exception, version\n   3.1, as published by the Free Software Foundation.\n\n   You should have received a copy of the GNU General Public License and\n   a copy of the GCC Runtime Library Exception along with this program;\n   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n   <http://www.gnu.org/licenses/>.\n\n ----\n\n Full text of license texts referred to above follows (that they are\n listed below does not necessarily imply the conditions apply to the\n present binary release):\n\n ----\n\n GCC RUNTIME LIBRARY EXCEPTION\n\n Version 3.1, 31 March 2009\n\n Copyright (C) 2009 Free Software Foundation, Inc. <http://fsf.org/>\n\n Everyone is permitted to copy and distribute verbatim copies of this\n license document, but changing it is not allowed.\n\n This GCC Runtime Library Exception (\"Exception\") is an additional\n permission under section 7 of the GNU General Public License, version\n 3 (\"GPLv3\"). It applies to a given file (the \"Runtime Library\") that\n bears a notice placed by the copyright holder of the file stating that\n the file is governed by GPLv3 along with this Exception.\n\n When you use GCC to compile a program, GCC may combine portions of\n certain GCC header files and runtime libraries with the compiled\n program. The purpose of this Exception is to allow compilation of\n non-GPL (including proprietary) programs to use, in this way, the\n header files and runtime libraries covered by this Exception.\n\n 0. Definitions.\n\n A file is an \"Independent Module\" if it either requires the Runtime\n Library for execution after a Compilation Process, or makes use of an\n interface provided by the Runtime Library, but is not otherwise based\n on the Runtime Library.\n\n \"GCC\" means a version of the GNU Compiler Collection, with or without\n modifications, governed by version 3 (or a specified later version) of\n the GNU General Public License (GPL) with the option of using any\n subsequent versions published by the FSF.\n\n \"GPL-compatible Software\" is software whose conditions of propagation,\n modification and use would permit combination with GCC in accord with\n the license of GCC.\n\n \"Target Code\" refers to output from any compiler for a real or virtual\n target processor architecture, in executable form or suitable for\n input to an assembler, loader, linker and/or execution\n phase. Notwithstanding that, Target Code does not include data in any\n format that is used as a compiler intermediate representation, or used\n for producing a compiler intermediate representation.\n\n The \"Compilation Process\" transforms code entirely represented in\n non-intermediate languages designed for human-written code, and/or in\n Java Virtual Machine byte code, into Target Code. Thus, for example,\n use of source code generators and preprocessors need not be considered\n part of the Compilation Process, since the Compilation Process can be\n understood as starting with the output of the generators or\n preprocessors.\n\n A Compilation Process is \"Eligible\" if it is done using GCC, alone or\n with other GPL-compatible software, or if it is done without using any\n work based on GCC. For example, using non-GPL-compatible Software to\n optimize any GCC intermediate representations would not qualify as an\n Eligible Compilation Process.\n\n 1. Grant of Additional Permission.\n\n You have permission to propagate a work of Target Code formed by\n combining the Runtime Library with Independent Modules, even if such\n propagation would otherwise violate the terms of GPLv3, provided that\n all Target Code was generated by Eligible Compilation Processes. You\n may then convey such a combination under terms of your choice,\n consistent with the licensing of the Independent Modules.\n\n 2. No Weakening of GCC Copyleft.\n\n The availability of this Exception does not imply any general\n presumption that third-party software is unaffected by the copyleft\n requirements of the license of GCC.\n\n ----\n\n                     GNU GENERAL PUBLIC LICENSE\n                        Version 3, 29 June 2007\n\n  Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>\n  Everyone is permitted to copy and distribute verbatim copies\n  of this license document, but changing it is not allowed.\n\n                             Preamble\n\n   The GNU General Public License is a free, copyleft license for\n software and other kinds of works.\n\n   The licenses for most software and other practical works are designed\n to take away your freedom to share and change the works.  By contrast,\n the GNU General Public License is intended to guarantee your freedom to\n share and change all versions of a program--to make sure it remains free\n software for all its users.  We, the Free Software Foundation, use the\n GNU General Public License for most of our software; it applies also to\n any other work released this way by its authors.  You can apply it to\n your programs, too.\n\n   When we speak of free software, we are referring to freedom, not\n price.  Our General Public Licenses are designed to make sure that you\n have the freedom to distribute copies of free software (and charge for\n them if you wish), that you receive source code or can get it if you\n want it, that you can change the software or use pieces of it in new\n free programs, and that you know you can do these things.\n\n   To protect your rights, we need to prevent others from denying you\n these rights or asking you to surrender the rights.  Therefore, you have\n certain responsibilities if you distribute copies of the software, or if\n you modify it: responsibilities to respect the freedom of others.\n\n   For example, if you distribute copies of such a program, whether\n gratis or for a fee, you must pass on to the recipients the same\n freedoms that you received.  You must make sure that they, too, receive\n or can get the source code.  And you must show them these terms so they\n know their rights.\n\n   Developers that use the GNU GPL protect your rights with two steps:\n (1) assert copyright on the software, and (2) offer you this License\n giving you legal permission to copy, distribute and/or modify it.\n\n   For the developers' and authors' protection, the GPL clearly explains\n that there is no warranty for this free software.  For both users' and\n authors' sake, the GPL requires that modified versions be marked as\n changed, so that their problems will not be attributed erroneously to\n authors of previous versions.\n\n   Some devices are designed to deny users access to install or run\n modified versions of the software inside them, although the manufacturer\n can do so.  This is fundamentally incompatible with the aim of\n protecting users' freedom to change the software.  The systematic\n pattern of such abuse occurs in the area of products for individuals to\n use, which is precisely where it is most unacceptable.  Therefore, we\n have designed this version of the GPL to prohibit the practice for those\n products.  If such problems arise substantially in other domains, we\n stand ready to extend this provision to those domains in future versions\n of the GPL, as needed to protect the freedom of users.\n\n   Finally, every program is threatened constantly by software patents.\n States should not allow patents to restrict development and use of\n software on general-purpose computers, but in those that do, we wish to\n avoid the special danger that patents applied to a free program could\n make it effectively proprietary.  To prevent this, the GPL assures that\n patents cannot be used to render the program non-free.\n\n   The precise terms and conditions for copying, distribution and\n modification follow.\n\n                        TERMS AND CONDITIONS\n\n   0. Definitions.\n\n   \"This License\" refers to version 3 of the GNU General Public License.\n\n   \"Copyright\" also means copyright-like laws that apply to other kinds of\n works, such as semiconductor masks.\n\n   \"The Program\" refers to any copyrightable work licensed under this\n License.  Each licensee is addressed as \"you\".  \"Licensees\" and\n \"recipients\" may be individuals or organizations.\n\n   To \"modify\" a work means to copy from or adapt all or part of the work\n in a fashion requiring copyright permission, other than the making of an\n exact copy.  The resulting work is called a \"modified version\" of the\n earlier work or a work \"based on\" the earlier work.\n\n   A \"covered work\" means either the unmodified Program or a work based\n on the Program.\n\n   To \"propagate\" a work means to do anything with it that, without\n permission, would make you directly or secondarily liable for\n infringement under applicable copyright law, except executing it on a\n computer or modifying a private copy.  Propagation includes copying,\n distribution (with or without modification), making available to the\n public, and in some countries other activities as well.\n\n   To \"convey\" a work means any kind of propagation that enables other\n parties to make or receive copies.  Mere interaction with a user through\n a computer network, with no transfer of a copy, is not conveying.\n\n   An interactive user interface displays \"Appropriate Legal Notices\"\n to the extent that it includes a convenient and prominently visible\n feature that (1) displays an appropriate copyright notice, and (2)\n tells the user that there is no warranty for the work (except to the\n extent that warranties are provided), that licensees may convey the\n work under this License, and how to view a copy of this License.  If\n the interface presents a list of user commands or options, such as a\n menu, a prominent item in the list meets this criterion.\n\n   1. Source Code.\n\n   The \"source code\" for a work means the preferred form of the work\n for making modifications to it.  \"Object code\" means any non-source\n form of a work.\n\n   A \"Standard Interface\" means an interface that either is an official\n standard defined by a recognized standards body, or, in the case of\n interfaces specified for a particular programming language, one that\n is widely used among developers working in that language.\n\n   The \"System Libraries\" of an executable work include anything, other\n than the work as a whole, that (a) is included in the normal form of\n packaging a Major Component, but which is not part of that Major\n Component, and (b) serves only to enable use of the work with that\n Major Component, or to implement a Standard Interface for which an\n implementation is available to the public in source code form.  A\n \"Major Component\", in this context, means a major essential component\n (kernel, window system, and so on) of the specific operating system\n (if any) on which the executable work runs, or a compiler used to\n produce the work, or an object code interpreter used to run it.\n\n   The \"Corresponding Source\" for a work in object code form means all\n the source code needed to generate, install, and (for an executable\n work) run the object code and to modify the work, including scripts to\n control those activities.  However, it does not include the work's\n System Libraries, or general-purpose tools or generally available free\n programs which are used unmodified in performing those activities but\n which are not part of the work.  For example, Corresponding Source\n includes interface definition files associated with source files for\n the work, and the source code for shared libraries and dynamically\n linked subprograms that the work is specifically designed to require,\n such as by intimate data communication or control flow between those\n subprograms and other parts of the work.\n\n   The Corresponding Source need not include anything that users\n can regenerate automatically from other parts of the Corresponding\n Source.\n\n   The Corresponding Source for a work in source code form is that\n same work.\n\n   2. Basic Permissions.\n\n   All rights granted under this License are granted for the term of\n copyright on the Program, and are irrevocable provided the stated\n conditions are met.  This License explicitly affirms your unlimited\n permission to run the unmodified Program.  The output from running a\n covered work is covered by this License only if the output, given its\n content, constitutes a covered work.  This License acknowledges your\n rights of fair use or other equivalent, as provided by copyright law.\n\n   You may make, run and propagate covered works that you do not\n convey, without conditions so long as your license otherwise remains\n in force.  You may convey covered works to others for the sole purpose\n of having them make modifications exclusively for you, or provide you\n with facilities for running those works, provided that you comply with\n the terms of this License in conveying all material for which you do\n not control copyright.  Those thus making or running the covered works\n for you must do so exclusively on your behalf, under your direction\n and control, on terms that prohibit them from making any copies of\n your copyrighted material outside their relationship with you.\n\n   Conveying under any other circumstances is permitted solely under\n the conditions stated below.  Sublicensing is not allowed; section 10\n makes it unnecessary.\n\n   3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n   No covered work shall be deemed part of an effective technological\n measure under any applicable law fulfilling obligations under article\n 11 of the WIPO copyright treaty adopted on 20 December 1996, or\n similar laws prohibiting or restricting circumvention of such\n measures.\n\n   When you convey a covered work, you waive any legal power to forbid\n circumvention of technological measures to the extent such circumvention\n is effected by exercising rights under this License with respect to\n the covered work, and you disclaim any intention to limit operation or\n modification of the work as a means of enforcing, against the work's\n users, your or third parties' legal rights to forbid circumvention of\n technological measures.\n\n   4. Conveying Verbatim Copies.\n\n   You may convey verbatim copies of the Program's source code as you\n receive it, in any medium, provided that you conspicuously and\n appropriately publish on each copy an appropriate copyright notice;\n keep intact all notices stating that this License and any\n non-permissive terms added in accord with section 7 apply to the code;\n keep intact all notices of the absence of any warranty; and give all\n recipients a copy of this License along with the Program.\n\n   You may charge any price or no price for each copy that you convey,\n and you may offer support or warranty protection for a fee.\n\n   5. Conveying Modified Source Versions.\n\n   You may convey a work based on the Program, or the modifications to\n produce it from the Program, in the form of source code under the\n terms of section 4, provided that you also meet all of these conditions:\n\n     a) The work must carry prominent notices stating that you modified\n     it, and giving a relevant date.\n\n     b) The work must carry prominent notices stating that it is\n     released under this License and any conditions added under section\n     7.  This requirement modifies the requirement in section 4 to\n     \"keep intact all notices\".\n\n     c) You must license the entire work, as a whole, under this\n     License to anyone who comes into possession of a copy.  This\n     License will therefore apply, along with any applicable section 7\n     additional terms, to the whole of the work, and all its parts,\n     regardless of how they are packaged.  This License gives no\n     permission to license the work in any other way, but it does not\n     invalidate such permission if you have separately received it.\n\n     d) If the work has interactive user interfaces, each must display\n     Appropriate Legal Notices; however, if the Program has interactive\n     interfaces that do not display Appropriate Legal Notices, your\n     work need not make them do so.\n\n   A compilation of a covered work with other separate and independent\n works, which are not by their nature extensions of the covered work,\n and which are not combined with it such as to form a larger program,\n in or on a volume of a storage or distribution medium, is called an\n \"aggregate\" if the compilation and its resulting copyright are not\n used to limit the access or legal rights of the compilation's users\n beyond what the individual works permit.  Inclusion of a covered work\n in an aggregate does not cause this License to apply to the other\n parts of the aggregate.\n\n   6. Conveying Non-Source Forms.\n\n   You may convey a covered work in object code form under the terms\n of sections 4 and 5, provided that you also convey the\n machine-readable Corresponding Source under the terms of this License,\n in one of these ways:\n\n     a) Convey the object code in, or embodied in, a physical product\n     (including a physical distribution medium), accompanied by the\n     Corresponding Source fixed on a durable physical medium\n     customarily used for software interchange.\n\n     b) Convey the object code in, or embodied in, a physical product\n     (including a physical distribution medium), accompanied by a\n     written offer, valid for at least three years and valid for as\n     long as you offer spare parts or customer support for that product\n     model, to give anyone who possesses the object code either (1) a\n     copy of the Corresponding Source for all the software in the\n     product that is covered by this License, on a durable physical\n     medium customarily used for software interchange, for a price no\n     more than your reasonable cost of physically performing this\n     conveying of source, or (2) access to copy the\n     Corresponding Source from a network server at no charge.\n\n     c) Convey individual copies of the object code with a copy of the\n     written offer to provide the Corresponding Source.  This\n     alternative is allowed only occasionally and noncommercially, and\n     only if you received the object code with such an offer, in accord\n     with subsection 6b.\n\n     d) Convey the object code by offering access from a designated\n     place (gratis or for a charge), and offer equivalent access to the\n     Corresponding Source in the same way through the same place at no\n     further charge.  You need not require recipients to copy the\n     Corresponding Source along with the object code.  If the place to\n     copy the object code is a network server, the Corresponding Source\n     may be on a different server (operated by you or a third party)\n     that supports equivalent copying facilities, provided you maintain\n     clear directions next to the object code saying where to find the\n     Corresponding Source.  Regardless of what server hosts the\n     Corresponding Source, you remain obligated to ensure that it is\n     available for as long as needed to satisfy these requirements.\n\n     e) Convey the object code using peer-to-peer transmission, provided\n     you inform other peers where the object code and Corresponding\n     Source of the work are being offered to the general public at no\n     charge under subsection 6d.\n\n   A separable portion of the object code, whose source code is excluded\n from the Corresponding Source as a System Library, need not be\n included in conveying the object code work.\n\n   A \"User Product\" is either (1) a \"consumer product\", which means any\n tangible personal property which is normally used for personal, family,\n or household purposes, or (2) anything designed or sold for incorporation\n into a dwelling.  In determining whether a product is a consumer product,\n doubtful cases shall be resolved in favor of coverage.  For a particular\n product received by a particular user, \"normally used\" refers to a\n typical or common use of that class of product, regardless of the status\n of the particular user or of the way in which the particular user\n actually uses, or expects or is expected to use, the product.  A product\n is a consumer product regardless of whether the product has substantial\n commercial, industrial or non-consumer uses, unless such uses represent\n the only significant mode of use of the product.\n\n   \"Installation Information\" for a User Product means any methods,\n procedures, authorization keys, or other information required to install\n and execute modified versions of a covered work in that User Product from\n a modified version of its Corresponding Source.  The information must\n suffice to ensure that the continued functioning of the modified object\n code is in no case prevented or interfered with solely because\n modification has been made.\n\n   If you convey an object code work under this section in, or with, or\n specifically for use in, a User Product, and the conveying occurs as\n part of a transaction in which the right of possession and use of the\n User Product is transferred to the recipient in perpetuity or for a\n fixed term (regardless of how the transaction is characterized), the\n Corresponding Source conveyed under this section must be accompanied\n by the Installation Information.  But this requirement does not apply\n if neither you nor any third party retains the ability to install\n modified object code on the User Product (for example, the work has\n been installed in ROM).\n\n   The requirement to provide Installation Information does not include a\n requirement to continue to provide support service, warranty, or updates\n for a work that has been modified or installed by the recipient, or for\n the User Product in which it has been modified or installed.  Access to a\n network may be denied when the modification itself materially and\n adversely affects the operation of the network or violates the rules and\n protocols for communication across the network.\n\n   Corresponding Source conveyed, and Installation Information provided,\n in accord with this section must be in a format that is publicly\n documented (and with an implementation available to the public in\n source code form), and must require no special password or key for\n unpacking, reading or copying.\n\n   7. Additional Terms.\n\n   \"Additional permissions\" are terms that supplement the terms of this\n License by making exceptions from one or more of its conditions.\n Additional permissions that are applicable to the entire Program shall\n be treated as though they were included in this License, to the extent\n that they are valid under applicable law.  If additional permissions\n apply only to part of the Program, that part may be used separately\n under those permissions, but the entire Program remains governed by\n this License without regard to the additional permissions.\n\n   When you convey a copy of a covered work, you may at your option\n remove any additional permissions from that copy, or from any part of\n it.  (Additional permissions may be written to require their own\n removal in certain cases when you modify the work.)  You may place\n additional permissions on material, added by you to a covered work,\n for which you have or can give appropriate copyright permission.\n\n   Notwithstanding any other provision of this License, for material you\n add to a covered work, you may (if authorized by the copyright holders of\n that material) supplement the terms of this License with terms:\n\n     a) Disclaiming warranty or limiting liability differently from the\n     terms of sections 15 and 16 of this License; or\n\n     b) Requiring preservation of specified reasonable legal notices or\n     author attributions in that material or in the Appropriate Legal\n     Notices displayed by works containing it; or\n\n     c) Prohibiting misrepresentation of the origin of that material, or\n     requiring that modified versions of such material be marked in\n     reasonable ways as different from the original version; or\n\n     d) Limiting the use for publicity purposes of names of licensors or\n     authors of the material; or\n\n     e) Declining to grant rights under trademark law for use of some\n     trade names, trademarks, or service marks; or\n\n     f) Requiring indemnification of licensors and authors of that\n     material by anyone who conveys the material (or modified versions of\n     it) with contractual assumptions of liability to the recipient, for\n     any liability that these contractual assumptions directly impose on\n     those licensors and authors.\n\n   All other non-permissive additional terms are considered \"further\n restrictions\" within the meaning of section 10.  If the Program as you\n received it, or any part of it, contains a notice stating that it is\n governed by this License along with a term that is a further\n restriction, you may remove that term.  If a license document contains\n a further restriction but permits relicensing or conveying under this\n License, you may add to a covered work material governed by the terms\n of that license document, provided that the further restriction does\n not survive such relicensing or conveying.\n\n   If you add terms to a covered work in accord with this section, you\n must place, in the relevant source files, a statement of the\n additional terms that apply to those files, or a notice indicating\n where to find the applicable terms.\n\n   Additional terms, permissive or non-permissive, may be stated in the\n form of a separately written license, or stated as exceptions;\n the above requirements apply either way.\n\n   8. Termination.\n\n   You may not propagate or modify a covered work except as expressly\n provided under this License.  Any attempt otherwise to propagate or\n modify it is void, and will automatically terminate your rights under\n this License (including any patent licenses granted under the third\n paragraph of section 11).\n\n   However, if you cease all violation of this License, then your\n license from a particular copyright holder is reinstated (a)\n provisionally, unless and until the copyright holder explicitly and\n finally terminates your license, and (b) permanently, if the copyright\n holder fails to notify you of the violation by some reasonable means\n prior to 60 days after the cessation.\n\n   Moreover, your license from a particular copyright holder is\n reinstated permanently if the copyright holder notifies you of the\n violation by some reasonable means, this is the first time you have\n received notice of violation of this License (for any work) from that\n copyright holder, and you cure the violation prior to 30 days after\n your receipt of the notice.\n\n   Termination of your rights under this section does not terminate the\n licenses of parties who have received copies or rights from you under\n this License.  If your rights have been terminated and not permanently\n reinstated, you do not qualify to receive new licenses for the same\n material under section 10.\n\n   9. Acceptance Not Required for Having Copies.\n\n   You are not required to accept this License in order to receive or\n run a copy of the Program.  Ancillary propagation of a covered work\n occurring solely as a consequence of using peer-to-peer transmission\n to receive a copy likewise does not require acceptance.  However,\n nothing other than this License grants you permission to propagate or\n modify any covered work.  These actions infringe copyright if you do\n not accept this License.  Therefore, by modifying or propagating a\n covered work, you indicate your acceptance of this License to do so.\n\n   10. Automatic Licensing of Downstream Recipients.\n\n   Each time you convey a covered work, the recipient automatically\n receives a license from the original licensors, to run, modify and\n propagate that work, subject to this License.  You are not responsible\n for enforcing compliance by third parties with this License.\n\n   An \"entity transaction\" is a transaction transferring control of an\n organization, or substantially all assets of one, or subdividing an\n organization, or merging organizations.  If propagation of a covered\n work results from an entity transaction, each party to that\n transaction who receives a copy of the work also receives whatever\n licenses to the work the party's predecessor in interest had or could\n give under the previous paragraph, plus a right to possession of the\n Corresponding Source of the work from the predecessor in interest, if\n the predecessor has it or can get it with reasonable efforts.\n\n   You may not impose any further restrictions on the exercise of the\n rights granted or affirmed under this License.  For example, you may\n not impose a license fee, royalty, or other charge for exercise of\n rights granted under this License, and you may not initiate litigation\n (including a cross-claim or counterclaim in a lawsuit) alleging that\n any patent claim is infringed by making, using, selling, offering for\n sale, or importing the Program or any portion of it.\n\n   11. Patents.\n\n   A \"contributor\" is a copyright holder who authorizes use under this\n License of the Program or a work on which the Program is based.  The\n work thus licensed is called the contributor's \"contributor version\".\n\n   A contributor's \"essential patent claims\" are all patent claims\n owned or controlled by the contributor, whether already acquired or\n hereafter acquired, that would be infringed by some manner, permitted\n by this License, of making, using, or selling its contributor version,\n but do not include claims that would be infringed only as a\n consequence of further modification of the contributor version.  For\n purposes of this definition, \"control\" includes the right to grant\n patent sublicenses in a manner consistent with the requirements of\n this License.\n\n   Each contributor grants you a non-exclusive, worldwide, royalty-free\n patent license under the contributor's essential patent claims, to\n make, use, sell, offer for sale, import and otherwise run, modify and\n propagate the contents of its contributor version.\n\n   In the following three paragraphs, a \"patent license\" is any express\n agreement or commitment, however denominated, not to enforce a patent\n (such as an express permission to practice a patent or covenant not to\n sue for patent infringement).  To \"grant\" such a patent license to a\n party means to make such an agreement or commitment not to enforce a\n patent against the party.\n\n   If you convey a covered work, knowingly relying on a patent license,\n and the Corresponding Source of the work is not available for anyone\n to copy, free of charge and under the terms of this License, through a\n publicly available network server or other readily accessible means,\n then you must either (1) cause the Corresponding Source to be so\n available, or (2) arrange to deprive yourself of the benefit of the\n patent license for this particular work, or (3) arrange, in a manner\n consistent with the requirements of this License, to extend the patent\n license to downstream recipients.  \"Knowingly relying\" means you have\n actual knowledge that, but for the patent license, your conveying the\n covered work in a country, or your recipient's use of the covered work\n in a country, would infringe one or more identifiable patents in that\n country that you have reason to believe are valid.\n\n   If, pursuant to or in connection with a single transaction or\n arrangement, you convey, or propagate by procuring conveyance of, a\n covered work, and grant a patent license to some of the parties\n receiving the covered work authorizing them to use, propagate, modify\n or convey a specific copy of the covered work, then the patent license\n you grant is automatically extended to all recipients of the covered\n work and works based on it.\n\n   A patent license is \"discriminatory\" if it does not include within\n the scope of its coverage, prohibits the exercise of, or is\n conditioned on the non-exercise of one or more of the rights that are\n specifically granted under this License.  You may not convey a covered\n work if you are a party to an arrangement with a third party that is\n in the business of distributing software, under which you make payment\n to the third party based on the extent of your activity of conveying\n the work, and under which the third party grants, to any of the\n parties who would receive the covered work from you, a discriminatory\n patent license (a) in connection with copies of the covered work\n conveyed by you (or copies made from those copies), or (b) primarily\n for and in connection with specific products or compilations that\n contain the covered work, unless you entered into that arrangement,\n or that patent license was granted, prior to 28 March 2007.\n\n   Nothing in this License shall be construed as excluding or limiting\n any implied license or other defenses to infringement that may\n otherwise be available to you under applicable patent law.\n\n   12. No Surrender of Others' Freedom.\n\n   If conditions are imposed on you (whether by court order, agreement or\n otherwise) that contradict the conditions of this License, they do not\n excuse you from the conditions of this License.  If you cannot convey a\n covered work so as to satisfy simultaneously your obligations under this\n License and any other pertinent obligations, then as a consequence you may\n not convey it at all.  For example, if you agree to terms that obligate you\n to collect a royalty for further conveying from those to whom you convey\n the Program, the only way you could satisfy both those terms and this\n License would be to refrain entirely from conveying the Program.\n\n   13. Use with the GNU Affero General Public License.\n\n   Notwithstanding any other provision of this License, you have\n permission to link or combine any covered work with a work licensed\n under version 3 of the GNU Affero General Public License into a single\n combined work, and to convey the resulting work.  The terms of this\n License will continue to apply to the part which is the covered work,\n but the special requirements of the GNU Affero General Public License,\n section 13, concerning interaction through a network will apply to the\n combination as such.\n\n   14. Revised Versions of this License.\n\n   The Free Software Foundation may publish revised and/or new versions of\n the GNU General Public License from time to time.  Such new versions will\n be similar in spirit to the present version, but may differ in detail to\n address new problems or concerns.\n\n   Each version is given a distinguishing version number.  If the\n Program specifies that a certain numbered version of the GNU General\n Public License \"or any later version\" applies to it, you have the\n option of following the terms and conditions either of that numbered\n version or of any later version published by the Free Software\n Foundation.  If the Program does not specify a version number of the\n GNU General Public License, you may choose any version ever published\n by the Free Software Foundation.\n\n   If the Program specifies that a proxy can decide which future\n versions of the GNU General Public License can be used, that proxy's\n public statement of acceptance of a version permanently authorizes you\n to choose that version for the Program.\n\n   Later license versions may give you additional or different\n permissions.  However, no additional obligations are imposed on any\n author or copyright holder as a result of your choosing to follow a\n later version.\n\n   15. Disclaimer of Warranty.\n\n   THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\n APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\n HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\n OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\n THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\n IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\n ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n   16. Limitation of Liability.\n\n   IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\n WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\n THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\n GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\n USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\n DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\n PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\n EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\n SUCH DAMAGES.\n\n   17. Interpretation of Sections 15 and 16.\n\n   If the disclaimer of warranty and limitation of liability provided\n above cannot be given local legal effect according to their terms,\n reviewing courts shall apply local law that most closely approximates\n an absolute waiver of all civil liability in connection with the\n Program, unless a warranty or assumption of liability accompanies a\n copy of the Program in return for a fee.\n\n                      END OF TERMS AND CONDITIONS\n\n             How to Apply These Terms to Your New Programs\n\n   If you develop a new program, and you want it to be of the greatest\n possible use to the public, the best way to achieve this is to make it\n free software which everyone can redistribute and change under these terms.\n\n   To do so, attach the following notices to the program.  It is safest\n to attach them to the start of each source file to most effectively\n state the exclusion of warranty; and each file should have at least\n the \"copyright\" line and a pointer to where the full notice is found.\n\n     <one line to give the program's name and a brief idea of what it does.>\n     Copyright (C) <year>  <name of author>\n\n     This program is free software: you can redistribute it and/or modify\n     it under the terms of the GNU General Public License as published by\n     the Free Software Foundation, either version 3 of the License, or\n     (at your option) any later version.\n\n     This program is distributed in the hope that it will be useful,\n     but WITHOUT ANY WARRANTY; without even the implied warranty of\n     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n     GNU General Public License for more details.\n\n     You should have received a copy of the GNU General Public License\n     along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n Also add information on how to contact you by electronic and paper mail.\n\n   If the program does terminal interaction, make it output a short\n notice like this when it starts in an interactive mode:\n\n     <program>  Copyright (C) <year>  <name of author>\n     This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n     This is free software, and you are welcome to redistribute it\n     under certain conditions; type `show c' for details.\n\n The hypothetical commands `show w' and `show c' should show the appropriate\n parts of the General Public License.  Of course, your program's commands\n might be different; for a GUI interface, you would use an \"about box\".\n\n   You should also get your employer (if you work as a programmer) or school,\n if any, to sign a \"copyright disclaimer\" for the program, if necessary.\n For more information on this, and how to apply and follow the GNU GPL, see\n <http://www.gnu.org/licenses/>.\n\n   The GNU General Public License does not permit incorporating your program\n into proprietary programs.  If your program is a subroutine library, you\n may consider it more useful to permit linking proprietary applications with\n the library.  If this is what you want to do, use the GNU Lesser General\n Public License instead of this License.  But first, please read\n <http://www.gnu.org/philosophy/why-not-lgpl.html>.\n\n",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Science/Research",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: C",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation :: CPython",
          "Topic :: Software Development",
          "Topic :: Scientific/Engineering",
          "Typing :: Typed",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX",
          "Operating System :: Unix",
          "Operating System :: MacOS"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "homepage, https://numpy.org",
          "documentation, https://numpy.org/doc/",
          "source, https://github.com/numpy/numpy",
          "download, https://pypi.org/project/numpy/#files",
          "tracker, https://github.com/numpy/numpy/issues",
          "release notes, https://numpy.org/doc/stable/release"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\numpy-2.1.3.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "openpyxl",
        "version": "3.1.5",
        "summary": "A Python library to read/write Excel 2010 xlsx/xlsm files",
        "description": ".. image:: https://coveralls.io/repos/bitbucket/openpyxl/openpyxl/badge.svg?branch=default\n    :target: https://coveralls.io/bitbucket/openpyxl/openpyxl?branch=default\n    :alt: coverage status\n\nIntroduction\n------------\n\nopenpyxl is a Python library to read/write Excel 2010 xlsx/xlsm/xltx/xltm files.\n\nIt was born from lack of existing library to read/write natively from Python\nthe Office Open XML format.\n\nAll kudos to the PHPExcel team as openpyxl was initially based on PHPExcel.\n\n\nSecurity\n--------\n\nBy default openpyxl does not guard against quadratic blowup or billion laughs\nxml attacks. To guard against these attacks install defusedxml.\n\nMailing List\n------------\n\nThe user list can be found on http://groups.google.com/group/openpyxl-users\n\n\nSample code::\n\n    from openpyxl import Workbook\n    wb = Workbook()\n\n    # grab the active worksheet\n    ws = wb.active\n\n    # Data can be assigned directly to cells\n    ws['A1'] = 42\n\n    # Rows can also be appended\n    ws.append([1, 2, 3])\n\n    # Python types will automatically be converted\n    import datetime\n    ws['A2'] = datetime.datetime.now()\n\n    # Save the file\n    wb.save(\"sample.xlsx\")\n\n\nDocumentation\n-------------\n\nThe documentation is at: https://openpyxl.readthedocs.io\n\n* installation methods\n* code examples\n* instructions for contributing\n\nRelease notes: https://openpyxl.readthedocs.io/en/stable/changes.html\n",
        "home_page": "https://openpyxl.readthedocs.io",
        "author": "See AUTHORS",
        "author_email": "charlie.clark@clark-consulting.eu",
        "license": "MIT",
        "license_file": [
          "LICENCE.rst"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX",
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11"
        ],
        "requires_dist": [
          "et-xmlfile"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://openpyxl.readthedocs.io/en/stable/",
          "Source, https://foss.heptapod.net/openpyxl/openpyxl",
          "Tracker, https://foss.heptapod.net/openpyxl/openpyxl/-/issues"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\openpyxl-3.1.5.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "packageurl-python",
        "version": "0.15.6",
        "summary": "A purl aka. Package URL parser and builder",
        "description": "=================\npackageurl-python\n=================\n\nPython library to parse and build \"purl\" aka. Package URLs.\nSee https://github.com/package-url/purl-spec for details.\n\nJoin the discussion at https://gitter.im/package-url/Lobby or enter a ticket for support.\n\nLicense: MIT\n\nTests and build status\n======================\n\n+----------------------+\n| **Tests and build**  |\n+======================+\n| |ci-tests|           |\n+----------------------+\n\nInstall\n=======\n::\n\n    pip install packageurl-python\n\nUsage\n=====\n::\n\n    >>> from packageurl import PackageURL\n\n    >>> purl = PackageURL.from_string(\"pkg:maven/org.apache.commons/io@1.3.4\")\n    >>> print(purl.to_dict())\n    {'type': 'maven', 'namespace': 'org.apache.commons', 'name': 'io', 'version': '1.3.4', 'qualifiers': None, 'subpath': None}\n\n    >>> print(purl.to_string())\n    pkg:maven/org.apache.commons/io@1.3.4\n\n    >>> print(str(purl))\n    pkg:maven/org.apache.commons/io@1.3.4\n\n    >>> print(repr(purl))\n    PackageURL(type='maven', namespace='org.apache.commons', name='io', version='1.3.4', qualifiers={}, subpath=None)\n\nUtilities\n=========\n\nDjango models\n^^^^^^^^^^^^^\n\n`packageurl.contrib.django.models.PackageURLMixin` is a Django abstract model mixin to\nuse Package URLs in Django.\n\nSQLAlchemy mixin\n^^^^^^^^^^^^^^^^\n\n`packageurl.contrib.sqlalchemy.mixin.PackageURLMixin` is a SQLAlchemy declarative mixin\nto use Package URLs in SQLAlchemy models.\n\nURL to PURL\n^^^^^^^^^^^\n\n`packageurl.contrib.url2purl.get_purl(url)` returns a Package URL inferred from an URL.\n\n::\n\n    >>> from packageurl.contrib import url2purl\n    >>> url2purl.get_purl(\"https://github.com/package-url/packageurl-python\")\n    PackageURL(type='github', namespace='package-url', name='packageurl-python', version=None, qualifiers={}, subpath=None)\n\nPURL to URL\n^^^^^^^^^^^\n\n- `packageurl.contrib.purl2url.get_repo_url(purl)` returns a repository URL inferred\n  from a Package URL.\n- `packageurl.contrib.purl2url.get_download_url(purl)` returns a download URL inferred\n  from a Package URL.\n- `packageurl.contrib.purl2url.get_inferred_urls(purl)` return all inferred URLs\n  (repository, download) from a Package URL.\n\n::\n\n    >>> from packageurl.contrib import purl2url\n\n    >>> purl2url.get_repo_url(\"pkg:gem/bundler@2.3.23\")\n    \"https://rubygems.org/gems/bundler/versions/2.3.23\"\n\n    >>> purl2url.get_download_url(\"pkg:gem/bundler@2.3.23\")\n    \"https://rubygems.org/downloads/bundler-2.3.23.gem\"\n\n    >>> purl2url.get_inferred_urls(\"pkg:gem/bundler@2.3.23\")\n    [\"https://rubygems.org/gems/bundler/versions/2.3.23\", \"https://rubygems.org/downloads/bundler-2.3.23.gem\"]\n\nRun tests\n=========\n\nInstall test dependencies::\n\n    python3 thirdparty/virtualenv.pyz --never-download --no-periodic-update .\n    bin/pip install -e .\"[test]\"\n\nRun tests::\n\n    bin/py.test tests\n\nMake a new release\n==================\n\n- Start a new release branch\n- Update the CHANGELOG.rst, AUTHORS.rst, and README.rst if needed\n- Bump version in setup.cfg\n- Run all tests\n- Install restview and validate that all .rst docs are correct\n- Commit and push this branch\n- Make a PR and merge once approved\n- Tag and push that tag. This triggers the pypi-release.yml workflow that takes care of\n  building the dist release files and upload those to pypi::\n\n    VERSION=v0.x.x\n    git tag -a $VERSION -m \"Tag $VERSION\"\n    git push origin $VERSION\n\n- Review the GitHub release created by the workflow at\n  https://github.com/package-url/packageurl-python/releases\n\n.. |ci-tests| image:: https://github.com/package-url/packageurl-python/actions/workflows/ci.yml/badge.svg?branch=main\n    :target: https://github.com/package-url/packageurl-python/actions/workflows/ci.yml\n    :alt: CI Tests and build status\n",
        "keywords": [
          "package",
          "url",
          "package manager",
          "package url"
        ],
        "home_page": "https://github.com/package-url/packageurl-python",
        "author": "the purl authors",
        "license": "MIT",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Software Development :: Libraries",
          "Topic :: Utilities",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "setuptools ; extra == 'build'",
          "wheel ; extra == 'build'",
          "isort ; extra == 'lint'",
          "black ; extra == 'lint'",
          "mypy ; extra == 'lint'",
          "sqlalchemy >=2.0.0 ; extra == 'sqlalchemy'",
          "pytest ; extra == 'test'"
        ],
        "requires_python": ">=3.7",
        "provides_extra": [
          "build",
          "lint",
          "sqlalchemy",
          "test"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\packageurl_python-0.15.6.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "packaging",
        "version": "24.1",
        "summary": "Core utilities for Python packages",
        "description": "packaging\n=========\n\n.. start-intro\n\nReusable core utilities for various Python Packaging\n`interoperability specifications <https://packaging.python.org/specifications/>`_.\n\nThis library provides utilities that implement the interoperability\nspecifications which have clearly one correct behaviour (eg: :pep:`440`)\nor benefit greatly from having a single shared implementation (eg: :pep:`425`).\n\n.. end-intro\n\nThe ``packaging`` project includes the following: version handling, specifiers,\nmarkers, requirements, tags, utilities.\n\nDocumentation\n-------------\n\nThe `documentation`_ provides information and the API for the following:\n\n- Version Handling\n- Specifiers\n- Markers\n- Requirements\n- Tags\n- Utilities\n\nInstallation\n------------\n\nUse ``pip`` to install these utilities::\n\n    pip install packaging\n\nThe ``packaging`` library uses calendar-based versioning (``YY.N``).\n\nDiscussion\n----------\n\nIf you run into bugs, you can file them in our `issue tracker`_.\n\nYou can also join ``#pypa`` on Freenode to ask questions or get involved.\n\n\n.. _`documentation`: https://packaging.pypa.io/\n.. _`issue tracker`: https://github.com/pypa/packaging/issues\n\n\nCode of Conduct\n---------------\n\nEveryone interacting in the packaging project's codebases, issue trackers, chat\nrooms, and mailing lists is expected to follow the `PSF Code of Conduct`_.\n\n.. _PSF Code of Conduct: https://github.com/pypa/.github/blob/main/CODE_OF_CONDUCT.md\n\nContributing\n------------\n\nThe ``CONTRIBUTING.rst`` file outlines how to contribute to this project as\nwell as how to report a potential security issue. The documentation for this\nproject also covers information about `project development`_ and `security`_.\n\n.. _`project development`: https://packaging.pypa.io/en/latest/development/\n.. _`security`: https://packaging.pypa.io/en/latest/security/\n\nProject History\n---------------\n\nPlease review the ``CHANGELOG.rst`` file or the `Changelog documentation`_ for\nrecent changes and project history.\n\n.. _`Changelog documentation`: https://packaging.pypa.io/en/latest/changelog/\n\n",
        "description_content_type": "text/x-rst",
        "author_email": "Donald Stufft <donald@stufft.io>",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Typing :: Typed"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://packaging.pypa.io/",
          "Source, https://github.com/pypa/packaging"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\packaging-24.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pandas",
        "version": "2.2.3",
        "summary": "Powerful data structures for data analysis, time series, and statistics",
        "description": "<div align=\"center\">\n  <img src=\"https://pandas.pydata.org/static/img/pandas.svg\"><br>\n</div>\n\n-----------------\n\n# pandas: powerful Python data analysis toolkit\n\n| | |\n| --- | --- |\n| Testing | [![CI - Test](https://github.com/pandas-dev/pandas/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/pandas-dev/pandas/actions/workflows/unit-tests.yml) [![Coverage](https://codecov.io/github/pandas-dev/pandas/coverage.svg?branch=main)](https://codecov.io/gh/pandas-dev/pandas) |\n| Package | [![PyPI Latest Release](https://img.shields.io/pypi/v/pandas.svg)](https://pypi.org/project/pandas/) [![PyPI Downloads](https://img.shields.io/pypi/dm/pandas.svg?label=PyPI%20downloads)](https://pypi.org/project/pandas/) [![Conda Latest Release](https://anaconda.org/conda-forge/pandas/badges/version.svg)](https://anaconda.org/conda-forge/pandas) [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/pandas.svg?label=Conda%20downloads)](https://anaconda.org/conda-forge/pandas) |\n| Meta | [![Powered by NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](https://numfocus.org) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3509134.svg)](https://doi.org/10.5281/zenodo.3509134) [![License - BSD 3-Clause](https://img.shields.io/pypi/l/pandas.svg)](https://github.com/pandas-dev/pandas/blob/main/LICENSE) [![Slack](https://img.shields.io/badge/join_Slack-information-brightgreen.svg?logo=slack)](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack) |\n\n\n## What is it?\n\n**pandas** is a Python package that provides fast, flexible, and expressive data\nstructures designed to make working with \"relational\" or \"labeled\" data both\neasy and intuitive. It aims to be the fundamental high-level building block for\ndoing practical, **real world** data analysis in Python. Additionally, it has\nthe broader goal of becoming **the most powerful and flexible open source data\nanalysis / manipulation tool available in any language**. It is already well on\nits way towards this goal.\n\n## Table of Contents\n\n- [Main Features](#main-features)\n- [Where to get it](#where-to-get-it)\n- [Dependencies](#dependencies)\n- [Installation from sources](#installation-from-sources)\n- [License](#license)\n- [Documentation](#documentation)\n- [Background](#background)\n- [Getting Help](#getting-help)\n- [Discussion and Development](#discussion-and-development)\n- [Contributing to pandas](#contributing-to-pandas)\n\n## Main Features\nHere are just a few of the things that pandas does well:\n\n  - Easy handling of [**missing data**][missing-data] (represented as\n    `NaN`, `NA`, or `NaT`) in floating point as well as non-floating point data\n  - Size mutability: columns can be [**inserted and\n    deleted**][insertion-deletion] from DataFrame and higher dimensional\n    objects\n  - Automatic and explicit [**data alignment**][alignment]: objects can\n    be explicitly aligned to a set of labels, or the user can simply\n    ignore the labels and let `Series`, `DataFrame`, etc. automatically\n    align the data for you in computations\n  - Powerful, flexible [**group by**][groupby] functionality to perform\n    split-apply-combine operations on data sets, for both aggregating\n    and transforming data\n  - Make it [**easy to convert**][conversion] ragged,\n    differently-indexed data in other Python and NumPy data structures\n    into DataFrame objects\n  - Intelligent label-based [**slicing**][slicing], [**fancy\n    indexing**][fancy-indexing], and [**subsetting**][subsetting] of\n    large data sets\n  - Intuitive [**merging**][merging] and [**joining**][joining] data\n    sets\n  - Flexible [**reshaping**][reshape] and [**pivoting**][pivot-table] of\n    data sets\n  - [**Hierarchical**][mi] labeling of axes (possible to have multiple\n    labels per tick)\n  - Robust IO tools for loading data from [**flat files**][flat-files]\n    (CSV and delimited), [**Excel files**][excel], [**databases**][db],\n    and saving/loading data from the ultrafast [**HDF5 format**][hdfstore]\n  - [**Time series**][timeseries]-specific functionality: date range\n    generation and frequency conversion, moving window statistics,\n    date shifting and lagging\n\n\n   [missing-data]: https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html\n   [insertion-deletion]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#column-selection-addition-deletion\n   [alignment]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html?highlight=alignment#intro-to-data-structures\n   [groupby]: https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#group-by-split-apply-combine\n   [conversion]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dataframe\n   [slicing]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#slicing-ranges\n   [fancy-indexing]: https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#advanced\n   [subsetting]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing\n   [merging]: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#database-style-dataframe-or-named-series-joining-merging\n   [joining]: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#joining-on-index\n   [reshape]: https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html\n   [pivot-table]: https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html\n   [mi]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#hierarchical-indexing-multiindex\n   [flat-files]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#csv-text-files\n   [excel]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#excel-files\n   [db]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#sql-queries\n   [hdfstore]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#hdf5-pytables\n   [timeseries]: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#time-series-date-functionality\n\n## Where to get it\nThe source code is currently hosted on GitHub at:\nhttps://github.com/pandas-dev/pandas\n\nBinary installers for the latest released version are available at the [Python\nPackage Index (PyPI)](https://pypi.org/project/pandas) and on [Conda](https://docs.conda.io/en/latest/).\n\n```sh\n# conda\nconda install -c conda-forge pandas\n```\n\n```sh\n# or PyPI\npip install pandas\n```\n\nThe list of changes to pandas between each release can be found\n[here](https://pandas.pydata.org/pandas-docs/stable/whatsnew/index.html). For full\ndetails, see the commit logs at https://github.com/pandas-dev/pandas.\n\n## Dependencies\n- [NumPy - Adds support for large, multi-dimensional arrays, matrices and high-level mathematical functions to operate on these arrays](https://www.numpy.org)\n- [python-dateutil - Provides powerful extensions to the standard datetime module](https://dateutil.readthedocs.io/en/stable/index.html)\n- [pytz - Brings the Olson tz database into Python which allows accurate and cross platform timezone calculations](https://github.com/stub42/pytz)\n\nSee the [full installation instructions](https://pandas.pydata.org/pandas-docs/stable/install.html#dependencies) for minimum supported versions of required, recommended and optional dependencies.\n\n## Installation from sources\nTo install pandas from source you need [Cython](https://cython.org/) in addition to the normal\ndependencies above. Cython can be installed from PyPI:\n\n```sh\npip install cython\n```\n\nIn the `pandas` directory (same one where you found this file after\ncloning the git repo), execute:\n\n```sh\npip install .\n```\n\nor for installing in [development mode](https://pip.pypa.io/en/latest/cli/pip_install/#install-editable):\n\n\n```sh\npython -m pip install -ve . --no-build-isolation --config-settings=editable-verbose=true\n```\n\nSee the full instructions for [installing from source](https://pandas.pydata.org/docs/dev/development/contributing_environment.html).\n\n## License\n[BSD 3](LICENSE)\n\n## Documentation\nThe official documentation is hosted on [PyData.org](https://pandas.pydata.org/pandas-docs/stable/).\n\n## Background\nWork on ``pandas`` started at [AQR](https://www.aqr.com/) (a quantitative hedge fund) in 2008 and\nhas been under active development since then.\n\n## Getting Help\n\nFor usage questions, the best place to go to is [StackOverflow](https://stackoverflow.com/questions/tagged/pandas).\nFurther, general questions and discussions can also take place on the [pydata mailing list](https://groups.google.com/forum/?fromgroups#!forum/pydata).\n\n## Discussion and Development\nMost development discussions take place on GitHub in this repo, via the [GitHub issue tracker](https://github.com/pandas-dev/pandas/issues).\n\nFurther, the [pandas-dev mailing list](https://mail.python.org/mailman/listinfo/pandas-dev) can also be used for specialized discussions or design issues, and a [Slack channel](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack) is available for quick development related questions.\n\nThere are also frequent [community meetings](https://pandas.pydata.org/docs/dev/development/community.html#community-meeting) for project maintainers open to the community as well as monthly [new contributor meetings](https://pandas.pydata.org/docs/dev/development/community.html#new-contributor-meeting) to help support new contributors.\n\nAdditional information on the communication channels can be found on the [contributor community](https://pandas.pydata.org/docs/development/community.html) page.\n\n## Contributing to pandas\n\n[![Open Source Helpers](https://www.codetriage.com/pandas-dev/pandas/badges/users.svg)](https://www.codetriage.com/pandas-dev/pandas)\n\nAll contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome.\n\nA detailed overview on how to contribute can be found in the **[contributing guide](https://pandas.pydata.org/docs/dev/development/contributing.html)**.\n\nIf you are simply looking to start working with the pandas codebase, navigate to the [GitHub \"issues\" tab](https://github.com/pandas-dev/pandas/issues) and start looking through interesting issues. There are a number of issues listed under [Docs](https://github.com/pandas-dev/pandas/issues?labels=Docs&sort=updated&state=open) and [good first issue](https://github.com/pandas-dev/pandas/issues?labels=good+first+issue&sort=updated&state=open) where you could start out.\n\nYou can also triage issues which may include reproducing bug reports, or asking for vital information such as version numbers or reproduction instructions. If you would like to start triaging issues, one easy way to get started is to [subscribe to pandas on CodeTriage](https://www.codetriage.com/pandas-dev/pandas).\n\nOr maybe through using pandas you have an idea of your own or are looking for something in the documentation and thinking â€˜this can be improvedâ€™...you can do something about it!\n\nFeel free to ask questions on the [mailing list](https://groups.google.com/forum/?fromgroups#!forum/pydata) or on [Slack](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack).\n\nAs contributors and maintainers to this project, you are expected to abide by pandas' code of conduct. More information can be found at: [Contributor Code of Conduct](https://github.com/pandas-dev/.github/blob/master/CODE_OF_CONDUCT.md)\n\n<hr>\n\n[Go to Top](#table-of-contents)\n",
        "description_content_type": "text/markdown",
        "home_page": "https://pandas.pydata.org",
        "author_email": "The Pandas Development Team <pandas-dev@python.org>",
        "license": "BSD 3-Clause License\n\nCopyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\nAll rights reserved.\n\nCopyright (c) 2011-2023, Open source contributors.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of the copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Science/Research",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Cython",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Scientific/Engineering"
        ],
        "requires_dist": [
          "numpy>=1.22.4; python_version < \"3.11\"",
          "numpy>=1.23.2; python_version == \"3.11\"",
          "numpy>=1.26.0; python_version >= \"3.12\"",
          "python-dateutil>=2.8.2",
          "pytz>=2020.1",
          "tzdata>=2022.7",
          "hypothesis>=6.46.1; extra == \"test\"",
          "pytest>=7.3.2; extra == \"test\"",
          "pytest-xdist>=2.2.0; extra == \"test\"",
          "pyarrow>=10.0.1; extra == \"pyarrow\"",
          "bottleneck>=1.3.6; extra == \"performance\"",
          "numba>=0.56.4; extra == \"performance\"",
          "numexpr>=2.8.4; extra == \"performance\"",
          "scipy>=1.10.0; extra == \"computation\"",
          "xarray>=2022.12.0; extra == \"computation\"",
          "fsspec>=2022.11.0; extra == \"fss\"",
          "s3fs>=2022.11.0; extra == \"aws\"",
          "gcsfs>=2022.11.0; extra == \"gcp\"",
          "pandas-gbq>=0.19.0; extra == \"gcp\"",
          "odfpy>=1.4.1; extra == \"excel\"",
          "openpyxl>=3.1.0; extra == \"excel\"",
          "python-calamine>=0.1.7; extra == \"excel\"",
          "pyxlsb>=1.0.10; extra == \"excel\"",
          "xlrd>=2.0.1; extra == \"excel\"",
          "xlsxwriter>=3.0.5; extra == \"excel\"",
          "pyarrow>=10.0.1; extra == \"parquet\"",
          "pyarrow>=10.0.1; extra == \"feather\"",
          "tables>=3.8.0; extra == \"hdf5\"",
          "pyreadstat>=1.2.0; extra == \"spss\"",
          "SQLAlchemy>=2.0.0; extra == \"postgresql\"",
          "psycopg2>=2.9.6; extra == \"postgresql\"",
          "adbc-driver-postgresql>=0.8.0; extra == \"postgresql\"",
          "SQLAlchemy>=2.0.0; extra == \"mysql\"",
          "pymysql>=1.0.2; extra == \"mysql\"",
          "SQLAlchemy>=2.0.0; extra == \"sql-other\"",
          "adbc-driver-postgresql>=0.8.0; extra == \"sql-other\"",
          "adbc-driver-sqlite>=0.8.0; extra == \"sql-other\"",
          "beautifulsoup4>=4.11.2; extra == \"html\"",
          "html5lib>=1.1; extra == \"html\"",
          "lxml>=4.9.2; extra == \"html\"",
          "lxml>=4.9.2; extra == \"xml\"",
          "matplotlib>=3.6.3; extra == \"plot\"",
          "jinja2>=3.1.2; extra == \"output-formatting\"",
          "tabulate>=0.9.0; extra == \"output-formatting\"",
          "PyQt5>=5.15.9; extra == \"clipboard\"",
          "qtpy>=2.3.0; extra == \"clipboard\"",
          "zstandard>=0.19.0; extra == \"compression\"",
          "dataframe-api-compat>=0.1.7; extra == \"consortium-standard\"",
          "adbc-driver-postgresql>=0.8.0; extra == \"all\"",
          "adbc-driver-sqlite>=0.8.0; extra == \"all\"",
          "beautifulsoup4>=4.11.2; extra == \"all\"",
          "bottleneck>=1.3.6; extra == \"all\"",
          "dataframe-api-compat>=0.1.7; extra == \"all\"",
          "fastparquet>=2022.12.0; extra == \"all\"",
          "fsspec>=2022.11.0; extra == \"all\"",
          "gcsfs>=2022.11.0; extra == \"all\"",
          "html5lib>=1.1; extra == \"all\"",
          "hypothesis>=6.46.1; extra == \"all\"",
          "jinja2>=3.1.2; extra == \"all\"",
          "lxml>=4.9.2; extra == \"all\"",
          "matplotlib>=3.6.3; extra == \"all\"",
          "numba>=0.56.4; extra == \"all\"",
          "numexpr>=2.8.4; extra == \"all\"",
          "odfpy>=1.4.1; extra == \"all\"",
          "openpyxl>=3.1.0; extra == \"all\"",
          "pandas-gbq>=0.19.0; extra == \"all\"",
          "psycopg2>=2.9.6; extra == \"all\"",
          "pyarrow>=10.0.1; extra == \"all\"",
          "pymysql>=1.0.2; extra == \"all\"",
          "PyQt5>=5.15.9; extra == \"all\"",
          "pyreadstat>=1.2.0; extra == \"all\"",
          "pytest>=7.3.2; extra == \"all\"",
          "pytest-xdist>=2.2.0; extra == \"all\"",
          "python-calamine>=0.1.7; extra == \"all\"",
          "pyxlsb>=1.0.10; extra == \"all\"",
          "qtpy>=2.3.0; extra == \"all\"",
          "scipy>=1.10.0; extra == \"all\"",
          "s3fs>=2022.11.0; extra == \"all\"",
          "SQLAlchemy>=2.0.0; extra == \"all\"",
          "tables>=3.8.0; extra == \"all\"",
          "tabulate>=0.9.0; extra == \"all\"",
          "xarray>=2022.12.0; extra == \"all\"",
          "xlrd>=2.0.1; extra == \"all\"",
          "xlsxwriter>=3.0.5; extra == \"all\"",
          "zstandard>=0.19.0; extra == \"all\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://pandas.pydata.org",
          "Documentation, https://pandas.pydata.org/docs/",
          "Repository, https://github.com/pandas-dev/pandas"
        ],
        "provides_extra": [
          "test",
          "pyarrow",
          "performance",
          "computation",
          "fss",
          "aws",
          "gcp",
          "excel",
          "parquet",
          "feather",
          "hdf5",
          "spss",
          "postgresql",
          "mysql",
          "sql-other",
          "html",
          "xml",
          "plot",
          "output-formatting",
          "clipboard",
          "compression",
          "consortium-standard",
          "all"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pandas-2.2.3.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pandocfilters",
        "version": "1.5.1",
        "summary": "Utilities for writing pandoc filters in python",
        "description": "pandocfilters\n=============\n\nA python module for writing `pandoc <http://pandoc.org/>`_ filters\n\nWhat are pandoc filters?\n--------------------------\nPandoc filters\nare pipes that read a JSON serialization of the Pandoc AST\nfrom stdin, transform it in some way, and write it to stdout.\nThey can be used with pandoc (>= 1.12) either using pipes ::\n\n    pandoc -t json -s | ./caps.py | pandoc -f json\n\nor using the ``--filter`` (or ``-F``) command-line option. ::\n\n    pandoc --filter ./caps.py -s\n\nFor more on pandoc filters, see the pandoc documentation under ``--filter``\nand `the tutorial on writing filters`__.\n\n__ http://johnmacfarlane.net/pandoc/scripting.html\n\nFor an alternative library for writing pandoc filters, with\na more \"Pythonic\" design, see `panflute`__.\n\n__ https://github.com/sergiocorreia/panflute\n\nCompatibility\n----------------\nPandoc 1.16 introduced link and image `attributes` to the existing\n`caption` and `target` arguments, requiring a change in pandocfilters\nthat breaks backwards compatibility. Consequently, you should use:\n\n- pandocfilters version <= 1.2.4 for pandoc versions 1.12--1.15, and\n- pandocfilters version >= 1.3.0 for pandoc versions >= 1.16.\n\nPandoc 1.17.3 (pandoc-types 1.17.*) introduced a new JSON format.\npandocfilters 1.4.0 should work with both the old and the new\nformat.\n\nInstalling\n--------------\nRun this inside the present directory::\n\n    python setup.py install\n\nOr install from PyPI::\n\n    pip install pandocfilters\n\nAvailable functions\n----------------------\nThe main functions ``pandocfilters`` exports are\n\n-  ``walk(x, action, format, meta)``\n\n   Walk a tree, applying an action to every object. Returns a modified\n   tree. An action is a function of the form\n   ``action(key, value, format, meta)``, where:\n\n   -  ``key`` is the type of the pandoc object (e.g. 'Str', 'Para')\n   -  ``value`` is the contents of the object (e.g. a string for 'Str', a list of\n      inline elements for 'Para')\n   -  ``format`` is the target output format (as supplied by the\n      ``format`` argument of ``walk``)\n   -  ``meta`` is the document's metadata\n\n   The return of an action is either:\n\n   -  ``None``: this means that the object should remain unchanged\n   -  a pandoc object: this will replace the original object\n   -  a list of pandoc objects: these will replace the original object;\n      the list is merged with the neighbors of the original objects\n      (spliced into the list the original object belongs to); returning\n      an empty list deletes the object\n\n-  ``toJSONFilter(action)``\n\n   Like ``toJSONFilters``, but takes a single action as argument.\n\n-  ``toJSONFilters(actions)``\n\n   Generate a JSON-to-JSON filter from stdin to stdout\n\n   The filter:\n\n   -  reads a JSON-formatted pandoc document from stdin\n   -  transforms it by walking the tree and performing the actions\n   -  returns a new JSON-formatted pandoc document to stdout\n\n   The argument ``actions`` is a list of functions of the form\n   ``action(key, value, format, meta)``, as described in more detail\n   under ``walk``.\n\n   This function calls ``applyJSONFilters``, with the ``format``\n   argument provided by the first command-line argument, if present.\n   (Pandoc sets this by default when calling filters.)\n\n-  ``applyJSONFilters(actions, source, format=\"\")``\n\n   Walk through JSON structure and apply filters\n\n   This:\n\n   -  reads a JSON-formatted pandoc document from a source string\n   -  transforms it by walking the tree and performing the actions\n   -  returns a new JSON-formatted pandoc document as a string\n\n   The ``actions`` argument is a list of functions (see ``walk`` for a\n   full description).\n\n   The argument ``source`` is a string encoded JSON object.\n\n   The argument ``format`` is a string describing the output format.\n\n   Returns a new JSON-formatted pandoc document.\n\n-  ``stringify(x)``\n\n   Walks the tree x and returns concatenated string content, leaving out\n   all formatting.\n\n-  ``attributes(attrs)``\n\n   Returns an attribute list, constructed from the dictionary attrs.\n\nHow to use\n----------\nMost users will only need ``toJSONFilter``.  Here is a simple example\nof its use::\n\n    #!/usr/bin/env python\n\n    \"\"\"\n    Pandoc filter to convert all regular text to uppercase.\n    Code, link URLs, etc. are not affected.\n    \"\"\"\n\n    from pandocfilters import toJSONFilter, Str\n\n    def caps(key, value, format, meta):\n      if key == 'Str':\n        return Str(value.upper())\n\n    if __name__ == \"__main__\":\n      toJSONFilter(caps)\n\nExamples\n--------\n\nThe examples subdirectory in the source repository contains the\nfollowing filters. These filters should provide a useful starting point\nfor developing your own pandocfilters.\n\n``abc.py``\n    Pandoc filter to process code blocks with class ``abc`` containing ABC\n    notation into images. Assumes that abcm2ps and ImageMagick's convert\n    are in the path. Images are put in the abc-images directory.\n\n``caps.py``\n    Pandoc filter to convert all regular text to uppercase. Code, link\n    URLs, etc. are not affected.\n\n``blockdiag.py``\n    Pandoc filter to process code blocks with class \"blockdiag\" into\n    generated images. Needs utils from http://blockdiag.com.\n\n``comments.py``\n    Pandoc filter that causes everything between\n    ``<!-- BEGIN COMMENT -->`` and ``<!-- END COMMENT -->`` to be ignored.\n    The comment lines must appear on lines by themselves, with blank\n    lines surrounding\n\n``deemph.py``\n    Pandoc filter that causes emphasized text to be displayed in ALL\n    CAPS.\n\n``deflists.py``\n    Pandoc filter to convert definition lists to bullet lists with the\n    defined terms in strong emphasis (for compatibility with standard\n    markdown).\n\n``gabc.py``\n    Pandoc filter to convert code blocks with class \"gabc\" to LaTeX\n    \\\\gabcsnippet commands in LaTeX output, and to images in HTML output.\n\n``graphviz.py``\n    Pandoc filter to process code blocks with class ``graphviz`` into\n    graphviz-generated images.\n\n``lilypond.py``\n    Pandoc filter to process code blocks with class \"ly\" containing\n    Lilypond notation.\n\n``metavars.py``\n    Pandoc filter to allow interpolation of metadata fields into a\n    document. ``%{fields}`` will be replaced by the field's value, assuming\n    it is of the type ``MetaInlines`` or ``MetaString``.\n\n``myemph.py``\n    Pandoc filter that causes emphasis to be rendered using the custom\n    macro ``\\myemph{...}`` rather than ``\\emph{...}`` in latex. Other output\n    formats are unaffected.\n\n``plantuml.py``\n    Pandoc filter to process code blocks with class ``plantuml`` to images.\n    Needs `plantuml.jar` from http://plantuml.com/.\n\n``ditaa.py``\n    Pandoc filter to process code blocks with class ``ditaa`` to images.\n    Needs `ditaa.jar` from http://ditaa.sourceforge.net/.\n\n``theorem.py``\n    Pandoc filter to convert divs with ``class=\"theorem\"`` to LaTeX theorem\n    environments in LaTeX output, and to numbered theorems in HTML\n    output.\n\n``tikz.py``\n    Pandoc filter to process raw latex tikz environments into images.\n    Assumes that pdflatex is in the path, and that the standalone\n    package is available. Also assumes that ImageMagick's convert is in\n    the path. Images are put in the ``tikz-images`` directory.\n\nAPI documentation\n-----------------\n\nBy default most filters use ``get_filename4code`` to\ncreate a directory ``...-images`` to save temporary\nfiles. This directory doesn't get removed as it can be used as a cache so that\nlater pandoc runs don't have to recreate files if they already exist. The\ndirectory is generated in the current directory.\n\nIf you prefer to have a clean directory after running pandoc filters, you\ncan set an environment variable ``PANDOCFILTER_CLEANUP`` to any non-empty value such as `1`\nwhich forces the code to create a temporary directory that will be removed\nby the end of execution.\n",
        "keywords": [
          "pandoc"
        ],
        "home_page": "http://github.com/jgm/pandocfilters",
        "author": "John MacFarlane",
        "author_email": "fiddlosopher@gmail.com",
        "license": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Environment :: Console",
          "Intended Audience :: End Users/Desktop",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Topic :: Text Processing :: Filters",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9"
        ],
        "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pandocfilters-1.5.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "parso",
        "version": "0.8.4",
        "platform": [
          "any"
        ],
        "summary": "A Python Parser",
        "description": "###################################################################\nparso - A Python Parser\n###################################################################\n\n\n.. image:: https://github.com/davidhalter/parso/workflows/Build/badge.svg?branch=master\n    :target: https://github.com/davidhalter/parso/actions\n    :alt: GitHub Actions build status\n\n.. image:: https://coveralls.io/repos/github/davidhalter/parso/badge.svg?branch=master\n    :target: https://coveralls.io/github/davidhalter/parso?branch=master\n    :alt: Coverage Status\n\n.. image:: https://pepy.tech/badge/parso\n    :target: https://pepy.tech/project/parso\n    :alt: PyPI Downloads\n\n.. image:: https://raw.githubusercontent.com/davidhalter/parso/master/docs/_static/logo_characters.png\n\nParso is a Python parser that supports error recovery and round-trip parsing\nfor different Python versions (in multiple Python versions). Parso is also able\nto list multiple syntax errors in your python file.\n\nParso has been battle-tested by jedi_. It was pulled out of jedi to be useful\nfor other projects as well.\n\nParso consists of a small API to parse Python and analyse the syntax tree.\n\nA simple example:\n\n.. code-block:: python\n\n    >>> import parso\n    >>> module = parso.parse('hello + 1', version=\"3.9\")\n    >>> expr = module.children[0]\n    >>> expr\n    PythonNode(arith_expr, [<Name: hello@1,0>, <Operator: +>, <Number: 1>])\n    >>> print(expr.get_code())\n    hello + 1\n    >>> name = expr.children[0]\n    >>> name\n    <Name: hello@1,0>\n    >>> name.end_pos\n    (1, 5)\n    >>> expr.end_pos\n    (1, 9)\n\nTo list multiple issues:\n\n.. code-block:: python\n\n    >>> grammar = parso.load_grammar()\n    >>> module = grammar.parse('foo +\\nbar\\ncontinue')\n    >>> error1, error2 = grammar.iter_errors(module)\n    >>> error1.message\n    'SyntaxError: invalid syntax'\n    >>> error2.message\n    \"SyntaxError: 'continue' not properly in loop\"\n\nResources\n=========\n\n- `Testing <https://parso.readthedocs.io/en/latest/docs/development.html#testing>`_\n- `PyPI <https://pypi.python.org/pypi/parso>`_\n- `Docs <https://parso.readthedocs.org/en/latest/>`_\n- Uses `semantic versioning <https://semver.org/>`_\n\nInstallation\n============\n\n    pip install parso\n\nFuture\n======\n\n- There will be better support for refactoring and comments. Stay tuned.\n- There's a WIP PEP8 validator. It's however not in a good shape, yet.\n\nKnown Issues\n============\n\n- `async`/`await` are already used as keywords in Python3.6.\n- `from __future__ import print_function` is not ignored.\n\n\nAcknowledgements\n================\n\n- Guido van Rossum (@gvanrossum) for creating the parser generator pgen2\n  (originally used in lib2to3).\n- `Salome Schneider <https://www.crepes-schnaegg.ch/cr%C3%AApes-schn%C3%A4gg/kunst-f%C3%BCrs-cr%C3%AApes-mobil/>`_\n  for the extremely awesome parso logo.\n\n\n.. _jedi: https://github.com/davidhalter/jedi\n\n\n.. :changelog:\n\nChangelog\n---------\n\nUnreleased\n++++++++++\n\n0.8.4 (2024-04-05)\n++++++++++++++++++\n\n- Add basic support for Python 3.13\n\n0.8.3 (2021-11-30)\n++++++++++++++++++\n\n- Add basic support for Python 3.11 and 3.12\n\n0.8.2 (2021-03-30)\n++++++++++++++++++\n\n- Various small bugfixes\n\n0.8.1 (2020-12-10)\n++++++++++++++++++\n\n- Various small bugfixes\n\n0.8.0 (2020-08-05)\n++++++++++++++++++\n\n- Dropped Support for Python 2.7, 3.4, 3.5\n- It's possible to use ``pathlib.Path`` objects now in the API\n- The stubs are gone, we are now using annotations\n- ``namedexpr_test`` nodes are now a proper class called ``NamedExpr``\n- A lot of smaller refactorings\n\n0.7.1 (2020-07-24)\n++++++++++++++++++\n\n- Fixed a couple of smaller bugs (mostly syntax error detection in\n  ``Grammar.iter_errors``)\n\nThis is going to be the last release that supports Python 2.7, 3.4 and 3.5.\n\n0.7.0 (2020-04-13)\n++++++++++++++++++\n\n- Fix a lot of annoying bugs in the diff parser. The fuzzer did not find\n  issues anymore even after running it for more than 24 hours (500k tests).\n- Small grammar change: suites can now contain newlines even after a newline.\n  This should really not matter if you don't use error recovery. It allows for\n  nicer error recovery.\n\n0.6.2 (2020-02-27)\n++++++++++++++++++\n\n- Bugfixes\n- Add Grammar.refactor (might still be subject to change until 0.7.0)\n\n0.6.1 (2020-02-03)\n++++++++++++++++++\n\n- Add ``parso.normalizer.Issue.end_pos`` to make it possible to know where an\n  issue ends\n\n0.6.0 (2020-01-26)\n++++++++++++++++++\n\n- Dropped Python 2.6/Python 3.3 support\n- del_stmt names are now considered as a definition\n  (for ``name.is_definition()``)\n- Bugfixes\n\n0.5.2 (2019-12-15)\n++++++++++++++++++\n\n- Add include_setitem to get_definition/is_definition and get_defined_names (#66)\n- Fix named expression error listing (#89, #90)\n- Fix some f-string tokenizer issues (#93)\n\n0.5.1 (2019-07-13)\n++++++++++++++++++\n\n- Fix: Some unicode identifiers were not correctly tokenized\n- Fix: Line continuations in f-strings are now working\n\n0.5.0 (2019-06-20)\n++++++++++++++++++\n\n- **Breaking Change** comp_for is now called sync_comp_for for all Python\n  versions to be compatible with the Python 3.8 Grammar\n- Added .pyi stubs for a lot of the parso API\n- Small FileIO changes\n\n0.4.0 (2019-04-05)\n++++++++++++++++++\n\n- Python 3.8 support\n- FileIO support, it's now possible to use abstract file IO, support is alpha\n\n0.3.4 (2019-02-13)\n+++++++++++++++++++\n\n- Fix an f-string tokenizer error\n\n0.3.3 (2019-02-06)\n+++++++++++++++++++\n\n- Fix async errors in the diff parser\n- A fix in iter_errors\n- This is a very small bugfix release\n\n0.3.2 (2019-01-24)\n+++++++++++++++++++\n\n- 20+ bugfixes in the diff parser and 3 in the tokenizer\n- A fuzzer for the diff parser, to give confidence that the diff parser is in a\n  good shape.\n- Some bugfixes for f-string\n\n0.3.1 (2018-07-09)\n+++++++++++++++++++\n\n- Bugfixes in the diff parser and keyword-only arguments\n\n0.3.0 (2018-06-30)\n+++++++++++++++++++\n\n- Rewrote the pgen2 parser generator.\n\n0.2.1 (2018-05-21)\n+++++++++++++++++++\n\n- A bugfix for the diff parser.\n- Grammar files can now be loaded from a specific path.\n\n0.2.0 (2018-04-15)\n+++++++++++++++++++\n\n- f-strings are now parsed as a part of the normal Python grammar. This makes\n  it way easier to deal with them.\n\n0.1.1 (2017-11-05)\n+++++++++++++++++++\n\n- Fixed a few bugs in the caching layer\n- Added support for Python 3.7\n\n0.1.0 (2017-09-04)\n+++++++++++++++++++\n\n- Pulling the library out of Jedi. Some APIs will definitely change.\n\n\n",
        "keywords": [
          "python",
          "parser",
          "parsing"
        ],
        "home_page": "https://github.com/davidhalter/parso",
        "author": "David Halter",
        "author_email": "davidhalter88@gmail.com",
        "maintainer": "David Halter",
        "maintainer_email": "davidhalter88@gmail.com",
        "license": "MIT",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Environment :: Plugins",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Text Editors :: Integrated Development Environments (IDE)",
          "Topic :: Utilities",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "flake8 (==5.0.4) ; extra == 'qa'",
          "mypy (==0.971) ; extra == 'qa'",
          "types-setuptools (==67.2.0.1) ; extra == 'qa'",
          "docopt ; extra == 'testing'",
          "pytest ; extra == 'testing'"
        ],
        "requires_python": ">=3.6",
        "provides_extra": [
          "qa",
          "testing"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\parso-0.8.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.0",
        "name": "pickleshare",
        "version": "0.7.5",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "Tiny 'shelve'-like database with concurrency support",
        "description": "PickleShare - a small 'shelve' like datastore with concurrency support\n\nLike shelve, a PickleShareDB object acts like a normal dictionary. Unlike shelve,\nmany processes can access the database simultaneously. Changing a value in \ndatabase is immediately visible to other processes accessing the same database.\n\nConcurrency is possible because the values are stored in separate files. Hence\nthe \"database\" is a directory where *all* files are governed by PickleShare.\n\nExample usage::\n\n    from pickleshare import *\n    db = PickleShareDB('~/testpickleshare')\n    db.clear()\n    print(\"Should be empty:\",db.items())\n    db['hello'] = 15\n    db['aku ankka'] = [1,2,313]\n    db['paths/are/ok/key'] = [1,(5,46)]\n    print(db.keys())\n\nThis module is certainly not ZODB, but can be used for low-load\n(non-mission-critical) situations where tiny code size trumps the \nadvanced features of a \"real\" object database.\n\nInstallation guide: pip install pickleshare\n\n\n",
        "keywords": [
          "database",
          "persistence",
          "pickle",
          "ipc",
          "shelve"
        ],
        "home_page": "https://github.com/pickleshare/pickleshare",
        "author": "Ville Vainio",
        "author_email": "vivainio@gmail.com",
        "license": "MIT",
        "classifier": [
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3"
        ],
        "requires_dist": [
          "pathlib2; python_version in \"2.6 2.7 3.2 3.3\""
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pickleshare-0.7.5.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pillow",
        "version": "11.1.0",
        "summary": "Python Imaging Library (Fork)",
        "description": "<p align=\"center\">\n    <img width=\"248\" height=\"250\" src=\"https://raw.githubusercontent.com/python-pillow/pillow-logo/main/pillow-logo-248x250.png\" alt=\"Pillow logo\">\n</p>\n\n# Pillow\n\n## Python Imaging Library (Fork)\n\nPillow is the friendly PIL fork by [Jeffrey A. Clark and\ncontributors](https://github.com/python-pillow/Pillow/graphs/contributors).\nPIL is the Python Imaging Library by Fredrik Lundh and contributors.\nAs of 2019, Pillow development is\n[supported by Tidelift](https://tidelift.com/subscription/pkg/pypi-pillow?utm_source=pypi-pillow&utm_medium=readme&utm_campaign=enterprise).\n\n<table>\n    <tr>\n        <th>docs</th>\n        <td>\n            <a href=\"https://pillow.readthedocs.io/?badge=latest\"><img\n                alt=\"Documentation Status\"\n                src=\"https://readthedocs.org/projects/pillow/badge/?version=latest\"></a>\n        </td>\n    </tr>\n    <tr>\n        <th>tests</th>\n        <td>\n            <a href=\"https://github.com/python-pillow/Pillow/actions/workflows/lint.yml\"><img\n                alt=\"GitHub Actions build status (Lint)\"\n                src=\"https://github.com/python-pillow/Pillow/workflows/Lint/badge.svg\"></a>\n            <a href=\"https://github.com/python-pillow/Pillow/actions/workflows/test.yml\"><img\n                alt=\"GitHub Actions build status (Test Linux and macOS)\"\n                src=\"https://github.com/python-pillow/Pillow/workflows/Test/badge.svg\"></a>\n            <a href=\"https://github.com/python-pillow/Pillow/actions/workflows/test-windows.yml\"><img\n                alt=\"GitHub Actions build status (Test Windows)\"\n                src=\"https://github.com/python-pillow/Pillow/workflows/Test%20Windows/badge.svg\"></a>\n            <a href=\"https://github.com/python-pillow/Pillow/actions/workflows/test-mingw.yml\"><img\n                alt=\"GitHub Actions build status (Test MinGW)\"\n                src=\"https://github.com/python-pillow/Pillow/workflows/Test%20MinGW/badge.svg\"></a>\n            <a href=\"https://github.com/python-pillow/Pillow/actions/workflows/test-cygwin.yml\"><img\n                alt=\"GitHub Actions build status (Test Cygwin)\"\n                src=\"https://github.com/python-pillow/Pillow/workflows/Test%20Cygwin/badge.svg\"></a>\n            <a href=\"https://github.com/python-pillow/Pillow/actions/workflows/test-docker.yml\"><img\n                alt=\"GitHub Actions build status (Test Docker)\"\n                src=\"https://github.com/python-pillow/Pillow/workflows/Test%20Docker/badge.svg\"></a>\n            <a href=\"https://ci.appveyor.com/project/python-pillow/Pillow\"><img\n                alt=\"AppVeyor CI build status (Windows)\"\n                src=\"https://img.shields.io/appveyor/build/python-pillow/Pillow/main.svg?label=Windows%20build\"></a>\n            <a href=\"https://github.com/python-pillow/Pillow/actions/workflows/wheels.yml\"><img\n                alt=\"GitHub Actions build status (Wheels)\"\n                src=\"https://github.com/python-pillow/Pillow/workflows/Wheels/badge.svg\"></a>\n            <a href=\"https://app.codecov.io/gh/python-pillow/Pillow\"><img\n                alt=\"Code coverage\"\n                src=\"https://codecov.io/gh/python-pillow/Pillow/branch/main/graph/badge.svg\"></a>\n            <a href=\"https://issues.oss-fuzz.com/issues?q=title:pillow\"><img\n                alt=\"Fuzzing Status\"\n                src=\"https://oss-fuzz-build-logs.storage.googleapis.com/badges/pillow.svg\"></a>\n        </td>\n    </tr>\n    <tr>\n        <th>package</th>\n        <td>\n            <a href=\"https://zenodo.org/badge/latestdoi/17549/python-pillow/Pillow\"><img\n                alt=\"Zenodo\"\n                src=\"https://zenodo.org/badge/17549/python-pillow/Pillow.svg\"></a>\n            <a href=\"https://tidelift.com/subscription/pkg/pypi-pillow?utm_source=pypi-pillow&utm_medium=badge\"><img\n                alt=\"Tidelift\"\n                src=\"https://tidelift.com/badges/package/pypi/pillow?style=flat\"></a>\n            <a href=\"https://pypi.org/project/pillow/\"><img\n                alt=\"Newest PyPI version\"\n                src=\"https://img.shields.io/pypi/v/pillow.svg\"></a>\n            <a href=\"https://pypi.org/project/pillow/\"><img\n                alt=\"Number of PyPI downloads\"\n                src=\"https://img.shields.io/pypi/dm/pillow.svg\"></a>\n            <a href=\"https://www.bestpractices.dev/projects/6331\"><img\n                alt=\"OpenSSF Best Practices\"\n                src=\"https://www.bestpractices.dev/projects/6331/badge\"></a>\n        </td>\n    </tr>\n    <tr>\n        <th>social</th>\n        <td>\n            <a href=\"https://gitter.im/python-pillow/Pillow?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\"><img\n                alt=\"Join the chat at https://gitter.im/python-pillow/Pillow\"\n                src=\"https://badges.gitter.im/python-pillow/Pillow.svg\"></a>\n            <a href=\"https://fosstodon.org/@pillow\"><img\n                alt=\"Follow on https://fosstodon.org/@pillow\"\n                src=\"https://img.shields.io/badge/publish-on%20Mastodon-595aff.svg\"\n                rel=\"me\"></a>\n        </td>\n    </tr>\n</table>\n\n## Overview\n\nThe Python Imaging Library adds image processing capabilities to your Python interpreter.\n\nThis library provides extensive file format support, an efficient internal representation, and fairly powerful image processing capabilities.\n\nThe core image library is designed for fast access to data stored in a few basic pixel formats. It should provide a solid foundation for a general image processing tool.\n\n## More Information\n\n- [Documentation](https://pillow.readthedocs.io/)\n  - [Installation](https://pillow.readthedocs.io/en/latest/installation/basic-installation.html)\n  - [Handbook](https://pillow.readthedocs.io/en/latest/handbook/index.html)\n- [Contribute](https://github.com/python-pillow/Pillow/blob/main/.github/CONTRIBUTING.md)\n  - [Issues](https://github.com/python-pillow/Pillow/issues)\n  - [Pull requests](https://github.com/python-pillow/Pillow/pulls)\n- [Release notes](https://pillow.readthedocs.io/en/stable/releasenotes/index.html)\n- [Changelog](https://github.com/python-pillow/Pillow/releases)\n  - [Pre-fork](https://github.com/python-pillow/Pillow/blob/main/CHANGES.rst#pre-fork)\n\n## Report a Vulnerability\n\nTo report a security vulnerability, please follow the procedure described in the [Tidelift security policy](https://tidelift.com/docs/security).\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "Imaging"
        ],
        "author_email": "\"Jeffrey A. Clark\" <aclark@aclark.net>",
        "license": "MIT-CMU",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 6 - Mature",
          "License :: OSI Approved :: CMU License (MIT-CMU)",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Multimedia :: Graphics",
          "Topic :: Multimedia :: Graphics :: Capture :: Digital Camera",
          "Topic :: Multimedia :: Graphics :: Capture :: Screen Capture",
          "Topic :: Multimedia :: Graphics :: Graphics Conversion",
          "Topic :: Multimedia :: Graphics :: Viewers",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "furo; extra == \"docs\"",
          "olefile; extra == \"docs\"",
          "sphinx>=8.1; extra == \"docs\"",
          "sphinx-copybutton; extra == \"docs\"",
          "sphinx-inline-tabs; extra == \"docs\"",
          "sphinxext-opengraph; extra == \"docs\"",
          "olefile; extra == \"fpx\"",
          "olefile; extra == \"mic\"",
          "check-manifest; extra == \"tests\"",
          "coverage>=7.4.2; extra == \"tests\"",
          "defusedxml; extra == \"tests\"",
          "markdown2; extra == \"tests\"",
          "olefile; extra == \"tests\"",
          "packaging; extra == \"tests\"",
          "pyroma; extra == \"tests\"",
          "pytest; extra == \"tests\"",
          "pytest-cov; extra == \"tests\"",
          "pytest-timeout; extra == \"tests\"",
          "trove-classifiers>=2024.10.12; extra == \"tests\"",
          "typing-extensions; python_version < \"3.10\" and extra == \"typing\"",
          "defusedxml; extra == \"xmp\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Changelog, https://github.com/python-pillow/Pillow/releases",
          "Documentation, https://pillow.readthedocs.io",
          "Funding, https://tidelift.com/subscription/pkg/pypi-pillow?utm_source=pypi-pillow&utm_medium=pypi",
          "Homepage, https://python-pillow.github.io",
          "Mastodon, https://fosstodon.org/@pillow",
          "Release notes, https://pillow.readthedocs.io/en/stable/releasenotes/index.html",
          "Source, https://github.com/python-pillow/Pillow"
        ],
        "provides_extra": [
          "docs",
          "fpx",
          "mic",
          "tests",
          "typing",
          "xmp"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pillow-11.1.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.2",
        "name": "pip",
        "version": "25.0.1",
        "summary": "The PyPA recommended tool for installing Python packages.",
        "description": "pip - The Python Package Installer\n==================================\n\n.. |pypi-version| image:: https://img.shields.io/pypi/v/pip.svg\n   :target: https://pypi.org/project/pip/\n   :alt: PyPI\n\n.. |python-versions| image:: https://img.shields.io/pypi/pyversions/pip\n   :target: https://pypi.org/project/pip\n   :alt: PyPI - Python Version\n\n.. |docs-badge| image:: https://readthedocs.org/projects/pip/badge/?version=latest\n   :target: https://pip.pypa.io/en/latest\n   :alt: Documentation\n\n|pypi-version| |python-versions| |docs-badge|\n\npip is the `package installer`_ for Python. You can use pip to install packages from the `Python Package Index`_ and other indexes.\n\nPlease take a look at our documentation for how to install and use pip:\n\n* `Installation`_\n* `Usage`_\n\nWe release updates regularly, with a new version every 3 months. Find more details in our documentation:\n\n* `Release notes`_\n* `Release process`_\n\nIf you find bugs, need help, or want to talk to the developers, please use our mailing lists or chat rooms:\n\n* `Issue tracking`_\n* `Discourse channel`_\n* `User IRC`_\n\nIf you want to get involved head over to GitHub to get the source code, look at our development documentation and feel free to jump on the developer mailing lists and chat rooms:\n\n* `GitHub page`_\n* `Development documentation`_\n* `Development IRC`_\n\nCode of Conduct\n---------------\n\nEveryone interacting in the pip project's codebases, issue trackers, chat\nrooms, and mailing lists is expected to follow the `PSF Code of Conduct`_.\n\n.. _package installer: https://packaging.python.org/guides/tool-recommendations/\n.. _Python Package Index: https://pypi.org\n.. _Installation: https://pip.pypa.io/en/stable/installation/\n.. _Usage: https://pip.pypa.io/en/stable/\n.. _Release notes: https://pip.pypa.io/en/stable/news.html\n.. _Release process: https://pip.pypa.io/en/latest/development/release-process/\n.. _GitHub page: https://github.com/pypa/pip\n.. _Development documentation: https://pip.pypa.io/en/latest/development\n.. _Issue tracking: https://github.com/pypa/pip/issues\n.. _Discourse channel: https://discuss.python.org/c/packaging\n.. _User IRC: https://kiwiirc.com/nextclient/#ircs://irc.libera.chat:+6697/pypa\n.. _Development IRC: https://kiwiirc.com/nextclient/#ircs://irc.libera.chat:+6697/pypa-dev\n.. _PSF Code of Conduct: https://github.com/pypa/.github/blob/main/CODE_OF_CONDUCT.md\n",
        "description_content_type": "text/x-rst",
        "author_email": "The pip developers <distutils-sig@python.org>",
        "license": "MIT",
        "license_file": [
          "LICENSE.txt",
          "AUTHORS.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Topic :: Software Development :: Build Tools",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://pip.pypa.io/",
          "Documentation, https://pip.pypa.io",
          "Source, https://github.com/pypa/pip",
          "Changelog, https://pip.pypa.io/en/stable/news/"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pip-25.0.1.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pipreqs",
        "version": "0.5.0",
        "summary": "Pip requirements.txt generator based on imports in project",
        "description": "=============================================================================\n``pipreqs`` - Generate requirements.txt file for any project based on imports\n=============================================================================\n\n.. image:: https://img.shields.io/travis/bndr/pipreqs.svg\n        :target: https://travis-ci.org/bndr/pipreqs\n\n\n.. image:: https://img.shields.io/pypi/v/pipreqs.svg\n        :target: https://pypi.python.org/pypi/pipreqs\n\n\n.. image:: https://codecov.io/gh/bndr/pipreqs/branch/master/graph/badge.svg?token=0rfPfUZEAX\n        :target: https://codecov.io/gh/bndr/pipreqs\n\n.. image:: https://img.shields.io/pypi/l/pipreqs.svg\n        :target: https://pypi.python.org/pypi/pipreqs\n\n\n\nInstallation\n------------\n\n.. code-block:: sh\n\n    pip install pipreqs\n\nObs.: if you don't want support for jupyter notebooks, you can install pipreqs without the dependencies that give support to it. \nTo do so, run:\n\n.. code-block:: sh\n\n    pip install --no-deps pipreqs\n    pip install yarg==0.1.9 docopt==0.6.2\n\nUsage\n-----\n\n::\n\n    Usage:\n        pipreqs [options] [<path>]\n\n    Arguments:\n        <path>                The path to the directory containing the application files for which a requirements file\n                              should be generated (defaults to the current working directory)\n\n    Options:\n        --use-local           Use ONLY local package info instead of querying PyPI\n        --pypi-server <url>   Use custom PyPi server\n        --proxy <url>         Use Proxy, parameter will be passed to requests library. You can also just set the\n                              environments parameter in your terminal:\n                              $ export HTTP_PROXY=\"http://10.10.1.10:3128\"\n                              $ export HTTPS_PROXY=\"https://10.10.1.10:1080\"\n        --debug               Print debug information\n        --ignore <dirs>...    Ignore extra directories, each separated by a comma\n        --no-follow-links     Do not follow symbolic links in the project\n        --encoding <charset>  Use encoding parameter for file open\n        --savepath <file>     Save the list of requirements in the given file\n        --print               Output the list of requirements in the standard output\n        --force               Overwrite existing requirements.txt\n        --diff <file>         Compare modules in requirements.txt to project imports\n        --clean <file>        Clean up requirements.txt by removing modules that are not imported in project\n        --mode <scheme>       Enables dynamic versioning with <compat>, <gt> or <non-pin> schemes\n                              <compat> | e.g. Flask~=1.1.2\n                              <gt>     | e.g. Flask>=1.1.2\n                              <no-pin> | e.g. Flask\n        --scan-notebooks      Look for imports in jupyter notebook files.\n\nExample\n-------\n\n::\n\n    $ pipreqs /home/project/location\n    Successfully saved requirements file in /home/project/location/requirements.txt\n\nContents of requirements.txt\n\n::\n\n    wheel==0.23.0\n    Yarg==0.1.9\n    docopt==0.6.2\n\nWhy not pip freeze?\n-------------------\n\n- ``pip freeze`` only saves the packages that are installed with ``pip install`` in your environment.\n- ``pip freeze`` saves all packages in the environment including those that you don't use in your current project (if you don't have ``virtualenv``).\n- and sometimes you just need to create ``requirements.txt`` for a new project without installing modules.\n\n.. :changelog:\n\nHistory\n-------\n\n0.4.11 (2020-03-29)\n--------------------\n\n* Implement '--mode' (Jake Teo, Jerome Chan)\n\n0.4.8 (2017-06-30)\n--------------------\n\n* Implement '--clean' and '--diff' (kxrd)\n* Exclude concurrent{,.futures} from stdlib if py2 (kxrd)\n\n0.4.7 (2017-04-20)\n--------------------\n\n* BUG: remove package/version duplicates\n* Style: pep8\n\n0.4.5 (2016-12-13)\n---------------------\n\n* Fixed the --pypi-server option\n\n0.4.4 (2016-07-14)\n---------------------\n\n* Remove Spaces in output\n* Add package to output even without version\n\n0.4.2 (2016-02-10)\n---------------------\n\n* Fix duplicated lines in requirements.txt (Dmitry Pribysh)\n\n0.4.1 (2016-02-05)\n---------------------\n\n* Added ignore option (Nick Rhinehart)\n\n0.4.0 (2016-01-28)\n---------------------\n\n* Walk Abstract Syntax Tree to find imports (Kay Sackey)\n\n0.3.9 (2016-01-20)\n---------------------\n\n* Fix regex for docstring comments (#35)\n\n0.3.8 (2016-01-12)\n---------------------\n\n* Add more package mapping\n* fix(pipreqs/mapping): remove pylab reference to matplotlib\n* Remove comments \"\"\" before going through imports\n* Update proxy documentation\n\n0.3.1 (2015-10-20)\n---------------------\n\n* fixed lint warnings (EJ Lee)\n* add --encoding parameter for open() (EJ Lee)\n* support windows directory separator (EJ Lee)\n\n0.3.0 (2015-09-29)\n---------------------\n\n* Add --proxy option\n* Add --pypi-server option\n\n0.2.9 (2015-09-24)\n---------------------\n\n* Ignore irreverent directory when generating requirement.txt (Lee Wei)\n* Modify logging level of \"Requirement.txt already exists\" to warning (Lee Wei)\n\n0.2.8 (2015-05-11)\n---------------------\n\n* Add --force option as a protection for overwrites\n\n0.2.6 (2015-05-11)\n---------------------\n\n* Fix exception when 'import' is used inside package name #17\n* Add more tests\n\n0.2.5 (2015-05-11)\n---------------------\n\n* Fix exception when 'import' is used in comments #17\n* Fix duplicate entries in requirements.txt\n\n0.2.4 (2015-05-10)\n---------------------\n\n* Refactoring\n* fix \"import as\"\n\n0.2.3 (2015-05-09)\n---------------------\n\n* Fix multiple alias imports on the same line (Tiago Costa)\n* More package mappings\n\n0.2.2 (2015-05-08)\n---------------------\n\n* Add ImportName -> PackageName mapping\n* More tests\n\n0.2.1 (2015-05-08)\n---------------------\n\n* Fix for TypeError for implicit conversion\n\n0.2.0 (2015-05-06)\n---------------------\n\n* Add --use-local option\n* Exclude relative imports. (Dongwon Shin)\n* Use \"latest_release_id\" instead of \"release_ids[-1]\" (Dongwon Shin)\n\n0.1.9 (2015-05-01)\n---------------------\n\n* Output tuning (Harri Berglund)\n* Use str.partition() to simplify the logic (cclaus)\n\n0.1.8 (2015-04-26)\n---------------------\n\n* Fixed problems with local imports (Dongwon Shin)\n* Fixed problems with imports with 'as' (Dongwon Shin)\n* Fix indentation, pep8 Styling. (Michael Borisov)\n* Optimize imports and adding missing import for sys module. (Michael Borisov)\n\n0.1.7 (2015-04-24)\n---------------------\n\n* Add more assertions in tests\n* Add more verbose output\n* Add recursive delete to Makefile clean\n* Update Readme\n\n0.1.6 (2015-04-22)\n---------------------\n\n* py3 print function\n\n0.1.5 (2015-04-22)\n---------------------\n\n* Add Readme, Add Examples\n* Add Stdlib into package\n\n0.1.1 (2015-04-22)\n---------------------\n\n* Fix regex matching for imports\n* Release on Pypi\n\n0.1.0 (2015-04-22)\n---------------------\n\n* First release on Github.\n\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "pip",
          "requirements",
          "imports"
        ],
        "home_page": "https://github.com/bndr/pipreqs",
        "author": "Vadim Kravcenko",
        "author_email": "vadim.kravcenko@gmail.com",
        "license": "Apache-2.0",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Natural Language :: English",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.8"
        ],
        "requires_dist": [
          "docopt (==0.6.2)",
          "ipython (==8.12.3)",
          "nbconvert (>=7.11.0,<8.0.0)",
          "yarg (==0.1.9)"
        ],
        "requires_python": ">=3.8.1,<3.13",
        "project_url": [
          "Repository, https://github.com/bndr/pipreqs"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pipreqs-0.5.0.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pip-requirements-parser",
        "version": "32.0.1",
        "summary": "pip requirements parser - a mostly correct pip requirements parsing library because it uses pip's own code.",
        "description": "pip-requirements-parser - a mostly correct pip requirements parsing library\n================================================================================\n\nCopyright (c) nexB Inc. and others.\nCopyright (c) The pip developers (see AUTHORS.rst file)\nSPDX-License-Identifier: MIT\nHomepage: https://github.com/nexB/pip-requirements and https://www.aboutcode.org/\n\n\n``pip-requirements-parser`` is a mostly correct pip requirements parsing\nlibrary ... because it uses pip's own code!\n\npip is the ``package installer`` for Python that is using \"requirements\" text\nfiles listing the packages to install.\n\nPer https://pip.pypa.io/en/stable/reference/requirements-file-format/ :\n\n    \"The requirements file format is closely tied to a number of internal\n    details of pip (e.g., pipâ€™s command line options). The basic format is\n    relatively stable and portable but the full syntax, as described here,\n    is only intended for consumption by pip, and other tools should take\n    that into account before using it for their own purposes.\"\n\nAnd per https://pip.pypa.io/en/stable/user_guide/#using-pip-from-your-program :\n\n    \"[..] pip is a command line program. While it is implemented in Python, and\n    so is available from your Python code via import pip, you must not use pipâ€™s\n    internal APIs in this way.\"\n    \n    \"What this means in practice is that everything inside of pip is considered\n    an implementation detail. Even the fact that the import name is pip is\n    subject to change without notice. While we do try not to break things as\n    much as possible, all the internal APIs can change at any time, for any\n    reason. It also means that we generally wonâ€™t fix issues that are a result\n    of using pip in an unsupported way.\"\n\n\nBecause of all this, pip requirements are notoriously difficult to parse right\nin all their diversity because:\n\n- pip does not have a public API and therefore cannot be reliably used as a\n  stable library. Some libraries attempt to do this though. (See Alternative)\n\n- The pip requirements file syntax is closely aligned with pip's command line\n  interface and command line options. In some ways a pip requirements file is a\n  list of pip command line options and arguments. Therefore, it is hard to parse\n  these short of reproducing the pip command line options parsing. At least one\n  other library is using a command line option parser to parse options correctly.\n\n\nThis ``pip-requirements-parser`` Python library is yet another pip requirements\nfiles parser, but this time doing it hopefully correctly and doing as well as\npip does it, because this is using pip's own code.\n\n\nThe ``pip-requirements-parser`` library offers these key advantages:\n\n- Other requirements parsers typically do not work in all the cases that ``pip``\n  supports: parsing any requirement as seen in the wild will fail parsing some\n  valid pip requirements. Since the ``pip-requirements-parser`` library is based\n  on pip's own code, it works **exactly** like pip and will parse all the\n  requirements files that pip can parse.\n\n- The ``pip-requirements-parser`` library offers a simple and stable code API\n  that will not change without notice.\n\n- The ``pip-requirements-parser`` library is designed to work offline without\n  making any external network call, while the original pip code needs network\n  access.\n\n- The ``pip-requirements-parser`` library is a single file that can easily be\n  copied around as needed for easy vendoring. This is useful as requirements\n  parsing is often needed to bootstrap in a constrained environment.\n\n- The ``pip-requirements-parser`` library has only one external dependency on\n  the common \"packaging\" package. Otherwise it uses only the standard library.\n  The benefits are the same as being a single file: fewer moving parts helps with\n  using it in more cases.\n\n- The ``pip-requirements-parser`` library reuses and passes the full subset of\n  the pip test suite that deals with requirements. This is a not really\n  surprising since this is pip's own code. The suite suite has been carefully\n  ported and adjusted to work with the updated code subset.\n\n- The standard pip requirements parser depends on the ``requests`` HTTP library\n  and makes network connection to PyPI and other referenced repositories when\n  parsing. The ``pip-requirements-parser`` library works entirely offline and the\n  requests dependency and calling has been entirely removed.\n\n- The ``pip-requirements-parser`` library has preserved the complete pip git\n  history for the subset of the code we kept. The original pip code was merged\n  from multiple modules keeping all the git history at the line/blame level using\n  some git fu and git filter repo. The benefit is that we will be able to more\n  easily track and merge future pip updates.\n\n- The ``pip-requirements-parser`` library has an extensive test suite  made of:\n\n  - pip's own tests\n  - new unit tests\n  - new requirements test files (over 40 new test files)\n  - the tests suite of some of the main other requirement parsers including:\n\n     - http://github.com/di/pip-api\n     - https://github.com/pyupio/dparse\n     - https://github.com/landscapeio/requirements-detector\n     - https://github.com/madpah/requirements-parser\n\nAs a result, it has likely the most comprehensive requiremente parsing test\nsuite around.\n\n\nUsage\n~~~~~~~~~~\n\nThe entry point is the ``RequirementsFile`` object::\n\n    >>> from pip_requirements_parser import RequirementsFile\n    >>> rf = RequirementsFile.from_file(\"requirements.txt\")\n\nFrom there, you can dump to a dict::\n    >>> rf.to_dict()\n\nOr access the requirements (either InstallRequirement or EditableRequirement\nobjects)::\n\n    >>> for req in rf.requirements:\n    ...    print(req.to_dict())\n    ...    print(req.dumps())\n\nAnd the various other parsed elements such as options, commenst and invalid lines\nthat have a parsing error::\n\n    >>> rf.options\n    >>> rf.comment_lines\n    >>> rf.invalid_lines\n\nEach of these and the ``requirements`` hahve a \"requirement_line\" attribute\nwith the original text.\n\nFinally you can get a requirements file back as a string::\n\n    >>> rf.dumps()\n\n\nAlternative\n------------------\n\nThere are several other parsers that either:\n\n- Implement their own parsing and can therefore miss some subtle differences\n- Or wrap and import pip as a library, working around the lack of pip API\n\nNone of these use the approach of reusing and forking the subset of pip that is\nneeded to parse requirements.  The ones that wrap pip require network access\nlike pip does. They potentially need updating each time there is a new pip\nrelease. The ones that reimplement pip parsing may not support all pip\nspecifics.\n\n\nImplement a new pip parser\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- pip-api https://github.com/di/pip-api does not support hashes and certain pip options.\n  It does however use argparse for parsing options and is therefore correctly\n  handling most options. The parser is a single script that only depends on\n  packaging (that is vendored). It is not designed to be used as a single script\n  though and ``pip`` is a dependency.\n\n- requirements-parser https://github.com/madpah/requirements-parse does not\n  support hashes and certain pip options\n\n- dparse https://github.com/pyupio/dparse\n\n- https://github.com/GoogleCloudPlatform/django-cloud-deploy/blob/d316b1e45357761e2b124143e6e12ce34ef6f975/django_cloud_deploy/skeleton/requirements_parser.py\n\n\nReuse and wrap pip's own parser\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- requirementslib https://github.com/sarugaku/requirementslib uses pip-shim\n  https://github.com/sarugaku/pip-shims which is a set of \"shims\" around each\n  pip versions in an attempt to offer an API to pip. Comes with 20+ dependencies,\n\n- micropipenv https://github.com/thoth-station/micropipenv/blob/d0c37c1bf0aadf5149aebe2df0bf1cb12ded4c40/micropipenv.py#L53\n\n- pip-tools https://github.com/jazzband/pip-tools/blob/9e1be05375104c56e07cdb0904e1b50b86f8b550/piptools/_compat/pip_compat.py\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "utilities",
          "pip",
          "requirements",
          "parser",
          "dependencies",
          "pypi"
        ],
        "home_page": "https://github.com/nexB/pip-requirements-parser",
        "author": "The pip authors, nexB. Inc. and others",
        "author_email": "info@aboutcode.org",
        "license": "MIT",
        "license_file": [
          "mit.LICENSE",
          "AUTHORS.rst",
          "CHANGELOG.rst",
          "README.rst"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Topic :: Software Development",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "packaging",
          "pyparsing",
          "Sphinx (>=3.3.1) ; extra == 'docs'",
          "sphinx-rtd-theme (>=0.5.0) ; extra == 'docs'",
          "doc8 (>=0.8.1) ; extra == 'docs'",
          "pytest (!=7.0.0,>=6) ; extra == 'testing'",
          "pytest-xdist (>=2) ; extra == 'testing'",
          "aboutcode-toolkit (>=6.0.0) ; extra == 'testing'",
          "black ; extra == 'testing'"
        ],
        "requires_python": ">=3.6.0",
        "provides_extra": [
          "docs",
          "testing"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pip_requirements_parser-32.0.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pip-tools",
        "version": "7.4.1",
        "summary": "pip-tools keeps your pinned dependencies fresh.",
        "description": "[![jazzband-image]][jazzband]\n[![pypi][pypi-image]][pypi]\n[![pyversions][pyversions-image]][pyversions]\n[![pre-commit][pre-commit-image]][pre-commit]\n[![buildstatus-gha][buildstatus-gha-image]][buildstatus-gha]\n[![codecov][codecov-image]][codecov]\n[![Matrix Room Badge]][Matrix Room]\n[![Matrix Space Badge]][Matrix Space]\n[![discord-chat-image]][discord-chat]\n\n# pip-tools = pip-compile + pip-sync\n\nA set of command line tools to help you keep your `pip`-based packages fresh,\neven when you've pinned them. You do pin them, right? (In building your Python application and its dependencies for production, you want to make sure that your builds are predictable and deterministic.)\n\n[![pip-tools overview for phase II][pip-tools-overview]][pip-tools-overview]\n\n## Installation\n\nSimilar to `pip`, `pip-tools` must be installed in each of your project's\n[virtual environments](https://packaging.python.org/tutorials/installing-packages/#creating-virtual-environments):\n\n```console\n$ source /path/to/venv/bin/activate\n(venv) $ python -m pip install pip-tools\n```\n\n**Note**: all of the remaining example commands assume you've activated your\nproject's virtual environment.\n\n## Example usage for `pip-compile`\n\nThe `pip-compile` command lets you compile a `requirements.txt` file from\nyour dependencies, specified in either `pyproject.toml`, `setup.cfg`,\n`setup.py`, or `requirements.in`.\n\nRun it with `pip-compile` or `python -m piptools compile` (or\n`pipx run --spec pip-tools pip-compile` if `pipx` was installed with the\nappropriate Python version). If you use multiple Python versions, you can also\nrun `py -X.Y -m piptools compile` on Windows and `pythonX.Y -m piptools compile`\non other systems.\n\n`pip-compile` should be run from the same virtual environment as your\nproject so conditional dependencies that require a specific Python version,\nor other environment markers, resolve relative to your project's\nenvironment.\n\n**Note**: If `pip-compile` finds an existing `requirements.txt` file that\nfulfils the dependencies then no changes will be made, even if updates are\navailable. To compile from scratch, first delete the existing\n`requirements.txt` file, or see\n[Updating requirements](#updating-requirements)\nfor alternative approaches.\n\n### Requirements from `pyproject.toml`\n\nThe `pyproject.toml` file is the\n[latest standard](https://peps.python.org/pep-0621/) for configuring\npackages and applications, and is recommended for new projects. `pip-compile`\nsupports both installing your `project.dependencies` as well as your\n`project.optional-dependencies`. Thanks to the fact that this is an\nofficial standard, you can use `pip-compile` to pin the dependencies\nin projects that use modern standards-adhering packaging tools like\n[Setuptools](https://setuptools.pypa.io), [Hatch](https://hatch.pypa.io/)\nor [flit](https://flit.pypa.io/).\n\nSuppose you have a 'foobar' Python application that is packaged using `Setuptools`,\nand you want to pin it for production. You can declare the project metadata as:\n\n```toml\n[build-system]\nrequires = [\"setuptools\", \"setuptools-scm\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nrequires-python = \">=3.9\"\nname = \"foobar\"\ndynamic = [\"dependencies\", \"optional-dependencies\"]\n\n[tool.setuptools.dynamic]\ndependencies = { file = [\"requirements.in\"] }\noptional-dependencies.test = { file = [\"requirements-test.txt\"] }\n\n```\n\nIf you have a Django application that is packaged using `Hatch`, and you\nwant to pin it for production. You also want to pin your development tools\nin a separate pin file. You declare `django` as a dependency and create an\noptional dependency `dev` that includes `pytest`:\n\n```toml\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[project]\nname = \"my-cool-django-app\"\nversion = \"42\"\ndependencies = [\"django\"]\n\n[project.optional-dependencies]\ndev = [\"pytest\"]\n```\n\nYou can produce your pin files as easily as:\n\n```console\n$ pip-compile -o requirements.txt pyproject.toml\n#\n# This file is autogenerated by pip-compile with Python 3.10\n# by the following command:\n#\n#    pip-compile --output-file=requirements.txt pyproject.toml\n#\nasgiref==3.6.0\n    # via django\ndjango==4.1.7\n    # via my-cool-django-app (pyproject.toml)\nsqlparse==0.4.3\n    # via django\n\n$ pip-compile --extra dev -o dev-requirements.txt pyproject.toml\n#\n# This file is autogenerated by pip-compile with Python 3.10\n# by the following command:\n#\n#    pip-compile --extra=dev --output-file=dev-requirements.txt pyproject.toml\n#\nasgiref==3.6.0\n    # via django\nattrs==22.2.0\n    # via pytest\ndjango==4.1.7\n    # via my-cool-django-app (pyproject.toml)\nexceptiongroup==1.1.1\n    # via pytest\niniconfig==2.0.0\n    # via pytest\npackaging==23.0\n    # via pytest\npluggy==1.0.0\n    # via pytest\npytest==7.2.2\n    # via my-cool-django-app (pyproject.toml)\nsqlparse==0.4.3\n    # via django\ntomli==2.0.1\n    # via pytest\n```\n\nThis is great for both pinning your applications, but also to keep the CI\nof your open-source Python package stable.\n\n### Requirements from `setup.py` and `setup.cfg`\n\n`pip-compile` has also full support for `setup.py`- and\n`setup.cfg`-based projects that use `setuptools`.\n\nJust define your dependencies and extras as usual and run\n`pip-compile` as above.\n\n### Requirements from `requirements.in`\n\nYou can also use plain text files for your requirements (e.g. if you don't\nwant your application to be a package). To use a `requirements.in` file to\ndeclare the Django dependency:\n\n```\n# requirements.in\ndjango\n```\n\nNow, run `pip-compile requirements.in`:\n\n```console\n$ pip-compile requirements.in\n#\n# This file is autogenerated by pip-compile with Python 3.10\n# by the following command:\n#\n#    pip-compile requirements.in\n#\nasgiref==3.6.0\n    # via django\ndjango==4.1.7\n    # via -r requirements.in\nsqlparse==0.4.3\n    # via django\n```\n\nAnd it will produce your `requirements.txt`, with all the Django dependencies\n(and all underlying dependencies) pinned.\n\n(updating-requirements)=\n\n### Updating requirements\n\n`pip-compile` generates a `requirements.txt` file using the latest versions\nthat fulfil the dependencies you specify in the supported files.\n\nIf `pip-compile` finds an existing `requirements.txt` file that fulfils the\ndependencies then no changes will be made, even if updates are available.\n\nTo force `pip-compile` to update all packages in an existing\n`requirements.txt`, run `pip-compile --upgrade`.\n\nTo update a specific package to the latest or a specific version use the\n`--upgrade-package` or `-P` flag:\n\n```console\n# only update the django package\n$ pip-compile --upgrade-package django\n\n# update both the django and requests packages\n$ pip-compile --upgrade-package django --upgrade-package requests\n\n# update the django package to the latest, and requests to v2.0.0\n$ pip-compile --upgrade-package django --upgrade-package requests==2.0.0\n```\n\nYou can combine `--upgrade` and `--upgrade-package` in one command, to\nprovide constraints on the allowed upgrades. For example to upgrade all\npackages whilst constraining requests to the latest version less than 3.0:\n\n```console\n$ pip-compile --upgrade --upgrade-package 'requests<3.0'\n```\n\n### Using hashes\n\nIf you would like to use _Hash-Checking Mode_ available in `pip` since\nversion 8.0, `pip-compile` offers `--generate-hashes` flag:\n\n```console\n$ pip-compile --generate-hashes requirements.in\n#\n# This file is autogenerated by pip-compile with Python 3.10\n# by the following command:\n#\n#    pip-compile --generate-hashes requirements.in\n#\nasgiref==3.6.0 \\\n    --hash=sha256:71e68008da809b957b7ee4b43dbccff33d1b23519fb8344e33f049897077afac \\\n    --hash=sha256:9567dfe7bd8d3c8c892227827c41cce860b368104c3431da67a0c5a65a949506\n    # via django\ndjango==4.1.7 \\\n    --hash=sha256:44f714b81c5f190d9d2ddad01a532fe502fa01c4cb8faf1d081f4264ed15dcd8 \\\n    --hash=sha256:f2f431e75adc40039ace496ad3b9f17227022e8b11566f4b363da44c7e44761e\n    # via -r requirements.in\nsqlparse==0.4.3 \\\n    --hash=sha256:0323c0ec29cd52bceabc1b4d9d579e311f3e4961b98d174201d5622a23b85e34 \\\n    --hash=sha256:69ca804846bb114d2ec380e4360a8a340db83f0ccf3afceeb1404df028f57268\n    # via django\n```\n\n### Output File\n\nTo output the pinned requirements in a filename other than\n`requirements.txt`, use `--output-file`. This might be useful for compiling\nmultiple files, for example with different constraints on django to test a\nlibrary with both versions using [tox](https://tox.readthedocs.io/en/latest/):\n\n```console\n$ pip-compile --upgrade-package 'django<1.0' --output-file requirements-django0x.txt\n$ pip-compile --upgrade-package 'django<2.0' --output-file requirements-django1x.txt\n```\n\nOr to output to standard output, use `--output-file=-`:\n\n```console\n$ pip-compile --output-file=- > requirements.txt\n$ pip-compile - --output-file=- < requirements.in > requirements.txt\n```\n\n### Forwarding options to `pip`\n\nAny valid `pip` flags or arguments may be passed on with `pip-compile`'s\n`--pip-args` option, e.g.\n\n```console\n$ pip-compile requirements.in --pip-args \"--retries 10 --timeout 30\"\n```\n\n### Configuration\n\nYou can define project-level defaults for `pip-compile` and `pip-sync` by\nwriting them to a configuration file in the same directory as your requirements\ninput files (or the current working directory if piping input from stdin).\nBy default, both `pip-compile` and `pip-sync` will look first\nfor a `.pip-tools.toml` file and then in your `pyproject.toml`. You can\nalso specify an alternate TOML configuration file with the `--config` option.\n\nIt is possible to specify configuration values both globally and command-specific.\nFor example, to by default generate `pip` hashes in the resulting\nrequirements file output, you can specify in a configuration file:\n\n```toml\n[tool.pip-tools]\ngenerate-hashes = true\n```\n\nOptions to `pip-compile` and `pip-sync` that may be used more than once\nmust be defined as lists in a configuration file, even if they only have one\nvalue.\n\n`pip-tools` supports default values for [all valid command-line flags](/cli/index.md)\nof its subcommands. Configuration keys may contain underscores instead of dashes,\nso the above could also be specified in this format:\n\n```toml\n[tool.pip-tools]\ngenerate_hashes = true\n```\n\nConfiguration defaults specific to `pip-compile` and `pip-sync` can be put beneath\nseparate sections. For example, to by default perform a dry-run with `pip-compile`:\n\n```toml\n[tool.pip-tools.compile] # \"sync\" for pip-sync\ndry-run = true\n```\n\nThis does not affect the `pip-sync` command, which also has a `--dry-run` option.\nNote that local settings take preference over the global ones of the same name,\nwhenever both are declared, thus this would also make `pip-compile` generate hashes,\nbut discard the global dry-run setting:\n\n```toml\n[tool.pip-tools]\ngenerate-hashes = true\ndry-run = true\n\n[tool.pip-tools.compile]\ndry-run = false\n```\n\nYou might be wrapping the `pip-compile` command in another script. To avoid\nconfusing consumers of your custom script you can override the update command\ngenerated at the top of requirements files by setting the\n`CUSTOM_COMPILE_COMMAND` environment variable.\n\n```console\n$ CUSTOM_COMPILE_COMMAND=\"./pipcompilewrapper\" pip-compile requirements.in\n#\n# This file is autogenerated by pip-compile with Python 3.10\n# by the following command:\n#\n#    ./pipcompilewrapper\n#\nasgiref==3.6.0\n    # via django\ndjango==4.1.7\n    # via -r requirements.in\nsqlparse==0.4.3\n    # via django\n```\n\n### Workflow for layered requirements\n\nIf you have different environments that you need to install different but\ncompatible packages for, then you can create layered requirements files and use\none layer to constrain the other.\n\nFor example, if you have a Django project where you want the newest `2.1`\nrelease in production and when developing you want to use the Django debug\ntoolbar, then you can create two `*.in` files, one for each layer:\n\n```\n# requirements.in\ndjango<2.2\n```\n\nAt the top of the development requirements `dev-requirements.in` you use `-c\nrequirements.txt` to constrain the dev requirements to packages already\nselected for production in `requirements.txt`.\n\n```\n# dev-requirements.in\n-c requirements.txt\ndjango-debug-toolbar<2.2\n```\n\nFirst, compile `requirements.txt` as usual:\n\n```\n$ pip-compile\n#\n# This file is autogenerated by pip-compile with Python 3.10\n# by the following command:\n#\n#    pip-compile\n#\ndjango==2.1.15\n    # via -r requirements.in\npytz==2023.3\n    # via django\n```\n\nNow compile the dev requirements and the `requirements.txt` file is used as\na constraint:\n\n```console\n$ pip-compile dev-requirements.in\n#\n# This file is autogenerated by pip-compile with Python 3.10\n# by the following command:\n#\n#    pip-compile dev-requirements.in\n#\ndjango==2.1.15\n    # via\n    #   -c requirements.txt\n    #   django-debug-toolbar\ndjango-debug-toolbar==2.1\n    # via -r dev-requirements.in\npytz==2023.3\n    # via\n    #   -c requirements.txt\n    #   django\nsqlparse==0.4.3\n    # via django-debug-toolbar\n```\n\nAs you can see above, even though a `2.2` release of Django is available, the\ndev requirements only include a `2.1` version of Django because they were\nconstrained. Now both compiled requirements files can be installed safely in\nthe dev environment.\n\nTo install requirements in production stage use:\n\n```console\n$ pip-sync\n```\n\nYou can install requirements in development stage by:\n\n```console\n$ pip-sync requirements.txt dev-requirements.txt\n```\n\n### Version control integration\n\nYou might use `pip-compile` as a hook for the [pre-commit](https://github.com/pre-commit/pre-commit).\nSee [pre-commit docs](https://pre-commit.com/) for instructions.\nSample `.pre-commit-config.yaml`:\n\n```yaml\nrepos:\n  - repo: https://github.com/jazzband/pip-tools\n    rev: 7.4.1\n    hooks:\n      - id: pip-compile\n```\n\nYou might want to customize `pip-compile` args by configuring `args` and/or `files`, for example:\n\n```yaml\nrepos:\n  - repo: https://github.com/jazzband/pip-tools\n    rev: 7.4.1\n    hooks:\n      - id: pip-compile\n        files: ^requirements/production\\.(in|txt)$\n        args: [--index-url=https://example.com, requirements/production.in]\n```\n\nIf you have multiple requirement files make sure you create a hook for each file.\n\n```yaml\nrepos:\n  - repo: https://github.com/jazzband/pip-tools\n    rev: 7.4.1\n    hooks:\n      - id: pip-compile\n        name: pip-compile setup.py\n        files: ^(setup\\.py|requirements\\.txt)$\n      - id: pip-compile\n        name: pip-compile requirements-dev.in\n        args: [requirements-dev.in]\n        files: ^requirements-dev\\.(in|txt)$\n      - id: pip-compile\n        name: pip-compile requirements-lint.in\n        args: [requirements-lint.in]\n        files: ^requirements-lint\\.(in|txt)$\n      - id: pip-compile\n        name: pip-compile requirements.in\n        args: [requirements.in]\n        files: ^requirements\\.(in|txt)$\n```\n\n### Example usage for `pip-sync`\n\nNow that you have a `requirements.txt`, you can use `pip-sync` to update\nyour virtual environment to reflect exactly what's in there. This will\ninstall/upgrade/uninstall everything necessary to match the\n`requirements.txt` contents.\n\nRun it with `pip-sync` or `python -m piptools sync`. If you use multiple\nPython versions, you can also run `py -X.Y -m piptools sync` on Windows and\n`pythonX.Y -m piptools sync` on other systems.\n\n`pip-sync` must be installed into and run from the same virtual\nenvironment as your project to identify which packages to install\nor upgrade.\n\n**Be careful**: `pip-sync` is meant to be used only with a\n`requirements.txt` generated by `pip-compile`.\n\n```console\n$ pip-sync\nUninstalling flake8-2.4.1:\n    Successfully uninstalled flake8-2.4.1\nCollecting click==4.1\n    Downloading click-4.1-py2.py3-none-any.whl (62kB)\n    100% |................................| 65kB 1.8MB/s\n    Found existing installation: click 4.0\n    Uninstalling click-4.0:\n        Successfully uninstalled click-4.0\nSuccessfully installed click-4.1\n```\n\nTo sync multiple `*.txt` dependency lists, just pass them in via command\nline arguments, e.g.\n\n```console\n$ pip-sync dev-requirements.txt requirements.txt\n```\n\nPassing in empty arguments would cause it to default to `requirements.txt`.\n\nAny valid `pip install` flags or arguments may be passed with `pip-sync`'s\n`--pip-args` option, e.g.\n\n```console\n$ pip-sync requirements.txt --pip-args \"--no-cache-dir --no-deps\"\n```\n\n**Note**: `pip-sync` will not upgrade or uninstall packaging tools like\n`setuptools`, `pip`, or `pip-tools` itself. Use `python -m pip install --upgrade`\nto upgrade those packages.\n\n### Should I commit `requirements.in` and `requirements.txt` to source control?\n\nGenerally, yes. If you want a reproducible environment installation available from your source control,\nthen yes, you should commit both `requirements.in` and `requirements.txt` to source control.\n\nNote that if you are deploying on multiple Python environments (read the section below),\nthen you must commit a separate output file for each Python environment.\nWe suggest to use the `{env}-requirements.txt` format\n(ex: `win32-py3.7-requirements.txt`, `macos-py3.10-requirements.txt`, etc.).\n\n### Cross-environment usage of `requirements.in`/`requirements.txt` and `pip-compile`\n\nThe dependencies of a package can change depending on the Python environment in which it\nis installed. Here, we define a Python environment as the combination of Operating\nSystem, Python version (3.7, 3.8, etc.), and Python implementation (CPython, PyPy,\netc.). For an exact definition, refer to the possible combinations of [PEP 508\nenvironment markers][environment-markers].\n\nAs the resulting `requirements.txt` can differ for each environment, users must\nexecute `pip-compile` **on each Python environment separately** to generate a\n`requirements.txt` valid for each said environment. The same `requirements.in` can\nbe used as the source file for all environments, using\n[PEP 508 environment markers][environment-markers] as\nneeded, the same way it would be done for regular `pip` cross-environment usage.\n\nIf the generated `requirements.txt` remains exactly the same for all Python\nenvironments, then it can be used across Python environments safely. **But** users\nshould be careful as any package update can introduce environment-dependent\ndependencies, making any newly generated `requirements.txt` environment-dependent too.\nAs a general rule, it's advised that users should still always execute `pip-compile`\non each targeted Python environment to avoid issues.\n\n### Maximizing reproducibility\n\n`pip-tools` is a great tool to improve the reproducibility of builds.\nBut there are a few things to keep in mind.\n\n- `pip-compile` will produce different results in different environments as described in the previous section.\n- `pip` must be used with the `PIP_CONSTRAINT` environment variable to lock dependencies in build environments as documented in [#8439](https://github.com/pypa/pip/issues/8439).\n- Dependencies come from many sources.\n\nContinuing the `pyproject.toml` example from earlier, creating a single lock file could be done like:\n\n```console\n$ pip-compile --all-build-deps --all-extras --output-file=constraints.txt --strip-extras pyproject.toml\n#\n# This file is autogenerated by pip-compile with Python 3.9\n# by the following command:\n#\n#    pip-compile --all-build-deps --all-extras --output-file=constraints.txt --strip-extras pyproject.toml\n#\nasgiref==3.5.2\n    # via django\nattrs==22.1.0\n    # via pytest\nbackports-zoneinfo==0.2.1\n    # via django\ndjango==4.1\n    # via my-cool-django-app (pyproject.toml)\neditables==0.3\n    # via hatchling\nhatchling==1.11.1\n    # via my-cool-django-app (pyproject.toml::build-system.requires)\niniconfig==1.1.1\n    # via pytest\npackaging==21.3\n    # via\n    #   hatchling\n    #   pytest\npathspec==0.10.2\n    # via hatchling\npluggy==1.0.0\n    # via\n    #   hatchling\n    #   pytest\npy==1.11.0\n    # via pytest\npyparsing==3.0.9\n    # via packaging\npytest==7.1.2\n    # via my-cool-django-app (pyproject.toml)\nsqlparse==0.4.2\n    # via django\ntomli==2.0.1\n    # via\n    #   hatchling\n    #   pytest\n```\n\nSome build backends may also request build dependencies dynamically using the `get_requires_for_build_` hooks described in [PEP 517] and [PEP 660].\nThis will be indicated in the output with one of the following suffixes:\n\n- `(pyproject.toml::build-system.backend::editable)`\n- `(pyproject.toml::build-system.backend::sdist)`\n- `(pyproject.toml::build-system.backend::wheel)`\n\n### Other useful tools\n\n- [pip-compile-multi](https://pip-compile-multi.readthedocs.io/en/latest/) - pip-compile command wrapper for multiple cross-referencing requirements files.\n- [pipdeptree](https://github.com/tox-dev/pipdeptree) to print the dependency tree of the installed packages.\n- `requirements.in`/`requirements.txt` syntax highlighting:\n\n  - [requirements.txt.vim](https://github.com/raimon49/requirements.txt.vim) for Vim.\n  - [Python extension for VS Code](https://marketplace.visualstudio.com/items?itemName=ms-python.python) for VS Code.\n  - [pip-requirements.el](https://github.com/Wilfred/pip-requirements.el) for Emacs.\n\n### Deprecations\n\nThis section lists `pip-tools` features that are currently deprecated.\n\n- In the next major release, the `--allow-unsafe` behavior will be enabled by\n  default (https://github.com/jazzband/pip-tools/issues/989).\n  Use `--no-allow-unsafe` to keep the old behavior. It is recommended\n  to pass `--allow-unsafe` now to adapt to the upcoming change.\n- The legacy resolver is deprecated and will be removed in future versions.\n  The new default is `--resolver=backtracking`.\n- In the next major release, the `--strip-extras` behavior will be enabled by\n  default (https://github.com/jazzband/pip-tools/issues/1613).\n  Use `--no-strip-extras` to keep the old behavior.\n\n### A Note on Resolvers\n\nYou can choose from either default backtracking resolver or the deprecated legacy resolver.\n\nThe legacy resolver will occasionally fail to resolve dependencies. The\nbacktracking resolver is more robust, but can take longer to run in general.\n\nYou can continue using the legacy resolver with `--resolver=legacy` although\nnote that it is deprecated and will be removed in a future release.\n\n[jazzband]: https://jazzband.co/\n[jazzband-image]: https://jazzband.co/static/img/badge.svg\n[pypi]: https://pypi.org/project/pip-tools/\n[pypi-image]: https://img.shields.io/pypi/v/pip-tools.svg\n[pyversions]: https://pypi.org/project/pip-tools/\n[pyversions-image]: https://img.shields.io/pypi/pyversions/pip-tools.svg\n[pre-commit]: https://results.pre-commit.ci/latest/github/jazzband/pip-tools/main\n[pre-commit-image]: https://results.pre-commit.ci/badge/github/jazzband/pip-tools/main.svg\n[buildstatus-gha]: https://github.com/jazzband/pip-tools/actions?query=workflow%3ACI\n[buildstatus-gha-image]: https://github.com/jazzband/pip-tools/workflows/CI/badge.svg\n[codecov]: https://codecov.io/gh/jazzband/pip-tools\n[codecov-image]: https://codecov.io/gh/jazzband/pip-tools/branch/main/graph/badge.svg\n[Matrix Room Badge]: https://img.shields.io/matrix/pip-tools:matrix.org?label=Discuss%20on%20Matrix%20at%20%23pip-tools%3Amatrix.org&logo=matrix&server_fqdn=matrix.org&style=flat\n[Matrix Room]: https://matrix.to/#/%23pip-tools:matrix.org\n[Matrix Space Badge]: https://img.shields.io/matrix/jazzband:matrix.org?label=Discuss%20on%20Matrix%20at%20%23jazzband%3Amatrix.org&logo=matrix&server_fqdn=matrix.org&style=flat\n[Matrix Space]: https://matrix.to/#/%23jazzband:matrix.org\n[pip-tools-overview]: https://github.com/jazzband/pip-tools/raw/main/img/pip-tools-overview.svg\n[environment-markers]: https://peps.python.org/pep-0508/#environment-markers\n[PEP 517]: https://peps.python.org/pep-0517/\n[PEP 660]: https://peps.python.org/pep-0660/\n[discord-chat]: https://discord.gg/pypa\n[discord-chat-image]: https://img.shields.io/discord/803025117553754132?label=Discord%20chat%20%23pip-tools&style=flat-square\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "pip",
          "requirements",
          "packaging"
        ],
        "author_email": "Vincent Driessen <me@nvie.com>",
        "license": "BSD",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Programming Language :: Python",
          "Topic :: Software Development :: Quality Assurance",
          "Topic :: Software Development :: Testing",
          "Topic :: System :: Systems Administration",
          "Topic :: Utilities",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "build >=1.0.0",
          "click >=8",
          "pip >=22.2",
          "pyproject-hooks",
          "setuptools",
          "wheel",
          "tomli ; python_version < \"3.11\"",
          "covdefaults ; extra == 'coverage'",
          "pytest-cov ; extra == 'coverage'",
          "pytest >=7.2.0 ; extra == 'testing'",
          "pytest-rerunfailures ; extra == 'testing'",
          "pytest-xdist ; extra == 'testing'",
          "tomli-w ; extra == 'testing'",
          "flit-core <4,>=2 ; extra == 'testing'",
          "poetry-core >=1.0.0 ; extra == 'testing'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "homepage, https://github.com/jazzband/pip-tools/",
          "documentation, https://pip-tools.readthedocs.io/en/latest/",
          "repository, https://github.com/jazzband/pip-tools",
          "changelog, https://github.com/jazzband/pip-tools/releases"
        ],
        "provides_extra": [
          "coverage",
          "testing"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pip_tools-7.4.1.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "platformdirs",
        "version": "4.2.2",
        "summary": "A small Python package for determining appropriate platform-specific dirs, e.g. a `user data dir`.",
        "description": "The problem\n===========\n\n.. image:: https://github.com/platformdirs/platformdirs/actions/workflows/check.yml/badge.svg\n   :target: https://github.com/platformdirs/platformdirs/actions\n\nWhen writing desktop application, finding the right location to store user data\nand configuration varies per platform. Even for single-platform apps, there\nmay by plenty of nuances in figuring out the right location.\n\nFor example, if running on macOS, you should use::\n\n    ~/Library/Application Support/<AppName>\n\nIf on Windows (at least English Win) that should be::\n\n    C:\\Documents and Settings\\<User>\\Application Data\\Local Settings\\<AppAuthor>\\<AppName>\n\nor possibly::\n\n    C:\\Documents and Settings\\<User>\\Application Data\\<AppAuthor>\\<AppName>\n\nfor `roaming profiles <https://docs.microsoft.com/en-us/previous-versions/windows/it-pro/windows-vista/cc766489(v=ws.10)>`_ but that is another story.\n\nOn Linux (and other Unices), according to the `XDG Basedir Spec`_, it should be::\n\n    ~/.local/share/<AppName>\n\n.. _XDG Basedir Spec: https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html\n\n``platformdirs`` to the rescue\n==============================\n\nThis kind of thing is what the ``platformdirs`` package is for.\n``platformdirs`` will help you choose an appropriate:\n\n- user data dir (``user_data_dir``)\n- user config dir (``user_config_dir``)\n- user cache dir (``user_cache_dir``)\n- site data dir (``site_data_dir``)\n- site config dir (``site_config_dir``)\n- user log dir (``user_log_dir``)\n- user documents dir (``user_documents_dir``)\n- user downloads dir (``user_downloads_dir``)\n- user pictures dir (``user_pictures_dir``)\n- user videos dir (``user_videos_dir``)\n- user music dir (``user_music_dir``)\n- user desktop dir (``user_desktop_dir``)\n- user runtime dir (``user_runtime_dir``)\n\nAnd also:\n\n- Is slightly opinionated on the directory names used. Look for \"OPINION\" in\n  documentation and code for when an opinion is being applied.\n\nExample output\n==============\n\nOn macOS:\n\n.. code-block:: pycon\n\n    >>> from platformdirs import *\n    >>> appname = \"SuperApp\"\n    >>> appauthor = \"Acme\"\n    >>> user_data_dir(appname, appauthor)\n    '/Users/trentm/Library/Application Support/SuperApp'\n    >>> site_data_dir(appname, appauthor)\n    '/Library/Application Support/SuperApp'\n    >>> user_cache_dir(appname, appauthor)\n    '/Users/trentm/Library/Caches/SuperApp'\n    >>> user_log_dir(appname, appauthor)\n    '/Users/trentm/Library/Logs/SuperApp'\n    >>> user_documents_dir()\n    '/Users/trentm/Documents'\n    >>> user_downloads_dir()\n    '/Users/trentm/Downloads'\n    >>> user_pictures_dir()\n    '/Users/trentm/Pictures'\n    >>> user_videos_dir()\n    '/Users/trentm/Movies'\n    >>> user_music_dir()\n    '/Users/trentm/Music'\n    >>> user_desktop_dir()\n    '/Users/trentm/Desktop'\n    >>> user_runtime_dir(appname, appauthor)\n    '/Users/trentm/Library/Caches/TemporaryItems/SuperApp'\n\nOn Windows:\n\n.. code-block:: pycon\n\n    >>> from platformdirs import *\n    >>> appname = \"SuperApp\"\n    >>> appauthor = \"Acme\"\n    >>> user_data_dir(appname, appauthor)\n    'C:\\\\Users\\\\trentm\\\\AppData\\\\Local\\\\Acme\\\\SuperApp'\n    >>> user_data_dir(appname, appauthor, roaming=True)\n    'C:\\\\Users\\\\trentm\\\\AppData\\\\Roaming\\\\Acme\\\\SuperApp'\n    >>> user_cache_dir(appname, appauthor)\n    'C:\\\\Users\\\\trentm\\\\AppData\\\\Local\\\\Acme\\\\SuperApp\\\\Cache'\n    >>> user_log_dir(appname, appauthor)\n    'C:\\\\Users\\\\trentm\\\\AppData\\\\Local\\\\Acme\\\\SuperApp\\\\Logs'\n    >>> user_documents_dir()\n    'C:\\\\Users\\\\trentm\\\\Documents'\n    >>> user_downloads_dir()\n    'C:\\\\Users\\\\trentm\\\\Downloads'\n    >>> user_pictures_dir()\n    'C:\\\\Users\\\\trentm\\\\Pictures'\n    >>> user_videos_dir()\n    'C:\\\\Users\\\\trentm\\\\Videos'\n    >>> user_music_dir()\n    'C:\\\\Users\\\\trentm\\\\Music'\n    >>> user_desktop_dir()\n    'C:\\\\Users\\\\trentm\\\\Desktop'\n    >>> user_runtime_dir(appname, appauthor)\n    'C:\\\\Users\\\\trentm\\\\AppData\\\\Local\\\\Temp\\\\Acme\\\\SuperApp'\n\nOn Linux:\n\n.. code-block:: pycon\n\n    >>> from platformdirs import *\n    >>> appname = \"SuperApp\"\n    >>> appauthor = \"Acme\"\n    >>> user_data_dir(appname, appauthor)\n    '/home/trentm/.local/share/SuperApp'\n    >>> site_data_dir(appname, appauthor)\n    '/usr/local/share/SuperApp'\n    >>> site_data_dir(appname, appauthor, multipath=True)\n    '/usr/local/share/SuperApp:/usr/share/SuperApp'\n    >>> user_cache_dir(appname, appauthor)\n    '/home/trentm/.cache/SuperApp'\n    >>> user_log_dir(appname, appauthor)\n    '/home/trentm/.local/state/SuperApp/log'\n    >>> user_config_dir(appname)\n    '/home/trentm/.config/SuperApp'\n    >>> user_documents_dir()\n    '/home/trentm/Documents'\n    >>> user_downloads_dir()\n    '/home/trentm/Downloads'\n    >>> user_pictures_dir()\n    '/home/trentm/Pictures'\n    >>> user_videos_dir()\n    '/home/trentm/Videos'\n    >>> user_music_dir()\n    '/home/trentm/Music'\n    >>> user_desktop_dir()\n    '/home/trentm/Desktop'\n    >>> user_runtime_dir(appname, appauthor)\n    '/run/user/{os.getuid()}/SuperApp'\n    >>> site_config_dir(appname)\n    '/etc/xdg/SuperApp'\n    >>> os.environ[\"XDG_CONFIG_DIRS\"] = \"/etc:/usr/local/etc\"\n    >>> site_config_dir(appname, multipath=True)\n    '/etc/SuperApp:/usr/local/etc/SuperApp'\n\nOn Android::\n\n    >>> from platformdirs import *\n    >>> appname = \"SuperApp\"\n    >>> appauthor = \"Acme\"\n    >>> user_data_dir(appname, appauthor)\n    '/data/data/com.myApp/files/SuperApp'\n    >>> user_cache_dir(appname, appauthor)\n    '/data/data/com.myApp/cache/SuperApp'\n    >>> user_log_dir(appname, appauthor)\n    '/data/data/com.myApp/cache/SuperApp/log'\n    >>> user_config_dir(appname)\n    '/data/data/com.myApp/shared_prefs/SuperApp'\n    >>> user_documents_dir()\n    '/storage/emulated/0/Documents'\n    >>> user_downloads_dir()\n    '/storage/emulated/0/Downloads'\n    >>> user_pictures_dir()\n    '/storage/emulated/0/Pictures'\n    >>> user_videos_dir()\n    '/storage/emulated/0/DCIM/Camera'\n    >>> user_music_dir()\n    '/storage/emulated/0/Music'\n    >>> user_desktop_dir()\n    '/storage/emulated/0/Desktop'\n    >>> user_runtime_dir(appname, appauthor)\n    '/data/data/com.myApp/cache/SuperApp/tmp'\n\nNote: Some android apps like Termux and Pydroid are used as shells. These\napps are used by the end user to emulate Linux environment. Presence of\n``SHELL`` environment variable is used by Platformdirs to differentiate\nbetween general android apps and android apps used as shells. Shell android\napps also support ``XDG_*`` environment variables.\n\n\n``PlatformDirs`` for convenience\n================================\n\n.. code-block:: pycon\n\n    >>> from platformdirs import PlatformDirs\n    >>> dirs = PlatformDirs(\"SuperApp\", \"Acme\")\n    >>> dirs.user_data_dir\n    '/Users/trentm/Library/Application Support/SuperApp'\n    >>> dirs.site_data_dir\n    '/Library/Application Support/SuperApp'\n    >>> dirs.user_cache_dir\n    '/Users/trentm/Library/Caches/SuperApp'\n    >>> dirs.user_log_dir\n    '/Users/trentm/Library/Logs/SuperApp'\n    >>> dirs.user_documents_dir\n    '/Users/trentm/Documents'\n    >>> dirs.user_downloads_dir\n    '/Users/trentm/Downloads'\n    >>> dirs.user_pictures_dir\n    '/Users/trentm/Pictures'\n    >>> dirs.user_videos_dir\n    '/Users/trentm/Movies'\n    >>> dirs.user_music_dir\n    '/Users/trentm/Music'\n    >>> dirs.user_desktop_dir\n    '/Users/trentm/Desktop'\n    >>> dirs.user_runtime_dir\n    '/Users/trentm/Library/Caches/TemporaryItems/SuperApp'\n\nPer-version isolation\n=====================\n\nIf you have multiple versions of your app in use that you want to be\nable to run side-by-side, then you may want version-isolation for these\ndirs::\n\n    >>> from platformdirs import PlatformDirs\n    >>> dirs = PlatformDirs(\"SuperApp\", \"Acme\", version=\"1.0\")\n    >>> dirs.user_data_dir\n    '/Users/trentm/Library/Application Support/SuperApp/1.0'\n    >>> dirs.site_data_dir\n    '/Library/Application Support/SuperApp/1.0'\n    >>> dirs.user_cache_dir\n    '/Users/trentm/Library/Caches/SuperApp/1.0'\n    >>> dirs.user_log_dir\n    '/Users/trentm/Library/Logs/SuperApp/1.0'\n    >>> dirs.user_documents_dir\n    '/Users/trentm/Documents'\n    >>> dirs.user_downloads_dir\n    '/Users/trentm/Downloads'\n    >>> dirs.user_pictures_dir\n    '/Users/trentm/Pictures'\n    >>> dirs.user_videos_dir\n    '/Users/trentm/Movies'\n    >>> dirs.user_music_dir\n    '/Users/trentm/Music'\n    >>> dirs.user_desktop_dir\n    '/Users/trentm/Desktop'\n    >>> dirs.user_runtime_dir\n    '/Users/trentm/Library/Caches/TemporaryItems/SuperApp/1.0'\n\nBe wary of using this for configuration files though; you'll need to handle\nmigrating configuration files manually.\n\nWhy this Fork?\n==============\n\nThis repository is a friendly fork of the wonderful work started by\n`ActiveState <https://github.com/ActiveState/appdirs>`_ who created\n``appdirs``, this package's ancestor.\n\nMaintaining an open source project is no easy task, particularly\nfrom within an organization, and the Python community is indebted\nto ``appdirs`` (and to Trent Mick and Jeff Rouse in particular) for\ncreating an incredibly useful simple module, as evidenced by the wide\nnumber of users it has attracted over the years.\n\nNonetheless, given the number of long-standing open issues\nand pull requests, and no clear path towards `ensuring\nthat maintenance of the package would continue or grow\n<https://github.com/ActiveState/appdirs/issues/79>`_, this fork was\ncreated.\n\nContributions are most welcome.\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "appdirs",
          "application",
          "cache",
          "directory",
          "log",
          "user"
        ],
        "maintainer_email": "BernÃ¡t GÃ¡bor <gaborjbernat@gmail.com>, Julian Berman <Julian@GrayVines.com>, Ofek Lev <oss@ofek.dev>, Ronny Pfannschmidt <opensource@ronnypfannschmidt.de>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "furo>=2023.9.10; extra == 'docs'",
          "proselint>=0.13; extra == 'docs'",
          "sphinx-autodoc-typehints>=1.25.2; extra == 'docs'",
          "sphinx>=7.2.6; extra == 'docs'",
          "appdirs==1.4.4; extra == 'test'",
          "covdefaults>=2.3; extra == 'test'",
          "pytest-cov>=4.1; extra == 'test'",
          "pytest-mock>=3.12; extra == 'test'",
          "pytest>=7.4.3; extra == 'test'",
          "mypy>=1.8; extra == 'type'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://platformdirs.readthedocs.io",
          "Homepage, https://github.com/platformdirs/platformdirs",
          "Source, https://github.com/platformdirs/platformdirs",
          "Tracker, https://github.com/platformdirs/platformdirs/issues"
        ],
        "provides_extra": [
          "docs",
          "test",
          "type"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\platformdirs-4.2.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "prompt_toolkit",
        "version": "3.0.47",
        "summary": "Library for building powerful interactive command lines in Python",
        "description": "Python Prompt Toolkit\n=====================\n\n|AppVeyor|  |PyPI|  |RTD|  |License|  |Codecov|\n\n.. image :: https://github.com/prompt-toolkit/python-prompt-toolkit/raw/master/docs/images/logo_400px.png\n\n``prompt_toolkit`` *is a library for building powerful interactive command line applications in Python.*\n\nRead the `documentation on readthedocs\n<http://python-prompt-toolkit.readthedocs.io/en/stable/>`_.\n\n\nGallery\n*******\n\n`ptpython <http://github.com/prompt-toolkit/ptpython/>`_ is an interactive\nPython Shell, build on top of ``prompt_toolkit``.\n\n.. image :: https://github.com/prompt-toolkit/python-prompt-toolkit/raw/master/docs/images/ptpython.png\n\n`More examples <https://python-prompt-toolkit.readthedocs.io/en/stable/pages/gallery.html>`_\n\n\nprompt_toolkit features\n***********************\n\n``prompt_toolkit`` could be a replacement for `GNU readline\n<https://tiswww.case.edu/php/chet/readline/rltop.html>`_, but it can be much\nmore than that.\n\nSome features:\n\n- **Pure Python**.\n- Syntax highlighting of the input while typing. (For instance, with a Pygments lexer.)\n- Multi-line input editing.\n- Advanced code completion.\n- Both Emacs and Vi key bindings. (Similar to readline.)\n- Even some advanced Vi functionality, like named registers and digraphs.\n- Reverse and forward incremental search.\n- Works well with Unicode double width characters. (Chinese input.)\n- Selecting text for copy/paste. (Both Emacs and Vi style.)\n- Support for `bracketed paste <https://cirw.in/blog/bracketed-paste>`_.\n- Mouse support for cursor positioning and scrolling.\n- Auto suggestions. (Like `fish shell <http://fishshell.com/>`_.)\n- Multiple input buffers.\n- No global state.\n- Lightweight, the only dependencies are Pygments and wcwidth.\n- Runs on Linux, OS X, FreeBSD, OpenBSD and Windows systems.\n- And much more...\n\nFeel free to create tickets for bugs and feature requests, and create pull\nrequests if you have nice patches that you would like to share with others.\n\n\nInstallation\n************\n\n::\n\n    pip install prompt_toolkit\n\nFor Conda, do:\n\n::\n\n    conda install -c https://conda.anaconda.org/conda-forge prompt_toolkit\n\n\nAbout Windows support\n*********************\n\n``prompt_toolkit`` is cross platform, and everything that you build on top\nshould run fine on both Unix and Windows systems. Windows support is best on\nrecent Windows 10 builds, for which the command line window supports vt100\nescape sequences. (If not supported, we fall back to using Win32 APIs for color\nand cursor movements).\n\nIt's worth noting that the implementation is a \"best effort of what is\npossible\". Both Unix and Windows terminals have their limitations. But in\ngeneral, the Unix experience will still be a little better.\n\n\nGetting started\n***************\n\nThe most simple example of the library would look like this:\n\n.. code:: python\n\n    from prompt_toolkit import prompt\n\n    if __name__ == '__main__':\n        answer = prompt('Give me some input: ')\n        print('You said: %s' % answer)\n\nFor more complex examples, have a look in the ``examples`` directory. All\nexamples are chosen to demonstrate only one thing. Also, don't be afraid to\nlook at the source code. The implementation of the ``prompt`` function could be\na good start.\n\nPhilosophy\n**********\n\nThe source code of ``prompt_toolkit`` should be **readable**, **concise** and\n**efficient**. We prefer short functions focusing each on one task and for which\nthe input and output types are clearly specified. We mostly prefer composition\nover inheritance, because inheritance can result in too much functionality in\nthe same object. We prefer immutable objects where possible (objects don't\nchange after initialization). Reusability is important. We absolutely refrain\nfrom having a changing global state, it should be possible to have multiple\nindependent instances of the same code in the same process. The architecture\nshould be layered: the lower levels operate on primitive operations and data\nstructures giving -- when correctly combined -- all the possible flexibility;\nwhile at the higher level, there should be a simpler API, ready-to-use and\nsufficient for most use cases. Thinking about algorithms and efficiency is\nimportant, but avoid premature optimization.\n\n\n`Projects using prompt_toolkit <PROJECTS.rst>`_\n***********************************************\n\nSpecial thanks to\n*****************\n\n- `Pygments <http://pygments.org/>`_: Syntax highlighter.\n- `wcwidth <https://github.com/jquast/wcwidth>`_: Determine columns needed for a wide characters.\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/prompt_toolkit.svg\n    :target: https://pypi.python.org/pypi/prompt-toolkit/\n    :alt: Latest Version\n\n.. |AppVeyor| image:: https://ci.appveyor.com/api/projects/status/32r7s2skrgm9ubva?svg=true\n    :target: https://ci.appveyor.com/project/prompt-toolkit/python-prompt-toolkit/\n\n.. |RTD| image:: https://readthedocs.org/projects/python-prompt-toolkit/badge/\n    :target: https://python-prompt-toolkit.readthedocs.io/en/master/\n\n.. |License| image:: https://img.shields.io/github/license/prompt-toolkit/python-prompt-toolkit.svg\n    :target: https://github.com/prompt-toolkit/python-prompt-toolkit/blob/master/LICENSE\n\n.. |Codecov| image:: https://codecov.io/gh/prompt-toolkit/python-prompt-toolkit/branch/master/graphs/badge.svg?style=flat\n    :target: https://codecov.io/gh/prompt-toolkit/python-prompt-toolkit/\n\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/prompt-toolkit/python-prompt-toolkit",
        "author": "Jonathan Slenders",
        "license_file": [
          "LICENSE",
          "AUTHORS.rst"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python",
          "Topic :: Software Development"
        ],
        "requires_dist": [
          "wcwidth"
        ],
        "requires_python": ">=3.7.0"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\prompt_toolkit-3.0.47.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pure_eval",
        "version": "0.2.3",
        "summary": "Safely evaluate AST nodes without side effects",
        "description": "# `pure_eval`\n\n[![Build Status](https://travis-ci.org/alexmojaki/pure_eval.svg?branch=master)](https://travis-ci.org/alexmojaki/pure_eval) [![Coverage Status](https://coveralls.io/repos/github/alexmojaki/pure_eval/badge.svg?branch=master)](https://coveralls.io/github/alexmojaki/pure_eval?branch=master) [![Supports Python versions 3.7+](https://img.shields.io/pypi/pyversions/pure_eval.svg)](https://pypi.python.org/pypi/pure_eval)\n\nThis is a Python package that lets you safely evaluate certain AST nodes without triggering arbitrary code that may have unwanted side effects.\n\nIt can be installed from PyPI:\n\n    pip install pure_eval\n\nTo demonstrate usage, suppose we have an object defined as follows:\n\n```python\nclass Rectangle:\n    def __init__(self, width, height):\n        self.width = width\n        self.height = height\n\n    @property\n    def area(self):\n        print(\"Calculating area...\")\n        return self.width * self.height\n\n\nrect = Rectangle(3, 5)\n```\n\nGiven the `rect` object, we want to evaluate whatever expressions we can in this source code:\n\n```python\nsource = \"(rect.width, rect.height, rect.area)\"\n```\n\nThis library works with the AST, so let's parse the source code and peek inside:\n\n```python\nimport ast\n\ntree = ast.parse(source)\nthe_tuple = tree.body[0].value\nfor node in the_tuple.elts:\n    print(ast.dump(node))\n```\n\nOutput:\n\n```python\nAttribute(value=Name(id='rect', ctx=Load()), attr='width', ctx=Load())\nAttribute(value=Name(id='rect', ctx=Load()), attr='height', ctx=Load())\nAttribute(value=Name(id='rect', ctx=Load()), attr='area', ctx=Load())\n```\n\nNow to actually use the library. First construct an Evaluator:\n\n```python\nfrom pure_eval import Evaluator\n\nevaluator = Evaluator({\"rect\": rect})\n```\n\nThe argument to `Evaluator` should be a mapping from variable names to their values. Or if you have access to the stack frame where `rect` is defined, you can instead use:\n\n```python\nevaluator = Evaluator.from_frame(frame)\n```\n\nNow to evaluate some nodes, using `evaluator[node]`:\n\n```python\nprint(\"rect.width:\", evaluator[the_tuple.elts[0]])\nprint(\"rect:\", evaluator[the_tuple.elts[0].value])\n```\n\nOutput:\n\n```\nrect.width: 3\nrect: <__main__.Rectangle object at 0x105b0dd30>\n```\n\nOK, but you could have done the same thing with `eval`. The useful part is that it will refuse to evaluate the property `rect.area` because that would trigger unknown code. If we try, it'll raise a `CannotEval` exception.\n\n```python\nfrom pure_eval import CannotEval\n\ntry:\n    print(\"rect.area:\", evaluator[the_tuple.elts[2]])  # fails\nexcept CannotEval as e:\n    print(e)  # prints CannotEval\n```\n\nTo find all the expressions that can be evaluated in a tree:\n\n```python\nfor node, value in evaluator.find_expressions(tree):\n    print(ast.dump(node), value)\n```\n\nOutput:\n\n```python\nAttribute(value=Name(id='rect', ctx=Load()), attr='width', ctx=Load()) 3\nAttribute(value=Name(id='rect', ctx=Load()), attr='height', ctx=Load()) 5\nName(id='rect', ctx=Load()) <__main__.Rectangle object at 0x105568d30>\nName(id='rect', ctx=Load()) <__main__.Rectangle object at 0x105568d30>\nName(id='rect', ctx=Load()) <__main__.Rectangle object at 0x105568d30>\n```\n\nNote that this includes `rect` three times, once for each appearance in the source code. Since all these nodes are equivalent, we can group them together:\n\n```python\nfrom pure_eval import group_expressions\n\nfor nodes, values in group_expressions(evaluator.find_expressions(tree)):\n    print(len(nodes), \"nodes with value:\", values)\n```\n\nOutput:\n\n```\n1 nodes with value: 3\n1 nodes with value: 5\n3 nodes with value: <__main__.Rectangle object at 0x10d374d30>\n```\n\nIf we want to list all the expressions in a tree, we may want to filter out certain expressions whose values are obvious. For example, suppose we have a function `foo`:\n\n```python\ndef foo():\n    pass\n```\n\nIf we refer to `foo` by its name as usual, then that's not interesting:\n\n```python\nfrom pure_eval import is_expression_interesting\n\nnode = ast.parse('foo').body[0].value\nprint(ast.dump(node))\nprint(is_expression_interesting(node, foo))\n```\n\nOutput:\n\n```python\nName(id='foo', ctx=Load())\nFalse\n```\n\nBut if we refer to it by a different name, then it's interesting:\n\n```python\nnode = ast.parse('bar').body[0].value\nprint(ast.dump(node))\nprint(is_expression_interesting(node, foo))\n```\n\nOutput:\n\n```python\nName(id='bar', ctx=Load())\nTrue\n```\n\nIn general `is_expression_interesting` returns False for the following values:\n- Literals (e.g. `123`, `'abc'`, `[1, 2, 3]`, `{'a': (), 'b': ([1, 2], [3])}`)\n- Variables or attributes whose name is equal to the value's `__name__`, such as `foo` above or `self.foo` if it was a method.\n- Builtins (e.g. `len`) referred to by their usual name.\n\nTo make things easier, you can combine finding expressions, grouping them, and filtering out the obvious ones with:\n\n```python\nevaluator.interesting_expressions_grouped(root)\n```\n\nTo get the source code of an AST node, I recommend [asttokens](https://github.com/gristlabs/asttokens).\n\nHere's a complete example that brings it all together:\n\n```python\nfrom asttokens import ASTTokens\nfrom pure_eval import Evaluator\n\nsource = \"\"\"\nx = 1\nd = {x: 2}\ny = d[x]\n\"\"\"\n\nnames = {}\nexec(source, names)\natok = ASTTokens(source, parse=True)\nfor nodes, value in Evaluator(names).interesting_expressions_grouped(atok.tree):\n    print(atok.get_text(nodes[0]), \"=\", value)\n```\n\nOutput:\n\n```python\nx = 1\nd = {1: 2}\ny = 2\nd[x] = 2\n```\n",
        "description_content_type": "text/markdown",
        "home_page": "http://github.com/alexmojaki/pure_eval",
        "author": "Alex Hall",
        "author_email": "alex.mojaki@gmail.com",
        "license": "MIT",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent"
        ],
        "requires_dist": [
          "pytest ; extra == 'tests'"
        ],
        "provides_extra": [
          "tests"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pure_eval-0.2.3.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "pydantic",
        "version": "2.9.2",
        "summary": "Data validation using Python type hints",
        "description": "# Pydantic\n[![CI](https://img.shields.io/github/actions/workflow/status/pydantic/pydantic/ci.yml?branch=main&logo=github&label=CI)](https://github.com/pydantic/pydantic/actions?query=event%3Apush+branch%3Amain+workflow%3ACI)\n[![Coverage](https://coverage-badge.samuelcolvin.workers.dev/pydantic/pydantic.svg)](https://coverage-badge.samuelcolvin.workers.dev/redirect/pydantic/pydantic)\n[![pypi](https://img.shields.io/pypi/v/pydantic.svg)](https://pypi.python.org/pypi/pydantic)\n[![CondaForge](https://img.shields.io/conda/v/conda-forge/pydantic.svg)](https://anaconda.org/conda-forge/pydantic)\n[![downloads](https://static.pepy.tech/badge/pydantic/month)](https://pepy.tech/project/pydantic)\n[![versions](https://img.shields.io/pypi/pyversions/pydantic.svg)](https://github.com/pydantic/pydantic)\n[![license](https://img.shields.io/github/license/pydantic/pydantic.svg)](https://github.com/pydantic/pydantic/blob/main/LICENSE)\n[![Pydantic v2](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json)](https://docs.pydantic.dev/latest/contributing/#badges)\n\nData validation using Python type hints.\n\nFast and extensible, Pydantic plays nicely with your linters/IDE/brain.\nDefine how data should be in pure, canonical Python 3.8+; validate it with Pydantic.\n\n## Pydantic Company :rocket:\n\nWe've started a company based on the principles that I believe have led to Pydantic's success.\nLearn more from the [Company Announcement](https://blog.pydantic.dev/blog/2023/02/16/company-announcement--pydantic/).\n\n## Pydantic V1.10 vs. V2\n\nPydantic V2 is a ground-up rewrite that offers many new features, performance improvements, and some breaking changes compared to Pydantic V1.\n\nIf you're using Pydantic V1 you may want to look at the\n[pydantic V1.10 Documentation](https://docs.pydantic.dev/) or,\n[`1.10.X-fixes` git branch](https://github.com/pydantic/pydantic/tree/1.10.X-fixes). Pydantic V2 also ships with the latest version of Pydantic V1 built in so that you can incrementally upgrade your code base and projects: `from pydantic import v1 as pydantic_v1`.\n\n## Help\n\nSee [documentation](https://docs.pydantic.dev/) for more details.\n\n## Installation\n\nInstall using `pip install -U pydantic` or `conda install pydantic -c conda-forge`.\nFor more installation options to make Pydantic even faster,\nsee the [Install](https://docs.pydantic.dev/install/) section in the documentation.\n\n## A Simple Example\n\n```py\nfrom datetime import datetime\nfrom typing import List, Optional\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    id: int\n    name: str = 'John Doe'\n    signup_ts: Optional[datetime] = None\n    friends: List[int] = []\n\nexternal_data = {'id': '123', 'signup_ts': '2017-06-01 12:22', 'friends': [1, '2', b'3']}\nuser = User(**external_data)\nprint(user)\n#> User id=123 name='John Doe' signup_ts=datetime.datetime(2017, 6, 1, 12, 22) friends=[1, 2, 3]\nprint(user.id)\n#> 123\n```\n\n## Contributing\n\nFor guidance on setting up a development environment and how to make a\ncontribution to Pydantic, see\n[Contributing to Pydantic](https://docs.pydantic.dev/contributing/).\n\n## Reporting a Security Vulnerability\n\nSee our [security policy](https://github.com/pydantic/pydantic/security/policy).\n\n## Changelog\n\n## v2.9.2 (2024-09-17)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.9.2)\n\n### What's Changed\n\n#### Fixes\n* Do not error when trying to evaluate annotations of private attributes by [@Viicos](https://github.com/Viicos) in [#10358](https://github.com/pydantic/pydantic/pull/10358)\n* Adding notes on designing sound `Callable` discriminators by [@sydney-runkle](https://github.com/sydney-runkle) in [#10400](https://github.com/pydantic/pydantic/pull/10400)\n* Fix serialization schema generation when using `PlainValidator` by [@Viicos](https://github.com/Viicos) in [#10427](https://github.com/pydantic/pydantic/pull/10427)\n* Fix `Union` serialization warnings by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1449](https://github.com/pydantic/pydantic-core/pull/1449)\n* Fix variance issue in `_IncEx` type alias, only allow `True` by [@Viicos](https://github.com/Viicos) in [#10414](https://github.com/pydantic/pydantic/pull/10414)\n* Fix `ZoneInfo` validation with various invalid types by [@sydney-runkle](https://github.com/sydney-runkle) in [#10408](https://github.com/pydantic/pydantic/pull/10408)\n\n## v2.9.1 (2024-09-09)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.9.1)\n\n### What's Changed\n\n#### Fixes\n* Fix Predicate issue in v2.9.0 by [@sydney-runkle](https://github.com/sydney-runkle) in [#10321](https://github.com/pydantic/pydantic/pull/10321)\n* Fixing `annotated-types` bound to `>=0.6.0` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10327](https://github.com/pydantic/pydantic/pull/10327)\n* Turn `tzdata` install requirement into optional `timezone` dependency by [@jakob-keller](https://github.com/jakob-keller) in [#10331](https://github.com/pydantic/pydantic/pull/10331)\n* Fix `IncExc` type alias definition by [@Viicos](https://github.com/Viicos) in [#10339](https://github.com/pydantic/pydantic/pull/10339)\n* Use correct types namespace when building namedtuple core schemas by [@Viicos](https://github.com/Viicos) in [#10337](https://github.com/pydantic/pydantic/pull/10337)\n* Fix evaluation of stringified annotations during namespace inspection by [@Viicos](https://github.com/Viicos) in [#10347](https://github.com/pydantic/pydantic/pull/10347)\n* Fix tagged union serialization with alias generators by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1442](https://github.com/pydantic/pydantic-core/pull/1442)\n\n## v2.9.0 (2024-09-05)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.9.0)\n\nThe code released in v2.9.0 is practically identical to that of v2.9.0b2.\n\n### What's Changed\n\n#### Packaging\n\n* Bump `ruff` to `v0.5.0` and `pyright` to `v1.1.369` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9801](https://github.com/pydantic/pydantic/pull/9801)\n* Bump `pydantic-extra-types` to `v2.9.0` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9832](https://github.com/pydantic/pydantic/pull/9832)\n* Support compatibility with `pdm v2.18.1` by [@Viicos](https://github.com/Viicos) in [#10138](https://github.com/pydantic/pydantic/pull/10138)\n* Bump `v1` version stub to `v1.10.18` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10214](https://github.com/pydantic/pydantic/pull/10214)\n* Bump `pydantic-core` to `v2.23.2` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10311](https://github.com/pydantic/pydantic/pull/10311)\n\n#### New Features\n\n* Add support for `ZoneInfo` by [@Youssefares](https://github.com/Youssefares) in [#9896](https://github.com/pydantic/pydantic/pull/9896)\n* Add `Config.val_json_bytes` by [@josh-newman](https://github.com/josh-newman) in [#9770](https://github.com/pydantic/pydantic/pull/9770)\n* Add DSN for Snowflake by [@aditkumar72](https://github.com/aditkumar72) in [#10128](https://github.com/pydantic/pydantic/pull/10128)\n* Support `complex` number by [@changhc](https://github.com/changhc) in [#9654](https://github.com/pydantic/pydantic/pull/9654)\n* Add support for `annotated_types.Not` by [@aditkumar72](https://github.com/aditkumar72) in [#10210](https://github.com/pydantic/pydantic/pull/10210)\n* Allow `WithJsonSchema` to inject `$ref`s w/ `http` or `https` links by [@dAIsySHEng1](https://github.com/dAIsySHEng1) in [#9863](https://github.com/pydantic/pydantic/pull/9863)\n* Allow validators to customize validation JSON schema by [@Viicos](https://github.com/Viicos) in [#10094](https://github.com/pydantic/pydantic/pull/10094)\n* Support parametrized `PathLike` types by [@nix010](https://github.com/nix010) in [#9764](https://github.com/pydantic/pydantic/pull/9764)\n* Add tagged union serializer that attempts to use `str` or `callable` discriminators to select the correct serializer by [@sydney-runkle](https://github.com/sydney-runkle) in in [pydantic/pydantic-core#1397](https://github.com/pydantic/pydantic-core/pull/1397)\n\n#### Changes\n\n* Breaking Change: Merge `dict` type `json_schema_extra` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9792](https://github.com/pydantic/pydantic/pull/9792)\n  * For more info (how to replicate old behavior) on this change, see [here](https://docs.pydantic.dev/dev/concepts/json_schema/#merging-json_schema_extra)\n* Refactor annotation injection for known (often generic) types by [@sydney-runkle](https://github.com/sydney-runkle) in [#9979](https://github.com/pydantic/pydantic/pull/9979)\n* Move annotation compatibility errors to validation phase by [@sydney-runkle](https://github.com/sydney-runkle) in [#9999](https://github.com/pydantic/pydantic/pull/9999)\n* Improve runtime errors for string constraints like `pattern` for incompatible types by [@sydney-runkle](https://github.com/sydney-runkle) in [#10158](https://github.com/pydantic/pydantic/pull/10158)\n* Remove `'allOf'` JSON schema workarounds by [@dpeachey](https://github.com/dpeachey) in [#10029](https://github.com/pydantic/pydantic/pull/10029)\n* Remove `typed_dict_cls` data from `CoreMetadata` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10180](https://github.com/pydantic/pydantic/pull/10180)\n* Deprecate passing a dict to the `Examples` class by [@Viicos](https://github.com/Viicos) in [#10181](https://github.com/pydantic/pydantic/pull/10181)\n* Remove `initial_metadata` from internal metadata construct by [@sydney-runkle](https://github.com/sydney-runkle) in [#10194](https://github.com/pydantic/pydantic/pull/10194)\n* Use `re.Pattern.search` instead of `re.Pattern.match` for consistency with `rust` behavior by [@tinez](https://github.com/tinez) in [pydantic/pydantic-core#1368](https://github.com/pydantic/pydantic-core/pull/1368)\n* Show value of wrongly typed data in `pydantic-core` serialization warning by [@BoxyUwU](https://github.com/BoxyUwU) in [pydantic/pydantic-core#1377](https://github.com/pydantic/pydantic-core/pull/1377)\n* Breaking Change: in `pydantic-core`, change `metadata` type hint in core schemas from `Any` -> `Dict[str, Any] | None` by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1411](https://github.com/pydantic/pydantic-core/pull/1411)\n* Raise helpful warning when `self` isn't returned from model validator by [@sydney-runkle](https://github.com/sydney-runkle) in [#10255](https://github.com/pydantic/pydantic/pull/10255)\n\n#### Performance\n\n* Initial start at improving import times for modules, using caching primarily by [@sydney-runkle](https://github.com/sydney-runkle) in [#10009](https://github.com/pydantic/pydantic/pull/10009)\n* Using cached internal import for `BaseModel` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10013](https://github.com/pydantic/pydantic/pull/10013)\n* Simplify internal generics logic - remove generator overhead by [@sydney-runkle](https://github.com/sydney-runkle) in [#10059](https://github.com/pydantic/pydantic/pull/10059)\n* Remove default module globals from types namespace by [@sydney-runkle](https://github.com/sydney-runkle) in [#10123](https://github.com/pydantic/pydantic/pull/10123)\n* Performance boost: skip caching parent namespaces in most cases by [@sydney-runkle](https://github.com/sydney-runkle) in [#10113](https://github.com/pydantic/pydantic/pull/10113)\n* Update ns stack with already copied ns by [@sydney-runkle](https://github.com/sydney-runkle) in [#10267](https://github.com/pydantic/pydantic/pull/10267)\n\n##### Minor Internal Improvements\n* âš¡ï¸ Speed up `multiple_of_validator()` by 31% in `pydantic/_internal/_validators.py` by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#9839](https://github.com/pydantic/pydantic/pull/9839)\n* âš¡ï¸ Speed up `ModelPrivateAttr.__set_name__()` by 18% in `pydantic/fields.py` by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#9841](https://github.com/pydantic/pydantic/pull/9841)\n* âš¡ï¸ Speed up `dataclass()` by 7% in `pydantic/dataclasses.py` by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#9843](https://github.com/pydantic/pydantic/pull/9843)\n* âš¡ï¸ Speed up function `_field_name_for_signature` by 37% in `pydantic/_internal/_signature.py` by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#9951](https://github.com/pydantic/pydantic/pull/9951)\n* âš¡ï¸ Speed up method `GenerateSchema._unpack_refs_defs` by 26% in `pydantic/_internal/_generate_schema.py` by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#9949](https://github.com/pydantic/pydantic/pull/9949)\n* âš¡ï¸ Speed up function `apply_each_item_validators` by 100% in `pydantic/_internal/_generate_schema.py` by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#9950](https://github.com/pydantic/pydantic/pull/9950)\n* âš¡ï¸ Speed up method `ConfigWrapper.core_config` by 28% in `pydantic/_internal/_config.py` by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#9953](https://github.com/pydantic/pydantic/pull/9953)\n\n#### Fixes\n\n* Respect `use_enum_values` on `Literal` types by [@kwint](https://github.com/kwint) in [#9787](https://github.com/pydantic/pydantic/pull/9787)\n* Prevent type error for exotic `BaseModel/RootModel` inheritance by [@dmontagu](https://github.com/dmontagu) in [#9913](https://github.com/pydantic/pydantic/pull/9913)\n* Fix typing issue with field_validator-decorated methods by [@dmontagu](https://github.com/dmontagu) in [#9914](https://github.com/pydantic/pydantic/pull/9914)\n* Replace `str` type annotation with `Any` in validator factories in documentation on validators by [@maximilianfellhuber](https://github.com/maximilianfellhuber) in [#9885](https://github.com/pydantic/pydantic/pull/9885)\n* Fix `ComputedFieldInfo.wrapped_property` pointer when a property setter is assigned by [@tlambert03](https://github.com/tlambert03) in [#9892](https://github.com/pydantic/pydantic/pull/9892)\n* Fix recursive typing of `main.IncEnx` by [@tlambert03](https://github.com/tlambert03) in [#9924](https://github.com/pydantic/pydantic/pull/9924)\n* Allow usage of `type[Annotated[...]]` by [@Viicos](https://github.com/Viicos) in [#9932](https://github.com/pydantic/pydantic/pull/9932)\n* `mypy` plugin: handle frozen fields on a per-field basis by [@dmontagu](https://github.com/dmontagu) in [#9935](https://github.com/pydantic/pydantic/pull/9935)\n* Fix typo in `invalid-annotated-type` error code by [@sydney-runkle](https://github.com/sydney-runkle) in [#9948](https://github.com/pydantic/pydantic/pull/9948)\n* Simplify schema generation for `uuid`, `url`, and `ip` types by [@sydney-runkle](https://github.com/sydney-runkle) in [#9975](https://github.com/pydantic/pydantic/pull/9975)\n* Move `date` schemas to `_generate_schema.py` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9976](https://github.com/pydantic/pydantic/pull/9976)\n* Move `decimal.Decimal` validation to `_generate_schema.py` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9977](https://github.com/pydantic/pydantic/pull/9977)\n* Simplify IP address schema in `_std_types_schema.py` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9959](https://github.com/pydantic/pydantic/pull/9959)\n* Fix type annotations for some potentially generic `GenerateSchema.match_type` options by [@sydney-runkle](https://github.com/sydney-runkle) in [#9961](https://github.com/pydantic/pydantic/pull/9961)\n* Add class name to \"has conflict\" warnings by [@msabramo](https://github.com/msabramo) in [#9964](https://github.com/pydantic/pydantic/pull/9964)\n* Fix `dataclass` ignoring `default_factory` passed in Annotated by [@kc0506](https://github.com/kc0506) in [#9971](https://github.com/pydantic/pydantic/pull/9971)\n* Fix `Sequence` ignoring `discriminator` by [@kc0506](https://github.com/kc0506) in [#9980](https://github.com/pydantic/pydantic/pull/9980)\n* Fix typing for `IPvAnyAddress` and `IPvAnyInterface` by [@haoyun](https://github.com/haoyun) in [#9990](https://github.com/pydantic/pydantic/pull/9990)\n* Fix false positives on v1 models in `mypy` plugin for `from_orm` check requiring from_attributes=True config by [@radekwlsk](https://github.com/radekwlsk) in [#9938](https://github.com/pydantic/pydantic/pull/9938)\n* Apply `strict=True` to `__init__` in `mypy` plugin by [@kc0506](https://github.com/kc0506) in [#9998](https://github.com/pydantic/pydantic/pull/9998)\n* Refactor application of `deque` annotations by [@sydney-runkle](https://github.com/sydney-runkle) in [#10018](https://github.com/pydantic/pydantic/pull/10018)\n* Raise a better user error when failing to evaluate a forward reference by [@Viicos](https://github.com/Viicos) in [#10030](https://github.com/pydantic/pydantic/pull/10030)\n* Fix evaluation of `__pydantic_extra__` annotation in specific circumstances by [@Viicos](https://github.com/Viicos) in [#10070](https://github.com/pydantic/pydantic/pull/10070)\n* Fix `frozen` enforcement for `dataclasses` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10066](https://github.com/pydantic/pydantic/pull/10066)\n* Remove logic to handle unused `__get_pydantic_core_schema__` signature by [@Viicos](https://github.com/Viicos) in [#10075](https://github.com/pydantic/pydantic/pull/10075)\n* Use `is_annotated` consistently by [@Viicos](https://github.com/Viicos) in [#10095](https://github.com/pydantic/pydantic/pull/10095)\n* Fix `PydanticDeprecatedSince26` typo by [@kc0506](https://github.com/kc0506) in [#10101](https://github.com/pydantic/pydantic/pull/10101)\n* Improve `pyright` tests, refactor model decorators signatures by [@Viicos](https://github.com/Viicos) in [#10092](https://github.com/pydantic/pydantic/pull/10092)\n* Fix `ip` serialization logic by [@sydney-runkle](https://github.com/sydney-runkle) in [#10112](https://github.com/pydantic/pydantic/pull/10112)\n* Warn when frozen defined twice for `dataclasses` by [@mochi22](https://github.com/mochi22) in [#10082](https://github.com/pydantic/pydantic/pull/10082)\n* Do not compute JSON Schema default when plain serializers are used with `when_used` set to `'json-unless-none'` and the default value is `None` by [@Viicos](https://github.com/Viicos) in [#10121](https://github.com/pydantic/pydantic/pull/10121)\n* Fix `ImportString` special cases by [@sydney-runkle](https://github.com/sydney-runkle) in [#10137](https://github.com/pydantic/pydantic/pull/10137)\n* Blacklist default globals to support exotic user code with `__` prefixed annotations by [@sydney-runkle](https://github.com/sydney-runkle) in [#10136](https://github.com/pydantic/pydantic/pull/10136)\n* Handle `nullable` schemas with `serialization` schema available during JSON Schema generation by [@Viicos](https://github.com/Viicos) in [#10132](https://github.com/pydantic/pydantic/pull/10132)\n* Reorganize `BaseModel` annotations by [@kc0506](https://github.com/kc0506) in [#10110](https://github.com/pydantic/pydantic/pull/10110)\n* Fix core schema simplification when serialization schemas are involved in specific scenarios by [@Viicos](https://github.com/Viicos) in [#10155](https://github.com/pydantic/pydantic/pull/10155)\n* Add support for stringified annotations when using `PrivateAttr` with `Annotated` by [@Viicos](https://github.com/Viicos) in [#10157](https://github.com/pydantic/pydantic/pull/10157)\n* Fix JSON Schema `number` type for literal and enum schemas by [@Viicos](https://github.com/Viicos) in [#10172](https://github.com/pydantic/pydantic/pull/10172)\n* Fix JSON Schema generation of fields with plain validators in serialization mode by [@Viicos](https://github.com/Viicos) in [#10167](https://github.com/pydantic/pydantic/pull/10167)\n* Fix invalid JSON Schemas being generated for functions in certain scenarios by [@Viicos](https://github.com/Viicos) in [#10188](https://github.com/pydantic/pydantic/pull/10188)\n* Make sure generated JSON Schemas are valid in tests by [@Viicos](https://github.com/Viicos) in [#10182](https://github.com/pydantic/pydantic/pull/10182)\n* Fix key error with custom serializer by [@sydney-runkle](https://github.com/sydney-runkle) in [#10200](https://github.com/pydantic/pydantic/pull/10200)\n* Add 'wss' for allowed schemes in NatsDsn by [@swelborn](https://github.com/swelborn) in [#10224](https://github.com/pydantic/pydantic/pull/10224)\n* Fix `Mapping` and `MutableMapping` annotations to use mapping schema instead of dict schema by [@sydney-runkle](https://github.com/sydney-runkle) in [#10020](https://github.com/pydantic/pydantic/pull/10020)\n* Fix JSON Schema generation for constrained dates by [@Viicos](https://github.com/Viicos) in [#10185](https://github.com/pydantic/pydantic/pull/10185)\n* Fix discriminated union bug regression when using enums by [@kfreezen](https://github.com/kfreezen) in [pydantic/pydantic-core#1286](https://github.com/pydantic/pydantic-core/pull/1286)\n* Fix `field_serializer` with computed field when using `*` by [@nix010](https://github.com/nix010) in [pydantic/pydantic-core#1349](https://github.com/pydantic/pydantic-core/pull/1349)\n* Try each option in `Union` serializer before inference by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1398](https://github.com/pydantic/pydantic-core/pull/1398)\n* Fix `float` serialization behavior in `strict` mode by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1400](https://github.com/pydantic/pydantic-core/pull/1400)\n* Introduce `exactness` into Decimal validation logic to improve union validation behavior by [@sydney-runkle](https://github.com/sydney-runkle) in in [pydantic/pydantic-core#1405](https://github.com/pydantic/pydantic-core/pull/1405)\n* Fix new warnings assertions to use `pytest.warns()` by [@mgorny](https://github.com/mgorny) in [#10241](https://github.com/pydantic/pydantic/pull/10241)\n* Fix a crash when cleaning the namespace in `ModelMetaclass` by [@Viicos](https://github.com/Viicos) in [#10242](https://github.com/pydantic/pydantic/pull/10242)\n* Fix parent namespace issue with model rebuilds by [@sydney-runkle](https://github.com/sydney-runkle) in [#10257](https://github.com/pydantic/pydantic/pull/10257)\n* Remove defaults filter for namespace by [@sydney-runkle](https://github.com/sydney-runkle) in [#10261](https://github.com/pydantic/pydantic/pull/10261)\n* Use identity instead of equality after validating model in `__init__` by [@Viicos](https://github.com/Viicos) in [#10264](https://github.com/pydantic/pydantic/pull/10264)\n* Support `BigInt` serialization for `int` subclasses by [@kxx317](https://github.com/kxx317) in [pydantic/pydantic-core#1417](https://github.com/pydantic/pydantic-core/pull/1417)\n* Support signature for wrap validators without `info` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10277](https://github.com/pydantic/pydantic/pull/10277)\n* Ensure `__pydantic_complete__` is set when rebuilding `dataclasses` by [@Viicos](https://github.com/Viicos) in [#10291](https://github.com/pydantic/pydantic/pull/10291)\n* Respect `schema_generator` config value in `TypeAdapter` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10300](https://github.com/pydantic/pydantic/pull/10300)\n\n### New Contributors\n\n#### `pydantic`\n\n* [@kwint](https://github.com/kwint) made their first contribution in [#9787](https://github.com/pydantic/pydantic/pull/9787)\n* [@seekinginfiniteloop](https://github.com/seekinginfiniteloop) made their first contribution in [#9822](https://github.com/pydantic/pydantic/pull/9822)\n* [@a-alexander](https://github.com/a-alexander) made their first contribution in [#9848](https://github.com/pydantic/pydantic/pull/9848)\n* [@maximilianfellhuber](https://github.com/maximilianfellhuber) made their first contribution in [#9885](https://github.com/pydantic/pydantic/pull/9885)\n* [@karmaBonfire](https://github.com/karmaBonfire) made their first contribution in [#9945](https://github.com/pydantic/pydantic/pull/9945)\n* [@s-rigaud](https://github.com/s-rigaud) made their first contribution in [#9958](https://github.com/pydantic/pydantic/pull/9958)\n* [@msabramo](https://github.com/msabramo) made their first contribution in [#9964](https://github.com/pydantic/pydantic/pull/9964)\n* [@DimaCybr](https://github.com/DimaCybr) made their first contribution in [#9972](https://github.com/pydantic/pydantic/pull/9972)\n* [@kc0506](https://github.com/kc0506) made their first contribution in [#9971](https://github.com/pydantic/pydantic/pull/9971)\n* [@haoyun](https://github.com/haoyun) made their first contribution in [#9990](https://github.com/pydantic/pydantic/pull/9990)\n* [@radekwlsk](https://github.com/radekwlsk) made their first contribution in [#9938](https://github.com/pydantic/pydantic/pull/9938)\n* [@dpeachey](https://github.com/dpeachey) made their first contribution in [#10029](https://github.com/pydantic/pydantic/pull/10029)\n* [@BoxyUwU](https://github.com/BoxyUwU) made their first contribution in [#10085](https://github.com/pydantic/pydantic/pull/10085)\n* [@mochi22](https://github.com/mochi22) made their first contribution in [#10082](https://github.com/pydantic/pydantic/pull/10082)\n* [@aditkumar72](https://github.com/aditkumar72) made their first contribution in [#10128](https://github.com/pydantic/pydantic/pull/10128)\n* [@changhc](https://github.com/changhc) made their first contribution in [#9654](https://github.com/pydantic/pydantic/pull/9654)\n* [@insumanth](https://github.com/insumanth) made their first contribution in [#10229](https://github.com/pydantic/pydantic/pull/10229)\n* [@AdolfoVillalobos](https://github.com/AdolfoVillalobos) made their first contribution in [#10240](https://github.com/pydantic/pydantic/pull/10240)\n* [@bllchmbrs](https://github.com/bllchmbrs) made their first contribution in [#10270](https://github.com/pydantic/pydantic/pull/10270)\n\n#### `pydantic-core`\n\n* [@kfreezen](https://github.com/kfreezen) made their first contribution in [pydantic/pydantic-core#1286](https://github.com/pydantic/pydantic-core/pull/1286)\n* [@tinez](https://github.com/tinez) made their first contribution in [pydantic/pydantic-core#1368](https://github.com/pydantic/pydantic-core/pull/1368)\n* [@fft001](https://github.com/fft001) made their first contribution in [pydantic/pydantic-core#1362](https://github.com/pydantic/pydantic-core/pull/1362)\n* [@nix010](https://github.com/nix010) made their first contribution in [pydantic/pydantic-core#1349](https://github.com/pydantic/pydantic-core/pull/1349)\n* [@BoxyUwU](https://github.com/BoxyUwU) made their first contribution in [pydantic/pydantic-core#1379](https://github.com/pydantic/pydantic-core/pull/1379)\n* [@candleindark](https://github.com/candleindark) made their first contribution in [pydantic/pydantic-core#1404](https://github.com/pydantic/pydantic-core/pull/1404)\n* [@changhc](https://github.com/changhc) made their first contribution in [pydantic/pydantic-core#1331](https://github.com/pydantic/pydantic-core/pull/1331)\n\n## v2.9.0b2 (2024-08-30)\n\nPre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.9.0b2) for details.\n\n## v2.9.0b1 (2024-08-26)\n\nPre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.9.0b1) for details.\n\n## v2.8.2 (2024-07-03)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.8.2)\n\n### What's Changed\n\n#### Fixes\n\n* Fix issue with assertion caused by pluggable schema validator by [@dmontagu](https://github.com/dmontagu) in [#9838](https://github.com/pydantic/pydantic/pull/9838)\n\n## v2.8.1 (2024-07-03)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.8.1)\n\n### What's Changed\n\n#### Packaging\n* Bump `ruff` to `v0.5.0` and `pyright` to `v1.1.369` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9801](https://github.com/pydantic/pydantic/pull/9801)\n* Bump `pydantic-core` to `v2.20.1`, `pydantic-extra-types` to `v2.9.0` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9832](https://github.com/pydantic/pydantic/pull/9832)\n\n#### Fixes\n* Fix breaking change in `to_snake` from v2.7 -> v2.8 by [@sydney-runkle](https://github.com/sydney-runkle) in [#9812](https://github.com/pydantic/pydantic/pull/9812)\n* Fix list constraint json schema application by [@sydney-runkle](https://github.com/sydney-runkle) in [#9818](https://github.com/pydantic/pydantic/pull/9818)\n* Support time duration more than 23 by [@nix010](https://github.com/nix010) in [pydantic/speedate#64](https://github.com/pydantic/speedate/pull/64)\n* Fix millisecond fraction being handled with the wrong scale by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/speedate#65](https://github.com/pydantic/speedate/pull/65)\n* Handle negative fractional durations correctly by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/speedate#71](https://github.com/pydantic/speedate/pull/71)\n\n## v2.8.0 (2024-07-01)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.8.0)\n\nThe code released in v2.8.0 is functionally identical to that of v2.8.0b1.\n\n### What's Changed\n\n#### Packaging\n\n* Update citation version automatically with new releases by [@sydney-runkle](https://github.com/sydney-runkle) in [#9673](https://github.com/pydantic/pydantic/pull/9673)\n* Bump pyright to `v1.1.367` and add type checking tests for pipeline API by [@adriangb](https://github.com/adriangb) in [#9674](https://github.com/pydantic/pydantic/pull/9674)\n* Update `pydantic.v1` stub to `v1.10.17` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9707](https://github.com/pydantic/pydantic/pull/9707)\n* General package updates to prep for `v2.8.0b1` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9741](https://github.com/pydantic/pydantic/pull/9741)\n* Bump `pydantic-core` to `v2.20.0` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9745](https://github.com/pydantic/pydantic/pull/9745)\n* Add support for Python 3.13 by [@sydney-runkle](https://github.com/sydney-runkle) in [#9743](https://github.com/pydantic/pydantic/pull/9743)\n* Update `pdm` version used for `pdm.lock` to v2.16.1 by [@sydney-runkle](https://github.com/sydney-runkle) in [#9761](https://github.com/pydantic/pydantic/pull/9761)\n* Update to `ruff` `v0.4.8` by [@Viicos](https://github.com/Viicos) in [#9585](https://github.com/pydantic/pydantic/pull/9585)\n\n#### New Features\n\n* Experimental: support `defer_build` for `TypeAdapter` by [@MarkusSintonen](https://github.com/MarkusSintonen) in [#8939](https://github.com/pydantic/pydantic/pull/8939)\n* Implement `deprecated` field in json schema by [@NeevCohen](https://github.com/NeevCohen) in [#9298](https://github.com/pydantic/pydantic/pull/9298)\n* Experimental: Add pipeline API by [@adriangb](https://github.com/adriangb) in [#9459](https://github.com/pydantic/pydantic/pull/9459)\n* Add support for programmatic title generation by [@NeevCohen](https://github.com/NeevCohen) in [#9183](https://github.com/pydantic/pydantic/pull/9183)\n* Implement `fail_fast` feature by [@uriyyo](https://github.com/uriyyo) in [#9708](https://github.com/pydantic/pydantic/pull/9708)\n* Add `ser_json_inf_nan='strings'` mode to produce valid JSON by [@josh-newman](https://github.com/josh-newman) in [pydantic/pydantic-core#1307](https://github.com/pydantic/pydantic-core/pull/1307)\n\n#### Changes\n\n* Add warning when \"alias\" is set in ignored `Annotated` field by [@nix010](https://github.com/nix010) in [#9170](https://github.com/pydantic/pydantic/pull/9170)\n* Support serialization of some serializable defaults in JSON schema by [@sydney-runkle](https://github.com/sydney-runkle) in [#9624](https://github.com/pydantic/pydantic/pull/9624)\n* Relax type specification for `__validators__` values in `create_model` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9697](https://github.com/pydantic/pydantic/pull/9697)\n* **Breaking Change:** Improve `smart` union matching logic by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1322](https://github.com/pydantic/pydantic-core/pull/1322)\nYou can read more about our `smart` union matching logic [here](https://docs.pydantic.dev/dev/concepts/unions/#smart-mode). In some cases, if the old behavior\nis desired, you can switch to `left-to-right` mode and change the order of your `Union` members.\n\n#### Performance\n\n##### Internal Improvements\n\n* âš¡ï¸ Speed up `_display_error_loc()` by 25% in `pydantic/v1/error_wrappers.py` by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#9653](https://github.com/pydantic/pydantic/pull/9653)\n* âš¡ï¸ Speed up `_get_all_json_refs()` by 34% in `pydantic/json_schema.py` by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#9650](https://github.com/pydantic/pydantic/pull/9650)\n* âš¡ï¸ Speed up `is_pydantic_dataclass()` by 41% in `pydantic/dataclasses.py` by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#9652](https://github.com/pydantic/pydantic/pull/9652)\n* âš¡ï¸ Speed up `to_snake()` by 27% in `pydantic/alias_generators.py` by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#9747](https://github.com/pydantic/pydantic/pull/9747)\n* âš¡ï¸ Speed up `unwrap_wrapped_function()` by 93% in `pydantic/_internal/_decorators.py` by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#9727](https://github.com/pydantic/pydantic/pull/9727)\n\n#### Fixes\n\n* Replace `__spec__.parent` with `__package__` by [@hramezani](https://github.com/hramezani) in [#9331](https://github.com/pydantic/pydantic/pull/9331)\n* Fix Outputted Model JSON Schema for `Sequence` type by [@anesmemisevic](https://github.com/anesmemisevic) in [#9303](https://github.com/pydantic/pydantic/pull/9303)\n* Fix typing of `_frame_depth` by [@Viicos](https://github.com/Viicos) in [#9353](https://github.com/pydantic/pydantic/pull/9353)\n* Make `ImportString` json schema compatible by [@amitschang](https://github.com/amitschang) in [#9344](https://github.com/pydantic/pydantic/pull/9344)\n* Hide private attributes (`PrivateAttr`) from `__init__` signature in type checkers by [@idan22moral](https://github.com/idan22moral) in [#9293](https://github.com/pydantic/pydantic/pull/9293)\n* Make detection of `TypeVar` defaults robust to the CPython `PEP-696` implementation by [@AlexWaygood](https://github.com/AlexWaygood) in [#9426](https://github.com/pydantic/pydantic/pull/9426)\n* Fix usage of `PlainSerializer` with builtin types by [@Viicos](https://github.com/Viicos) in [#9450](https://github.com/pydantic/pydantic/pull/9450)\n* Add more robust custom validation examples by [@ChrisPappalardo](https://github.com/ChrisPappalardo) in [#9468](https://github.com/pydantic/pydantic/pull/9468)\n* Fix ignored `strict` specification for `StringConstraint(strict=False)` by [@vbmendes](https://github.com/vbmendes) in [#9476](https://github.com/pydantic/pydantic/pull/9476)\n* **Breaking Change:** Use PEP 570 syntax by [@Viicos](https://github.com/Viicos) in [#9479](https://github.com/pydantic/pydantic/pull/9479)\n* Use `Self` where possible by [@Viicos](https://github.com/Viicos) in [#9479](https://github.com/pydantic/pydantic/pull/9479)\n* Do not alter `RootModel.model_construct` signature in the `mypy` plugin by [@Viicos](https://github.com/Viicos) in [#9480](https://github.com/pydantic/pydantic/pull/9480)\n* Fixed type hint of `validation_context` by [@OhioDschungel6](https://github.com/OhioDschungel6) in [#9508](https://github.com/pydantic/pydantic/pull/9508)\n* Support context being passed to TypeAdapter's `dump_json`/`dump_python` by [@alexcouper](https://github.com/alexcouper) in [#9495](https://github.com/pydantic/pydantic/pull/9495)\n* Updates type signature for `Field()` constructor by [@bjmc](https://github.com/bjmc) in [#9484](https://github.com/pydantic/pydantic/pull/9484)\n* Improve builtin alias generators by [@sydney-runkle](https://github.com/sydney-runkle) in [#9561](https://github.com/pydantic/pydantic/pull/9561)\n* Fix typing of `TypeAdapter` by [@Viicos](https://github.com/Viicos) in [#9570](https://github.com/pydantic/pydantic/pull/9570)\n* Add fallback default value for private fields in `__setstate__` of BaseModel by [@anhpham1509](https://github.com/anhpham1509) in [#9584](https://github.com/pydantic/pydantic/pull/9584)\n* Support `PEP 746` by [@adriangb](https://github.com/adriangb) in [#9587](https://github.com/pydantic/pydantic/pull/9587)\n* Allow validator and serializer functions to have default values by [@Viicos](https://github.com/Viicos) in [#9478](https://github.com/pydantic/pydantic/pull/9478)\n* Fix bug with mypy plugin's handling of covariant `TypeVar` fields by [@dmontagu](https://github.com/dmontagu) in [#9606](https://github.com/pydantic/pydantic/pull/9606)\n* Fix multiple annotation / constraint application logic by [@sydney-runkle](https://github.com/sydney-runkle) in [#9623](https://github.com/pydantic/pydantic/pull/9623)\n* Respect `regex` flags in validation and json schema by [@sydney-runkle](https://github.com/sydney-runkle) in [#9591](https://github.com/pydantic/pydantic/pull/9591)\n* Fix type hint on `IpvAnyAddress` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9640](https://github.com/pydantic/pydantic/pull/9640)\n* Allow a field specifier on `__pydantic_extra__` by [@dmontagu](https://github.com/dmontagu) in [#9659](https://github.com/pydantic/pydantic/pull/9659)\n* Use normalized case for file path comparison by [@sydney-runkle](https://github.com/sydney-runkle) in [#9737](https://github.com/pydantic/pydantic/pull/9737)\n* Modify constraint application logic to allow field constraints on `Optional[Decimal]` by [@lazyhope](https://github.com/lazyhope) in [#9754](https://github.com/pydantic/pydantic/pull/9754)\n* `validate_call` type params fix by [@sydney-runkle](https://github.com/sydney-runkle) in [#9760](https://github.com/pydantic/pydantic/pull/9760)\n* Check all warnings returned by pytest.warns() by [@s-t-e-v-e-n-k](https://github.com/s-t-e-v-e-n-k) in [#9702](https://github.com/pydantic/pydantic/pull/9702)\n* Reuse `re.Pattern` object in regex patterns to allow for regex flags by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1318](https://github.com/pydantic/pydantic-core/pull/1318)\n\n### New Contributors\n\n* [@idan22moral](https://github.com/idan22moral) made their first contribution in [#9294](https://github.com/pydantic/pydantic/pull/9294)\n* [@anesmemisevic](https://github.com/anesmemisevic) made their first contribution in [#9303](https://github.com/pydantic/pydantic/pull/9303)\n* [@max-muoto](https://github.com/max-muoto) made their first contribution in [#9338](https://github.com/pydantic/pydantic/pull/9338)\n* [@amitschang](https://github.com/amitschang) made their first contribution in [#9344](https://github.com/pydantic/pydantic/pull/9344)\n* [@paulmartin91](https://github.com/paulmartin91) made their first contribution in [#9410](https://github.com/pydantic/pydantic/pull/9410)\n* [@OhioDschungel6](https://github.com/OhioDschungel6) made their first contribution in [#9405](https://github.com/pydantic/pydantic/pull/9405)\n* [@AlexWaygood](https://github.com/AlexWaygood) made their first contribution in [#9426](https://github.com/pydantic/pydantic/pull/9426)\n* [@kinuax](https://github.com/kinuax) made their first contribution in [#9433](https://github.com/pydantic/pydantic/pull/9433)\n* [@antoni-jamiolkowski](https://github.com/antoni-jamiolkowski) made their first contribution in [#9431](https://github.com/pydantic/pydantic/pull/9431)\n* [@candleindark](https://github.com/candleindark) made their first contribution in [#9448](https://github.com/pydantic/pydantic/pull/9448)\n* [@nix010](https://github.com/nix010) made their first contribution in [#9170](https://github.com/pydantic/pydantic/pull/9170)\n* [@tomy0000000](https://github.com/tomy0000000) made their first contribution in [#9457](https://github.com/pydantic/pydantic/pull/9457)\n* [@vbmendes](https://github.com/vbmendes) made their first contribution in [#9470](https://github.com/pydantic/pydantic/pull/9470)\n* [@micheleAlberto](https://github.com/micheleAlberto) made their first contribution in [#9471](https://github.com/pydantic/pydantic/pull/9471)\n* [@ChrisPappalardo](https://github.com/ChrisPappalardo) made their first contribution in [#9468](https://github.com/pydantic/pydantic/pull/9468)\n* [@blueTurtz](https://github.com/blueTurtz) made their first contribution in [#9475](https://github.com/pydantic/pydantic/pull/9475)\n* [@WinterBlue16](https://github.com/WinterBlue16) made their first contribution in [#9477](https://github.com/pydantic/pydantic/pull/9477)\n* [@bittner](https://github.com/bittner) made their first contribution in [#9500](https://github.com/pydantic/pydantic/pull/9500)\n* [@alexcouper](https://github.com/alexcouper) made their first contribution in [#9495](https://github.com/pydantic/pydantic/pull/9495)\n* [@bjmc](https://github.com/bjmc) made their first contribution in [#9484](https://github.com/pydantic/pydantic/pull/9484)\n* [@pjvv](https://github.com/pjvv) made their first contribution in [#9529](https://github.com/pydantic/pydantic/pull/9529)\n* [@nedbat](https://github.com/nedbat) made their first contribution in [#9530](https://github.com/pydantic/pydantic/pull/9530)\n* [@gunnellEvan](https://github.com/gunnellEvan) made their first contribution in [#9469](https://github.com/pydantic/pydantic/pull/9469)\n* [@jaymbans](https://github.com/jaymbans) made their first contribution in [#9531](https://github.com/pydantic/pydantic/pull/9531)\n* [@MarcBresson](https://github.com/MarcBresson) made their first contribution in [#9534](https://github.com/pydantic/pydantic/pull/9534)\n* [@anhpham1509](https://github.com/anhpham1509) made their first contribution in [#9584](https://github.com/pydantic/pydantic/pull/9584)\n* [@K-dash](https://github.com/K-dash) made their first contribution in [#9595](https://github.com/pydantic/pydantic/pull/9595)\n* [@s-t-e-v-e-n-k](https://github.com/s-t-e-v-e-n-k) made their first contribution in [#9527](https://github.com/pydantic/pydantic/pull/9527)\n* [@airwoodix](https://github.com/airwoodix) made their first contribution in [#9506](https://github.com/pydantic/pydantic/pull/9506)\n* [@misrasaurabh1](https://github.com/misrasaurabh1) made their first contribution in [#9653](https://github.com/pydantic/pydantic/pull/9653)\n* [@AlessandroMiola](https://github.com/AlessandroMiola) made their first contribution in [#9740](https://github.com/pydantic/pydantic/pull/9740)\n* [@mylapallilavanyaa](https://github.com/mylapallilavanyaa) made their first contribution in [#9746](https://github.com/pydantic/pydantic/pull/9746)\n* [@lazyhope](https://github.com/lazyhope) made their first contribution in [#9754](https://github.com/pydantic/pydantic/pull/9754)\n* [@YassinNouh21](https://github.com/YassinNouh21) made their first contribution in [#9759](https://github.com/pydantic/pydantic/pull/9759)\n\n## v2.8.0b1 (2024-06-27)\n\nPre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.8.0b1) for details.\n\n## v2.7.4 (2024-06-12)\n\n[Github release](https://github.com/pydantic/pydantic/releases/tag/v2.7.4)\n\n### What's Changed\n\n#### Packaging\n\n* Bump `pydantic.v1` to `v1.10.16` reference by [@sydney-runkle](https://github.com/sydney-runkle) in [#9639](https://github.com/pydantic/pydantic/pull/9639)\n\n#### Fixes\n\n* Specify `recursive_guard` as kwarg in `FutureRef._evaluate` by [@vfazio](https://github.com/vfazio) in [#9612](https://github.com/pydantic/pydantic/pull/9612)\n\n## v2.7.3 (2024-06-03)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.7.3)\n\n### What's Changed\n\n#### Packaging\n\n* Bump `pydantic-core` to `v2.18.4` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9550](https://github.com/pydantic/pydantic/pull/9550)\n\n#### Fixes\n\n* Fix u style unicode strings in python [@samuelcolvin](https://github.com/samuelcolvin) in [pydantic/jiter#110](https://github.com/pydantic/jiter/pull/110)\n\n## v2.7.2 (2024-05-28)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.7.2)\n\n### What's Changed\n\n#### Packaging\n\n* Bump `pydantic-core` to `v2.18.3` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9515](https://github.com/pydantic/pydantic/pull/9515)\n\n#### Fixes\n\n* Replace `__spec__.parent` with `__package__` by [@hramezani](https://github.com/hramezani) in [#9331](https://github.com/pydantic/pydantic/pull/9331)\n* Fix validation of `int`s with leading unary minus by [@RajatRajdeep](https://github.com/RajatRajdeep) in [pydantic/pydantic-core#1291](https://github.com/pydantic/pydantic-core/pull/1291)\n* Fix `str` subclass validation for enums by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1273](https://github.com/pydantic/pydantic-core/pull/1273)\n* Support `BigInt`s in `Literal`s and `Enum`s by [@samuelcolvin](https://github.com/samuelcolvin) in [pydantic/pydantic-core#1297](https://github.com/pydantic/pydantic-core/pull/1297)\n* Fix: uuid - allow `str` subclass as input by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/pydantic-core#1296](https://github.com/pydantic/pydantic-core/pull/1296)\n\n## v2.7.1 (2024-04-23)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.7.1)\n\n### What's Changed\n\n#### Packaging\n\n* Bump `pydantic-core` to `v2.18.2` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9307](https://github.com/pydantic/pydantic/pull/9307)\n\n#### New Features\n\n* Ftp and Websocket connection strings support by [@CherrySuryp](https://github.com/CherrySuryp) in [#9205](https://github.com/pydantic/pydantic/pull/9205)\n\n#### Changes\n\n* Use field description for RootModel schema description when there is `â€¦` by [@LouisGobert](https://github.com/LouisGobert) in [#9214](https://github.com/pydantic/pydantic/pull/9214)\n\n#### Fixes\n\n* Fix `validation_alias` behavior with `model_construct` for `AliasChoices` and `AliasPath` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9223](https://github.com/pydantic/pydantic/pull/9223)\n* Revert `typing.Literal` and import it outside the TYPE_CHECKING block by [@frost-nzcr4](https://github.com/frost-nzcr4) in [#9232](https://github.com/pydantic/pydantic/pull/9232)\n* Fix `Secret` serialization schema, applicable for unions by [@sydney-runkle](https://github.com/sydney-runkle) in [#9240](https://github.com/pydantic/pydantic/pull/9240)\n* Fix `strict` application to `function-after` with `use_enum_values` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9279](https://github.com/pydantic/pydantic/pull/9279)\n* Address case where `model_construct` on a class which defines `model_post_init` fails with `AttributeError` by [@babygrimes](https://github.com/babygrimes) in [#9168](https://github.com/pydantic/pydantic/pull/9168)\n* Fix `model_json_schema` with config types by [@NeevCohen](https://github.com/NeevCohen) in [#9287](https://github.com/pydantic/pydantic/pull/9287)\n* Support multiple zeros as an `int` by [@samuelcolvin](https://github.com/samuelcolvin) in [pydantic/pydantic-core#1269](https://github.com/pydantic/pydantic-core/pull/1269)\n* Fix validation of `int`s with leading unary plus by [@cknv](https://github.com/cknv) in [pydantic/pydantic-core#1272](https://github.com/pydantic/pydantic-core/pull/1272)\n* Fix interaction between `extra != 'ignore'` and `from_attributes=True` by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/pydantic-core#1276](https://github.com/pydantic/pydantic-core/pull/1276)\n* Handle error from `Enum`'s `missing` function as `ValidationError` by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1274](https://github.com/pydantic/pydantic-core/pull/1754)\n* Fix memory leak with `Iterable` validation by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/pydantic-core#1271](https://github.com/pydantic/pydantic-core/pull/1751)\n\n### New Contributors\n\n* [@zzstoatzz](https://github.com/zzstoatzz) made their first contribution in [#9219](https://github.com/pydantic/pydantic/pull/9219)\n* [@frost-nzcr4](https://github.com/frost-nzcr4) made their first contribution in [#9232](https://github.com/pydantic/pydantic/pull/9232)\n* [@CherrySuryp](https://github.com/CherrySuryp) made their first contribution in [#9205](https://github.com/pydantic/pydantic/pull/9205)\n* [@vagenas](https://github.com/vagenas) made their first contribution in [#9268](https://github.com/pydantic/pydantic/pull/9268)\n* [@ollz272](https://github.com/ollz272) made their first contribution in [#9262](https://github.com/pydantic/pydantic/pull/9262)\n* [@babygrimes](https://github.com/babygrimes) made their first contribution in [#9168](https://github.com/pydantic/pydantic/pull/9168)\n* [@swelborn](https://github.com/swelborn) made their first contribution in [#9296](https://github.com/pydantic/pydantic/pull/9296)\n* [@kf-novi](https://github.com/kf-novi) made their first contribution in [#9236](https://github.com/pydantic/pydantic/pull/9236)\n* [@lgeiger](https://github.com/lgeiger) made their first contribution in [#9288](https://github.com/pydantic/pydantic/pull/9288)\n\n## v2.7.0 (2024-04-11)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.7.0)\n\nThe code released in v2.7.0 is practically identical to that of v2.7.0b1.\n\n### What's Changed\n\n#### Packaging\n\n* Reorganize `pyproject.toml` sections by [@Viicos](https://github.com/Viicos) in [#8899](https://github.com/pydantic/pydantic/pull/8899)\n* Bump `pydantic-core` to `v2.18.1` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9211](https://github.com/pydantic/pydantic/pull/9211)\n* Adopt `jiter` `v0.2.0` by [@samuelcolvin](https://github.com/samuelcolvin) in [pydantic/pydantic-core#1250](https://github.com/pydantic/pydantic-core/pull/1250)\n\n#### New Features\n\n* Extract attribute docstrings from `FieldInfo.description` by [@Viicos](https://github.com/Viicos) in [#6563](https://github.com/pydantic/pydantic/pull/6563)\n* Add a `with_config` decorator to comply with typing spec by [@Viicos](https://github.com/Viicos) in [#8611](https://github.com/pydantic/pydantic/pull/8611)\n* Allow an optional separator splitting the value and unit of the result of `ByteSize.human_readable` by [@jks15satoshi](https://github.com/jks15satoshi) in [#8706](https://github.com/pydantic/pydantic/pull/8706)\n* Add generic `Secret` base type by [@conradogarciaberrotaran](https://github.com/conradogarciaberrotaran) in [#8519](https://github.com/pydantic/pydantic/pull/8519)\n* Make use of `Sphinx` inventories for cross references in docs by [@Viicos](https://github.com/Viicos) in [#8682](https://github.com/pydantic/pydantic/pull/8682)\n* Add environment variable to disable plugins by [@geospackle](https://github.com/geospackle) in [#8767](https://github.com/pydantic/pydantic/pull/8767)\n* Add support for `deprecated` fields by [@Viicos](https://github.com/Viicos) in [#8237](https://github.com/pydantic/pydantic/pull/8237)\n* Allow `field_serializer('*')` by [@ornariece](https://github.com/ornariece) in [#9001](https://github.com/pydantic/pydantic/pull/9001)\n* Handle a case when `model_config` is defined as a model property by [@alexeyt101](https://github.com/alexeyt101) in [#9004](https://github.com/pydantic/pydantic/pull/9004)\n* Update `create_model()` to support `typing.Annotated` as input by [@wannieman98](https://github.com/wannieman98) in [#8947](https://github.com/pydantic/pydantic/pull/8947)\n* Add `ClickhouseDsn` support by [@solidguy7](https://github.com/solidguy7) in [#9062](https://github.com/pydantic/pydantic/pull/9062)\n* Add support for `re.Pattern[str]` to `pattern` field by [@jag-k](https://github.com/jag-k) in [#9053](https://github.com/pydantic/pydantic/pull/9053)\n* Support for `serialize_as_any` runtime setting by [@sydney-runkle](https://github.com/sydney-runkle) in [#8830](https://github.com/pydantic/pydantic/pull/8830)\n* Add support for `typing.Self` by [@Youssefares](https://github.com/Youssefares) in [#9023](https://github.com/pydantic/pydantic/pull/9023)\n* Ability to pass `context` to serialization by [@ornariece](https://github.com/ornariece) in [#8965](https://github.com/pydantic/pydantic/pull/8965)\n* Add feedback widget to docs with flarelytics integration by [@sydney-runkle](https://github.com/sydney-runkle) in [#9129](https://github.com/pydantic/pydantic/pull/9129)\n* Support for parsing partial JSON strings in Python by [@samuelcolvin](https://github.com/samuelcolvin) in [pydantic/jiter#66](https://github.com/pydantic/jiter/pull/66)\n\n**Finalized in v2.7.0, rather than v2.7.0b1:**\n* Add support for field level number to str coercion option by [@NeevCohen](https://github.com/NeevCohen) in [#9137](https://github.com/pydantic/pydantic/pull/9137)\n* Update `warnings` parameter for serialization utilities to allow raising a warning by [@Lance-Drane](https://github.com/Lance-Drane) in [#9166](https://github.com/pydantic/pydantic/pull/9166)\n\n#### Changes\n\n* Correct docs, logic for `model_construct` behavior with `extra` by [@sydney-runkle](https://github.com/sydney-runkle) in [#8807](https://github.com/pydantic/pydantic/pull/8807)\n* Improve error message for improper `RootModel` subclasses by [@sydney-runkle](https://github.com/sydney-runkle) in [#8857](https://github.com/pydantic/pydantic/pull/8857)\n* **Breaking Change:** Use `PEP570` syntax by [@Viicos](https://github.com/Viicos) in [#8940](https://github.com/pydantic/pydantic/pull/8940)\n* Add `enum` and `type` to the JSON schema for single item literals by [@dmontagu](https://github.com/dmontagu) in [#8944](https://github.com/pydantic/pydantic/pull/8944)\n* Deprecate `update_json_schema` internal function by [@sydney-runkle](https://github.com/sydney-runkle) in [#9125](https://github.com/pydantic/pydantic/pull/9125)\n* Serialize duration to hour minute second, instead of just seconds by [@kakilangit](https://github.com/kakilangit) in [pydantic/speedate#50](https://github.com/pydantic/speedate/pull/50)\n* Trimming str before parsing to int and float by [@hungtsetse](https://github.com/hungtsetse) in [pydantic/pydantic-core#1203](https://github.com/pydantic/pydantic-core/pull/1203)\n\n#### Performance\n\n* `enum` validator improvements by [@samuelcolvin](https://github.com/samuelcolvin) in [#9045](https://github.com/pydantic/pydantic/pull/9045)\n* Move `enum` validation and serialization to Rust by [@samuelcolvin](https://github.com/samuelcolvin) in [#9064](https://github.com/pydantic/pydantic/pull/9064)\n* Improve schema generation for nested dataclasses by [@sydney-runkle](https://github.com/sydney-runkle) in [#9114](https://github.com/pydantic/pydantic/pull/9114)\n* Fast path for ASCII python string creation in JSON by [@samuelcolvin](https://github.com/samuelcolvin) in in [pydantic/jiter#72](https://github.com/pydantic/jiter/pull/72)\n* SIMD integer and string JSON parsing on `aarch64`(**Note:** SIMD on x86 will be implemented in a future release) by [@samuelcolvin](https://github.com/samuelcolvin) in in [pydantic/jiter#65](https://github.com/pydantic/jiter/pull/65)\n* Support JSON `Cow<str>` from `jiter` by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/pydantic-core#1231](https://github.com/pydantic/pydantic-core/pull/1231)\n* MAJOR performance improvement: update to PyO3 0.21 final by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/pydantic-core#1248](https://github.com/pydantic/pydantic-core/pull/1248)\n* cache Python strings by [@samuelcolvin](https://github.com/samuelcolvin) in [pydantic/pydantic-core#1240](https://github.com/pydantic/pydantic-core/pull/1240)\n\n#### Fixes\n\n* Fix strict parsing for some `Sequence`s by [@sydney-runkle](https://github.com/sydney-runkle) in [#8614](https://github.com/pydantic/pydantic/pull/8614)\n* Add a check on the existence of `__qualname__` by [@anci3ntr0ck](https://github.com/anci3ntr0ck) in [#8642](https://github.com/pydantic/pydantic/pull/8642)\n* Handle `__pydantic_extra__` annotation being a string or inherited by [@alexmojaki](https://github.com/alexmojaki) in [#8659](https://github.com/pydantic/pydantic/pull/8659)\n* Fix json validation for `NameEmail` by [@Holi0317](https://github.com/Holi0317) in [#8650](https://github.com/pydantic/pydantic/pull/8650)\n* Fix type-safety of attribute access in `BaseModel` by [@bluenote10](https://github.com/bluenote10) in [#8651](https://github.com/pydantic/pydantic/pull/8651)\n* Fix bug with `mypy` plugin and `no_strict_optional = True` by [@dmontagu](https://github.com/dmontagu) in [#8666](https://github.com/pydantic/pydantic/pull/8666)\n* Fix `ByteSize` error `type` change by [@sydney-runkle](https://github.com/sydney-runkle) in [#8681](https://github.com/pydantic/pydantic/pull/8681)\n* Fix inheriting annotations in dataclasses by [@sydney-runkle](https://github.com/sydney-runkle) in [#8679](https://github.com/pydantic/pydantic/pull/8679)\n* Fix regression in core schema generation for indirect definition references by [@dmontagu](https://github.com/dmontagu) in [#8702](https://github.com/pydantic/pydantic/pull/8702)\n* Fix unsupported types bug with plain validator by [@sydney-runkle](https://github.com/sydney-runkle) in [#8710](https://github.com/pydantic/pydantic/pull/8710)\n* Reverting problematic fix from 2.6 release, fixing schema building bug by [@sydney-runkle](https://github.com/sydney-runkle) in [#8718](https://github.com/pydantic/pydantic/pull/8718)\n* fixes `__pydantic_config__` ignored for TypeDict by [@13sin](https://github.com/13sin) in [#8734](https://github.com/pydantic/pydantic/pull/8734)\n* Fix test failures with `pytest v8.0.0` due to `pytest.warns()` starting to work inside `pytest.raises()` by [@mgorny](https://github.com/mgorny) in [#8678](https://github.com/pydantic/pydantic/pull/8678)\n* Use `is_valid_field` from 1.x for `mypy` plugin by [@DanielNoord](https://github.com/DanielNoord) in [#8738](https://github.com/pydantic/pydantic/pull/8738)\n* Better-support `mypy` strict equality flag by [@dmontagu](https://github.com/dmontagu) in [#8799](https://github.com/pydantic/pydantic/pull/8799)\n* model_json_schema export with Annotated types misses 'required' parameters by [@LouisGobert](https://github.com/LouisGobert) in [#8793](https://github.com/pydantic/pydantic/pull/8793)\n* Fix default inclusion in `FieldInfo.__repr_args__` by [@sydney-runkle](https://github.com/sydney-runkle) in [#8801](https://github.com/pydantic/pydantic/pull/8801)\n* Fix resolution of forward refs in dataclass base classes that are not present in the subclass module namespace by [@matsjoyce-refeyn](https://github.com/matsjoyce-refeyn) in [#8751](https://github.com/pydantic/pydantic/pull/8751)\n* Fix `BaseModel` type annotations to be resolvable by `typing.get_type_hints` by [@devmonkey22](https://github.com/devmonkey22) in [#7680](https://github.com/pydantic/pydantic/pull/7680)\n* Fix: allow empty string aliases with `AliasGenerator` by [@sydney-runkle](https://github.com/sydney-runkle) in [#8810](https://github.com/pydantic/pydantic/pull/8810)\n* Fix test along with `date` -> `datetime` timezone assumption fix by [@sydney-runkle](https://github.com/sydney-runkle) in [#8823](https://github.com/pydantic/pydantic/pull/8823)\n* Fix deprecation warning with usage of `ast.Str` by [@Viicos](https://github.com/Viicos) in [#8837](https://github.com/pydantic/pydantic/pull/8837)\n* Add missing `deprecated` decorators by [@Viicos](https://github.com/Viicos) in [#8877](https://github.com/pydantic/pydantic/pull/8877)\n* Fix serialization of `NameEmail` if name includes an email address by [@NeevCohen](https://github.com/NeevCohen) in [#8860](https://github.com/pydantic/pydantic/pull/8860)\n* Add information about class in error message of schema generation by [@Czaki](https://github.com/Czaki) in [#8917](https://github.com/pydantic/pydantic/pull/8917)\n* Make `TypeAdapter`'s typing compatible with special forms by [@adriangb](https://github.com/adriangb) in [#8923](https://github.com/pydantic/pydantic/pull/8923)\n* Fix issue with config behavior being baked into the ref schema for `enum`s by [@dmontagu](https://github.com/dmontagu) in [#8920](https://github.com/pydantic/pydantic/pull/8920)\n* More helpful error re wrong `model_json_schema` usage by [@sydney-runkle](https://github.com/sydney-runkle) in [#8928](https://github.com/pydantic/pydantic/pull/8928)\n* Fix nested discriminated union schema gen, pt 2 by [@sydney-runkle](https://github.com/sydney-runkle) in [#8932](https://github.com/pydantic/pydantic/pull/8932)\n* Fix schema build for nested dataclasses / TypedDicts with discriminators by [@sydney-runkle](https://github.com/sydney-runkle) in [#8950](https://github.com/pydantic/pydantic/pull/8950)\n* Remove unnecessary logic for definitions schema gen with discriminated unions by [@sydney-runkle](https://github.com/sydney-runkle) in [#8951](https://github.com/pydantic/pydantic/pull/8951)\n* Fix handling of optionals in `mypy` plugin by [@dmontagu](https://github.com/dmontagu) in [#9008](https://github.com/pydantic/pydantic/pull/9008)\n* Fix `PlainSerializer` usage with std type constructor by [@sydney-runkle](https://github.com/sydney-runkle) in [#9031](https://github.com/pydantic/pydantic/pull/9031)\n* Remove unnecessary warning for config in plugin by [@dmontagu](https://github.com/dmontagu) in [#9039](https://github.com/pydantic/pydantic/pull/9039)\n* Fix default value serializing by [@NeevCohen](https://github.com/NeevCohen) in [#9066](https://github.com/pydantic/pydantic/pull/9066)\n* Fix extra fields check in `Model.__getattr__()` by [@NeevCohen](https://github.com/NeevCohen) in [#9082](https://github.com/pydantic/pydantic/pull/9082)\n* Fix `ClassVar` forward ref inherited from parent class by [@alexmojaki](https://github.com/alexmojaki) in [#9097](https://github.com/pydantic/pydantic/pull/9097)\n* fix sequence like validator with strict `True` by [@andresliszt](https://github.com/andresliszt) in [#8977](https://github.com/pydantic/pydantic/pull/8977)\n* Improve warning message when a field name shadows a field in a parent model by [@chan-vince](https://github.com/chan-vince) in [#9105](https://github.com/pydantic/pydantic/pull/9105)\n* Do not warn about shadowed fields if they are not redefined in a child class by [@chan-vince](https://github.com/chan-vince) in [#9111](https://github.com/pydantic/pydantic/pull/9111)\n* Fix discriminated union bug with unsubstituted type var by [@sydney-runkle](https://github.com/sydney-runkle) in [#9124](https://github.com/pydantic/pydantic/pull/9124)\n* Support serialization of `deque` when passed to `Sequence[blah blah blah]` by [@sydney-runkle](https://github.com/sydney-runkle) in [#9128](https://github.com/pydantic/pydantic/pull/9128)\n* Init private attributes from super-types in `model_post_init` by [@Viicos](https://github.com/Viicos) in [#9134](https://github.com/pydantic/pydantic/pull/9134)\n* fix `model_construct` with `validation_alias` by [@ornariece](https://github.com/ornariece) in [#9144](https://github.com/pydantic/pydantic/pull/9144)\n* Ensure json-schema generator handles `Literal` `null` types by [@bruno-f-cruz](https://github.com/bruno-f-cruz) in [#9135](https://github.com/pydantic/pydantic/pull/9135)\n* **Fixed in v2.7.0**: Fix allow extra generic by [@dmontagu](https://github.com/dmontagu) in [#9193](https://github.com/pydantic/pydantic/pull/9193)\n\n### New Contributors\n\n* [@hungtsetse](https://github.com/hungtsetse) made their first contribution in [#8546](https://github.com/pydantic/pydantic/pull/8546)\n* [@StrawHatDrag0n](https://github.com/StrawHatDrag0n) made their first contribution in [#8583](https://github.com/pydantic/pydantic/pull/8583)\n* [@anci3ntr0ck](https://github.com/anci3ntr0ck) made their first contribution in [#8642](https://github.com/pydantic/pydantic/pull/8642)\n* [@Holi0317](https://github.com/Holi0317) made their first contribution in [#8650](https://github.com/pydantic/pydantic/pull/8650)\n* [@bluenote10](https://github.com/bluenote10) made their first contribution in [#8651](https://github.com/pydantic/pydantic/pull/8651)\n* [@ADSteele916](https://github.com/ADSteele916) made their first contribution in [#8703](https://github.com/pydantic/pydantic/pull/8703)\n* [@musicinmybrain](https://github.com/musicinmybrain) made their first contribution in [#8731](https://github.com/pydantic/pydantic/pull/8731)\n* [@jks15satoshi](https://github.com/jks15satoshi) made their first contribution in [#8706](https://github.com/pydantic/pydantic/pull/8706)\n* [@13sin](https://github.com/13sin) made their first contribution in [#8734](https://github.com/pydantic/pydantic/pull/8734)\n* [@DanielNoord](https://github.com/DanielNoord) made their first contribution in [#8738](https://github.com/pydantic/pydantic/pull/8738)\n* [@conradogarciaberrotaran](https://github.com/conradogarciaberrotaran) made their first contribution in [#8519](https://github.com/pydantic/pydantic/pull/8519)\n* [@chris-griffin](https://github.com/chris-griffin) made their first contribution in [#8775](https://github.com/pydantic/pydantic/pull/8775)\n* [@LouisGobert](https://github.com/LouisGobert) made their first contribution in [#8793](https://github.com/pydantic/pydantic/pull/8793)\n* [@matsjoyce-refeyn](https://github.com/matsjoyce-refeyn) made their first contribution in [#8751](https://github.com/pydantic/pydantic/pull/8751)\n* [@devmonkey22](https://github.com/devmonkey22) made their first contribution in [#7680](https://github.com/pydantic/pydantic/pull/7680)\n* [@adamency](https://github.com/adamency) made their first contribution in [#8847](https://github.com/pydantic/pydantic/pull/8847)\n* [@MamfTheKramf](https://github.com/MamfTheKramf) made their first contribution in [#8851](https://github.com/pydantic/pydantic/pull/8851)\n* [@ornariece](https://github.com/ornariece) made their first contribution in [#9001](https://github.com/pydantic/pydantic/pull/9001)\n* [@alexeyt101](https://github.com/alexeyt101) made their first contribution in [#9004](https://github.com/pydantic/pydantic/pull/9004)\n* [@wannieman98](https://github.com/wannieman98) made their first contribution in [#8947](https://github.com/pydantic/pydantic/pull/8947)\n* [@solidguy7](https://github.com/solidguy7) made their first contribution in [#9062](https://github.com/pydantic/pydantic/pull/9062)\n* [@kloczek](https://github.com/kloczek) made their first contribution in [#9047](https://github.com/pydantic/pydantic/pull/9047)\n* [@jag-k](https://github.com/jag-k) made their first contribution in [#9053](https://github.com/pydantic/pydantic/pull/9053)\n* [@priya-gitTest](https://github.com/priya-gitTest) made their first contribution in [#9088](https://github.com/pydantic/pydantic/pull/9088)\n* [@Youssefares](https://github.com/Youssefares) made their first contribution in [#9023](https://github.com/pydantic/pydantic/pull/9023)\n* [@chan-vince](https://github.com/chan-vince) made their first contribution in [#9105](https://github.com/pydantic/pydantic/pull/9105)\n* [@bruno-f-cruz](https://github.com/bruno-f-cruz) made their first contribution in [#9135](https://github.com/pydantic/pydantic/pull/9135)\n* [@Lance-Drane](https://github.com/Lance-Drane) made their first contribution in [#9166](https://github.com/pydantic/pydantic/pull/9166)\n\n## v2.7.0b1 (2024-04-03)\n\nPre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.7.0b1) for details.\n\n## v2.6.4 (2024-03-12)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.6.4)\n\n### What's Changed\n\n#### Fixes\n\n* Fix usage of `AliasGenerator` with `computed_field` decorator by [@sydney-runkle](https://github.com/sydney-runkle) in [#8806](https://github.com/pydantic/pydantic/pull/8806)\n* Fix nested discriminated union schema gen, pt 2 by [@sydney-runkle](https://github.com/sydney-runkle) in [#8932](https://github.com/pydantic/pydantic/pull/8932)\n* Fix bug with no_strict_optional=True caused by API deferral by [@dmontagu](https://github.com/dmontagu) in [#8826](https://github.com/pydantic/pydantic/pull/8826)\n\n\n## v2.6.3 (2024-02-27)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.6.3)\n\n### What's Changed\n\n#### Packaging\n\n* Update `pydantic-settings` version in the docs by [@hramezani](https://github.com/hramezani) in [#8906](https://github.com/pydantic/pydantic/pull/8906)\n\n#### Fixes\n\n* Fix discriminated union schema gen bug by [@sydney-runkle](https://github.com/sydney-runkle) in [#8904](https://github.com/pydantic/pydantic/pull/8904)\n\n\n## v2.6.2 (2024-02-23)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.6.2)\n\n### What's Changed\n\n#### Packaging\n\n* Upgrade to `pydantic-core` 2.16.3 by [@sydney-runkle](https://github.com/sydney-runkle) in [#8879](https://github.com/pydantic/pydantic/pull/8879)\n\n#### Fixes\n\n* 'YYYY-MM-DD' date string coerced to datetime shouldn't infer timezone by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1193](https://github.com/pydantic/pydantic-core/pull/1193)\n\n\n## v2.6.1 (2024-02-05)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.6.1)\n\n### What's Changed\n\n#### Packaging\n\n* Upgrade to `pydantic-core` 2.16.2 by [@sydney-runkle](https://github.com/sydney-runkle) in [#8717](https://github.com/pydantic/pydantic/pull/8717)\n\n#### Fixes\n\n* Fix bug with `mypy` plugin and `no_strict_optional = True` by [@dmontagu](https://github.com/dmontagu) in [#8666](https://github.com/pydantic/pydantic/pull/8666)\n* Fix `ByteSize` error `type` change by [@sydney-runkle](https://github.com/sydney-runkle) in [#8681](https://github.com/pydantic/pydantic/pull/8681)\n* Fix inheriting `Field` annotations in dataclasses by [@sydney-runkle](https://github.com/sydney-runkle) in [#8679](https://github.com/pydantic/pydantic/pull/8679)\n* Fix regression in core schema generation for indirect definition references by [@dmontagu](https://github.com/dmontagu) in [#8702](https://github.com/pydantic/pydantic/pull/8702)\n* Fix unsupported types bug with `PlainValidator` by [@sydney-runkle](https://github.com/sydney-runkle) in [#8710](https://github.com/pydantic/pydantic/pull/8710)\n* Reverting problematic fix from 2.6 release, fixing schema building bug by [@sydney-runkle](https://github.com/sydney-runkle) in [#8718](https://github.com/pydantic/pydantic/pull/8718)\n* Fix warning for tuple of wrong size in `Union` by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/pydantic-core#1174](https://github.com/pydantic/pydantic-core/pull/1174)\n* Fix `computed_field` JSON serializer `exclude_none` behavior by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1187](https://github.com/pydantic/pydantic-core/pull/1187)\n\n\n## v2.6.0 (2024-01-23)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.6.0)\n\nThe code released in v2.6.0 is practically identical to that of v2.6.0b1.\n\n### What's Changed\n\n#### Packaging\n\n* Check for `email-validator` version >= 2.0 by [@commonism](https://github.com/commonism) in [#6033](https://github.com/pydantic/pydantic/pull/6033)\n* Upgrade `ruff`` target version to Python 3.8 by [@Elkiwa](https://github.com/Elkiwa) in [#8341](https://github.com/pydantic/pydantic/pull/8341)\n* Update to `pydantic-extra-types==2.4.1` by [@yezz123](https://github.com/yezz123) in [#8478](https://github.com/pydantic/pydantic/pull/8478)\n* Update to `pyright==1.1.345` by [@Viicos](https://github.com/Viicos) in [#8453](https://github.com/pydantic/pydantic/pull/8453)\n* Update pydantic-core from 2.14.6 to 2.16.1, significant changes from these updates are described below, full changelog [here](https://github.com/pydantic/pydantic-core/compare/v2.14.6...v2.16.1)\n\n#### New Features\n\n* Add `NatsDsn` by [@ekeew](https://github.com/ekeew) in [#6874](https://github.com/pydantic/pydantic/pull/6874)\n* Add `ConfigDict.ser_json_inf_nan` by [@davidhewitt](https://github.com/davidhewitt) in [#8159](https://github.com/pydantic/pydantic/pull/8159)\n* Add `types.OnErrorOmit` by [@adriangb](https://github.com/adriangb) in [#8222](https://github.com/pydantic/pydantic/pull/8222)\n* Support `AliasGenerator` usage by [@sydney-runkle](https://github.com/sydney-runkle) in [#8282](https://github.com/pydantic/pydantic/pull/8282)\n* Add Pydantic People Page to docs by [@sydney-runkle](https://github.com/sydney-runkle) in [#8345](https://github.com/pydantic/pydantic/pull/8345)\n* Support `yyyy-MM-DD` datetime parsing by [@sydney-runkle](https://github.com/sydney-runkle) in [#8404](https://github.com/pydantic/pydantic/pull/8404)\n* Added bits conversions to the `ByteSize` class [#8415](https://github.com/pydantic/pydantic/issues/8415) by [@luca-matei](https://github.com/luca-matei) in [#8507](https://github.com/pydantic/pydantic/pull/8507)\n* Enable json schema creation with type `ByteSize` by [@geospackle](https://github.com/geospackle) in [#8537](https://github.com/pydantic/pydantic/pull/8537)\n* Add `eval_type_backport` to handle union operator and builtin generic subscripting in older Pythons by [@alexmojaki](https://github.com/alexmojaki) in [#8209](https://github.com/pydantic/pydantic/pull/8209)\n* Add support for `dataclass` fields `init` by [@dmontagu](https://github.com/dmontagu) in [#8552](https://github.com/pydantic/pydantic/pull/8552)\n* Implement pickling for `ValidationError` by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/pydantic-core#1119](https://github.com/pydantic/pydantic-core/pull/1119)\n* Add unified tuple validator that can handle \"variadic\" tuples via PEP-646 by [@dmontagu](https://github.com/dmontagu) in [pydantic/pydantic-core#865](https://github.com/pydantic/pydantic-core/pull/865)\n\n#### Changes\n\n* Drop Python3.7 support by [@hramezani](https://github.com/hramezani) in [#7188](https://github.com/pydantic/pydantic/pull/7188)\n* Drop Python 3.7, and PyPy 3.7 and 3.8 by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/pydantic-core#1129](https://github.com/pydantic/pydantic-core/pull/1129)\n* Use positional-only `self` in `BaseModel` constructor, so no field name can ever conflict with it by [@ariebovenberg](https://github.com/ariebovenberg) in [#8072](https://github.com/pydantic/pydantic/pull/8072)\n* Make `@validate_call` return a function instead of a custom descriptor - fixes binding issue with inheritance and adds `self/cls` argument to validation errors by [@alexmojaki](https://github.com/alexmojaki) in [#8268](https://github.com/pydantic/pydantic/pull/8268)\n* Exclude `BaseModel` docstring from JSON schema description by [@sydney-runkle](https://github.com/sydney-runkle) in [#8352](https://github.com/pydantic/pydantic/pull/8352)\n* Introducing `classproperty` decorator for `model_computed_fields` by [@Jocelyn-Gas](https://github.com/Jocelyn-Gas) in [#8437](https://github.com/pydantic/pydantic/pull/8437)\n* Explicitly raise an error if field names clashes with types by [@Viicos](https://github.com/Viicos) in [#8243](https://github.com/pydantic/pydantic/pull/8243)\n* Use stricter serializer for unions of simple types by [@alexdrydew](https://github.com/alexdrydew) [pydantic/pydantic-core#1132](https://github.com/pydantic/pydantic-core/pull/1132)\n\n#### Performance\n\n* Add Codspeed profiling Actions workflow  by [@lambertsbennett](https://github.com/lambertsbennett) in [#8054](https://github.com/pydantic/pydantic/pull/8054)\n* Improve `int` extraction by [@samuelcolvin](https://github.com/samuelcolvin) in [pydantic/pydantic-core#1155](https://github.com/pydantic/pydantic-core/pull/1155)\n* Improve performance of recursion guard by [@samuelcolvin](https://github.com/samuelcolvin) in [pydantic/pydantic-core#1156](https://github.com/pydantic/pydantic-core/pull/1156)\n* `dataclass` serialization speedups by [@samuelcolvin](https://github.com/samuelcolvin) in [pydantic/pydantic-core#1162](https://github.com/pydantic/pydantic-core/pull/1162)\n* Avoid `HashMap` creation when looking up small JSON objects in `LazyIndexMaps` by [@samuelcolvin](https://github.com/samuelcolvin) in [pydantic/jiter#55](https://github.com/pydantic/jiter/pull/55)\n* use hashbrown to speedup python string caching by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/jiter#51](https://github.com/pydantic/jiter/pull/51)\n* Replace `Peak` with more efficient `Peek` by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/jiter#48](https://github.com/pydantic/jiter/pull/48)\n\n#### Fixes\n\n* Move `getattr` warning in deprecated `BaseConfig` by [@tlambert03](https://github.com/tlambert03) in [#7183](https://github.com/pydantic/pydantic/pull/7183)\n* Only hash `model_fields`, not whole `__dict__` by [@alexmojaki](https://github.com/alexmojaki) in [#7786](https://github.com/pydantic/pydantic/pull/7786)\n* Fix mishandling of unions while freezing types in the `mypy` plugin by [@dmontagu](https://github.com/dmontagu) in [#7411](https://github.com/pydantic/pydantic/pull/7411)\n* Fix `mypy` error on untyped `ClassVar` by [@vincent-hachin-wmx](https://github.com/vincent-hachin-wmx) in [#8138](https://github.com/pydantic/pydantic/pull/8138)\n* Only compare pydantic fields in `BaseModel.__eq__` instead of whole `__dict__` by [@QuentinSoubeyranAqemia](https://github.com/QuentinSoubeyranAqemia) in [#7825](https://github.com/pydantic/pydantic/pull/7825)\n* Update `strict` docstring in `model_validate` method. by [@LukeTonin](https://github.com/LukeTonin) in [#8223](https://github.com/pydantic/pydantic/pull/8223)\n* Fix overload position of `computed_field` by [@Viicos](https://github.com/Viicos) in [#8227](https://github.com/pydantic/pydantic/pull/8227)\n* Fix custom type type casting used in multiple attributes by [@ianhfc](https://github.com/ianhfc) in [#8066](https://github.com/pydantic/pydantic/pull/8066)\n* Fix issue not allowing `validate_call` decorator to be dynamically assigned to a class method by [@jusexton](https://github.com/jusexton) in [#8249](https://github.com/pydantic/pydantic/pull/8249)\n* Fix issue `unittest.mock` deprecation warnings  by [@ibleedicare](https://github.com/ibleedicare) in [#8262](https://github.com/pydantic/pydantic/pull/8262)\n* Added tests for the case `JsonValue` contains subclassed primitive values by [@jusexton](https://github.com/jusexton) in [#8286](https://github.com/pydantic/pydantic/pull/8286)\n* Fix `mypy` error on free before validator (classmethod) by [@sydney-runkle](https://github.com/sydney-runkle) in [#8285](https://github.com/pydantic/pydantic/pull/8285)\n* Fix `to_snake` conversion by [@jevins09](https://github.com/jevins09) in [#8316](https://github.com/pydantic/pydantic/pull/8316)\n* Fix type annotation of `ModelMetaclass.__prepare__` by [@slanzmich](https://github.com/slanzmich) in [#8305](https://github.com/pydantic/pydantic/pull/8305)\n* Disallow `config` specification when initializing a `TypeAdapter` when the annotated type has config already by [@sydney-runkle](https://github.com/sydney-runkle) in [#8365](https://github.com/pydantic/pydantic/pull/8365)\n* Fix a naming issue with JSON schema for generics parametrized by recursive type aliases by [@dmontagu](https://github.com/dmontagu) in [#8389](https://github.com/pydantic/pydantic/pull/8389)\n* Fix type annotation in pydantic people script by [@shenxiangzhuang](https://github.com/shenxiangzhuang) in [#8402](https://github.com/pydantic/pydantic/pull/8402)\n* Add support for field `alias` in `dataclass` signature by [@NeevCohen](https://github.com/NeevCohen) in [#8387](https://github.com/pydantic/pydantic/pull/8387)\n* Fix bug with schema generation with `Field(...)` in a forward ref by [@dmontagu](https://github.com/dmontagu) in [#8494](https://github.com/pydantic/pydantic/pull/8494)\n* Fix ordering of keys in `__dict__` with `model_construct` call by [@sydney-runkle](https://github.com/sydney-runkle) in [#8500](https://github.com/pydantic/pydantic/pull/8500)\n* Fix module `path_type` creation when globals does not contain `__name__` by [@hramezani](https://github.com/hramezani) in [#8470](https://github.com/pydantic/pydantic/pull/8470)\n* Fix for namespace issue with dataclasses with `from __future__ import annotations` by [@sydney-runkle](https://github.com/sydney-runkle) in [#8513](https://github.com/pydantic/pydantic/pull/8513)\n* Fix: make function validator types positional-only by [@pmmmwh](https://github.com/pmmmwh) in [#8479](https://github.com/pydantic/pydantic/pull/8479)\n* Fix usage of `@deprecated` by [@Viicos](https://github.com/Viicos) in [#8294](https://github.com/pydantic/pydantic/pull/8294)\n* Add more support for private attributes in `model_construct` call by [@sydney-runkle](https://github.com/sydney-runkle) in [#8525](https://github.com/pydantic/pydantic/pull/8525)\n* Use a stack for the types namespace by [@dmontagu](https://github.com/dmontagu) in [#8378](https://github.com/pydantic/pydantic/pull/8378)\n* Fix schema-building bug with `TypeAliasType` for types with refs by [@dmontagu](https://github.com/dmontagu) in [#8526](https://github.com/pydantic/pydantic/pull/8526)\n* Support `pydantic.Field(repr=False)` in dataclasses by [@tigeryy2](https://github.com/tigeryy2) in [#8511](https://github.com/pydantic/pydantic/pull/8511)\n* Override `dataclass_transform` behavior for `RootModel` by [@Viicos](https://github.com/Viicos) in [#8163](https://github.com/pydantic/pydantic/pull/8163)\n* Refactor signature generation for simplicity by [@sydney-runkle](https://github.com/sydney-runkle) in [#8572](https://github.com/pydantic/pydantic/pull/8572)\n* Fix ordering bug of PlainValidator annotation by [@Anvil](https://github.com/Anvil) in [#8567](https://github.com/pydantic/pydantic/pull/8567)\n* Fix `exclude_none` for json serialization of `computed_field`s by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1098](https://github.com/pydantic/pydantic-core/pull/1098)\n* Support yyyy-MM-DD string for datetimes by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1124](https://github.com/pydantic/pydantic-core/pull/1124)\n* Tweak ordering of definitions in generated schemas by [@StrawHatDrag0n](https://github.com/StrawHatDrag0n) in [#8583](https://github.com/pydantic/pydantic/pull/8583)\n\n\n### New Contributors\n\n#### `pydantic`\n* [@ekeew](https://github.com/ekeew) made their first contribution in [#6874](https://github.com/pydantic/pydantic/pull/6874)\n* [@lambertsbennett](https://github.com/lambertsbennett) made their first contribution in [#8054](https://github.com/pydantic/pydantic/pull/8054)\n* [@vincent-hachin-wmx](https://github.com/vincent-hachin-wmx) made their first contribution in [#8138](https://github.com/pydantic/pydantic/pull/8138)\n* [@QuentinSoubeyranAqemia](https://github.com/QuentinSoubeyranAqemia) made their first contribution in [#7825](https://github.com/pydantic/pydantic/pull/7825)\n* [@ariebovenberg](https://github.com/ariebovenberg) made their first contribution in [#8072](https://github.com/pydantic/pydantic/pull/8072)\n* [@LukeTonin](https://github.com/LukeTonin) made their first contribution in [#8223](https://github.com/pydantic/pydantic/pull/8223)\n* [@denisart](https://github.com/denisart) made their first contribution in [#8231](https://github.com/pydantic/pydantic/pull/8231)\n* [@ianhfc](https://github.com/ianhfc) made their first contribution in [#8066](https://github.com/pydantic/pydantic/pull/8066)\n* [@eonu](https://github.com/eonu) made their first contribution in [#8255](https://github.com/pydantic/pydantic/pull/8255)\n* [@amandahla](https://github.com/amandahla) made their first contribution in [#8263](https://github.com/pydantic/pydantic/pull/8263)\n* [@ibleedicare](https://github.com/ibleedicare) made their first contribution in [#8262](https://github.com/pydantic/pydantic/pull/8262)\n* [@jevins09](https://github.com/jevins09) made their first contribution in [#8316](https://github.com/pydantic/pydantic/pull/8316)\n* [@cuu508](https://github.com/cuu508) made their first contribution in [#8322](https://github.com/pydantic/pydantic/pull/8322)\n* [@slanzmich](https://github.com/slanzmich) made their first contribution in [#8305](https://github.com/pydantic/pydantic/pull/8305)\n* [@jensenbox](https://github.com/jensenbox) made their first contribution in [#8331](https://github.com/pydantic/pydantic/pull/8331)\n* [@szepeviktor](https://github.com/szepeviktor) made their first contribution in [#8356](https://github.com/pydantic/pydantic/pull/8356)\n* [@Elkiwa](https://github.com/Elkiwa) made their first contribution in [#8341](https://github.com/pydantic/pydantic/pull/8341)\n* [@parhamfh](https://github.com/parhamfh) made their first contribution in [#8395](https://github.com/pydantic/pydantic/pull/8395)\n* [@shenxiangzhuang](https://github.com/shenxiangzhuang) made their first contribution in [#8402](https://github.com/pydantic/pydantic/pull/8402)\n* [@NeevCohen](https://github.com/NeevCohen) made their first contribution in [#8387](https://github.com/pydantic/pydantic/pull/8387)\n* [@zby](https://github.com/zby) made their first contribution in [#8497](https://github.com/pydantic/pydantic/pull/8497)\n* [@patelnets](https://github.com/patelnets) made their first contribution in [#8491](https://github.com/pydantic/pydantic/pull/8491)\n* [@edwardwli](https://github.com/edwardwli) made their first contribution in [#8503](https://github.com/pydantic/pydantic/pull/8503)\n* [@luca-matei](https://github.com/luca-matei) made their first contribution in [#8507](https://github.com/pydantic/pydantic/pull/8507)\n* [@Jocelyn-Gas](https://github.com/Jocelyn-Gas) made their first contribution in [#8437](https://github.com/pydantic/pydantic/pull/8437)\n* [@bL34cHig0](https://github.com/bL34cHig0) made their first contribution in [#8501](https://github.com/pydantic/pydantic/pull/8501)\n* [@tigeryy2](https://github.com/tigeryy2) made their first contribution in [#8511](https://github.com/pydantic/pydantic/pull/8511)\n* [@geospackle](https://github.com/geospackle) made their first contribution in [#8537](https://github.com/pydantic/pydantic/pull/8537)\n* [@Anvil](https://github.com/Anvil) made their first contribution in [#8567](https://github.com/pydantic/pydantic/pull/8567)\n* [@hungtsetse](https://github.com/hungtsetse) made their first contribution in [#8546](https://github.com/pydantic/pydantic/pull/8546)\n* [@StrawHatDrag0n](https://github.com/StrawHatDrag0n) made their first contribution in [#8583](https://github.com/pydantic/pydantic/pull/8583)\n\n#### `pydantic-core`\n* [@mariuswinger](https://github.com/mariuswinger) made their first contribution in [pydantic/pydantic-core#1087](https://github.com/pydantic/pydantic-core/pull/1087)\n* [@adamchainz](https://github.com/adamchainz) made their first contribution in [pydantic/pydantic-core#1090](https://github.com/pydantic/pydantic-core/pull/1090)\n* [@akx](https://github.com/akx) made their first contribution in [pydantic/pydantic-core#1123](https://github.com/pydantic/pydantic-core/pull/1123)\n\n## v2.6.0b1 (2024-01-19)\n\nPre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.6.0b1) for details.\n\n## v2.5.3 (2023-12-22)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.5.3)\n\n### What's Changed\n\n#### Packaging\n\n* uprev `pydantic-core` to 2.14.6\n\n#### Fixes\n\n* Fix memory leak with recursive definitions creating reference cycles by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/pydantic-core#1125](https://github.com/pydantic/pydantic-core/pull/1125)\n\n## v2.5.2 (2023-11-22)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.5.2)\n\n### What's Changed\n\n#### Packaging\n\n* uprev `pydantic-core` to 2.14.5\n\n#### New Features\n\n* Add `ConfigDict.ser_json_inf_nan` by [@davidhewitt](https://github.com/davidhewitt) in [#8159](https://github.com/pydantic/pydantic/pull/8159)\n\n#### Fixes\n\n* Fix validation of `Literal` from JSON keys when used as `dict` key by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1075](https://github.com/pydantic/pydantic-core/pull/1075)\n* Fix bug re `custom_init` on members of `Union` by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1076](https://github.com/pydantic/pydantic-core/pull/1076)\n* Fix `JsonValue` `bool` serialization by [@sydney-runkle](https://github.com/sydney-runkle) in [#8190](https://github.com/pydantic/pydantic/pull/8159)\n* Fix handling of unhashable inputs with `Literal` in `Union`s by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1089](https://github.com/pydantic/pydantic-core/pull/1089)\n\n## v2.5.1 (2023-11-15)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.5.1)\n\n### What's Changed\n\n#### Packaging\n\n* uprev pydantic-core to 2.14.3 by [@samuelcolvin](https://github.com/samuelcolvin) in [#8120](https://github.com/pydantic/pydantic/pull/8120)\n\n#### Fixes\n\n* Fix package description limit by [@dmontagu](https://github.com/dmontagu) in [#8097](https://github.com/pydantic/pydantic/pull/8097)\n* Fix `ValidateCallWrapper` error when creating a model which has a [@validate_call](https://github.com/validate_call) wrapped field annotation by [@sydney-runkle](https://github.com/sydney-runkle) in [#8110](https://github.com/pydantic/pydantic/pull/8110)\n\n## v2.5.0 (2023-11-13)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.5.0)\n\nThe code released in v2.5.0 is functionally identical to that of v2.5.0b1.\n\n### What's Changed\n\n#### Packaging\n\n* Update pydantic-core from 2.10.1 to 2.14.1, significant changes from these updates are described below, full changelog [here](https://github.com/pydantic/pydantic-core/compare/v2.10.1...v2.14.1)\n* Update to `pyright==1.1.335` by [@Viicos](https://github.com/Viicos) in [#8075](https://github.com/pydantic/pydantic/pull/8075)\n\n#### New Features\n\n* Allow plugins to catch non `ValidationError` errors by [@adriangb](https://github.com/adriangb) in [#7806](https://github.com/pydantic/pydantic/pull/7806)\n* Support `__doc__` argument in `create_model()` by [@chris-spann](https://github.com/chris-spann) in [#7863](https://github.com/pydantic/pydantic/pull/7863)\n* Expose `regex_engine` flag - meaning you can use with the Rust or Python regex libraries in constraints by [@utkini](https://github.com/utkini) in [#7768](https://github.com/pydantic/pydantic/pull/7768)\n* Save return type generated from type annotation in `ComputedFieldInfo` by [@alexmojaki](https://github.com/alexmojaki) in [#7889](https://github.com/pydantic/pydantic/pull/7889)\n* Adopting `ruff` formatter by [@Luca-Blight](https://github.com/Luca-Blight) in [#7930](https://github.com/pydantic/pydantic/pull/7930)\n* Added `validation_error_cause` to config by [@zakstucke](https://github.com/zakstucke) in [#7626](https://github.com/pydantic/pydantic/pull/7626)\n* Make path of the item to validate available in plugin by [@hramezani](https://github.com/hramezani) in [#7861](https://github.com/pydantic/pydantic/pull/7861)\n* Add `CallableDiscriminator` and `Tag` by [@dmontagu](https://github.com/dmontagu) in [#7983](https://github.com/pydantic/pydantic/pull/7983)\n  * `CallableDiscriminator` renamed to `Discriminator` by [@dmontagu](https://github.com/dmontagu) in [#8047](https://github.com/pydantic/pydantic/pull/8047)\n* Make union case tags affect union error messages by [@dmontagu](https://github.com/dmontagu) in [#8001](https://github.com/pydantic/pydantic/pull/8001)\n* Add `examples` and `json_schema_extra` to `@computed_field` by [@alexmojaki](https://github.com/alexmojaki) in [#8013](https://github.com/pydantic/pydantic/pull/8013)\n* Add `JsonValue` type by [@dmontagu](https://github.com/dmontagu) in [#7998](https://github.com/pydantic/pydantic/pull/7998)\n* Allow `str` as argument to `Discriminator` by [@dmontagu](https://github.com/dmontagu) in [#8047](https://github.com/pydantic/pydantic/pull/8047)\n* Add `SchemaSerializer.__reduce__` method to enable pickle serialization by [@edoakes](https://github.com/edoakes) in [pydantic/pydantic-core#1006](https://github.com/pydantic/pydantic-core/pull/1006)\n\n#### Changes\n\n* **Significant Change:** replace `ultra_strict` with new smart union implementation, the way unions are validated has changed significantly to improve performance and correctness, we have worked hard to absolutely minimise the number of cases where behaviour has changed, see the PR for details - by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/pydantic-core#867](https://github.com/pydantic/pydantic-core/pull/867)\n* Add support for instance method reassignment when `extra='allow'` by [@sydney-runkle](https://github.com/sydney-runkle) in [#7683](https://github.com/pydantic/pydantic/pull/7683)\n* Support JSON schema generation for `Enum` types with no cases by [@sydney-runkle](https://github.com/sydney-runkle) in [#7927](https://github.com/pydantic/pydantic/pull/7927)\n* Warn if a class inherits from `Generic` before `BaseModel` by [@alexmojaki](https://github.com/alexmojaki) in [#7891](https://github.com/pydantic/pydantic/pull/7891)\n\n#### Performance\n\n* New custom JSON parser, `jiter` by [@samuelcolvin](https://github.com/samuelcolvin) in [pydantic/pydantic-core#974](https://github.com/pydantic/pydantic-core/pull/974)\n* PGO build for MacOS M1 by [@samuelcolvin](https://github.com/samuelcolvin) in [pydantic/pydantic-core#1063](https://github.com/pydantic/pydantic-core/pull/1063)\n* Use `__getattr__` for all package imports, improve import time by [@samuelcolvin](https://github.com/samuelcolvin) in [#7947](https://github.com/pydantic/pydantic/pull/7947)\n\n#### Fixes\n\n* Fix `mypy` issue with subclasses of `RootModel` by [@sydney-runkle](https://github.com/sydney-runkle) in [#7677](https://github.com/pydantic/pydantic/pull/7677)\n* Properly rebuild the `FieldInfo` when a forward ref gets evaluated by [@dmontagu](https://github.com/dmontagu) in [#7698](https://github.com/pydantic/pydantic/pull/7698)\n* Fix failure to load `SecretStr` from JSON (regression in v2.4) by [@sydney-runkle](https://github.com/sydney-runkle) in [#7729](https://github.com/pydantic/pydantic/pull/7729)\n* Fix `defer_build` behavior with `TypeAdapter` by [@sydney-runkle](https://github.com/sydney-runkle) in [#7736](https://github.com/pydantic/pydantic/pull/7736)\n* Improve compatibility with legacy `mypy` versions by [@dmontagu](https://github.com/dmontagu) in [#7742](https://github.com/pydantic/pydantic/pull/7742)\n* Fix: update `TypeVar` handling when default is not set by [@pmmmwh](https://github.com/pmmmwh) in [#7719](https://github.com/pydantic/pydantic/pull/7719)\n* Support specification of `strict` on `Enum` type fields by [@sydney-runkle](https://github.com/sydney-runkle) in [#7761](https://github.com/pydantic/pydantic/pull/7761)\n* Wrap `weakref.ref` instead of subclassing to fix `cloudpickle` serialization by [@edoakes](https://github.com/edoakes) in [#7780](https://github.com/pydantic/pydantic/pull/7780)\n* Keep values of private attributes set within `model_post_init` in subclasses by [@alexmojaki](https://github.com/alexmojaki) in [#7775](https://github.com/pydantic/pydantic/pull/7775)\n* Add more specific type for non-callable `json_schema_extra` by [@alexmojaki](https://github.com/alexmojaki) in [#7803](https://github.com/pydantic/pydantic/pull/7803)\n* Raise an error when deleting frozen (model) fields by [@alexmojaki](https://github.com/alexmojaki) in [#7800](https://github.com/pydantic/pydantic/pull/7800)\n* Fix schema sorting bug with default values by [@sydney-runkle](https://github.com/sydney-runkle) in [#7817](https://github.com/pydantic/pydantic/pull/7817)\n* Use generated alias for aliases that are not specified otherwise by [@alexmojaki](https://github.com/alexmojaki) in [#7802](https://github.com/pydantic/pydantic/pull/7802)\n* Support `strict` specification for `UUID` types by [@sydney-runkle](https://github.com/sydney-runkle) in [#7865](https://github.com/pydantic/pydantic/pull/7865)\n* JSON schema: fix extra parameter handling by [@me-and](https://github.com/me-and) in [#7810](https://github.com/pydantic/pydantic/pull/7810)\n* Fix: support `pydantic.Field(kw_only=True)` with inherited dataclasses by [@PrettyWood](https://github.com/PrettyWood) in [#7827](https://github.com/pydantic/pydantic/pull/7827)\n* Support `validate_call` decorator for methods in classes with `__slots__` by [@sydney-runkle](https://github.com/sydney-runkle) in [#7883](https://github.com/pydantic/pydantic/pull/7883)\n* Fix pydantic dataclass problem with `dataclasses.field` default by [@hramezani](https://github.com/hramezani) in [#7898](https://github.com/pydantic/pydantic/pull/7898)\n* Fix schema generation for generics with union type bounds by [@sydney-runkle](https://github.com/sydney-runkle) in [#7899](https://github.com/pydantic/pydantic/pull/7899)\n* Fix version for `importlib_metadata` on python 3.7 by [@sydney-runkle](https://github.com/sydney-runkle) in [#7904](https://github.com/pydantic/pydantic/pull/7904)\n* Support `|` operator (Union) in PydanticRecursiveRef by [@alexmojaki](https://github.com/alexmojaki) in [#7892](https://github.com/pydantic/pydantic/pull/7892)\n* Fix `display_as_type` for `TypeAliasType` in python 3.12 by [@dmontagu](https://github.com/dmontagu) in [#7929](https://github.com/pydantic/pydantic/pull/7929)\n* Add support for `NotRequired` generics in `TypedDict` by [@sydney-runkle](https://github.com/sydney-runkle) in [#7932](https://github.com/pydantic/pydantic/pull/7932)\n* Make generic `TypeAliasType` specifications produce different schema definitions by [@alexdrydew](https://github.com/alexdrydew) in [#7893](https://github.com/pydantic/pydantic/pull/7893)\n* Added fix for signature of inherited dataclass by [@howsunjow](https://github.com/howsunjow) in [#7925](https://github.com/pydantic/pydantic/pull/7925)\n* Make the model name generation more robust in JSON schema by [@joakimnordling](https://github.com/joakimnordling) in [#7881](https://github.com/pydantic/pydantic/pull/7881)\n* Fix plurals in validation error messages (in tests) by [@Iipin](https://github.com/Iipin) in [#7972](https://github.com/pydantic/pydantic/pull/7972)\n* `PrivateAttr` is passed from `Annotated` default position by [@tabassco](https://github.com/tabassco) in [#8004](https://github.com/pydantic/pydantic/pull/8004)\n* Don't decode bytes (which may not be UTF8) when displaying SecretBytes by [@alexmojaki](https://github.com/alexmojaki) in [#8012](https://github.com/pydantic/pydantic/pull/8012)\n* Use `classmethod` instead of `classmethod[Any, Any, Any]` by [@Mr-Pepe](https://github.com/Mr-Pepe) in [#7979](https://github.com/pydantic/pydantic/pull/7979)\n* Clearer error on invalid Plugin by [@samuelcolvin](https://github.com/samuelcolvin) in [#8023](https://github.com/pydantic/pydantic/pull/8023)\n* Correct pydantic dataclasses import by [@samuelcolvin](https://github.com/samuelcolvin) in [#8027](https://github.com/pydantic/pydantic/pull/8027)\n* Fix misbehavior for models referencing redefined type aliases by [@dmontagu](https://github.com/dmontagu) in [#8050](https://github.com/pydantic/pydantic/pull/8050)\n* Fix `Optional` field with `validate_default` only performing one field validation by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1002](https://github.com/pydantic/pydantic-core/pull/1002)\n* Fix `definition-ref` bug with `Dict` keys by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1014](https://github.com/pydantic/pydantic-core/pull/1014)\n* Fix bug allowing validation of `bool` types with `coerce_numbers_to_str=True` by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1017](https://github.com/pydantic/pydantic-core/pull/1017)\n* Don't accept `NaN` in float and decimal constraints by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/pydantic-core#1037](https://github.com/pydantic/pydantic-core/pull/1037)\n* Add `lax_str` and `lax_int` support for enum values not inherited from str/int by [@michaelhly](https://github.com/michaelhly) in [pydantic/pydantic-core#1015](https://github.com/pydantic/pydantic-core/pull/1015)\n* Support subclasses in lists in `Union` of `List` types by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1039](https://github.com/pydantic/pydantic-core/pull/1039)\n* Allow validation against `max_digits` and `decimals` to pass if normalized or non-normalized input is valid by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1049](https://github.com/pydantic/pydantic-core/pull/1049)\n* Fix: proper pluralization in `ValidationError` messages by [@Iipin](https://github.com/Iipin) in [pydantic/pydantic-core#1050](https://github.com/pydantic/pydantic-core/pull/1050)\n* Disallow the string `'-'` as `datetime` input by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/speedate#52](https://github.com/pydantic/speedate/pull/52) & [pydantic/pydantic-core#1060](https://github.com/pydantic/pydantic-core/pull/1060)\n* Fix: NaN and Inf float serialization by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/pydantic-core#1062](https://github.com/pydantic/pydantic-core/pull/1062)\n* Restore manylinux-compatible PGO builds by [@davidhewitt](https://github.com/davidhewitt) in [pydantic/pydantic-core#1068](https://github.com/pydantic/pydantic-core/pull/1068)\n\n### New Contributors\n\n#### `pydantic`\n* [@schneebuzz](https://github.com/schneebuzz) made their first contribution in [#7699](https://github.com/pydantic/pydantic/pull/7699)\n* [@edoakes](https://github.com/edoakes) made their first contribution in [#7780](https://github.com/pydantic/pydantic/pull/7780)\n* [@alexmojaki](https://github.com/alexmojaki) made their first contribution in [#7775](https://github.com/pydantic/pydantic/pull/7775)\n* [@NickG123](https://github.com/NickG123) made their first contribution in [#7751](https://github.com/pydantic/pydantic/pull/7751)\n* [@gowthamgts](https://github.com/gowthamgts) made their first contribution in [#7830](https://github.com/pydantic/pydantic/pull/7830)\n* [@jamesbraza](https://github.com/jamesbraza) made their first contribution in [#7848](https://github.com/pydantic/pydantic/pull/7848)\n* [@laundmo](https://github.com/laundmo) made their first contribution in [#7850](https://github.com/pydantic/pydantic/pull/7850)\n* [@rahmatnazali](https://github.com/rahmatnazali) made their first contribution in [#7870](https://github.com/pydantic/pydantic/pull/7870)\n* [@waterfountain1996](https://github.com/waterfountain1996) made their first contribution in [#7878](https://github.com/pydantic/pydantic/pull/7878)\n* [@chris-spann](https://github.com/chris-spann) made their first contribution in [#7863](https://github.com/pydantic/pydantic/pull/7863)\n* [@me-and](https://github.com/me-and) made their first contribution in [#7810](https://github.com/pydantic/pydantic/pull/7810)\n* [@utkini](https://github.com/utkini) made their first contribution in [#7768](https://github.com/pydantic/pydantic/pull/7768)\n* [@bn-l](https://github.com/bn-l) made their first contribution in [#7744](https://github.com/pydantic/pydantic/pull/7744)\n* [@alexdrydew](https://github.com/alexdrydew) made their first contribution in [#7893](https://github.com/pydantic/pydantic/pull/7893)\n* [@Luca-Blight](https://github.com/Luca-Blight) made their first contribution in [#7930](https://github.com/pydantic/pydantic/pull/7930)\n* [@howsunjow](https://github.com/howsunjow) made their first contribution in [#7925](https://github.com/pydantic/pydantic/pull/7925)\n* [@joakimnordling](https://github.com/joakimnordling) made their first contribution in [#7881](https://github.com/pydantic/pydantic/pull/7881)\n* [@icfly2](https://github.com/icfly2) made their first contribution in [#7976](https://github.com/pydantic/pydantic/pull/7976)\n* [@Yummy-Yums](https://github.com/Yummy-Yums) made their first contribution in [#8003](https://github.com/pydantic/pydantic/pull/8003)\n* [@Iipin](https://github.com/Iipin) made their first contribution in [#7972](https://github.com/pydantic/pydantic/pull/7972)\n* [@tabassco](https://github.com/tabassco) made their first contribution in [#8004](https://github.com/pydantic/pydantic/pull/8004)\n* [@Mr-Pepe](https://github.com/Mr-Pepe) made their first contribution in [#7979](https://github.com/pydantic/pydantic/pull/7979)\n* [@0x00cl](https://github.com/0x00cl) made their first contribution in [#8010](https://github.com/pydantic/pydantic/pull/8010)\n* [@barraponto](https://github.com/barraponto) made their first contribution in [#8032](https://github.com/pydantic/pydantic/pull/8032)\n\n#### `pydantic-core`\n* [@sisp](https://github.com/sisp) made their first contribution in [pydantic/pydantic-core#995](https://github.com/pydantic/pydantic-core/pull/995)\n* [@michaelhly](https://github.com/michaelhly) made their first contribution in [pydantic/pydantic-core#1015](https://github.com/pydantic/pydantic-core/pull/1015)\n\n## v2.5.0b1 (2023-11-09)\n\nPre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.5.0b1) for details.\n\n## v2.4.2 (2023-09-27)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.4.2)\n\n### What's Changed\n\n#### Fixes\n\n* Fix bug with JSON schema for sequence of discriminated union by [@dmontagu](https://github.com/dmontagu) in [#7647](https://github.com/pydantic/pydantic/pull/7647)\n* Fix schema references in discriminated unions by [@adriangb](https://github.com/adriangb) in [#7646](https://github.com/pydantic/pydantic/pull/7646)\n* Fix json schema generation for recursive models by [@adriangb](https://github.com/adriangb) in [#7653](https://github.com/pydantic/pydantic/pull/7653)\n* Fix `models_json_schema` for generic models by [@adriangb](https://github.com/adriangb) in [#7654](https://github.com/pydantic/pydantic/pull/7654)\n* Fix xfailed test for generic model signatures by [@adriangb](https://github.com/adriangb) in [#7658](https://github.com/pydantic/pydantic/pull/7658)\n\n### New Contributors\n\n* [@austinorr](https://github.com/austinorr) made their first contribution in [#7657](https://github.com/pydantic/pydantic/pull/7657)\n* [@peterHoburg](https://github.com/peterHoburg) made their first contribution in [#7670](https://github.com/pydantic/pydantic/pull/7670)\n\n## v2.4.1 (2023-09-26)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.4.1)\n\n### What's Changed\n\n#### Packaging\n\n* Update pydantic-core to 2.10.1 by [@davidhewitt](https://github.com/davidhewitt) in [#7633](https://github.com/pydantic/pydantic/pull/7633)\n\n#### Fixes\n\n* Serialize unsubstituted type vars as `Any` by [@adriangb](https://github.com/adriangb) in [#7606](https://github.com/pydantic/pydantic/pull/7606)\n* Remove schema building caches by [@adriangb](https://github.com/adriangb) in [#7624](https://github.com/pydantic/pydantic/pull/7624)\n* Fix an issue where JSON schema extras weren't JSON encoded by [@dmontagu](https://github.com/dmontagu) in [#7625](https://github.com/pydantic/pydantic/pull/7625)\n\n## v2.4.0 (2023-09-22)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.4.0)\n\n### What's Changed\n\n#### Packaging\n\n* Update pydantic-core to 2.10.0 by [@samuelcolvin](https://github.com/samuelcolvin) in [#7542](https://github.com/pydantic/pydantic/pull/7542)\n\n#### New Features\n\n* Add `Base64Url` types by [@dmontagu](https://github.com/dmontagu) in [#7286](https://github.com/pydantic/pydantic/pull/7286)\n* Implement optional `number` to `str` coercion by [@lig](https://github.com/lig) in [#7508](https://github.com/pydantic/pydantic/pull/7508)\n* Allow access to `field_name` and `data` in all validators if there is data and a field name by [@samuelcolvin](https://github.com/samuelcolvin) in [#7542](https://github.com/pydantic/pydantic/pull/7542)\n* Add `BaseModel.model_validate_strings` and `TypeAdapter.validate_strings` by [@hramezani](https://github.com/hramezani) in [#7552](https://github.com/pydantic/pydantic/pull/7552)\n* Add Pydantic `plugins` experimental implementation by [@lig](https://github.com/lig) [@samuelcolvin](https://github.com/samuelcolvin) and [@Kludex](https://github.com/Kludex) in [#6820](https://github.com/pydantic/pydantic/pull/6820)\n\n#### Changes\n\n* Do not override `model_post_init` in subclass with private attrs by [@Viicos](https://github.com/Viicos) in [#7302](https://github.com/pydantic/pydantic/pull/7302)\n* Make fields with defaults not required in the serialization schema by default by [@dmontagu](https://github.com/dmontagu) in [#7275](https://github.com/pydantic/pydantic/pull/7275)\n* Mark `Extra` as deprecated by [@disrupted](https://github.com/disrupted) in [#7299](https://github.com/pydantic/pydantic/pull/7299)\n* Make `EncodedStr` a dataclass by [@Kludex](https://github.com/Kludex) in [#7396](https://github.com/pydantic/pydantic/pull/7396)\n* Move `annotated_handlers` to be public by [@samuelcolvin](https://github.com/samuelcolvin) in [#7569](https://github.com/pydantic/pydantic/pull/7569)\n\n#### Performance\n\n* Simplify flattening and inlining of `CoreSchema` by [@adriangb](https://github.com/adriangb) in [#7523](https://github.com/pydantic/pydantic/pull/7523)\n* Remove unused copies in `CoreSchema` walking by [@adriangb](https://github.com/adriangb) in [#7528](https://github.com/pydantic/pydantic/pull/7528)\n* Add caches for collecting definitions and invalid schemas from a CoreSchema by [@adriangb](https://github.com/adriangb) in [#7527](https://github.com/pydantic/pydantic/pull/7527)\n* Eagerly resolve discriminated unions and cache cases where we can't by [@adriangb](https://github.com/adriangb) in [#7529](https://github.com/pydantic/pydantic/pull/7529)\n* Replace `dict.get` and `dict.setdefault` with more verbose versions in `CoreSchema` building hot paths by [@adriangb](https://github.com/adriangb) in [#7536](https://github.com/pydantic/pydantic/pull/7536)\n* Cache invalid `CoreSchema` discovery by [@adriangb](https://github.com/adriangb) in [#7535](https://github.com/pydantic/pydantic/pull/7535)\n* Allow disabling `CoreSchema` validation for faster startup times by [@adriangb](https://github.com/adriangb) in [#7565](https://github.com/pydantic/pydantic/pull/7565)\n\n#### Fixes\n\n* Fix config detection for `TypedDict` from grandparent classes by [@dmontagu](https://github.com/dmontagu) in [#7272](https://github.com/pydantic/pydantic/pull/7272)\n* Fix hash function generation for frozen models with unusual MRO by [@dmontagu](https://github.com/dmontagu) in [#7274](https://github.com/pydantic/pydantic/pull/7274)\n* Make `strict` config overridable in field for Path by [@hramezani](https://github.com/hramezani) in [#7281](https://github.com/pydantic/pydantic/pull/7281)\n* Use `ser_json_<timedelta|bytes>` on default in `GenerateJsonSchema` by [@Kludex](https://github.com/Kludex) in [#7269](https://github.com/pydantic/pydantic/pull/7269)\n* Adding a check that alias is validated as an identifier for Python by [@andree0](https://github.com/andree0) in [#7319](https://github.com/pydantic/pydantic/pull/7319)\n* Raise an error when computed field overrides field by [@sydney-runkle](https://github.com/sydney-runkle) in [#7346](https://github.com/pydantic/pydantic/pull/7346)\n* Fix applying `SkipValidation` to referenced schemas by [@adriangb](https://github.com/adriangb) in [#7381](https://github.com/pydantic/pydantic/pull/7381)\n* Enforce behavior of private attributes having double leading underscore by [@lig](https://github.com/lig) in [#7265](https://github.com/pydantic/pydantic/pull/7265)\n* Standardize `__get_pydantic_core_schema__` signature by [@hramezani](https://github.com/hramezani) in [#7415](https://github.com/pydantic/pydantic/pull/7415)\n* Fix generic dataclass fields mutation bug (when using `TypeAdapter`) by [@sydney-runkle](https://github.com/sydney-runkle) in [#7435](https://github.com/pydantic/pydantic/pull/7435)\n* Fix `TypeError` on `model_validator` in `wrap` mode by [@pmmmwh](https://github.com/pmmmwh) in [#7496](https://github.com/pydantic/pydantic/pull/7496)\n* Improve enum error message by [@hramezani](https://github.com/hramezani) in [#7506](https://github.com/pydantic/pydantic/pull/7506)\n* Make `repr` work for instances that failed initialization when handling `ValidationError`s by [@dmontagu](https://github.com/dmontagu) in [#7439](https://github.com/pydantic/pydantic/pull/7439)\n* Fixed a regular expression denial of service issue by limiting whitespaces by [@prodigysml](https://github.com/prodigysml) in [#7360](https://github.com/pydantic/pydantic/pull/7360)\n* Fix handling of `UUID` values having `UUID.version=None` by [@lig](https://github.com/lig) in [#7566](https://github.com/pydantic/pydantic/pull/7566)\n* Fix `__iter__` returning private `cached_property` info by [@sydney-runkle](https://github.com/sydney-runkle) in [#7570](https://github.com/pydantic/pydantic/pull/7570)\n* Improvements to version info message by [@samuelcolvin](https://github.com/samuelcolvin) in [#7594](https://github.com/pydantic/pydantic/pull/7594)\n\n### New Contributors\n* [@15498th](https://github.com/15498th) made their first contribution in [#7238](https://github.com/pydantic/pydantic/pull/7238)\n* [@GabrielCappelli](https://github.com/GabrielCappelli) made their first contribution in [#7213](https://github.com/pydantic/pydantic/pull/7213)\n* [@tobni](https://github.com/tobni) made their first contribution in [#7184](https://github.com/pydantic/pydantic/pull/7184)\n* [@redruin1](https://github.com/redruin1) made their first contribution in [#7282](https://github.com/pydantic/pydantic/pull/7282)\n* [@FacerAin](https://github.com/FacerAin) made their first contribution in [#7288](https://github.com/pydantic/pydantic/pull/7288)\n* [@acdha](https://github.com/acdha) made their first contribution in [#7297](https://github.com/pydantic/pydantic/pull/7297)\n* [@andree0](https://github.com/andree0) made their first contribution in [#7319](https://github.com/pydantic/pydantic/pull/7319)\n* [@gordonhart](https://github.com/gordonhart) made their first contribution in [#7375](https://github.com/pydantic/pydantic/pull/7375)\n* [@pmmmwh](https://github.com/pmmmwh) made their first contribution in [#7496](https://github.com/pydantic/pydantic/pull/7496)\n* [@disrupted](https://github.com/disrupted) made their first contribution in [#7299](https://github.com/pydantic/pydantic/pull/7299)\n* [@prodigysml](https://github.com/prodigysml) made their first contribution in [#7360](https://github.com/pydantic/pydantic/pull/7360)\n\n## v2.3.0 (2023-08-23)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.3.0)\n\n* ðŸ”¥ Remove orphaned changes file from repo by [@lig](https://github.com/lig) in [#7168](https://github.com/pydantic/pydantic/pull/7168)\n* Add copy button on documentation by [@Kludex](https://github.com/Kludex) in [#7190](https://github.com/pydantic/pydantic/pull/7190)\n* Fix docs on JSON type by [@Kludex](https://github.com/Kludex) in [#7189](https://github.com/pydantic/pydantic/pull/7189)\n* Update mypy 1.5.0 to 1.5.1 in CI by [@hramezani](https://github.com/hramezani) in [#7191](https://github.com/pydantic/pydantic/pull/7191)\n* fix download links badge by [@samuelcolvin](https://github.com/samuelcolvin) in [#7200](https://github.com/pydantic/pydantic/pull/7200)\n* add 2.2.1 to changelog by [@samuelcolvin](https://github.com/samuelcolvin) in [#7212](https://github.com/pydantic/pydantic/pull/7212)\n* Make ModelWrapValidator protocols generic by [@dmontagu](https://github.com/dmontagu) in [#7154](https://github.com/pydantic/pydantic/pull/7154)\n* Correct `Field(..., exclude: bool)` docs by [@samuelcolvin](https://github.com/samuelcolvin) in [#7214](https://github.com/pydantic/pydantic/pull/7214)\n* Make shadowing attributes a warning instead of an error by [@adriangb](https://github.com/adriangb) in [#7193](https://github.com/pydantic/pydantic/pull/7193)\n* Document `Base64Str` and `Base64Bytes` by [@Kludex](https://github.com/Kludex) in [#7192](https://github.com/pydantic/pydantic/pull/7192)\n* Fix `config.defer_build` for serialization first cases by [@samuelcolvin](https://github.com/samuelcolvin) in [#7024](https://github.com/pydantic/pydantic/pull/7024)\n* clean Model docstrings in JSON Schema by [@samuelcolvin](https://github.com/samuelcolvin) in [#7210](https://github.com/pydantic/pydantic/pull/7210)\n* fix [#7228](https://github.com/pydantic/pydantic/pull/7228) (typo): docs in `validators.md` to correct `validate_default` kwarg by [@lmmx](https://github.com/lmmx) in [#7229](https://github.com/pydantic/pydantic/pull/7229)\n* âœ… Implement `tzinfo.fromutc` method for `TzInfo` in `pydantic-core` by [@lig](https://github.com/lig) in [#7019](https://github.com/pydantic/pydantic/pull/7019)\n* Support `__get_validators__` by [@hramezani](https://github.com/hramezani) in [#7197](https://github.com/pydantic/pydantic/pull/7197)\n\n## v2.2.1 (2023-08-18)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.2.1)\n\n* Make `xfail`ing test for root model extra stop `xfail`ing by [@dmontagu](https://github.com/dmontagu) in [#6937](https://github.com/pydantic/pydantic/pull/6937)\n* Optimize recursion detection by stopping on the second visit for the same object by [@mciucu](https://github.com/mciucu) in [#7160](https://github.com/pydantic/pydantic/pull/7160)\n* fix link in docs by [@tlambert03](https://github.com/tlambert03) in [#7166](https://github.com/pydantic/pydantic/pull/7166)\n* Replace MiMalloc w/ default allocator by [@adriangb](https://github.com/adriangb) in [pydantic/pydantic-core#900](https://github.com/pydantic/pydantic-core/pull/900)\n* Bump pydantic-core to 2.6.1 and prepare 2.2.1 release by [@adriangb](https://github.com/adriangb) in [#7176](https://github.com/pydantic/pydantic/pull/7176)\n\n## v2.2.0 (2023-08-17)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.2.0)\n\n* Split \"pipx install\" setup command into two commands on the documentation site by [@nomadmtb](https://github.com/nomadmtb) in [#6869](https://github.com/pydantic/pydantic/pull/6869)\n* Deprecate `Field.include` by [@hramezani](https://github.com/hramezani) in [#6852](https://github.com/pydantic/pydantic/pull/6852)\n* Fix typo in default factory error msg by [@hramezani](https://github.com/hramezani) in [#6880](https://github.com/pydantic/pydantic/pull/6880)\n* Simplify handling of typing.Annotated in GenerateSchema by [@dmontagu](https://github.com/dmontagu) in [#6887](https://github.com/pydantic/pydantic/pull/6887)\n* Re-enable fastapi tests in CI by [@dmontagu](https://github.com/dmontagu) in [#6883](https://github.com/pydantic/pydantic/pull/6883)\n* Make it harder to hit collisions with json schema defrefs by [@dmontagu](https://github.com/dmontagu) in [#6566](https://github.com/pydantic/pydantic/pull/6566)\n* Cleaner error for invalid input to `Path` fields by [@samuelcolvin](https://github.com/samuelcolvin) in [#6903](https://github.com/pydantic/pydantic/pull/6903)\n* :memo: support Coordinate Type by [@yezz123](https://github.com/yezz123) in [#6906](https://github.com/pydantic/pydantic/pull/6906)\n* Fix `ForwardRef` wrapper for py 3.10.0 (shim until bpo-45166) by [@randomir](https://github.com/randomir) in [#6919](https://github.com/pydantic/pydantic/pull/6919)\n* Fix misbehavior related to copying of RootModel by [@dmontagu](https://github.com/dmontagu) in [#6918](https://github.com/pydantic/pydantic/pull/6918)\n* Fix issue with recursion error caused by ParamSpec by [@dmontagu](https://github.com/dmontagu) in [#6923](https://github.com/pydantic/pydantic/pull/6923)\n* Add section about Constrained classes to the Migration Guide by [@Kludex](https://github.com/Kludex) in [#6924](https://github.com/pydantic/pydantic/pull/6924)\n* Use `main` branch for badge links by [@Viicos](https://github.com/Viicos) in [#6925](https://github.com/pydantic/pydantic/pull/6925)\n* Add test for v1/v2 Annotated discrepancy by [@carlbordum](https://github.com/carlbordum) in [#6926](https://github.com/pydantic/pydantic/pull/6926)\n* Make the v1 mypy plugin work with both v1 and v2 by [@dmontagu](https://github.com/dmontagu) in [#6921](https://github.com/pydantic/pydantic/pull/6921)\n* Fix issue where generic models couldn't be parametrized with BaseModel by [@dmontagu](https://github.com/dmontagu) in [#6933](https://github.com/pydantic/pydantic/pull/6933)\n* Remove xfail for discriminated union with alias by [@dmontagu](https://github.com/dmontagu) in [#6938](https://github.com/pydantic/pydantic/pull/6938)\n* add field_serializer to computed_field by [@andresliszt](https://github.com/andresliszt) in [#6965](https://github.com/pydantic/pydantic/pull/6965)\n* Use union_schema with Type[Union[...]] by [@JeanArhancet](https://github.com/JeanArhancet) in [#6952](https://github.com/pydantic/pydantic/pull/6952)\n* Fix inherited typeddict attributes / config by [@adriangb](https://github.com/adriangb) in [#6981](https://github.com/pydantic/pydantic/pull/6981)\n* fix dataclass annotated before validator called twice by [@davidhewitt](https://github.com/davidhewitt) in [#6998](https://github.com/pydantic/pydantic/pull/6998)\n* Update test-fastapi deselected tests by [@hramezani](https://github.com/hramezani) in [#7014](https://github.com/pydantic/pydantic/pull/7014)\n* Fix validator doc format by [@hramezani](https://github.com/hramezani) in [#7015](https://github.com/pydantic/pydantic/pull/7015)\n* Fix typo in docstring of model_json_schema by [@AdamVinch-Federated](https://github.com/AdamVinch-Federated) in [#7032](https://github.com/pydantic/pydantic/pull/7032)\n* remove unused \"type ignores\" with pyright by [@samuelcolvin](https://github.com/samuelcolvin) in [#7026](https://github.com/pydantic/pydantic/pull/7026)\n* Add benchmark representing FastAPI startup time by [@adriangb](https://github.com/adriangb) in [#7030](https://github.com/pydantic/pydantic/pull/7030)\n* Fix json_encoders for Enum subclasses by [@adriangb](https://github.com/adriangb) in [#7029](https://github.com/pydantic/pydantic/pull/7029)\n* Update docstring of `ser_json_bytes` regarding base64 encoding by [@Viicos](https://github.com/Viicos) in [#7052](https://github.com/pydantic/pydantic/pull/7052)\n* Allow `@validate_call` to work on async methods by [@adriangb](https://github.com/adriangb) in [#7046](https://github.com/pydantic/pydantic/pull/7046)\n* Fix: mypy error with `Settings` and `SettingsConfigDict` by [@JeanArhancet](https://github.com/JeanArhancet) in [#7002](https://github.com/pydantic/pydantic/pull/7002)\n* Fix some typos (repeated words and it's/its) by [@eumiro](https://github.com/eumiro) in [#7063](https://github.com/pydantic/pydantic/pull/7063)\n* Fix the typo in docstring by [@harunyasar](https://github.com/harunyasar) in [#7062](https://github.com/pydantic/pydantic/pull/7062)\n* Docs: Fix broken URL in the pydantic-settings package recommendation by [@swetjen](https://github.com/swetjen) in [#6995](https://github.com/pydantic/pydantic/pull/6995)\n* Handle constraints being applied to schemas that don't accept it by [@adriangb](https://github.com/adriangb) in [#6951](https://github.com/pydantic/pydantic/pull/6951)\n* Replace almost_equal_floats with math.isclose by [@eumiro](https://github.com/eumiro) in [#7082](https://github.com/pydantic/pydantic/pull/7082)\n* bump pydantic-core to 2.5.0 by [@davidhewitt](https://github.com/davidhewitt) in [#7077](https://github.com/pydantic/pydantic/pull/7077)\n* Add `short_version` and use it in links by [@hramezani](https://github.com/hramezani) in [#7115](https://github.com/pydantic/pydantic/pull/7115)\n* ðŸ“ Add usage link to `RootModel` by [@Kludex](https://github.com/Kludex) in [#7113](https://github.com/pydantic/pydantic/pull/7113)\n* Revert \"Fix default port for mongosrv DSNs (#6827)\" by [@Kludex](https://github.com/Kludex) in [#7116](https://github.com/pydantic/pydantic/pull/7116)\n* Clarify validate_default and _Unset handling in usage docs and migration guide by [@benbenbang](https://github.com/benbenbang) in [#6950](https://github.com/pydantic/pydantic/pull/6950)\n* Tweak documentation of `Field.exclude` by [@Viicos](https://github.com/Viicos) in [#7086](https://github.com/pydantic/pydantic/pull/7086)\n* Do not require `validate_assignment` to use `Field.frozen` by [@Viicos](https://github.com/Viicos) in [#7103](https://github.com/pydantic/pydantic/pull/7103)\n* tweaks to `_core_utils` by [@samuelcolvin](https://github.com/samuelcolvin) in [#7040](https://github.com/pydantic/pydantic/pull/7040)\n* Make DefaultDict working with set by [@hramezani](https://github.com/hramezani) in [#7126](https://github.com/pydantic/pydantic/pull/7126)\n* Don't always require typing.Generic as a base for partially parametrized models by [@dmontagu](https://github.com/dmontagu) in [#7119](https://github.com/pydantic/pydantic/pull/7119)\n* Fix issue with JSON schema incorrectly using parent class core schema by [@dmontagu](https://github.com/dmontagu) in [#7020](https://github.com/pydantic/pydantic/pull/7020)\n* Fix xfailed test related to TypedDict and alias_generator by [@dmontagu](https://github.com/dmontagu) in [#6940](https://github.com/pydantic/pydantic/pull/6940)\n* Improve error message for NameEmail by [@dmontagu](https://github.com/dmontagu) in [#6939](https://github.com/pydantic/pydantic/pull/6939)\n* Fix generic computed fields by [@dmontagu](https://github.com/dmontagu) in [#6988](https://github.com/pydantic/pydantic/pull/6988)\n* Reflect namedtuple default values during validation by [@dmontagu](https://github.com/dmontagu) in [#7144](https://github.com/pydantic/pydantic/pull/7144)\n* Update dependencies, fix pydantic-core usage, fix CI issues by [@dmontagu](https://github.com/dmontagu) in [#7150](https://github.com/pydantic/pydantic/pull/7150)\n* Add mypy 1.5.0 by [@hramezani](https://github.com/hramezani) in [#7118](https://github.com/pydantic/pydantic/pull/7118)\n* Handle non-json native enum values by [@adriangb](https://github.com/adriangb) in [#7056](https://github.com/pydantic/pydantic/pull/7056)\n* document `round_trip` in Json type documentation  by [@jc-louis](https://github.com/jc-louis) in [#7137](https://github.com/pydantic/pydantic/pull/7137)\n* Relax signature checks to better support builtins and C extension functions as validators by [@adriangb](https://github.com/adriangb) in [#7101](https://github.com/pydantic/pydantic/pull/7101)\n* add union_mode='left_to_right' by [@davidhewitt](https://github.com/davidhewitt) in [#7151](https://github.com/pydantic/pydantic/pull/7151)\n* Include an error message hint for inherited ordering by [@yvalencia91](https://github.com/yvalencia91) in [#7124](https://github.com/pydantic/pydantic/pull/7124)\n* Fix one docs link and resolve some warnings for two others by [@dmontagu](https://github.com/dmontagu) in [#7153](https://github.com/pydantic/pydantic/pull/7153)\n* Include Field extra keys name in warning by [@hramezani](https://github.com/hramezani) in [#7136](https://github.com/pydantic/pydantic/pull/7136)\n\n## v2.1.1 (2023-07-25)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.1.1)\n\n* Skip FieldInfo merging when unnecessary by [@dmontagu](https://github.com/dmontagu) in [#6862](https://github.com/pydantic/pydantic/pull/6862)\n\n## v2.1.0 (2023-07-25)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.1.0)\n\n* Add `StringConstraints` for use as Annotated metadata by [@adriangb](https://github.com/adriangb) in [#6605](https://github.com/pydantic/pydantic/pull/6605)\n* Try to fix intermittently failing CI by [@adriangb](https://github.com/adriangb) in [#6683](https://github.com/pydantic/pydantic/pull/6683)\n* Remove redundant example of optional vs default. by [@ehiggs-deliverect](https://github.com/ehiggs-deliverect) in [#6676](https://github.com/pydantic/pydantic/pull/6676)\n* Docs update by [@samuelcolvin](https://github.com/samuelcolvin) in [#6692](https://github.com/pydantic/pydantic/pull/6692)\n* Remove the Validate always section in validator docs by [@adriangb](https://github.com/adriangb) in [#6679](https://github.com/pydantic/pydantic/pull/6679)\n* Fix recursion error in json schema generation by [@adriangb](https://github.com/adriangb) in [#6720](https://github.com/pydantic/pydantic/pull/6720)\n* Fix incorrect subclass check for secretstr by [@AlexVndnblcke](https://github.com/AlexVndnblcke) in [#6730](https://github.com/pydantic/pydantic/pull/6730)\n* update pdm / pdm lockfile to 2.8.0 by [@davidhewitt](https://github.com/davidhewitt) in [#6714](https://github.com/pydantic/pydantic/pull/6714)\n* unpin pdm on more CI jobs by [@davidhewitt](https://github.com/davidhewitt) in [#6755](https://github.com/pydantic/pydantic/pull/6755)\n* improve source locations for auxiliary packages in docs by [@davidhewitt](https://github.com/davidhewitt) in [#6749](https://github.com/pydantic/pydantic/pull/6749)\n* Assume builtins don't accept an info argument by [@adriangb](https://github.com/adriangb) in [#6754](https://github.com/pydantic/pydantic/pull/6754)\n* Fix bug where calling `help(BaseModelSubclass)` raises errors by [@hramezani](https://github.com/hramezani) in [#6758](https://github.com/pydantic/pydantic/pull/6758)\n* Fix mypy plugin handling of `@model_validator(mode=\"after\")` by [@ljodal](https://github.com/ljodal) in [#6753](https://github.com/pydantic/pydantic/pull/6753)\n* update pydantic-core to 2.3.1 by [@davidhewitt](https://github.com/davidhewitt) in [#6756](https://github.com/pydantic/pydantic/pull/6756)\n* Mypy plugin for settings by [@hramezani](https://github.com/hramezani) in [#6760](https://github.com/pydantic/pydantic/pull/6760)\n* Use `contentSchema` keyword for JSON schema by [@dmontagu](https://github.com/dmontagu) in [#6715](https://github.com/pydantic/pydantic/pull/6715)\n* fast-path checking finite decimals by [@davidhewitt](https://github.com/davidhewitt) in [#6769](https://github.com/pydantic/pydantic/pull/6769)\n* Docs update by [@samuelcolvin](https://github.com/samuelcolvin) in [#6771](https://github.com/pydantic/pydantic/pull/6771)\n* Improve json schema doc by [@hramezani](https://github.com/hramezani) in [#6772](https://github.com/pydantic/pydantic/pull/6772)\n* Update validator docs by [@adriangb](https://github.com/adriangb) in [#6695](https://github.com/pydantic/pydantic/pull/6695)\n* Fix typehint for wrap validator by [@dmontagu](https://github.com/dmontagu) in [#6788](https://github.com/pydantic/pydantic/pull/6788)\n* ðŸ› Fix validation warning for unions of Literal and other type by [@lig](https://github.com/lig) in [#6628](https://github.com/pydantic/pydantic/pull/6628)\n* Update documentation for generics support in V2 by [@tpdorsey](https://github.com/tpdorsey) in [#6685](https://github.com/pydantic/pydantic/pull/6685)\n* add pydantic-core build info to `version_info()` by [@samuelcolvin](https://github.com/samuelcolvin) in [#6785](https://github.com/pydantic/pydantic/pull/6785)\n* Fix pydantic dataclasses that use slots with default values by [@dmontagu](https://github.com/dmontagu) in [#6796](https://github.com/pydantic/pydantic/pull/6796)\n* Fix inheritance of hash function for frozen models by [@dmontagu](https://github.com/dmontagu) in [#6789](https://github.com/pydantic/pydantic/pull/6789)\n* âœ¨ Add `SkipJsonSchema` annotation by [@Kludex](https://github.com/Kludex) in [#6653](https://github.com/pydantic/pydantic/pull/6653)\n* Error if an invalid field name is used with Field by [@dmontagu](https://github.com/dmontagu) in [#6797](https://github.com/pydantic/pydantic/pull/6797)\n* Add `GenericModel` to `MOVED_IN_V2` by [@adriangb](https://github.com/adriangb) in [#6776](https://github.com/pydantic/pydantic/pull/6776)\n* Remove unused code from `docs/usage/types/custom.md` by [@hramezani](https://github.com/hramezani) in [#6803](https://github.com/pydantic/pydantic/pull/6803)\n* Fix `float` -> `Decimal` coercion precision loss by [@adriangb](https://github.com/adriangb) in [#6810](https://github.com/pydantic/pydantic/pull/6810)\n* remove email validation from the north star benchmark by [@davidhewitt](https://github.com/davidhewitt) in [#6816](https://github.com/pydantic/pydantic/pull/6816)\n* Fix link to mypy by [@progsmile](https://github.com/progsmile) in [#6824](https://github.com/pydantic/pydantic/pull/6824)\n* Improve initialization hooks example by [@hramezani](https://github.com/hramezani) in [#6822](https://github.com/pydantic/pydantic/pull/6822)\n* Fix default port for mongosrv DSNs by [@dmontagu](https://github.com/dmontagu) in [#6827](https://github.com/pydantic/pydantic/pull/6827)\n* Improve API documentation, in particular more links between usage and API docs by [@samuelcolvin](https://github.com/samuelcolvin) in [#6780](https://github.com/pydantic/pydantic/pull/6780)\n* update pydantic-core to 2.4.0 by [@davidhewitt](https://github.com/davidhewitt) in [#6831](https://github.com/pydantic/pydantic/pull/6831)\n* Fix `annotated_types.MaxLen` validator for custom sequence types by [@ImogenBits](https://github.com/ImogenBits) in [#6809](https://github.com/pydantic/pydantic/pull/6809)\n* Update V1 by [@hramezani](https://github.com/hramezani) in [#6833](https://github.com/pydantic/pydantic/pull/6833)\n* Make it so callable JSON schema extra works by [@dmontagu](https://github.com/dmontagu) in [#6798](https://github.com/pydantic/pydantic/pull/6798)\n* Fix serialization issue with `InstanceOf` by [@dmontagu](https://github.com/dmontagu) in [#6829](https://github.com/pydantic/pydantic/pull/6829)\n* Add back support for `json_encoders` by [@adriangb](https://github.com/adriangb) in [#6811](https://github.com/pydantic/pydantic/pull/6811)\n* Update field annotations when building the schema by [@dmontagu](https://github.com/dmontagu) in [#6838](https://github.com/pydantic/pydantic/pull/6838)\n* Use `WeakValueDictionary` to fix generic memory leak by [@dmontagu](https://github.com/dmontagu) in [#6681](https://github.com/pydantic/pydantic/pull/6681)\n* Add `config.defer_build` to optionally make model building lazy by [@samuelcolvin](https://github.com/samuelcolvin) in [#6823](https://github.com/pydantic/pydantic/pull/6823)\n* delegate `UUID` serialization to pydantic-core by [@davidhewitt](https://github.com/davidhewitt) in [#6850](https://github.com/pydantic/pydantic/pull/6850)\n* Update `json_encoders` docs by [@adriangb](https://github.com/adriangb) in [#6848](https://github.com/pydantic/pydantic/pull/6848)\n* Fix error message for `staticmethod`/`classmethod` order with validate_call by [@dmontagu](https://github.com/dmontagu) in [#6686](https://github.com/pydantic/pydantic/pull/6686)\n* Improve documentation for `Config` by [@samuelcolvin](https://github.com/samuelcolvin) in [#6847](https://github.com/pydantic/pydantic/pull/6847)\n* Update serialization doc to mention `Field.exclude` takes priority over call-time `include/exclude` by [@hramezani](https://github.com/hramezani) in [#6851](https://github.com/pydantic/pydantic/pull/6851)\n* Allow customizing core schema generation by making `GenerateSchema` public by [@adriangb](https://github.com/adriangb) in [#6737](https://github.com/pydantic/pydantic/pull/6737)\n\n## v2.0.3 (2023-07-05)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.0.3)\n\n* Mention PyObject (v1) moving to ImportString (v2) in migration doc by [@slafs](https://github.com/slafs) in [#6456](https://github.com/pydantic/pydantic/pull/6456)\n* Fix release-tweet CI by [@Kludex](https://github.com/Kludex) in [#6461](https://github.com/pydantic/pydantic/pull/6461)\n* Revise the section on required / optional / nullable fields. by [@ybressler](https://github.com/ybressler) in [#6468](https://github.com/pydantic/pydantic/pull/6468)\n* Warn if a type hint is not in fact a type by [@adriangb](https://github.com/adriangb) in [#6479](https://github.com/pydantic/pydantic/pull/6479)\n* Replace TransformSchema with GetPydanticSchema by [@dmontagu](https://github.com/dmontagu) in [#6484](https://github.com/pydantic/pydantic/pull/6484)\n* Fix the un-hashability of various annotation types, for use in caching generic containers by [@dmontagu](https://github.com/dmontagu) in [#6480](https://github.com/pydantic/pydantic/pull/6480)\n* PYD-164: Rework custom types docs by [@adriangb](https://github.com/adriangb) in [#6490](https://github.com/pydantic/pydantic/pull/6490)\n* Fix ci by [@adriangb](https://github.com/adriangb) in [#6507](https://github.com/pydantic/pydantic/pull/6507)\n* Fix forward ref in generic by [@adriangb](https://github.com/adriangb) in [#6511](https://github.com/pydantic/pydantic/pull/6511)\n* Fix generation of serialization JSON schemas for core_schema.ChainSchema by [@dmontagu](https://github.com/dmontagu) in [#6515](https://github.com/pydantic/pydantic/pull/6515)\n* Document the change in `Field.alias` behavior in Pydantic V2 by [@hramezani](https://github.com/hramezani) in [#6508](https://github.com/pydantic/pydantic/pull/6508)\n* Give better error message attempting to compute the json schema of a model with undefined fields by [@dmontagu](https://github.com/dmontagu) in [#6519](https://github.com/pydantic/pydantic/pull/6519)\n* Document `alias_priority` by [@tpdorsey](https://github.com/tpdorsey) in [#6520](https://github.com/pydantic/pydantic/pull/6520)\n* Add redirect for types documentation by [@tpdorsey](https://github.com/tpdorsey) in [#6513](https://github.com/pydantic/pydantic/pull/6513)\n* Allow updating docs without release by [@samuelcolvin](https://github.com/samuelcolvin) in [#6551](https://github.com/pydantic/pydantic/pull/6551)\n* Ensure docs tests always run in the right folder by [@dmontagu](https://github.com/dmontagu) in [#6487](https://github.com/pydantic/pydantic/pull/6487)\n* Defer evaluation of return type hints for serializer functions by [@dmontagu](https://github.com/dmontagu) in [#6516](https://github.com/pydantic/pydantic/pull/6516)\n* Disable E501 from Ruff and rely on just Black by [@adriangb](https://github.com/adriangb) in [#6552](https://github.com/pydantic/pydantic/pull/6552)\n* Update JSON Schema documentation for V2 by [@tpdorsey](https://github.com/tpdorsey) in [#6492](https://github.com/pydantic/pydantic/pull/6492)\n* Add documentation of cyclic reference handling by [@dmontagu](https://github.com/dmontagu) in [#6493](https://github.com/pydantic/pydantic/pull/6493)\n* Remove the need for change files by [@samuelcolvin](https://github.com/samuelcolvin) in [#6556](https://github.com/pydantic/pydantic/pull/6556)\n* add \"north star\" benchmark by [@davidhewitt](https://github.com/davidhewitt) in [#6547](https://github.com/pydantic/pydantic/pull/6547)\n* Update Dataclasses docs by [@tpdorsey](https://github.com/tpdorsey) in [#6470](https://github.com/pydantic/pydantic/pull/6470)\n* â™»ï¸ Use different error message on v1 redirects by [@Kludex](https://github.com/Kludex) in [#6595](https://github.com/pydantic/pydantic/pull/6595)\n* â¬† Upgrade `pydantic-core` to v2.2.0 by [@lig](https://github.com/lig) in [#6589](https://github.com/pydantic/pydantic/pull/6589)\n* Fix serialization for IPvAny by [@dmontagu](https://github.com/dmontagu) in [#6572](https://github.com/pydantic/pydantic/pull/6572)\n* Improve CI by using PDM instead of pip to install typing-extensions by [@adriangb](https://github.com/adriangb) in [#6602](https://github.com/pydantic/pydantic/pull/6602)\n* Add `enum` error type docs  by [@lig](https://github.com/lig) in [#6603](https://github.com/pydantic/pydantic/pull/6603)\n* ðŸ› Fix `max_length` for unicode strings by [@lig](https://github.com/lig) in [#6559](https://github.com/pydantic/pydantic/pull/6559)\n* Add documentation for accessing features via `pydantic.v1` by [@tpdorsey](https://github.com/tpdorsey) in [#6604](https://github.com/pydantic/pydantic/pull/6604)\n* Include extra when iterating over a model by [@adriangb](https://github.com/adriangb) in [#6562](https://github.com/pydantic/pydantic/pull/6562)\n* Fix typing of model_validator by [@adriangb](https://github.com/adriangb) in [#6514](https://github.com/pydantic/pydantic/pull/6514)\n* Touch up Decimal validator by [@adriangb](https://github.com/adriangb) in [#6327](https://github.com/pydantic/pydantic/pull/6327)\n* Fix various docstrings using fixed pytest-examples by [@dmontagu](https://github.com/dmontagu) in [#6607](https://github.com/pydantic/pydantic/pull/6607)\n* Handle function validators in a discriminated union by [@dmontagu](https://github.com/dmontagu) in [#6570](https://github.com/pydantic/pydantic/pull/6570)\n* Review json_schema.md by [@tpdorsey](https://github.com/tpdorsey) in [#6608](https://github.com/pydantic/pydantic/pull/6608)\n* Make validate_call work on basemodel methods by [@dmontagu](https://github.com/dmontagu) in [#6569](https://github.com/pydantic/pydantic/pull/6569)\n* add test for big int json serde by [@davidhewitt](https://github.com/davidhewitt) in [#6614](https://github.com/pydantic/pydantic/pull/6614)\n* Fix pydantic dataclass problem with dataclasses.field default_factory by [@hramezani](https://github.com/hramezani) in [#6616](https://github.com/pydantic/pydantic/pull/6616)\n* Fixed mypy type inference for TypeAdapter by [@zakstucke](https://github.com/zakstucke) in [#6617](https://github.com/pydantic/pydantic/pull/6617)\n* Make it work to use None as a generic parameter by [@dmontagu](https://github.com/dmontagu) in [#6609](https://github.com/pydantic/pydantic/pull/6609)\n* Make it work to use `$ref` as an alias by [@dmontagu](https://github.com/dmontagu) in [#6568](https://github.com/pydantic/pydantic/pull/6568)\n* add note to migration guide about changes to `AnyUrl` etc by [@davidhewitt](https://github.com/davidhewitt) in [#6618](https://github.com/pydantic/pydantic/pull/6618)\n* ðŸ› Support defining `json_schema_extra` on `RootModel` using `Field` by [@lig](https://github.com/lig) in [#6622](https://github.com/pydantic/pydantic/pull/6622)\n* Update pre-commit to prevent commits to main branch on accident by [@dmontagu](https://github.com/dmontagu) in [#6636](https://github.com/pydantic/pydantic/pull/6636)\n* Fix PDM CI for python 3.7 on MacOS/windows by [@dmontagu](https://github.com/dmontagu) in [#6627](https://github.com/pydantic/pydantic/pull/6627)\n* Produce more accurate signatures for pydantic dataclasses by [@dmontagu](https://github.com/dmontagu) in [#6633](https://github.com/pydantic/pydantic/pull/6633)\n* Updates to Url types for Pydantic V2 by [@tpdorsey](https://github.com/tpdorsey) in [#6638](https://github.com/pydantic/pydantic/pull/6638)\n* Fix list markdown in `transform` docstring by [@StefanBRas](https://github.com/StefanBRas) in [#6649](https://github.com/pydantic/pydantic/pull/6649)\n* simplify slots_dataclass construction to appease mypy by [@davidhewitt](https://github.com/davidhewitt) in [#6639](https://github.com/pydantic/pydantic/pull/6639)\n* Update TypedDict schema generation docstring by [@adriangb](https://github.com/adriangb) in [#6651](https://github.com/pydantic/pydantic/pull/6651)\n* Detect and lint-error for prints by [@dmontagu](https://github.com/dmontagu) in [#6655](https://github.com/pydantic/pydantic/pull/6655)\n* Add xfailing test for pydantic-core PR 766 by [@dmontagu](https://github.com/dmontagu) in [#6641](https://github.com/pydantic/pydantic/pull/6641)\n* Ignore unrecognized fields from dataclasses metadata by [@dmontagu](https://github.com/dmontagu) in [#6634](https://github.com/pydantic/pydantic/pull/6634)\n* Make non-existent class getattr a mypy error by [@dmontagu](https://github.com/dmontagu) in [#6658](https://github.com/pydantic/pydantic/pull/6658)\n* Update pydantic-core to 2.3.0 by [@hramezani](https://github.com/hramezani) in [#6648](https://github.com/pydantic/pydantic/pull/6648)\n* Use OrderedDict from typing_extensions by [@dmontagu](https://github.com/dmontagu) in [#6664](https://github.com/pydantic/pydantic/pull/6664)\n* Fix typehint for JSON schema extra callable by [@dmontagu](https://github.com/dmontagu) in [#6659](https://github.com/pydantic/pydantic/pull/6659)\n\n## v2.0.2 (2023-07-05)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.0.2)\n\n* Fix bug where round-trip pickling/unpickling a `RootModel` would change the value of `__dict__`, [#6457](https://github.com/pydantic/pydantic/pull/6457) by [@dmontagu](https://github.com/dmontagu)\n* Allow single-item discriminated unions, [#6405](https://github.com/pydantic/pydantic/pull/6405) by [@dmontagu](https://github.com/dmontagu)\n* Fix issue with union parsing of enums, [#6440](https://github.com/pydantic/pydantic/pull/6440) by [@dmontagu](https://github.com/dmontagu)\n* Docs: Fixed `constr` documentation, renamed old `regex` to new `pattern`, [#6452](https://github.com/pydantic/pydantic/pull/6452) by [@miili](https://github.com/miili)\n* Change `GenerateJsonSchema.generate_definitions` signature, [#6436](https://github.com/pydantic/pydantic/pull/6436) by [@dmontagu](https://github.com/dmontagu)\n\nSee the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0.2)\n\n## v2.0.1 (2023-07-04)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.0.1)\n\nFirst patch release of Pydantic V2\n\n* Extra fields added via `setattr` (i.e. `m.some_extra_field = 'extra_value'`)\n  are added to `.model_extra` if `model_config` `extra='allowed'`. Fixed [#6333](https://github.com/pydantic/pydantic/pull/6333), [#6365](https://github.com/pydantic/pydantic/pull/6365) by [@aaraney](https://github.com/aaraney)\n* Automatically unpack JSON schema '$ref' for custom types, [#6343](https://github.com/pydantic/pydantic/pull/6343) by [@adriangb](https://github.com/adriangb)\n* Fix tagged unions multiple processing in submodels, [#6340](https://github.com/pydantic/pydantic/pull/6340) by [@suharnikov](https://github.com/suharnikov)\n\nSee the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0.1)\n\n## v2.0 (2023-06-30)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.0)\n\nPydantic V2 is here! :tada:\n\nSee [this post](https://docs.pydantic.dev/2.0/blog/pydantic-v2-final/) for more details.\n\n## v2.0b3 (2023-06-16)\n\nThird beta pre-release of Pydantic V2\n\nSee the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0b3)\n\n## v2.0b2 (2023-06-03)\n\nAdd `from_attributes` runtime flag to `TypeAdapter.validate_python` and `BaseModel.model_validate`.\n\nSee the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0b2)\n\n## v2.0b1 (2023-06-01)\n\nFirst beta pre-release of Pydantic V2\n\nSee the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0b1)\n\n## v2.0a4 (2023-05-05)\n\nFourth pre-release of Pydantic V2\n\nSee the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0a4)\n\n## v2.0a3 (2023-04-20)\n\nThird pre-release of Pydantic V2\n\nSee the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0a3)\n\n## v2.0a2 (2023-04-12)\n\nSecond pre-release of Pydantic V2\n\nSee the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0a2)\n\n## v2.0a1 (2023-04-03)\n\nFirst pre-release of Pydantic V2!\n\nSee [this post](https://docs.pydantic.dev/blog/pydantic-v2-alpha/) for more details.\n\n\n... see [here](https://docs.pydantic.dev/changelog/#v0322-2019-08-17) for earlier changes.\n",
        "description_content_type": "text/markdown",
        "author_email": "Samuel Colvin <s@muelcolvin.com>, Eric Jolibois <em.jolibois@gmail.com>, Hasan Ramezani <hasan.r67@gmail.com>, Adrian Garcia Badaracco <1755071+adriangb@users.noreply.github.com>, Terrence Dorsey <terry@pydantic.dev>, David Montague <david@pydantic.dev>, Serge Matveenko <lig@countzero.co>, Marcelo Trylesinski <marcelotryle@gmail.com>, Sydney Runkle <sydneymarierunkle@gmail.com>, David Hewitt <mail@davidhewitt.io>, Alex Hall <alex.mojaki@gmail.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Environment :: MacOS X",
          "Framework :: Hypothesis",
          "Framework :: Pydantic",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: MIT License",
          "Operating System :: POSIX :: Linux",
          "Operating System :: Unix",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "annotated-types>=0.6.0",
          "pydantic-core==2.23.4",
          "typing-extensions>=4.12.2; python_version >= '3.13'",
          "typing-extensions>=4.6.1; python_version < '3.13'",
          "email-validator>=2.0.0; extra == 'email'",
          "tzdata; (python_version >= '3.9' and sys_platform == 'win32') and extra == 'timezone'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://github.com/pydantic/pydantic",
          "Documentation, https://docs.pydantic.dev",
          "Funding, https://github.com/sponsors/samuelcolvin",
          "Source, https://github.com/pydantic/pydantic",
          "Changelog, https://docs.pydantic.dev/latest/changelog/"
        ],
        "provides_extra": [
          "email",
          "timezone"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pydantic-2.9.2.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "pydantic_core",
        "version": "2.23.4",
        "summary": "Core functionality for Pydantic validation and serialization",
        "description": "# pydantic-core\n\n[![CI](https://github.com/pydantic/pydantic-core/workflows/ci/badge.svg?event=push)](https://github.com/pydantic/pydantic-core/actions?query=event%3Apush+branch%3Amain+workflow%3Aci)\n[![Coverage](https://codecov.io/gh/pydantic/pydantic-core/branch/main/graph/badge.svg)](https://codecov.io/gh/pydantic/pydantic-core)\n[![pypi](https://img.shields.io/pypi/v/pydantic-core.svg)](https://pypi.python.org/pypi/pydantic-core)\n[![versions](https://img.shields.io/pypi/pyversions/pydantic-core.svg)](https://github.com/pydantic/pydantic-core)\n[![license](https://img.shields.io/github/license/pydantic/pydantic-core.svg)](https://github.com/pydantic/pydantic-core/blob/main/LICENSE)\n\nThis package provides the core functionality for [pydantic](https://docs.pydantic.dev) validation and serialization.\n\nPydantic-core is currently around 17x faster than pydantic V1.\nSee [`tests/benchmarks/`](./tests/benchmarks/) for details.\n\n## Example of direct usage\n\n_NOTE: You should not need to use pydantic-core directly; instead, use pydantic, which in turn uses pydantic-core._\n\n```py\nfrom pydantic_core import SchemaValidator, ValidationError\n\n\nv = SchemaValidator(\n    {\n        'type': 'typed-dict',\n        'fields': {\n            'name': {\n                'type': 'typed-dict-field',\n                'schema': {\n                    'type': 'str',\n                },\n            },\n            'age': {\n                'type': 'typed-dict-field',\n                'schema': {\n                    'type': 'int',\n                    'ge': 18,\n                },\n            },\n            'is_developer': {\n                'type': 'typed-dict-field',\n                'schema': {\n                    'type': 'default',\n                    'schema': {'type': 'bool'},\n                    'default': True,\n                },\n            },\n        },\n    }\n)\n\nr1 = v.validate_python({'name': 'Samuel', 'age': 35})\nassert r1 == {'name': 'Samuel', 'age': 35, 'is_developer': True}\n\n# pydantic-core can also validate JSON directly\nr2 = v.validate_json('{\"name\": \"Samuel\", \"age\": 35}')\nassert r1 == r2\n\ntry:\n    v.validate_python({'name': 'Samuel', 'age': 11})\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for model\n    age\n      Input should be greater than or equal to 18\n      [type=greater_than_equal, context={ge: 18}, input_value=11, input_type=int]\n    \"\"\"\n```\n\n## Getting Started\n\nYou'll need rust stable [installed](https://rustup.rs/), or rust nightly if you want to generate accurate coverage.\n\nWith rust and python 3.8+ installed, compiling pydantic-core should be possible with roughly the following:\n\n```bash\n# clone this repo or your fork\ngit clone git@github.com:pydantic/pydantic-core.git\ncd pydantic-core\n# create a new virtual env\npython3 -m venv env\nsource env/bin/activate\n# install dependencies and install pydantic-core\nmake install\n```\n\nThat should be it, the example shown above should now run.\n\nYou might find it useful to look at [`python/pydantic_core/_pydantic_core.pyi`](./python/pydantic_core/_pydantic_core.pyi) and\n[`python/pydantic_core/core_schema.py`](./python/pydantic_core/core_schema.py) for more information on the python API,\nbeyond that, [`tests/`](./tests) provide a large number of examples of usage.\n\nIf you want to contribute to pydantic-core, you'll want to use some other make commands:\n* `make build-dev` to build the package during development\n* `make build-prod` to perform an optimised build for benchmarking\n* `make test` to run the tests\n* `make testcov` to run the tests and generate a coverage report\n* `make lint` to run the linter\n* `make format` to format python and rust code\n* `make` to run `format build-dev lint test`\n\n## Profiling\n\nIt's possible to profile the code using the [`flamegraph` utility from `flamegraph-rs`](https://github.com/flamegraph-rs/flamegraph). (Tested on Linux.) You can install this with `cargo install flamegraph`.\n\nRun `make build-profiling` to install a release build with debugging symbols included (needed for profiling).\n\nOnce that is built, you can profile pytest benchmarks with (e.g.):\n\n```bash\nflamegraph -- pytest tests/benchmarks/test_micro_benchmarks.py -k test_list_of_ints_core_py --benchmark-enable\n```\nThe `flamegraph` command will produce an interactive SVG at `flamegraph.svg`.\n\n## Releasing\n\n1. Bump package version locally. Do not just edit `Cargo.toml` on Github, you need both `Cargo.toml` and `Cargo.lock` to be updated.\n2. Make a PR for the version bump and merge it.\n3. Go to https://github.com/pydantic/pydantic-core/releases and click \"Draft a new release\"\n4. In the \"Choose a tag\" dropdown enter the new tag `v<the.new.version>` and select \"Create new tag on publish\" when the option appears.\n5. Enter the release title in the form \"v<the.new.version> <YYYY-MM-DD>\"\n6. Click Generate release notes button\n7. Click Publish release\n8. Go to https://github.com/pydantic/pydantic-core/actions and ensure that all build for release are done successfully.\n9. Go to https://pypi.org/project/pydantic-core/ and ensure that the latest release is published.\n10. Done ðŸŽ‰\n\n",
        "description_content_type": "text/markdown; charset=UTF-8; variant=GFM",
        "home_page": "https://github.com/pydantic/pydantic-core",
        "author_email": "Samuel Colvin <s@muelcolvin.com>",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Rust",
          "Framework :: Pydantic",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "License :: OSI Approved :: MIT License",
          "Operating System :: POSIX :: Linux",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: MacOS",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "typing-extensions >=4.6.0, !=4.7.0"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://github.com/pydantic/pydantic-core",
          "Funding, https://github.com/sponsors/samuelcolvin",
          "Source, https://github.com/pydantic/pydantic-core"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pydantic_core-2.23.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "Pygments",
        "version": "2.18.0",
        "summary": "Pygments is a syntax highlighting package written in Python.",
        "description": "Pygments\n~~~~~~~~\n\nPygments is a syntax highlighting package written in Python.\n\nIt is a generic syntax highlighter suitable for use in code hosting, forums,\nwikis or other applications that need to prettify source code.  Highlights\nare:\n\n* a wide range of over 500 languages and other text formats is supported\n* special attention is paid to details, increasing quality by a fair amount\n* support for new languages and formats are added easily\n* a number of output formats, presently HTML, LaTeX, RTF, SVG, all image\n  formats that PIL supports and ANSI sequences\n* it is usable as a command-line tool and as a library\n\nCopyright 2006-2024 by the Pygments team, see ``AUTHORS``.\nLicensed under the BSD, see ``LICENSE`` for details.\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "syntax",
          "highlighting"
        ],
        "author_email": "Georg Brandl <georg@python.org>",
        "maintainer": "MatthÃ¤us G. Chajdas",
        "maintainer_email": "Georg Brandl <georg@python.org>, Jean Abou Samra <jean@abou-samra.fr>",
        "license": "BSD-2-Clause",
        "license_file": [
          "AUTHORS",
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 6 - Mature",
          "Intended Audience :: Developers",
          "Intended Audience :: End Users/Desktop",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Text Processing :: Filters",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "colorama>=0.4.6; extra == 'windows-terminal'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://pygments.org",
          "Documentation, https://pygments.org/docs",
          "Source, https://github.com/pygments/pygments",
          "Bug Tracker, https://github.com/pygments/pygments/issues",
          "Changelog, https://github.com/pygments/pygments/blob/master/CHANGES"
        ],
        "provides_extra": [
          "plugins",
          "windows-terminal"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pygments-2.18.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "PyJWT",
        "version": "1.7.1",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "JSON Web Token implementation in Python",
        "description": "PyJWT\n=====\n\n.. image:: https://travis-ci.com/jpadilla/pyjwt.svg?branch=master\n   :target: http://travis-ci.com/jpadilla/pyjwt?branch=master\n\n.. image:: https://ci.appveyor.com/api/projects/status/h8nt70aqtwhht39t?svg=true\n   :target: https://ci.appveyor.com/project/jpadilla/pyjwt\n\n.. image:: https://img.shields.io/pypi/v/pyjwt.svg\n   :target: https://pypi.python.org/pypi/pyjwt\n\n.. image:: https://coveralls.io/repos/jpadilla/pyjwt/badge.svg?branch=master\n   :target: https://coveralls.io/r/jpadilla/pyjwt?branch=master\n\n.. image:: https://readthedocs.org/projects/pyjwt/badge/?version=latest\n   :target: https://pyjwt.readthedocs.io\n\nA Python implementation of `RFC 7519 <https://tools.ietf.org/html/rfc7519>`_. Original implementation was written by `@progrium <https://github.com/progrium>`_.\n\nSponsor\n-------\n\n+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| |auth0-logo| | If you want to quickly add secure token-based authentication to Python projects, feel free to check Auth0's Python SDK and free plan at `auth0.com/overview <https://auth0.com/overview?utm_source=GHsponsor&utm_medium=GHsponsor&utm_campaign=pyjwt&utm_content=auth>`_. |\n+--------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n.. |auth0-logo| image:: https://user-images.githubusercontent.com/83319/31722733-de95bbde-b3ea-11e7-96bf-4f4e8f915588.png\n\nInstalling\n----------\n\nInstall with **pip**:\n\n.. code-block:: sh\n\n    $ pip install PyJWT\n\n\nUsage\n-----\n\n.. code:: python\n\n    >>> import jwt\n    >>> encoded = jwt.encode({'some': 'payload'}, 'secret', algorithm='HS256')\n    'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb21lIjoicGF5bG9hZCJ9.4twFt5NiznN84AWoo1d7KO1T_yoc0Z6XOpOVswacPZg'\n\n    >>> jwt.decode(encoded, 'secret', algorithms=['HS256'])\n    {'some': 'payload'}\n\n\nCommand line\n------------\n\nUsage::\n\n    pyjwt [options] INPUT\n\nDecoding examples::\n\n    pyjwt --key=secret decode TOKEN\n    pyjwt decode --no-verify TOKEN\n\nSee more options executing ``pyjwt --help``.\n\n\nDocumentation\n-------------\n\nView the full docs online at https://pyjwt.readthedocs.io/en/latest/\n\n\nTests\n-----\n\nYou can run tests from the project root after cloning with:\n\n.. code-block:: sh\n\n    $ python setup.py test\n\n\n",
        "keywords": [
          "jwt",
          "json",
          "web",
          "token",
          "security",
          "signing"
        ],
        "home_page": "http://github.com/jpadilla/pyjwt",
        "author": "Jose Padilla",
        "author_email": "hello@jpadilla.com",
        "license": "MIT",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "cryptography (>=1.4) ; extra == 'crypto'",
          "flake8 ; extra == 'flake8'",
          "flake8-import-order ; extra == 'flake8'",
          "pep8-naming ; extra == 'flake8'",
          "pytest (<5.0.0,>=4.0.1) ; extra == 'test'",
          "pytest-cov (<3.0.0,>=2.6.0) ; extra == 'test'",
          "pytest-runner (<5.0.0,>=4.2) ; extra == 'test'"
        ],
        "provides_extra": [
          "crypto",
          "flake8",
          "test"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\PyJWT-1.7.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pylint",
        "version": "3.3.1",
        "summary": "python code static checker",
        "description": "`Pylint`_\n=========\n\n.. _`Pylint`: https://pylint.readthedocs.io/\n\n.. This is used inside the doc to recover the start of the introduction\n\n.. image:: https://github.com/pylint-dev/pylint/actions/workflows/tests.yaml/badge.svg?branch=main\n    :target: https://github.com/pylint-dev/pylint/actions\n\n.. image:: https://codecov.io/gh/pylint-dev/pylint/branch/main/graph/badge.svg?token=ZETEzayrfk\n    :target: https://codecov.io/gh/pylint-dev/pylint\n\n.. image:: https://img.shields.io/pypi/v/pylint.svg\n    :alt: PyPI Package version\n    :target: https://pypi.python.org/pypi/pylint\n\n.. image:: https://readthedocs.org/projects/pylint/badge/?version=latest\n    :target: https://pylint.readthedocs.io/en/latest/?badge=latest\n    :alt: Documentation Status\n\n.. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n    :target: https://github.com/ambv/black\n\n.. image:: https://img.shields.io/badge/linting-pylint-yellowgreen\n    :target: https://github.com/pylint-dev/pylint\n\n.. image:: https://results.pre-commit.ci/badge/github/pylint-dev/pylint/main.svg\n   :target: https://results.pre-commit.ci/latest/github/pylint-dev/pylint/main\n   :alt: pre-commit.ci status\n\n.. image:: https://bestpractices.coreinfrastructure.org/projects/6328/badge\n   :target: https://bestpractices.coreinfrastructure.org/projects/6328\n   :alt: CII Best Practices\n\n.. image:: https://img.shields.io/ossf-scorecard/github.com/PyCQA/pylint?label=openssf%20scorecard&style=flat\n   :target: https://api.securityscorecards.dev/projects/github.com/PyCQA/pylint\n   :alt: OpenSSF Scorecard\n\n.. image:: https://img.shields.io/discord/825463413634891776.svg\n   :target: https://discord.gg/qYxpadCgkx\n   :alt: Discord\n\nWhat is Pylint?\n---------------\n\nPylint is a `static code analyser`_ for Python 2 or 3. The latest version supports Python\n3.9.0 and above.\n\n.. _`static code analyser`: https://en.wikipedia.org/wiki/Static_code_analysis\n\nPylint analyses your code without actually running it. It checks for errors, enforces a\ncoding standard, looks for `code smells`_, and can make suggestions about how the code\ncould be refactored.\n\n.. _`code smells`: https://martinfowler.com/bliki/CodeSmell.html\n\nInstall\n-------\n\n.. This is used inside the doc to recover the start of the short text for installation\n\nFor command line use, pylint is installed with::\n\n    pip install pylint\n\nOr if you want to also check spelling with ``enchant`` (you might need to\n`install the enchant C library <https://pyenchant.github.io/pyenchant/install.html#installing-the-enchant-c-library>`_):\n\n.. code-block:: sh\n\n   pip install pylint[spelling]\n\nIt can also be integrated in most editors or IDEs. More information can be found\n`in the documentation`_.\n\n.. _in the documentation: https://pylint.readthedocs.io/en/latest/user_guide/installation/index.html\n\n.. This is used inside the doc to recover the end of the short text for installation\n\nWhat differentiates Pylint?\n---------------------------\n\nPylint is not trusting your typing and is inferring the actual values of nodes (for a\nstart because there was no typing when pylint started off) using its internal code\nrepresentation (astroid). If your code is ``import logging as argparse``, Pylint\ncan check and know that ``argparse.error(...)`` is in fact a logging call and not an\nargparse call. This makes pylint slower, but it also lets pylint find more issues if\nyour code is not fully typed.\n\n    [inference] is the killer feature that keeps us using [pylint] in our project despite how painfully slow it is.\n    - `Realist pylint user`_, 2022\n\n.. _`Realist pylint user`: https://github.com/charliermarsh/ruff/issues/970#issuecomment-1381067064\n\npylint, not afraid of being a little slower than it already is, is also a lot more thorough than other linters.\nThere are more checks, including some opinionated ones that are deactivated by default\nbut can be enabled using configuration.\n\nHow to use pylint\n-----------------\n\nPylint isn't smarter than you: it may warn you about things that you have\nconscientiously done or check for some things that you don't care about.\nDuring adoption, especially in a legacy project where pylint was never enforced,\nit's best to start with the ``--errors-only`` flag, then disable\nconvention and refactor messages with ``--disable=C,R`` and progressively\nre-evaluate and re-enable messages as your priorities evolve.\n\nPylint is highly configurable and permits to write plugins in order to add your\nown checks (for example, for internal libraries or an internal rule). Pylint also has an\necosystem of existing plugins for popular frameworks and third-party libraries.\n\n.. note::\n\n    Pylint supports the Python standard library out of the box. Third-party\n    libraries are not always supported, so a plugin might be needed. A good place\n    to start is ``PyPI`` which often returns a plugin by searching for\n    ``pylint <library>``. `pylint-pydantic`_, `pylint-django`_ and\n    `pylint-sonarjson`_ are examples of such plugins. More information about plugins\n    and how to load them can be found at `plugins`_.\n\n.. _`plugins`: https://pylint.readthedocs.io/en/latest/development_guide/how_tos/plugins.html#plugins\n.. _`pylint-pydantic`: https://pypi.org/project/pylint-pydantic\n.. _`pylint-django`: https://github.com/pylint-dev/pylint-django\n.. _`pylint-sonarjson`: https://github.com/cnescatlab/pylint-sonarjson-catlab\n\nAdvised linters alongside pylint\n--------------------------------\n\nProjects that you might want to use alongside pylint include ruff_ (**really** fast,\nwith builtin auto-fix and a large number of checks taken from popular linters, but\nimplemented in ``rust``) or flake8_ (a framework to implement your own checks in python using ``ast`` directly),\nmypy_, pyright_ / pylance or pyre_ (typing checks), bandit_ (security oriented checks), black_ and\nisort_ (auto-formatting), autoflake_ (automated removal of unused imports or variables), pyupgrade_\n(automated upgrade to newer python syntax) and pydocstringformatter_ (automated pep257).\n\n.. _ruff: https://github.com/astral-sh/ruff\n.. _flake8: https://github.com/PyCQA/flake8\n.. _bandit: https://github.com/PyCQA/bandit\n.. _mypy: https://github.com/python/mypy\n.. _pyright: https://github.com/microsoft/pyright\n.. _pyre: https://github.com/facebook/pyre-check\n.. _black: https://github.com/psf/black\n.. _autoflake: https://github.com/myint/autoflake\n.. _pyupgrade: https://github.com/asottile/pyupgrade\n.. _pydocstringformatter: https://github.com/DanielNoord/pydocstringformatter\n.. _isort: https://pycqa.github.io/isort/\n\nAdditional tools included in pylint\n-----------------------------------\n\nPylint ships with two additional tools:\n\n- pyreverse_ (standalone tool that generates package and class diagrams.)\n- symilar_  (duplicate code finder that is also integrated in pylint)\n\n.. _pyreverse: https://pylint.readthedocs.io/en/latest/pyreverse.html\n.. _symilar: https://pylint.readthedocs.io/en/latest/symilar.html\n\n\n.. This is used inside the doc to recover the end of the introduction\n\nContributing\n------------\n\n.. This is used inside the doc to recover the start of the short text for contribution\n\nWe welcome all forms of contributions such as updates for documentation, new code, checking issues for duplicates or telling us\nthat we can close them, confirming that issues still exist, `creating issues because\nyou found a bug or want a feature`_, etc. Everything is much appreciated!\n\nPlease follow the `code of conduct`_ and check `the Contributor Guides`_ if you want to\nmake a code contribution.\n\n.. _creating issues because you found a bug or want a feature: https://pylint.readthedocs.io/en/latest/contact.html#bug-reports-feedback\n.. _code of conduct: https://github.com/pylint-dev/pylint/blob/main/CODE_OF_CONDUCT.md\n.. _the Contributor Guides: https://pylint.readthedocs.io/en/latest/development_guide/contribute.html\n\n.. This is used inside the doc to recover the end of the short text for contribution\n\nShow your usage\n-----------------\n\nYou can place this badge in your README to let others know your project uses pylint.\n\n    .. image:: https://img.shields.io/badge/linting-pylint-yellowgreen\n        :target: https://github.com/pylint-dev/pylint\n\nLearn how to add a badge to your documentation in `the badge documentation`_.\n\n.. _the badge documentation: https://pylint.readthedocs.io/en/latest/user_guide/installation/badge.html\n\nLicense\n-------\n\npylint is, with a few exceptions listed below, `GPLv2 <https://github.com/pylint-dev/pylint/blob/main/LICENSE>`_.\n\nThe icon files are licensed under the `CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0/>`_ license:\n\n- `doc/logo.png <https://raw.githubusercontent.com/pylint-dev/pylint/main/doc/logo.png>`_\n- `doc/logo.svg <https://raw.githubusercontent.com/pylint-dev/pylint/main/doc/logo.svg>`_\n\nSupport\n-------\n\nPlease check `the contact information`_.\n\n.. _`the contact information`: https://pylint.readthedocs.io/en/latest/contact.html\n\n.. |tideliftlogo| image:: https://raw.githubusercontent.com/pylint-dev/pylint/main/doc/media/Tidelift_Logos_RGB_Tidelift_Shorthand_On-White.png\n   :width: 200\n   :alt: Tidelift\n\n.. list-table::\n   :widths: 10 100\n\n   * - |tideliftlogo|\n     - Professional support for pylint is available as part of the `Tidelift\n       Subscription`_.  Tidelift gives software development teams a single source for\n       purchasing and maintaining their software, with professional grade assurances\n       from the experts who know it best, while seamlessly integrating with existing\n       tools.\n\n.. _Tidelift Subscription: https://tidelift.com/subscription/pkg/pypi-pylint?utm_source=pypi-pylint&utm_medium=referral&utm_campaign=readme\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "static code analysis",
          "linter",
          "python",
          "lint"
        ],
        "author_email": "Python Code Quality Authority <code-quality@python.org>",
        "license": "GPL-2.0-or-later",
        "license_file": [
          "LICENSE",
          "CONTRIBUTORS.txt"
        ],
        "classifier": [
          "Development Status :: 6 - Mature",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: GNU General Public License v2 (GPLv2)",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Debuggers",
          "Topic :: Software Development :: Quality Assurance",
          "Topic :: Software Development :: Testing",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "platformdirs >=2.2.0",
          "astroid <=3.4.0-dev0,>=3.3.4",
          "isort !=5.13.0,<6,>=4.2.5",
          "mccabe <0.8,>=0.6",
          "tomlkit >=0.10.1",
          "typing-extensions >=3.10.0 ; python_version < \"3.10\"",
          "dill >=0.2 ; python_version < \"3.11\"",
          "tomli >=1.1.0 ; python_version < \"3.11\"",
          "dill >=0.3.6 ; python_version >= \"3.11\"",
          "dill >=0.3.7 ; python_version >= \"3.12\"",
          "colorama >=0.4.5 ; sys_platform == \"win32\"",
          "pyenchant ~=3.2 ; extra == 'spelling'",
          "gitpython >3 ; extra == 'testutils'"
        ],
        "requires_python": ">=3.9.0",
        "project_url": [
          "Docs: User Guide, https://pylint.readthedocs.io/en/latest/",
          "Source Code, https://github.com/pylint-dev/pylint",
          "homepage, https://github.com/pylint-dev/pylint",
          "What's New, https://pylint.readthedocs.io/en/latest/whatsnew/3/",
          "Bug Tracker, https://github.com/pylint-dev/pylint/issues",
          "Discord Server, https://discord.com/invite/Egy6P8AMB5",
          "Docs: Contributor Guide, https://pylint.readthedocs.io/en/latest/development_guide/contributor_guide/index.html"
        ],
        "provides_extra": [
          "spelling",
          "testutils"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pylint-3.3.1.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pyparsing",
        "version": "3.1.4",
        "summary": "pyparsing module - Classes and methods to define and execute parsing grammars",
        "description": "PyParsing -- A Python Parsing Module\n====================================\n\n|Version| |Build Status| |Coverage| |License| |Python Versions| |Snyk Score|\n\nIntroduction\n============\n\nThe pyparsing module is an alternative approach to creating and\nexecuting simple grammars, vs. the traditional lex/yacc approach, or the\nuse of regular expressions. The pyparsing module provides a library of\nclasses that client code uses to construct the grammar directly in\nPython code.\n\n*[Since first writing this description of pyparsing in late 2003, this\ntechnique for developing parsers has become more widespread, under the\nname Parsing Expression Grammars - PEGs. See more information on PEGs*\n`here <https://en.wikipedia.org/wiki/Parsing_expression_grammar>`__\n*.]*\n\nHere is a program to parse ``\"Hello, World!\"`` (or any greeting of the form\n``\"salutation, addressee!\"``):\n\n.. code:: python\n\n    from pyparsing import Word, alphas\n    greet = Word(alphas) + \",\" + Word(alphas) + \"!\"\n    hello = \"Hello, World!\"\n    print(hello, \"->\", greet.parseString(hello))\n\nThe program outputs the following::\n\n    Hello, World! -> ['Hello', ',', 'World', '!']\n\nThe Python representation of the grammar is quite readable, owing to the\nself-explanatory class names, and the use of '+', '|' and '^' operator\ndefinitions.\n\nThe parsed results returned from ``parseString()`` is a collection of type\n``ParseResults``, which can be accessed as a\nnested list, a dictionary, or an object with named attributes.\n\nThe pyparsing module handles some of the problems that are typically\nvexing when writing text parsers:\n\n- extra or missing whitespace (the above program will also handle ``\"Hello,World!\"``, ``\"Hello , World !\"``, etc.)\n- quoted strings\n- embedded comments\n\nThe examples directory includes a simple SQL parser, simple CORBA IDL\nparser, a config file parser, a chemical formula parser, and a four-\nfunction algebraic notation parser, among many others.\n\nDocumentation\n=============\n\nThere are many examples in the online docstrings of the classes\nand methods in pyparsing. You can find them compiled into `online docs <https://pyparsing-docs.readthedocs.io/en/latest/>`__. Additional\ndocumentation resources and project info are listed in the online\n`GitHub wiki <https://github.com/pyparsing/pyparsing/wiki>`__. An\nentire directory of examples can be found `here <https://github.com/pyparsing/pyparsing/tree/master/examples>`__.\n\nLicense\n=======\n\nMIT License. See header of the `pyparsing __init__.py <https://github.com/pyparsing/pyparsing/blob/master/pyparsing/__init__.py#L1-L23>`__ file.\n\nHistory\n=======\n\nSee `CHANGES <https://github.com/pyparsing/pyparsing/blob/master/CHANGES>`__ file.\n\n.. |Build Status| image:: https://github.com/pyparsing/pyparsing/actions/workflows/ci.yml/badge.svg\n   :target: https://github.com/pyparsing/pyparsing/actions/workflows/ci.yml\n\n.. |Coverage| image:: https://codecov.io/gh/pyparsing/pyparsing/branch/master/graph/badge.svg\n  :target: https://codecov.io/gh/pyparsing/pyparsing\n\n.. |Version| image:: https://img.shields.io/pypi/v/pyparsing?style=flat-square\n    :target: https://pypi.org/project/pyparsing/\n    :alt: Version\n\n.. |License| image:: https://img.shields.io/pypi/l/pyparsing.svg?style=flat-square\n    :target: https://pypi.org/project/pyparsing/\n    :alt: License\n\n.. |Python Versions| image:: https://img.shields.io/pypi/pyversions/pyparsing.svg?style=flat-square\n    :target: https://pypi.org/project/python-liquid/\n    :alt: Python versions\n\n.. |Snyk Score| image:: https://snyk.io//advisor/python/pyparsing/badge.svg\n   :target: https://snyk.io//advisor/python/pyparsing\n   :alt: pyparsing\n\n",
        "description_content_type": "text/x-rst",
        "author_email": "Paul McGuire <ptmcg.gm+pyparsing@gmail.com>",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Compilers",
          "Topic :: Text Processing",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "railroad-diagrams ; extra == \"diagrams\"",
          "jinja2 ; extra == \"diagrams\""
        ],
        "requires_python": ">=3.6.8",
        "project_url": [
          "Homepage, https://github.com/pyparsing/pyparsing/"
        ],
        "provides_extra": [
          "diagrams"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pyparsing-3.1.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pyproject_hooks",
        "version": "1.1.0",
        "summary": "Wrappers to call pyproject.toml-based build backend hooks.",
        "description": "``pyproject-hooks``\n===================\n\nThis is a low-level library for calling build-backends in ``pyproject.toml``-based project. It provides the basic functionality to help write tooling that generates distribution files from Python projects.\n\nIf you want a tool that builds Python packages, you'll want to use https://github.com/pypa/build instead. This is an underlying piece for `pip`, `build` and other \"build frontends\" use to call \"build backends\" within them.\n\nYou can read more in the `documentation <https://pyproject-hooks.readthedocs.io/>`_.\n\n  Note: The ``pep517`` project has been replaced by this project (low level) and the ``build`` project (high level).\n\n",
        "description_content_type": "text/x-rst",
        "author_email": "Thomas Kluyver <thomas@kluyver.me.uk>",
        "classifier": [
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Changelog, https://pyproject-hooks.readthedocs.io/en/latest/changelog.html",
          "Documentation, https://pyproject-hooks.readthedocs.io/",
          "Source, https://github.com/pypa/pyproject-hooks"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pyproject_hooks-1.1.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "python-dateutil",
        "version": "2.9.0.post0",
        "summary": "Extensions to the standard Python datetime module",
        "description": "dateutil - powerful extensions to datetime\n==========================================\n\n|pypi| |support| |licence|\n\n|gitter| |readthedocs|\n\n|travis| |appveyor| |pipelines| |coverage|\n\n.. |pypi| image:: https://img.shields.io/pypi/v/python-dateutil.svg?style=flat-square\n    :target: https://pypi.org/project/python-dateutil/\n    :alt: pypi version\n\n.. |support| image:: https://img.shields.io/pypi/pyversions/python-dateutil.svg?style=flat-square\n    :target: https://pypi.org/project/python-dateutil/\n    :alt: supported Python version\n\n.. |travis| image:: https://img.shields.io/travis/dateutil/dateutil/master.svg?style=flat-square&label=Travis%20Build\n    :target: https://travis-ci.org/dateutil/dateutil\n    :alt: travis build status\n\n.. |appveyor| image:: https://img.shields.io/appveyor/ci/dateutil/dateutil/master.svg?style=flat-square&logo=appveyor\n    :target: https://ci.appveyor.com/project/dateutil/dateutil\n    :alt: appveyor build status\n\n.. |pipelines| image:: https://dev.azure.com/pythondateutilazure/dateutil/_apis/build/status/dateutil.dateutil?branchName=master\n    :target: https://dev.azure.com/pythondateutilazure/dateutil/_build/latest?definitionId=1&branchName=master\n    :alt: azure pipelines build status\n\n.. |coverage| image:: https://codecov.io/gh/dateutil/dateutil/branch/master/graphs/badge.svg?branch=master\n    :target: https://codecov.io/gh/dateutil/dateutil?branch=master\n    :alt: Code coverage\n\n.. |gitter| image:: https://badges.gitter.im/dateutil/dateutil.svg\n   :alt: Join the chat at https://gitter.im/dateutil/dateutil\n   :target: https://gitter.im/dateutil/dateutil\n\n.. |licence| image:: https://img.shields.io/pypi/l/python-dateutil.svg?style=flat-square\n    :target: https://pypi.org/project/python-dateutil/\n    :alt: licence\n\n.. |readthedocs| image:: https://img.shields.io/readthedocs/dateutil/latest.svg?style=flat-square&label=Read%20the%20Docs\n   :alt: Read the documentation at https://dateutil.readthedocs.io/en/latest/\n   :target: https://dateutil.readthedocs.io/en/latest/\n\nThe `dateutil` module provides powerful extensions to\nthe standard `datetime` module, available in Python.\n\nInstallation\n============\n`dateutil` can be installed from PyPI using `pip` (note that the package name is\ndifferent from the importable name)::\n\n    pip install python-dateutil\n\nDownload\n========\ndateutil is available on PyPI\nhttps://pypi.org/project/python-dateutil/\n\nThe documentation is hosted at:\nhttps://dateutil.readthedocs.io/en/stable/\n\nCode\n====\nThe code and issue tracker are hosted on GitHub:\nhttps://github.com/dateutil/dateutil/\n\nFeatures\n========\n\n* Computing of relative deltas (next month, next year,\n  next Monday, last week of month, etc);\n* Computing of relative deltas between two given\n  date and/or datetime objects;\n* Computing of dates based on very flexible recurrence rules,\n  using a superset of the `iCalendar <https://www.ietf.org/rfc/rfc2445.txt>`_\n  specification. Parsing of RFC strings is supported as well.\n* Generic parsing of dates in almost any string format;\n* Timezone (tzinfo) implementations for tzfile(5) format\n  files (/etc/localtime, /usr/share/zoneinfo, etc), TZ\n  environment string (in all known formats), iCalendar\n  format files, given ranges (with help from relative deltas),\n  local machine timezone, fixed offset timezone, UTC timezone,\n  and Windows registry-based time zones.\n* Internal up-to-date world timezone information based on\n  Olson's database.\n* Computing of Easter Sunday dates for any given year,\n  using Western, Orthodox or Julian algorithms;\n* A comprehensive test suite.\n\nQuick example\n=============\nHere's a snapshot, just to give an idea about the power of the\npackage. For more examples, look at the documentation.\n\nSuppose you want to know how much time is left, in\nyears/months/days/etc, before the next easter happening on a\nyear with a Friday 13th in August, and you want to get today's\ndate out of the \"date\" unix system command. Here is the code:\n\n.. code-block:: python3\n\n    >>> from dateutil.relativedelta import *\n    >>> from dateutil.easter import *\n    >>> from dateutil.rrule import *\n    >>> from dateutil.parser import *\n    >>> from datetime import *\n    >>> now = parse(\"Sat Oct 11 17:13:46 UTC 2003\")\n    >>> today = now.date()\n    >>> year = rrule(YEARLY,dtstart=now,bymonth=8,bymonthday=13,byweekday=FR)[0].year\n    >>> rdelta = relativedelta(easter(year), today)\n    >>> print(\"Today is: %s\" % today)\n    Today is: 2003-10-11\n    >>> print(\"Year with next Aug 13th on a Friday is: %s\" % year)\n    Year with next Aug 13th on a Friday is: 2004\n    >>> print(\"How far is the Easter of that year: %s\" % rdelta)\n    How far is the Easter of that year: relativedelta(months=+6)\n    >>> print(\"And the Easter of that year is: %s\" % (today+rdelta))\n    And the Easter of that year is: 2004-04-11\n\nBeing exactly 6 months ahead was **really** a coincidence :)\n\nContributing\n============\n\nWe welcome many types of contributions - bug reports, pull requests (code, infrastructure or documentation fixes). For more information about how to contribute to the project, see the ``CONTRIBUTING.md`` file in the repository.\n\n\nAuthor\n======\nThe dateutil module was written by Gustavo Niemeyer <gustavo@niemeyer.net>\nin 2003.\n\nIt is maintained by:\n\n* Gustavo Niemeyer <gustavo@niemeyer.net> 2003-2011\n* Tomi PievilÃ¤inen <tomi.pievilainen@iki.fi> 2012-2014\n* Yaron de Leeuw <me@jarondl.net> 2014-2016\n* Paul Ganssle <paul@ganssle.io> 2015-\n\nStarting with version 2.4.1 and running until 2.8.2, all source and binary\ndistributions will be signed by a PGP key that has, at the very least, been\nsigned by the key which made the previous release. A table of release signing\nkeys can be found below:\n\n===========  ============================\nReleases     Signing key fingerprint\n===========  ============================\n2.4.1-2.8.2  `6B49 ACBA DCF6 BD1C A206 67AB CD54 FCE3 D964 BEFB`_\n===========  ============================\n\nNew releases *may* have signed tags, but binary and source distributions\nuploaded to PyPI will no longer have GPG signatures attached.\n\nContact\n=======\nOur mailing list is available at `dateutil@python.org <https://mail.python.org/mailman/listinfo/dateutil>`_. As it is hosted by the PSF, it is subject to the `PSF code of\nconduct <https://www.python.org/psf/conduct/>`_.\n\nLicense\n=======\n\nAll contributions after December 1, 2017 released under dual license - either `Apache 2.0 License <https://www.apache.org/licenses/LICENSE-2.0>`_ or the `BSD 3-Clause License <https://opensource.org/licenses/BSD-3-Clause>`_. Contributions before December 1, 2017 - except those those explicitly relicensed - are released only under the BSD 3-Clause License.\n\n\n.. _6B49 ACBA DCF6 BD1C A206 67AB CD54 FCE3 D964 BEFB:\n   https://pgp.mit.edu/pks/lookup?op=vindex&search=0xCD54FCE3D964BEFB\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/dateutil/dateutil",
        "author": "Gustavo Niemeyer",
        "author_email": "gustavo@niemeyer.net",
        "maintainer": "Paul Ganssle",
        "maintainer_email": "dateutil@python.org",
        "license": "Dual License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Software Development :: Libraries"
        ],
        "requires_dist": [
          "six >=1.5"
        ],
        "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,>=2.7",
        "project_url": [
          "Documentation, https://dateutil.readthedocs.io/en/stable/",
          "Source, https://github.com/dateutil/dateutil"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\python_dateutil-2.9.0.post0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pytz",
        "version": "2024.1",
        "platform": [
          "Independent"
        ],
        "summary": "World timezone definitions, modern and historical",
        "description": "pytz - World Timezone Definitions for Python\n============================================\n\n:Author: Stuart Bishop <stuart@stuartbishop.net>\n\nIntroduction\n~~~~~~~~~~~~\n\npytz brings the Olson tz database into Python. This library allows\naccurate and cross platform timezone calculations using Python 2.4\nor higher. It also solves the issue of ambiguous times at the end\nof daylight saving time, which you can read more about in the Python\nLibrary Reference (``datetime.tzinfo``).\n\nAlmost all of the Olson timezones are supported.\n\n.. note::\n\n    Projects using Python 3.9 or later should be using the support\n    now included as part of the standard library, and third party\n    packages work with it such as `tzdata <https://pypi.org/project/tzdata/>`_.\n    pytz offers no advantages beyond backwards compatibility with\n    code written for earlier versions of Python.\n\n.. note::\n\n    This library differs from the documented Python API for\n    tzinfo implementations; if you want to create local wallclock\n    times you need to use the ``localize()`` method documented in this\n    document. In addition, if you perform date arithmetic on local\n    times that cross DST boundaries, the result may be in an incorrect\n    timezone (ie. subtract 1 minute from 2002-10-27 1:00 EST and you get\n    2002-10-27 0:59 EST instead of the correct 2002-10-27 1:59 EDT). A\n    ``normalize()`` method is provided to correct this. Unfortunately these\n    issues cannot be resolved without modifying the Python datetime\n    implementation (see PEP-431).\n\n\nInstallation\n~~~~~~~~~~~~\n\nThis package can either be installed using ``pip`` or from a tarball using the\nstandard Python distutils.\n\nIf you are installing using ``pip``, you don't need to download anything as the\nlatest version will be downloaded for you from PyPI::\n\n    pip install pytz\n\nIf you are installing from a tarball, run the following command as an\nadministrative user::\n\n    python setup.py install\n\n\npytz for Enterprise\n~~~~~~~~~~~~~~~~~~~\n\nAvailable as part of the Tidelift Subscription.\n\nThe maintainers of pytz and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. `Learn more. <https://tidelift.com/subscription/pkg/pypi-pytz?utm_source=pypi-pytz&utm_medium=referral&utm_campaign=enterprise&utm_term=repo>`_.\n\n\nExample & Usage\n~~~~~~~~~~~~~~~\n\nLocalized times and date arithmetic\n-----------------------------------\n\n>>> from datetime import datetime, timedelta\n>>> from pytz import timezone\n>>> import pytz\n>>> utc = pytz.utc\n>>> utc.zone\n'UTC'\n>>> eastern = timezone('US/Eastern')\n>>> eastern.zone\n'US/Eastern'\n>>> amsterdam = timezone('Europe/Amsterdam')\n>>> fmt = '%Y-%m-%d %H:%M:%S %Z%z'\n\nThis library only supports two ways of building a localized time. The\nfirst is to use the ``localize()`` method provided by the pytz library.\nThis is used to localize a naive datetime (datetime with no timezone\ninformation):\n\n>>> loc_dt = eastern.localize(datetime(2002, 10, 27, 6, 0, 0))\n>>> print(loc_dt.strftime(fmt))\n2002-10-27 06:00:00 EST-0500\n\nThe second way of building a localized time is by converting an existing\nlocalized time using the standard ``astimezone()`` method:\n\n>>> ams_dt = loc_dt.astimezone(amsterdam)\n>>> ams_dt.strftime(fmt)\n'2002-10-27 12:00:00 CET+0100'\n\nUnfortunately using the tzinfo argument of the standard datetime\nconstructors ''does not work'' with pytz for many timezones.\n\n>>> datetime(2002, 10, 27, 12, 0, 0, tzinfo=amsterdam).strftime(fmt)  # /!\\ Does not work this way!\n'2002-10-27 12:00:00 LMT+0018'\n\nIt is safe for timezones without daylight saving transitions though, such\nas UTC:\n\n>>> datetime(2002, 10, 27, 12, 0, 0, tzinfo=pytz.utc).strftime(fmt)  # /!\\ Not recommended except for UTC\n'2002-10-27 12:00:00 UTC+0000'\n\nThe preferred way of dealing with times is to always work in UTC,\nconverting to localtime only when generating output to be read\nby humans.\n\n>>> utc_dt = datetime(2002, 10, 27, 6, 0, 0, tzinfo=utc)\n>>> loc_dt = utc_dt.astimezone(eastern)\n>>> loc_dt.strftime(fmt)\n'2002-10-27 01:00:00 EST-0500'\n\nThis library also allows you to do date arithmetic using local\ntimes, although it is more complicated than working in UTC as you\nneed to use the ``normalize()`` method to handle daylight saving time\nand other timezone transitions. In this example, ``loc_dt`` is set\nto the instant when daylight saving time ends in the US/Eastern\ntimezone.\n\n>>> before = loc_dt - timedelta(minutes=10)\n>>> before.strftime(fmt)\n'2002-10-27 00:50:00 EST-0500'\n>>> eastern.normalize(before).strftime(fmt)\n'2002-10-27 01:50:00 EDT-0400'\n>>> after = eastern.normalize(before + timedelta(minutes=20))\n>>> after.strftime(fmt)\n'2002-10-27 01:10:00 EST-0500'\n\nCreating local times is also tricky, and the reason why working with\nlocal times is not recommended. Unfortunately, you cannot just pass\na ``tzinfo`` argument when constructing a datetime (see the next\nsection for more details)\n\n>>> dt = datetime(2002, 10, 27, 1, 30, 0)\n>>> dt1 = eastern.localize(dt, is_dst=True)\n>>> dt1.strftime(fmt)\n'2002-10-27 01:30:00 EDT-0400'\n>>> dt2 = eastern.localize(dt, is_dst=False)\n>>> dt2.strftime(fmt)\n'2002-10-27 01:30:00 EST-0500'\n\nConverting between timezones is more easily done, using the\nstandard astimezone method.\n\n>>> utc_dt = datetime.fromtimestamp(1143408899, tz=utc)\n>>> utc_dt.strftime(fmt)\n'2006-03-26 21:34:59 UTC+0000'\n>>> au_tz = timezone('Australia/Sydney')\n>>> au_dt = utc_dt.astimezone(au_tz)\n>>> au_dt.strftime(fmt)\n'2006-03-27 08:34:59 AEDT+1100'\n>>> utc_dt2 = au_dt.astimezone(utc)\n>>> utc_dt2.strftime(fmt)\n'2006-03-26 21:34:59 UTC+0000'\n>>> utc_dt == utc_dt2\nTrue\n\nYou can take shortcuts when dealing with the UTC side of timezone\nconversions. ``normalize()`` and ``localize()`` are not really\nnecessary when there are no daylight saving time transitions to\ndeal with.\n\n>>> utc_dt = datetime.fromtimestamp(1143408899, tz=utc)\n>>> utc_dt.strftime(fmt)\n'2006-03-26 21:34:59 UTC+0000'\n>>> au_tz = timezone('Australia/Sydney')\n>>> au_dt = au_tz.normalize(utc_dt.astimezone(au_tz))\n>>> au_dt.strftime(fmt)\n'2006-03-27 08:34:59 AEDT+1100'\n>>> utc_dt2 = au_dt.astimezone(utc)\n>>> utc_dt2.strftime(fmt)\n'2006-03-26 21:34:59 UTC+0000'\n\n\n``tzinfo`` API\n--------------\n\nThe ``tzinfo`` instances returned by the ``timezone()`` function have\nbeen extended to cope with ambiguous times by adding an ``is_dst``\nparameter to the ``utcoffset()``, ``dst()`` && ``tzname()`` methods.\n\n>>> tz = timezone('America/St_Johns')\n\n>>> normal = datetime(2009, 9, 1)\n>>> ambiguous = datetime(2009, 10, 31, 23, 30)\n\nThe ``is_dst`` parameter is ignored for most timestamps. It is only used\nduring DST transition ambiguous periods to resolve that ambiguity.\n\n>>> print(tz.utcoffset(normal, is_dst=True))\n-1 day, 21:30:00\n>>> print(tz.dst(normal, is_dst=True))\n1:00:00\n>>> tz.tzname(normal, is_dst=True)\n'NDT'\n\n>>> print(tz.utcoffset(ambiguous, is_dst=True))\n-1 day, 21:30:00\n>>> print(tz.dst(ambiguous, is_dst=True))\n1:00:00\n>>> tz.tzname(ambiguous, is_dst=True)\n'NDT'\n\n>>> print(tz.utcoffset(normal, is_dst=False))\n-1 day, 21:30:00\n>>> tz.dst(normal, is_dst=False).seconds\n3600\n>>> tz.tzname(normal, is_dst=False)\n'NDT'\n\n>>> print(tz.utcoffset(ambiguous, is_dst=False))\n-1 day, 20:30:00\n>>> tz.dst(ambiguous, is_dst=False)\ndatetime.timedelta(0)\n>>> tz.tzname(ambiguous, is_dst=False)\n'NST'\n\nIf ``is_dst`` is not specified, ambiguous timestamps will raise\nan ``pytz.exceptions.AmbiguousTimeError`` exception.\n\n>>> print(tz.utcoffset(normal))\n-1 day, 21:30:00\n>>> print(tz.dst(normal))\n1:00:00\n>>> tz.tzname(normal)\n'NDT'\n\n>>> import pytz.exceptions\n>>> try:\n...     tz.utcoffset(ambiguous)\n... except pytz.exceptions.AmbiguousTimeError:\n...     print('pytz.exceptions.AmbiguousTimeError: %s' % ambiguous)\npytz.exceptions.AmbiguousTimeError: 2009-10-31 23:30:00\n>>> try:\n...     tz.dst(ambiguous)\n... except pytz.exceptions.AmbiguousTimeError:\n...     print('pytz.exceptions.AmbiguousTimeError: %s' % ambiguous)\npytz.exceptions.AmbiguousTimeError: 2009-10-31 23:30:00\n>>> try:\n...     tz.tzname(ambiguous)\n... except pytz.exceptions.AmbiguousTimeError:\n...     print('pytz.exceptions.AmbiguousTimeError: %s' % ambiguous)\npytz.exceptions.AmbiguousTimeError: 2009-10-31 23:30:00\n\n\nProblems with Localtime\n~~~~~~~~~~~~~~~~~~~~~~~\n\nThe major problem we have to deal with is that certain datetimes\nmay occur twice in a year. For example, in the US/Eastern timezone\non the last Sunday morning in October, the following sequence\nhappens:\n\n    - 01:00 EDT occurs\n    - 1 hour later, instead of 2:00am the clock is turned back 1 hour\n      and 01:00 happens again (this time 01:00 EST)\n\nIn fact, every instant between 01:00 and 02:00 occurs twice. This means\nthat if you try and create a time in the 'US/Eastern' timezone\nthe standard datetime syntax, there is no way to specify if you meant\nbefore of after the end-of-daylight-saving-time transition. Using the\npytz custom syntax, the best you can do is make an educated guess:\n\n>>> loc_dt = eastern.localize(datetime(2002, 10, 27, 1, 30, 00))\n>>> loc_dt.strftime(fmt)\n'2002-10-27 01:30:00 EST-0500'\n\nAs you can see, the system has chosen one for you and there is a 50%\nchance of it being out by one hour. For some applications, this does\nnot matter. However, if you are trying to schedule meetings with people\nin different timezones or analyze log files it is not acceptable.\n\nThe best and simplest solution is to stick with using UTC.  The pytz\npackage encourages using UTC for internal timezone representation by\nincluding a special UTC implementation based on the standard Python\nreference implementation in the Python documentation.\n\nThe UTC timezone unpickles to be the same instance, and pickles to a\nsmaller size than other pytz tzinfo instances.  The UTC implementation\ncan be obtained as pytz.utc, pytz.UTC, or pytz.timezone('UTC').\n\n>>> import pickle, pytz\n>>> dt = datetime(2005, 3, 1, 14, 13, 21, tzinfo=utc)\n>>> naive = dt.replace(tzinfo=None)\n>>> p = pickle.dumps(dt, 1)\n>>> naive_p = pickle.dumps(naive, 1)\n>>> len(p) - len(naive_p)\n17\n>>> new = pickle.loads(p)\n>>> new == dt\nTrue\n>>> new is dt\nFalse\n>>> new.tzinfo is dt.tzinfo\nTrue\n>>> pytz.utc is pytz.UTC is pytz.timezone('UTC')\nTrue\n\nNote that some other timezones are commonly thought of as the same (GMT,\nGreenwich, Universal, etc.). The definition of UTC is distinct from these\nother timezones, and they are not equivalent. For this reason, they will\nnot compare the same in Python.\n\n>>> utc == pytz.timezone('GMT')\nFalse\n\nSee the section `What is UTC`_, below.\n\nIf you insist on working with local times, this library provides a\nfacility for constructing them unambiguously:\n\n>>> loc_dt = datetime(2002, 10, 27, 1, 30, 00)\n>>> est_dt = eastern.localize(loc_dt, is_dst=True)\n>>> edt_dt = eastern.localize(loc_dt, is_dst=False)\n>>> print(est_dt.strftime(fmt) + ' / ' + edt_dt.strftime(fmt))\n2002-10-27 01:30:00 EDT-0400 / 2002-10-27 01:30:00 EST-0500\n\nIf you pass None as the is_dst flag to localize(), pytz will refuse to\nguess and raise exceptions if you try to build ambiguous or non-existent\ntimes.\n\nFor example, 1:30am on 27th Oct 2002 happened twice in the US/Eastern\ntimezone when the clocks where put back at the end of Daylight Saving\nTime:\n\n>>> dt = datetime(2002, 10, 27, 1, 30, 00)\n>>> try:\n...     eastern.localize(dt, is_dst=None)\n... except pytz.exceptions.AmbiguousTimeError:\n...     print('pytz.exceptions.AmbiguousTimeError: %s' % dt)\npytz.exceptions.AmbiguousTimeError: 2002-10-27 01:30:00\n\nSimilarly, 2:30am on 7th April 2002 never happened at all in the\nUS/Eastern timezone, as the clocks where put forward at 2:00am skipping\nthe entire hour:\n\n>>> dt = datetime(2002, 4, 7, 2, 30, 00)\n>>> try:\n...     eastern.localize(dt, is_dst=None)\n... except pytz.exceptions.NonExistentTimeError:\n...     print('pytz.exceptions.NonExistentTimeError: %s' % dt)\npytz.exceptions.NonExistentTimeError: 2002-04-07 02:30:00\n\nBoth of these exceptions share a common base class to make error handling\neasier:\n\n>>> isinstance(pytz.AmbiguousTimeError(), pytz.InvalidTimeError)\nTrue\n>>> isinstance(pytz.NonExistentTimeError(), pytz.InvalidTimeError)\nTrue\n\n\nA special case is where countries change their timezone definitions\nwith no daylight savings time switch. For example, in 1915 Warsaw\nswitched from Warsaw time to Central European time with no daylight savings\ntransition. So at the stroke of midnight on August 5th 1915 the clocks\nwere wound back 24 minutes creating an ambiguous time period that cannot\nbe specified without referring to the timezone abbreviation or the\nactual UTC offset. In this case midnight happened twice, neither time\nduring a daylight saving time period. pytz handles this transition by\ntreating the ambiguous period before the switch as daylight savings\ntime, and the ambiguous period after as standard time.\n\n\n>>> warsaw = pytz.timezone('Europe/Warsaw')\n>>> amb_dt1 = warsaw.localize(datetime(1915, 8, 4, 23, 59, 59), is_dst=True)\n>>> amb_dt1.strftime(fmt)\n'1915-08-04 23:59:59 WMT+0124'\n>>> amb_dt2 = warsaw.localize(datetime(1915, 8, 4, 23, 59, 59), is_dst=False)\n>>> amb_dt2.strftime(fmt)\n'1915-08-04 23:59:59 CET+0100'\n>>> switch_dt = warsaw.localize(datetime(1915, 8, 5, 00, 00, 00), is_dst=False)\n>>> switch_dt.strftime(fmt)\n'1915-08-05 00:00:00 CET+0100'\n>>> str(switch_dt - amb_dt1)\n'0:24:01'\n>>> str(switch_dt - amb_dt2)\n'0:00:01'\n\nThe best way of creating a time during an ambiguous time period is\nby converting from another timezone such as UTC:\n\n>>> utc_dt = datetime(1915, 8, 4, 22, 36, tzinfo=pytz.utc)\n>>> utc_dt.astimezone(warsaw).strftime(fmt)\n'1915-08-04 23:36:00 CET+0100'\n\nThe standard Python way of handling all these ambiguities is not to\nhandle them, such as demonstrated in this example using the US/Eastern\ntimezone definition from the Python documentation (Note that this\nimplementation only works for dates between 1987 and 2006 - it is\nincluded for tests only!):\n\n>>> from pytz.reference import Eastern # pytz.reference only for tests\n>>> dt = datetime(2002, 10, 27, 0, 30, tzinfo=Eastern)\n>>> str(dt)\n'2002-10-27 00:30:00-04:00'\n>>> str(dt + timedelta(hours=1))\n'2002-10-27 01:30:00-05:00'\n>>> str(dt + timedelta(hours=2))\n'2002-10-27 02:30:00-05:00'\n>>> str(dt + timedelta(hours=3))\n'2002-10-27 03:30:00-05:00'\n\nNotice the first two results? At first glance you might think they are\ncorrect, but taking the UTC offset into account you find that they are\nactually two hours appart instead of the 1 hour we asked for.\n\n>>> from pytz.reference import UTC # pytz.reference only for tests\n>>> str(dt.astimezone(UTC))\n'2002-10-27 04:30:00+00:00'\n>>> str((dt + timedelta(hours=1)).astimezone(UTC))\n'2002-10-27 06:30:00+00:00'\n\n\nCountry Information\n~~~~~~~~~~~~~~~~~~~\n\nA mechanism is provided to access the timezones commonly in use\nfor a particular country, looked up using the ISO 3166 country code.\nIt returns a list of strings that can be used to retrieve the relevant\ntzinfo instance using ``pytz.timezone()``:\n\n>>> print(' '.join(pytz.country_timezones['nz']))\nPacific/Auckland Pacific/Chatham\n\nThe Olson database comes with a ISO 3166 country code to English country\nname mapping that pytz exposes as a dictionary:\n\n>>> print(pytz.country_names['nz'])\nNew Zealand\n\n\nWhat is UTC\n~~~~~~~~~~~\n\n'UTC' is `Coordinated Universal Time`_. It is a successor to, but distinct\nfrom, Greenwich Mean Time (GMT) and the various definitions of Universal\nTime. UTC is now the worldwide standard for regulating clocks and time\nmeasurement.\n\nAll other timezones are defined relative to UTC, and include offsets like\nUTC+0800 - hours to add or subtract from UTC to derive the local time. No\ndaylight saving time occurs in UTC, making it a useful timezone to perform\ndate arithmetic without worrying about the confusion and ambiguities caused\nby daylight saving time transitions, your country changing its timezone, or\nmobile computers that roam through multiple timezones.\n\n..  _Coordinated Universal Time: https://en.wikipedia.org/wiki/Coordinated_Universal_Time\n\n\nHelpers\n~~~~~~~\n\nThere are two lists of timezones provided.\n\n``all_timezones`` is the exhaustive list of the timezone names that can\nbe used.\n\n>>> from pytz import all_timezones\n>>> len(all_timezones) >= 500\nTrue\n>>> 'Etc/Greenwich' in all_timezones\nTrue\n\n``common_timezones`` is a list of useful, current timezones. It doesn't\ncontain deprecated zones or historical zones, except for a few I've\ndeemed in common usage, such as US/Eastern (open a bug report if you\nthink other timezones are deserving of being included here). It is also\na sequence of strings.\n\n>>> from pytz import common_timezones\n>>> len(common_timezones) < len(all_timezones)\nTrue\n>>> 'Etc/Greenwich' in common_timezones\nFalse\n>>> 'Australia/Melbourne' in common_timezones\nTrue\n>>> 'US/Eastern' in common_timezones\nTrue\n>>> 'Canada/Eastern' in common_timezones\nTrue\n>>> 'Australia/Yancowinna' in all_timezones\nTrue\n>>> 'Australia/Yancowinna' in common_timezones\nFalse\n\nBoth ``common_timezones`` and ``all_timezones`` are alphabetically\nsorted:\n\n>>> common_timezones_dupe = common_timezones[:]\n>>> common_timezones_dupe.sort()\n>>> common_timezones == common_timezones_dupe\nTrue\n>>> all_timezones_dupe = all_timezones[:]\n>>> all_timezones_dupe.sort()\n>>> all_timezones == all_timezones_dupe\nTrue\n\n``all_timezones`` and ``common_timezones`` are also available as sets.\n\n>>> from pytz import all_timezones_set, common_timezones_set\n>>> 'US/Eastern' in all_timezones_set\nTrue\n>>> 'US/Eastern' in common_timezones_set\nTrue\n>>> 'Australia/Victoria' in common_timezones_set\nFalse\n\nYou can also retrieve lists of timezones used by particular countries\nusing the ``country_timezones()`` function. It requires an ISO-3166\ntwo letter country code.\n\n>>> from pytz import country_timezones\n>>> print(' '.join(country_timezones('ch')))\nEurope/Zurich\n>>> print(' '.join(country_timezones('CH')))\nEurope/Zurich\n\n\nInternationalization - i18n/l10n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nPytz is an interface to the IANA database, which uses ASCII names. The `Unicode  Consortium's Unicode Locales (CLDR) <http://cldr.unicode.org>`_\nproject provides translations. Python packages such as\n`Babel <https://babel.pocoo.org/en/latest/api/dates.html#timezone-functionality>`_\nand Thomas Khyn's `l18n <https://pypi.org/project/l18n/>`_ package can be used\nto access these translations from Python.\n\n\nLicense\n~~~~~~~\n\nMIT license.\n\nThis code is also available as part of Zope 3 under the Zope Public\nLicense,  Version 2.1 (ZPL).\n\nI'm happy to relicense this code if necessary for inclusion in other\nopen source projects.\n\n\nLatest Versions\n~~~~~~~~~~~~~~~\n\nThis package will be updated after releases of the Olson timezone\ndatabase.  The latest version can be downloaded from the `Python Package\nIndex <https://pypi.org/project/pytz/>`_.  The code that is used\nto generate this distribution is hosted on Github and available\nusing git::\n\n    git clone https://github.com/stub42/pytz.git\n\nAnnouncements of new releases are made on\n`Launchpad <https://launchpad.net/pytz>`_, and the\n`Atom feed <http://feeds.launchpad.net/pytz/announcements.atom>`_\nhosted there.\n\n\nBugs, Feature Requests & Patches\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nBugs should be reported on `Github <https://github.com/stub42/pytz/issues>`_.\nFeature requests are unlikely to be considered, and efforts instead directed\nto timezone support now built into Python or packages that work with it.\n\n\nSecurity Issues\n~~~~~~~~~~~~~~~\n\nReports about security issues can be made via `Tidelift <https://tidelift.com/security>`_.\n\n\nIssues & Limitations\n~~~~~~~~~~~~~~~~~~~~\n\n- This project is in maintenance mode. Projects using Python 3.9 or later\n  are best served by using the timezone functionaly now included in core\n  Python and packages that work with it such as `tzdata <https://pypi.org/project/tzdata/>`_.\n\n- Offsets from UTC are rounded to the nearest whole minute, so timezones\n  such as Europe/Amsterdam pre 1937 will be up to 30 seconds out. This\n  was a limitation of the Python datetime library.\n\n- If you think a timezone definition is incorrect, I probably can't fix\n  it. pytz is a direct translation of the Olson timezone database, and\n  changes to the timezone definitions need to be made to this source.\n  If you find errors they should be reported to the time zone mailing\n  list, linked from http://www.iana.org/time-zones.\n\n\nFurther Reading\n~~~~~~~~~~~~~~~\n\nMore info than you want to know about timezones:\nhttps://data.iana.org/time-zones/tz-link.html\n\n\nContact\n~~~~~~~\n\nStuart Bishop <stuart@stuartbishop.net>\n\n\n",
        "keywords": [
          "timezone",
          "tzinfo",
          "datetime",
          "olson",
          "time"
        ],
        "home_page": "http://pythonhosted.org/pytz",
        "download_url": "https://pypi.org/project/pytz/",
        "author": "Stuart Bishop",
        "author_email": "stuart@stuartbishop.net",
        "maintainer": "Stuart Bishop",
        "maintainer_email": "stuart@stuartbishop.net",
        "license": "MIT",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 6 - Mature",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.4",
          "Programming Language :: Python :: 2.5",
          "Programming Language :: Python :: 2.6",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.1",
          "Programming Language :: Python :: 3.2",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pytz-2024.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pywin32",
        "version": "306",
        "summary": "Python for Window Extensions",
        "description": "# pywin32\n\n[![CI](https://github.com/mhammond/pywin32/workflows/CI/badge.svg)](https://github.com/mhammond/pywin32/actions?query=workflow%3ACI)\n[![PyPI - Version](https://img.shields.io/pypi/v/pywin32.svg)](https://pypi.org/project/pywin32)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/pywin32.svg)](https://pypi.org/project/pywin32)\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/pywin32.svg)](https://pypi.org/project/pywin32)\n[![License - PSF-2.0](https://img.shields.io/badge/license-PSF--2.0-9400d3.svg)](https://spdx.org/licenses/PSF-2.0.html)\n\n-----\n\nThis is the readme for the Python for Win32 (pywin32) extensions, which provides access to many of the Windows APIs from Python.\n\nSee [CHANGES.txt](https://github.com/mhammond/pywin32/blob/master/CHANGES.txt) for recent notable changes.\n\nOnly Python 3 is supported. If you want Python 2 support, you want build `228`.\n\n## Docs\n\nThe docs are a long and sad story, but [there's now an online version](https://mhammond.github.io/pywin32/)\nof the helpfile that ships with the installers (thanks [@ofek](https://github.com/mhammond/pywin32/pull/1774)!).\nLots of that is very old, but some is auto-generated and current. Would love help untangling the docs!\n\n## Support\n\nFeel free to [open issues](https://github.com/mhammond/pywin32/issues) for\nall bugs (or suspected bugs) in pywin32. [pull-requests](https://github.com/mhammond/pywin32/pulls)\nfor all bugs or features are also welcome.\n\nHowever, please **do not open github issues for general support requests**, or\nfor problems or questions using the modules in this package - they will be\nclosed. For such issues, please email the\n[python-win32 mailing list](http://mail.python.org/mailman/listinfo/python-win32) -\nnote that you must be subscribed to the list before posting.\n\n## Binaries\n[Binary releases are deprecated.](https://mhammond.github.io/pywin32_installers.html)\nWhile they are still provided, [find them here](https://github.com/mhammond/pywin32/releases)\n\n## Installing via PIP\n\nYou should install pywin32 via pip - eg,\n> python -m pip install --upgrade pywin32\n\nIf you encounter any problems when upgrading (eg, \"module not found\" errors or similar), you\nshould execute:\n\n> python Scripts/pywin32_postinstall.py -install\n\nThis will make some small attempts to cleanup older conflicting installs.\n\nNote that if you want to use pywin32 for \"system wide\" features, such as\nregistering COM objects or implementing Windows Services, then you must run\nthat command from an elevated (ie, \"Run as Administrator) command prompt.\n\nFor unreleased changes, you can download builds made by [github actions](https://github.com/mhammond/pywin32/actions/) -\nchoose any \"workflow\" from the `main` branch and download its \"artifacts\")\n\n### `The specified procedure could not be found` / `Entry-point not found` Errors?\nA very common report is that people install pywin32, but many imports fail with errors\nsimilar to the above.\n\nIn almost all cases, this tends to mean there are other pywin32 DLLs installed in your system,\nbut in a different location than the new ones. This sometimes happens in environments that\ncome with pywin32 pre-shipped (eg, anaconda?).\n\nThe possible solutions are:\n\n* Run the \"post_install\" script documented above.\n\n* Otherwise, find and remove all other copies of `pywintypesXX.dll` and `pythoncomXX.dll`\n  (where `XX` is the Python version - eg, \"39\")\n\n### Running as a Windows Service\n\nModern Python installers do not, by default, install Python in a way that is suitable for\nrunning as a service, particularly for other users.\n\n* Ensure Python is installed in a location where the user running the service has\n  access to the installation and is able to load `pywintypesXX.dll` and `pythonXX.dll`.\n\n* Manually copy `pythonservice.exe` from the `site-packages/win32` directory to\n  the same place as these DLLs.\n\n## Building from source\n\nInstall Visual Studio 2019 (later probably works, but options might be different),\nselect \"Desktop Development with C++\", then the following options:\n* Windows 10 SDK (latest offered I guess? At time of writing, 10.0.18362)\n* \"C++ for MFC for ...\"\n* ARM build tools if necessary.\n\n(the free compilers probably work too, but haven't been tested - let me know your experiences!)\n\n`setup.py` is a standard distutils build script, so you probably want:\n\n> python setup.py install\n\nor\n\n> python setup.py --help\n\nSome modules need obscure SDKs to build - `setup.py` should succeed, gracefully\ntelling you why it failed to build them - if the build actually fails with your\nconfiguration, please [open an issue](https://github.com/mhammond/pywin32/issues).\n\n## Release process\n\nThe following steps are performed when making a new release - this is mainly\nto form a checklist so mhammond doesn't forget what to do :)\n\n* Ensure CHANGES.txt has everything worth noting, commit it.\n\n* Update setup.py with the new build number.\n\n* Execute build.bat, wait forever, test the artifacts.\n\n* Upload .whl artifacts to pypi - we do this before pushing the tag because they might be\n  rejected for an invalid `README.md`. Done via `py -3.? -m twine upload dist/*XXX*.whl`.\n\n* Commit setup.py (so the new build number is in the repo), create a new git tag\n\n* Upload the .exe installers to github.\n\n* Update setup.py with the new build number + \".1\" (eg, 123.1), to ensure\n  future test builds aren't mistaken for the real release.\n\n* Make sure everything is pushed to github, including the tag (ie,\n  `git push --tags`)\n\n* Send mail to python-win32\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/mhammond/pywin32",
        "author": "Mark Hammond (et al)",
        "author_email": "mhammond@skippinet.com.au",
        "license": "PSF",
        "classifier": [
          "Environment :: Win32 (MS Windows)",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Python Software Foundation License",
          "Operating System :: Microsoft :: Windows",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pywin32-306.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "PyYAML",
        "version": "6.0.2",
        "platform": [
          "Any"
        ],
        "summary": "YAML parser and emitter for Python",
        "description": "YAML is a data serialization format designed for human readability\nand interaction with scripting languages.  PyYAML is a YAML parser\nand emitter for Python.\n\nPyYAML features a complete YAML 1.1 parser, Unicode support, pickle\nsupport, capable extension API, and sensible error messages.  PyYAML\nsupports standard YAML tags and provides Python-specific tags that\nallow to represent an arbitrary Python object.\n\nPyYAML is applicable for a broad range of tasks from complex\nconfiguration files to object serialization and persistence.\n",
        "home_page": "https://pyyaml.org/",
        "download_url": "https://pypi.org/project/PyYAML/",
        "author": "Kirill Simonov",
        "author_email": "xi@resolvent.net",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Cython",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Text Processing :: Markup"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Bug Tracker, https://github.com/yaml/pyyaml/issues",
          "CI, https://github.com/yaml/pyyaml/actions",
          "Documentation, https://pyyaml.org/wiki/PyYAMLDocumentation",
          "Mailing lists, http://lists.sourceforge.net/lists/listinfo/yaml-core",
          "Source Code, https://github.com/yaml/pyyaml"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\PyYAML-6.0.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pyzmq",
        "version": "26.2.0",
        "summary": "Python bindings for 0MQ",
        "description": "# PyZMQ: Python bindings for Ã˜MQ\n\nThis package contains Python bindings for [ZeroMQ](https://zeromq.org).\nÃ˜MQ is a lightweight and fast messaging implementation.\n\nPyZMQ should work with any reasonable version of Python (â‰¥ 3.7), as well as PyPy.\nThe Cython backend used by CPython supports libzmq â‰¥ 2.1.4 (including 3.2.x and 4.x),\nbut the CFFI backend used by PyPy only supports libzmq â‰¥ 3.2.2 (including 4.x).\n\nFor a summary of changes to pyzmq, see our\n[changelog](https://pyzmq.readthedocs.io/en/latest/changelog.html).\n\n### Ã˜MQ 3.x, 4.x\n\nPyZMQ fully supports the 3.x and 4.x APIs of libzmq,\ndeveloped at [zeromq/libzmq](https://github.com/zeromq/libzmq).\nNo code to change, no flags to pass,\njust build pyzmq against the latest and it should work.\n\nPyZMQ does not support the old libzmq 2 API on PyPy.\n\n## Documentation\n\nSee PyZMQ's Sphinx-generated\ndocumentation [on Read the Docs](https://pyzmq.readthedocs.io) for API\ndetails, and some notes on Python and Cython development. If you want to\nlearn about using Ã˜MQ in general, the excellent [Ã˜MQ\nGuide](http://zguide.zeromq.org/py:all) is the place to start, which has a\nPython version of every example. We also have some information on our\n[wiki](https://github.com/zeromq/pyzmq/wiki).\n\n## Downloading\n\nUnless you specifically want to develop PyZMQ, we recommend downloading\nthe PyZMQ source code or wheels from\n[PyPI](https://pypi.io/project/pyzmq/),\nor install with conda.\n\nYou can also get the latest source code from our GitHub repository, but\nbuilding from the repository will require that you install recent Cython.\n\n## Building and installation\n\nFor more detail on building pyzmq, see [our docs](https://pyzmq.readthedocs.io/en/latest/howto/build.html).\n\nWe build wheels for macOS, Windows, and Linux, so you can get a binary on those platforms with:\n\n```\npip install pyzmq\n```\n\nbut compiling from source with `pip install pyzmq` should work in most environments.\nMake sure you are using the latest pip, or it may not find the right wheels.\n\nIf the wheel doesn't work for some reason, or you want to force pyzmq to be compiled\n(this is often preferable if you already have libzmq installed and configured the way you want it),\nyou can force installation from source with:\n\n```\npip install --no-binary=pyzmq pyzmq\n```\n\n## Old versions\n\npyzmq 16 drops support Python 2.6 and 3.2.\nIf you need to use one of those Python versions, you can pin your pyzmq version to before 16:\n\n```\npip install 'pyzmq<16'\n```\n\nFor libzmq 2.0.x, use 'pyzmq\\<2.1'\n\npyzmq-2.1.11 was the last version of pyzmq to support Python 2.5,\nand pyzmq â‰¥ 2.2.0 requires Python â‰¥ 2.6.\npyzmq-13.0.0 introduces PyPy support via CFFI, which only supports libzmq-3.2.2 and newer.\n\nPyZMQ releases â‰¤ 2.2.0 matched libzmq versioning, but this is no longer the case,\nstarting with PyZMQ 13.0.0 (it was the thirteenth release, so why not?).\nPyZMQ â‰¥ 13.0 follows semantic versioning conventions accounting only for PyZMQ itself.\n",
        "description_content_type": "text/markdown",
        "author": "Brian E. Granger, Min Ragan-Kelley",
        "author_email": "PyZMQ Contributors <zeromq-dev@lists.zeromq.org>",
        "license": "BSD 3-Clause License\n\nCopyright (c) 2009-2012, Brian Granger, Min Ragan-Kelley\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: Science/Research",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: BSD License",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX",
          "Topic :: System :: Networking",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "cffi; implementation_name == \"pypy\""
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Homepage, https://pyzmq.readthedocs.org",
          "Documentation, https://pyzmq.readthedocs.org",
          "Source, https://github.com/zeromq/pyzmq",
          "Tracker, https://github.com/zeromq/pyzmq/issues"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\pyzmq-26.2.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "py-serializable",
        "version": "1.1.0",
        "summary": "Library for serializing and deserializing Python Objects to and from JSON and XML.",
        "description": "# py-serializable\n\n[![shield_pypi-version]][link_pypi]\n[![shield_conda-forge-version]][link_conda-forge]\n[![shield_rtfd]][link_rtfd]\n[![shield_gh-workflow-test]][link_gh-workflow-test]\n[![shield_license]][license_file]\n[![shield_twitter-follow]][link_twitter]\n\n----\n\nThis Pythonic library provides a framework for serializing/deserializing Python classes to and from JSON and XML.\n\nIt relies upon the use of \n[Python Properties](https://docs.python.org/3/library/functions.html?highlight=property#property) in your Python\nclasses.\n\nRead the full [documentation][link_rtfd] for more details.\n\n## Installation\n\nInstall this from [PyPi.org][link_pypi] using your preferred Python package manager.\n\nExample using `pip`:\n\n```shell\npip install py-serializable\n```\n\nExample using `poetry`:\n\n```shell\npoetry add py-serializable\n```\n\n## Usage\n\nSee the full [documentation][link_rtfd] or our [unit tests][link_unit_tests] for usage and details.\n\n## Python Support\n\nWe endeavour to support all functionality for all [current actively supported Python versions](https://www.python.org/downloads/).\nHowever, some features may not be possible/present in older Python versions due to their lack of support.\n\n## Contributing\n\nFeel free to open issues, bugreports or pull requests.  \nSee the [CONTRIBUTING][contributing_file] file for details.\n\n## Copyright & License\n\n`py-serializable` is Copyright (c) Paul Horton 2022. All Rights Reserved.\n\nPermission to modify and redistribute is granted under the terms of the Apache 2.0 license.  \nSee the [LICENSE][license_file] file for the full license.\n\n[license_file]: https://github.com/madpah/serializable/blob/main/LICENSE\n[contributing_file]: https://github.com/madpah/serializable/blob/main/CONTRIBUTING.md\n[link_rtfd]: https://py-serializable.readthedocs.io/\n\n[shield_gh-workflow-test]: https://img.shields.io/github/actions/workflow/status/madpah/serializable/python.yml?branch=main \"build\"\n[shield_rtfd]: https://img.shields.io/readthedocs/py-serializable?logo=readthedocs&logoColor=white\n[shield_pypi-version]: https://img.shields.io/pypi/v/py-serializable?logo=Python&logoColor=white&label=PyPI \"PyPI\"\n[shield_conda-forge-version]: https://img.shields.io/conda/vn/conda-forge/py-serializable?logo=anaconda&logoColor=white&label=conda-forge \"conda-forge\"\n[shield_license]: https://img.shields.io/github/license/madpah/serializable?logo=open%20source%20initiative&logoColor=white \"license\"\n[shield_twitter-follow]: https://img.shields.io/badge/Twitter-follow-blue?logo=Twitter&logoColor=white \"twitter follow\"\n[link_gh-workflow-test]: https://github.com/madpah/serializable/actions/workflows/python.yml?query=branch%3Amain\n[link_pypi]: https://pypi.org/project/py-serializable/\n[link_conda-forge]: https://anaconda.org/conda-forge/py-serializable\n[link_twitter]: https://twitter.com/madpah\n[link_unit_tests]: https://github.com/madpah/serializable/blob/main/tests\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "serialization",
          "deserialization",
          "JSON",
          "XML"
        ],
        "home_page": "https://github.com/madpah/serializable#readme",
        "author": "Paul Horton",
        "author_email": "paul.horton@owasp.org",
        "maintainer": "Jan Kowalleck",
        "maintainer_email": "jan.kowalleck@gmail.com",
        "license": "Apache-2.0",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Software Development",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "defusedxml (>=0.7.1,<0.8.0)"
        ],
        "requires_python": ">=3.8,<4.0",
        "project_url": [
          "Bug Tracker, https://github.com/madpah/serializable/issues",
          "Documentation, https://py-serializable.readthedocs.io/",
          "Repository, https://github.com/madpah/serializable"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\py_serializable-1.1.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "rdflib",
        "version": "7.1.1",
        "summary": "RDFLib is a Python library for working with RDF, a simple yet powerful language for representing information.",
        "description": "![](docs/_static/RDFlib.png)    \n\nRDFLib\n======\n[![Build Status](https://github.com/RDFLib/rdflib/actions/workflows/validate.yaml/badge.svg?branch=main)](https://github.com/RDFLib/rdflib/actions?query=branch%3Amain)\n[![Documentation Status](https://readthedocs.org/projects/rdflib/badge/?version=latest)](https://rdflib.readthedocs.io/en/latest/?badge=latest)\n[![Coveralls branch](https://img.shields.io/coveralls/RDFLib/rdflib/main.svg)](https://coveralls.io/r/RDFLib/rdflib?branch=main)\n\n[![GitHub stars](https://img.shields.io/github/stars/RDFLib/rdflib.svg)](https://github.com/RDFLib/rdflib/stargazers)\n[![Downloads](https://pepy.tech/badge/rdflib/week)](https://pepy.tech/project/rdflib)\n[![PyPI](https://img.shields.io/pypi/v/rdflib.svg)](https://pypi.python.org/pypi/rdflib)\n[![PyPI](https://img.shields.io/pypi/pyversions/rdflib.svg)](https://pypi.python.org/pypi/rdflib)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.6845245.svg)](https://doi.org/10.5281/zenodo.6845245)\n\n[![Contribute with Gitpod](https://img.shields.io/badge/Contribute%20with-Gitpod-908a85?logo=gitpod)](https://gitpod.io/#https://github.com/RDFLib/rdflib)\n[![Gitter](https://badges.gitter.im/RDFLib/rdflib.svg)](https://gitter.im/RDFLib/rdflib?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n[![Matrix](https://img.shields.io/matrix/rdflib:matrix.org?label=matrix.org%20chat)](https://matrix.to/#/#RDFLib_rdflib:gitter.im)\n\nRDFLib is a pure Python package for working with [RDF](http://www.w3.org/RDF/). RDFLib contains most things you need to work with RDF, including:\n\n* parsers and serializers for RDF/XML, N3, NTriples, N-Quads, Turtle, TriX, Trig and JSON-LD\n* a Graph interface which can be backed by any one of a number of Store implementations\n* store implementations for in-memory, persistent on disk (Berkeley DB) and remote SPARQL endpoints\n* a SPARQL 1.1 implementation - supporting SPARQL 1.1 Queries and Update statements\n* SPARQL function extension mechanisms\n\n## RDFlib Family of packages\nThe RDFlib community maintains many RDF-related Python code repositories with different purposes. For example:\n\n* [rdflib](https://github.com/RDFLib/rdflib) - the RDFLib core\n* [sparqlwrapper](https://github.com/RDFLib/sparqlwrapper) - a simple Python wrapper around a SPARQL service to remotely execute your queries\n* [pyLODE](https://github.com/RDFLib/pyLODE) - An OWL ontology documentation tool using Python and templating, based on LODE.\n* [pyrdfa3](https://github.com/RDFLib/pyrdfa3) - RDFa 1.1 distiller/parser library: can extract RDFa 1.1/1.0 from (X)HTML, SVG, or XML in general.\n* [pymicrodata](https://github.com/RDFLib/pymicrodata) - A module to extract RDF from an HTML5 page annotated with microdata. \n* [pySHACL](https://github.com/RDFLib/pySHACL) - A pure Python module which allows for the validation of RDF graphs against SHACL graphs.\n* [OWL-RL](https://github.com/RDFLib/OWL-RL) - A simple implementation of the OWL2 RL Profile which expands the graph with all possible triples that OWL RL defines.\n\nPlease see the list for all packages/repositories here:\n\n* <https://github.com/RDFLib>\n\nHelp with maintenance of all of the RDFLib family of packages is always welcome and appreciated.\n\n## Versions & Releases\n\n* `main` branch in this repository is the unstable release\n* `7.1.1` current stable release, bugfixes to 7.1.0\n* `7.0.0` previous stable release, supports Python 3.8.1+ only.\n    * see [Releases](https://github.com/RDFLib/rdflib/releases)\n* `6.x.y` supports Python 3.7+ only. Many improvements over 5.0.0\n    * see [Releases](https://github.com/RDFLib/rdflib/releases)\n* `5.x.y` supports Python 2.7 and 3.4+ and is [mostly backwards compatible with 4.2.2](https://rdflib.readthedocs.io/en/stable/upgrade4to5.html).\n\nSee <https://github.com/RDFLib/rdflib/releases/> for the release details.\n\n## Documentation\nSee <https://rdflib.readthedocs.io> for our documentation built from the code. Note that there are `latest`, `stable` and versioned builds, such as `5.0.0`, matching releases.\n\n## Installation\nThe stable release of RDFLib may be installed with Python's package management tool *pip*:\n\n    $ pip install rdflib\n\nSome features of RDFLib require optional dependencies which may be installed using *pip* extras:\n\n    $ pip install rdflib[berkeleydb,networkx,html,lxml,orjson]\n\nAlternatively manually download the package from the Python Package\nIndex (PyPI) at https://pypi.python.org/pypi/rdflib\n\nThe current version of RDFLib is 7.1.1, see the ``CHANGELOG.md`` file for what's new in this release.\n\n### Installation of the current main branch (for developers)\n\nWith *pip* you can also install rdflib from the git repository with one of the following options:\n\n    $ pip install git+https://github.com/rdflib/rdflib@main\n\nor\n\n    $ pip install -e git+https://github.com/rdflib/rdflib@main#egg=rdflib\n\nor from your locally cloned repository you can install it with one of the following options:\n\n    $ poetry install  # installs into a poetry-managed venv\n\nor\n\n    $ pip install -e .\n\n## Getting Started\nRDFLib aims to be a pythonic RDF API. RDFLib's main data object is a `Graph` which is a Python collection\nof RDF *Subject, Predicate, Object* Triples:\n\nTo create graph and load it with RDF data from DBPedia then print the results:\n\n```python\nfrom rdflib import Graph\ng = Graph()\ng.parse('http://dbpedia.org/resource/Semantic_Web')\n\nfor s, p, o in g:\n    print(s, p, o)\n```\nThe components of the triples are URIs (resources) or Literals\n(values).\n\nURIs are grouped together by *namespace*, common namespaces are included in RDFLib:\n\n```python\nfrom rdflib.namespace import DC, DCTERMS, DOAP, FOAF, SKOS, OWL, RDF, RDFS, VOID, XMLNS, XSD\n```\n\nYou can use them like this:\n\n```python\nfrom rdflib import Graph, URIRef, Literal\nfrom rdflib.namespace import RDFS, XSD\n\ng = Graph()\nsemweb = URIRef('http://dbpedia.org/resource/Semantic_Web')\ntype = g.value(semweb, RDFS.label)\n```\nWhere `RDFS` is the RDFS namespace, `XSD` the XML Schema Datatypes namespace and `g.value` returns an object of the triple-pattern given (or an arbitrary one if multiple exist).\n\nOr like this, adding a triple to a graph `g`:\n\n```python\ng.add((\n    URIRef(\"http://example.com/person/nick\"),\n    FOAF.givenName,\n    Literal(\"Nick\", datatype=XSD.string)\n))\n```\nThe triple (in n-triples notation) `<http://example.com/person/nick> <http://xmlns.com/foaf/0.1/givenName> \"Nick\"^^<http://www.w3.org/2001/XMLSchema#string> .`\nis created where the property `FOAF.givenName` is the URI `<http://xmlns.com/foaf/0.1/givenName>` and `XSD.string` is the\nURI `<http://www.w3.org/2001/XMLSchema#string>`.\n\nYou can bind namespaces to prefixes to shorten the URIs for RDF/XML, Turtle, N3, TriG, TriX & JSON-LD serializations:\n\n ```python\ng.bind(\"foaf\", FOAF)\ng.bind(\"xsd\", XSD)\n```\nThis will allow the n-triples triple above to be serialised like this:\n ```python\nprint(g.serialize(format=\"turtle\"))\n```\n\nWith these results:\n```turtle\nPREFIX foaf: <http://xmlns.com/foaf/0.1/>\nPREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n\n<http://example.com/person/nick> foaf:givenName \"Nick\"^^xsd:string .\n```\n\nNew Namespaces can also be defined:\n\n```python\ndbpedia = Namespace('http://dbpedia.org/ontology/')\n\nabstracts = list(x for x in g.objects(semweb, dbpedia['abstract']) if x.language=='en')\n```\n\nSee also [./examples](./examples)\n\n\n## Features\nThe library contains parsers and serializers for RDF/XML, N3,\nNTriples, N-Quads, Turtle, TriX, JSON-LD, RDFa and Microdata.\n\nThe library presents a Graph interface which can be backed by\nany one of a number of Store implementations.\n\nThis core RDFLib package includes store implementations for\nin-memory storage and persistent storage on top of the Berkeley DB.\n\nA SPARQL 1.1 implementation is included - supporting SPARQL 1.1 Queries and Update statements.\n\nRDFLib is open source and is maintained on [GitHub](https://github.com/RDFLib/rdflib/). RDFLib releases, current and previous\nare listed on [PyPI](https://pypi.python.org/pypi/rdflib/)\n\nMultiple other projects are contained within the RDFlib \"family\", see <https://github.com/RDFLib/>.\n\n## Running tests\n\n### Running the tests on the host\n\nRun the test suite with `pytest`.\n```shell\npoetry install\npoetry run pytest\n```\n\n### Running test coverage on the host with coverage report\n\nRun the test suite and generate a HTML coverage report with `pytest` and `pytest-cov`.\n```shell\npoetry run pytest --cov\n```\n\n### Viewing test coverage\n\nOnce tests have produced HTML output of the coverage report, view it by running:\n```shell\npoetry run pytest --cov --cov-report term --cov-report html\npython -m http.server --directory=htmlcov\n```\n\n## Contributing\n\nRDFLib survives and grows via user contributions!\nPlease read our [contributing guide](https://rdflib.readthedocs.io/en/latest/CONTRIBUTING.html) and [developers guide](https://rdflib.readthedocs.io/en/latest/developers.html) to get started.\nPlease consider lodging Pull Requests here:\n\n* <https://github.com/RDFLib/rdflib/pulls>\n\nTo get a development environment consider using Gitpod or Google Cloud Shell.\n\n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/RDFLib/rdflib)\n[![Open in Cloud Shell](https://gstatic.com/cloudssh/images/open-btn.svg)](https://shell.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https%3A%2F%2Fgithub.com%2FRDFLib%2Frdflib&cloudshell_git_branch=main&cloudshell_open_in_editor=README.md)\n\nYou can also raise issues here:\n\n* <https://github.com/RDFLib/rdflib/issues>\n\n## Support & Contacts\nFor general \"how do I...\" queries, please use https://stackoverflow.com and tag your question with `rdflib`.\nExisting questions:\n\n* <https://stackoverflow.com/questions/tagged/rdflib>\n\nIf you want to contact the rdflib maintainers, please do so via:\n\n* the rdflib-dev mailing list: <https://groups.google.com/group/rdflib-dev>\n* the chat, which is available at [gitter](https://gitter.im/RDFLib/rdflib) or via matrix [#RDFLib_rdflib:gitter.im](https://matrix.to/#/#RDFLib_rdflib:gitter.im)\n\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/RDFLib/rdflib",
        "author": "Daniel 'eikeon' Krech",
        "author_email": "eikeon@eikeon.com",
        "maintainer": "RDFLib Team",
        "maintainer_email": "rdflib-dev@googlegroups.com",
        "license": "BSD-3-Clause",
        "classifier": [
          "License :: OSI Approved :: BSD License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "berkeleydb (>=18.1.0,<19.0.0); extra == \"berkeleydb\"",
          "html5rdf (>=1.2,<2); extra == \"html\"",
          "isodate (>=0.7.2,<1.0.0); python_version < \"3.11\"",
          "lxml (>=4.3,<6.0); extra == \"lxml\"",
          "networkx (>=2,<4); extra == \"networkx\"",
          "orjson (>=3.9.14,<4); extra == \"orjson\"",
          "pyparsing (>=2.1.0,<4)"
        ],
        "requires_python": ">=3.8.1,<4.0.0",
        "project_url": [
          "Documentation, https://rdflib.readthedocs.org/",
          "Repository, https://github.com/RDFLib/rdflib"
        ],
        "provides_extra": [
          "berkeleydb",
          "html",
          "lxml",
          "networkx",
          "orjson"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\rdflib-7.1.1.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "referencing",
        "version": "0.35.1",
        "summary": "JSON Referencing + Python",
        "description": "===============\n``referencing``\n===============\n\n|PyPI| |Pythons| |CI| |ReadTheDocs| |pre-commit|\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/referencing.svg\n  :alt: PyPI version\n  :target: https://pypi.org/project/referencing/\n\n.. |Pythons| image:: https://img.shields.io/pypi/pyversions/referencing.svg\n  :alt: Supported Python versions\n  :target: https://pypi.org/project/referencing/\n\n.. |CI| image:: https://github.com/python-jsonschema/referencing/workflows/CI/badge.svg\n  :alt: Build status\n  :target: https://github.com/python-jsonschema/referencing/actions?query=workflow%3ACI\n\n.. |ReadTheDocs| image:: https://readthedocs.org/projects/referencing/badge/?version=stable&style=flat\n   :alt: ReadTheDocs status\n   :target: https://referencing.readthedocs.io/en/stable/\n\n.. |pre-commit| image:: https://results.pre-commit.ci/badge/github/python-jsonschema/referencing/main.svg\n  :alt: pre-commit.ci status\n  :target: https://results.pre-commit.ci/latest/github/python-jsonschema/referencing/main\n\n\nAn implementation-agnostic implementation of JSON reference resolution.\n\nSee `the documentation <https://referencing.readthedocs.io/>`_ for more details.\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "asyncapi",
          "json",
          "jsonschema",
          "openapi",
          "referencing"
        ],
        "author_email": "Julian Berman <Julian+referencing@GrayVines.com>",
        "license_file": [
          "COPYING"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: File Formats :: JSON",
          "Topic :: File Formats :: JSON :: JSON Schema"
        ],
        "requires_dist": [
          "attrs>=22.2.0",
          "rpds-py>=0.7.0"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://referencing.readthedocs.io/",
          "Homepage, https://github.com/python-jsonschema/referencing",
          "Issues, https://github.com/python-jsonschema/referencing/issues/",
          "Funding, https://github.com/sponsors/Julian",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-referencing?utm_source=pypi-referencing&utm_medium=referral&utm_campaign=pypi-link",
          "Changelog, https://referencing.readthedocs.io/en/stable/changes/",
          "Source, https://github.com/python-jsonschema/referencing"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\referencing-0.35.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "regex",
        "version": "2024.7.24",
        "summary": "Alternative regular expression module, to replace re.",
        "description": "Introduction\n------------\n\nThis regex implementation is backwards-compatible with the standard 're' module, but offers additional functionality.\n\nPython 2\n--------\n\nPython 2 is no longer supported. The last release that supported Python 2 was 2021.11.10.\n\nPyPy\n----\n\nThis module is targeted at CPython. It expects that all codepoints are the same width, so it won't behave properly with PyPy outside U+0000..U+007F because PyPy stores strings as UTF-8.\n\nMultithreading\n--------------\n\nThe regex module releases the GIL during matching on instances of the built-in (immutable) string classes, enabling other Python threads to run concurrently. It is also possible to force the regex module to release the GIL during matching by calling the matching methods with the keyword argument ``concurrent=True``. The behaviour is undefined if the string changes during matching, so use it *only* when it is guaranteed that that won't happen.\n\nUnicode\n-------\n\nThis module supports Unicode 15.1.0. Full Unicode case-folding is supported.\n\nFlags\n-----\n\nThere are 2 kinds of flag: scoped and global. Scoped flags can apply to only part of a pattern and can be turned on or off; global flags apply to the entire pattern and can only be turned on.\n\nThe scoped flags are: ``ASCII (?a)``, ``FULLCASE (?f)``, ``IGNORECASE (?i)``, ``LOCALE (?L)``, ``MULTILINE (?m)``, ``DOTALL (?s)``, ``UNICODE (?u)``, ``VERBOSE (?x)``, ``WORD (?w)``.\n\nThe global flags are: ``BESTMATCH (?b)``, ``ENHANCEMATCH (?e)``, ``POSIX (?p)``, ``REVERSE (?r)``, ``VERSION0 (?V0)``, ``VERSION1 (?V1)``.\n\nIf neither the ``ASCII``, ``LOCALE`` nor ``UNICODE`` flag is specified, it will default to ``UNICODE`` if the regex pattern is a Unicode string and ``ASCII`` if it's a bytestring.\n\nThe ``ENHANCEMATCH`` flag makes fuzzy matching attempt to improve the fit of the next match that it finds.\n\nThe ``BESTMATCH`` flag makes fuzzy matching search for the best match instead of the next match.\n\nOld vs new behaviour\n--------------------\n\nIn order to be compatible with the re module, this module has 2 behaviours:\n\n* **Version 0** behaviour (old behaviour, compatible with the re module):\n\n  Please note that the re module's behaviour may change over time, and I'll endeavour to match that behaviour in version 0.\n\n  * Indicated by the ``VERSION0`` flag.\n\n  * Zero-width matches are not handled correctly in the re module before Python 3.7. The behaviour in those earlier versions is:\n\n    * ``.split`` won't split a string at a zero-width match.\n\n    * ``.sub`` will advance by one character after a zero-width match.\n\n  * Inline flags apply to the entire pattern, and they can't be turned off.\n\n  * Only simple sets are supported.\n\n  * Case-insensitive matches in Unicode use simple case-folding by default.\n\n* **Version 1** behaviour (new behaviour, possibly different from the re module):\n\n  * Indicated by the ``VERSION1`` flag.\n\n  * Zero-width matches are handled correctly.\n\n  * Inline flags apply to the end of the group or pattern, and they can be turned off.\n\n  * Nested sets and set operations are supported.\n\n  * Case-insensitive matches in Unicode use full case-folding by default.\n\nIf no version is specified, the regex module will default to ``regex.DEFAULT_VERSION``.\n\nCase-insensitive matches in Unicode\n-----------------------------------\n\nThe regex module supports both simple and full case-folding for case-insensitive matches in Unicode. Use of full case-folding can be turned on using the ``FULLCASE`` flag. Please note that this flag affects how the ``IGNORECASE`` flag works; the ``FULLCASE`` flag itself does not turn on case-insensitive matching.\n\nVersion 0 behaviour: the flag is off by default.\n\nVersion 1 behaviour: the flag is on by default.\n\nNested sets and set operations\n------------------------------\n\nIt's not possible to support both simple sets, as used in the re module, and nested sets at the same time because of a difference in the meaning of an unescaped ``\"[\"`` in a set.\n\nFor example, the pattern ``[[a-z]--[aeiou]]`` is treated in the version 0 behaviour (simple sets, compatible with the re module) as:\n\n* Set containing \"[\" and the letters \"a\" to \"z\"\n\n* Literal \"--\"\n\n* Set containing letters \"a\", \"e\", \"i\", \"o\", \"u\"\n\n* Literal \"]\"\n\nbut in the version 1 behaviour (nested sets, enhanced behaviour) as:\n\n* Set which is:\n\n  * Set containing the letters \"a\" to \"z\"\n\n* but excluding:\n\n  * Set containing the letters \"a\", \"e\", \"i\", \"o\", \"u\"\n\nVersion 0 behaviour: only simple sets are supported.\n\nVersion 1 behaviour: nested sets and set operations are supported.\n\nNotes on named groups\n---------------------\n\nAll groups have a group number, starting from 1.\n\nGroups with the same group name will have the same group number, and groups with a different group name will have a different group number.\n\nThe same name can be used by more than one group, with later captures 'overwriting' earlier captures. All the captures of the group will be available from the ``captures`` method of the match object.\n\nGroup numbers will be reused across different branches of a branch reset, eg. ``(?|(first)|(second))`` has only group 1. If groups have different group names then they will, of course, have different group numbers, eg. ``(?|(?P<foo>first)|(?P<bar>second))`` has group 1 (\"foo\") and group 2 (\"bar\").\n\nIn the regex ``(\\s+)(?|(?P<foo>[A-Z]+)|(\\w+) (?P<foo>[0-9]+)`` there are 2 groups:\n\n* ``(\\s+)`` is group 1.\n\n* ``(?P<foo>[A-Z]+)`` is group 2, also called \"foo\".\n\n* ``(\\w+)`` is group 2 because of the branch reset.\n\n* ``(?P<foo>[0-9]+)`` is group 2 because it's called \"foo\".\n\nIf you want to prevent ``(\\w+)`` from being group 2, you need to name it (different name, different group number).\n\nAdditional features\n-------------------\n\nThe issue numbers relate to the Python bug tracker, except where listed otherwise.\n\nAdded ``\\p{Horiz_Space}`` and ``\\p{Vert_Space}`` (`GitHub issue 477 <https://github.com/mrabarnett/mrab-regex/issues/477#issuecomment-1216779547>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``\\p{Horiz_Space}`` or ``\\p{H}`` matches horizontal whitespace and ``\\p{Vert_Space}`` or ``\\p{V}`` matches vertical whitespace.\n\nAdded support for lookaround in conditional pattern (`Hg issue 163 <https://github.com/mrabarnett/mrab-regex/issues/163>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe test of a conditional pattern can be a lookaround.\n\n.. sourcecode:: python\n\n  >>> regex.match(r'(?(?=\\d)\\d+|\\w+)', '123abc')\n  <regex.Match object; span=(0, 3), match='123'>\n  >>> regex.match(r'(?(?=\\d)\\d+|\\w+)', 'abc123')\n  <regex.Match object; span=(0, 6), match='abc123'>\n\nThis is not quite the same as putting a lookaround in the first branch of a pair of alternatives.\n\n.. sourcecode:: python\n\n  >>> print(regex.match(r'(?:(?=\\d)\\d+\\b|\\w+)', '123abc'))\n  <regex.Match object; span=(0, 6), match='123abc'>\n  >>> print(regex.match(r'(?(?=\\d)\\d+\\b|\\w+)', '123abc'))\n  None\n\nIn the first example, the lookaround matched, but the remainder of the first branch failed to match, and so the second branch was attempted, whereas in the second example, the lookaround matched, and the first branch failed to match, but the second branch was **not** attempted.\n\nAdded POSIX matching (leftmost longest) (`Hg issue 150 <https://github.com/mrabarnett/mrab-regex/issues/150>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe POSIX standard for regex is to return the leftmost longest match. This can be turned on using the ``POSIX`` flag.\n\n.. sourcecode:: python\n\n  >>> # Normal matching.\n  >>> regex.search(r'Mr|Mrs', 'Mrs')\n  <regex.Match object; span=(0, 2), match='Mr'>\n  >>> regex.search(r'one(self)?(selfsufficient)?', 'oneselfsufficient')\n  <regex.Match object; span=(0, 7), match='oneself'>\n  >>> # POSIX matching.\n  >>> regex.search(r'(?p)Mr|Mrs', 'Mrs')\n  <regex.Match object; span=(0, 3), match='Mrs'>\n  >>> regex.search(r'(?p)one(self)?(selfsufficient)?', 'oneselfsufficient')\n  <regex.Match object; span=(0, 17), match='oneselfsufficient'>\n\nNote that it will take longer to find matches because when it finds a match at a certain position, it won't return that immediately, but will keep looking to see if there's another longer match there.\n\nAdded ``(?(DEFINE)...)`` (`Hg issue 152 <https://github.com/mrabarnett/mrab-regex/issues/152>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIf there's no group called \"DEFINE\", then ... will be ignored except that any groups defined within it can be called and that the normal rules for numbering groups still apply.\n\n.. sourcecode:: python\n\n  >>> regex.search(r'(?(DEFINE)(?P<quant>\\d+)(?P<item>\\w+))(?&quant) (?&item)', '5 elephants')\n  <regex.Match object; span=(0, 11), match='5 elephants'>\n\nAdded ``(*PRUNE)``, ``(*SKIP)`` and ``(*FAIL)`` (`Hg issue 153 <https://github.com/mrabarnett/mrab-regex/issues/153>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``(*PRUNE)`` discards the backtracking info up to that point. When used in an atomic group or a lookaround, it won't affect the enclosing pattern.\n\n``(*SKIP)`` is similar to ``(*PRUNE)``, except that it also sets where in the text the next attempt to match will start. When used in an atomic group or a lookaround, it won't affect the enclosing pattern.\n\n``(*FAIL)`` causes immediate backtracking. ``(*F)`` is a permitted abbreviation.\n\nAdded ``\\K`` (`Hg issue 151 <https://github.com/mrabarnett/mrab-regex/issues/151>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nKeeps the part of the entire match after the position where ``\\K`` occurred; the part before it is discarded.\n\nIt does not affect what groups return.\n\n.. sourcecode:: python\n\n  >>> m = regex.search(r'(\\w\\w\\K\\w\\w\\w)', 'abcdef')\n  >>> m[0]\n  'cde'\n  >>> m[1]\n  'abcde'\n  >>>\n  >>> m = regex.search(r'(?r)(\\w\\w\\K\\w\\w\\w)', 'abcdef')\n  >>> m[0]\n  'bc'\n  >>> m[1]\n  'bcdef'\n\nAdded capture subscripting for ``expandf`` and ``subf``/``subfn`` (`Hg issue 133 <https://github.com/mrabarnett/mrab-regex/issues/133>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nYou can use subscripting to get the captures of a repeated group.\n\n.. sourcecode:: python\n\n  >>> m = regex.match(r\"(\\w)+\", \"abc\")\n  >>> m.expandf(\"{1}\")\n  'c'\n  >>> m.expandf(\"{1[0]} {1[1]} {1[2]}\")\n  'a b c'\n  >>> m.expandf(\"{1[-1]} {1[-2]} {1[-3]}\")\n  'c b a'\n  >>>\n  >>> m = regex.match(r\"(?P<letter>\\w)+\", \"abc\")\n  >>> m.expandf(\"{letter}\")\n  'c'\n  >>> m.expandf(\"{letter[0]} {letter[1]} {letter[2]}\")\n  'a b c'\n  >>> m.expandf(\"{letter[-1]} {letter[-2]} {letter[-3]}\")\n  'c b a'\n\nAdded support for referring to a group by number using ``(?P=...)``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThis is in addition to the existing ``\\g<...>``.\n\nFixed the handling of locale-sensitive regexes\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``LOCALE`` flag is intended for legacy code and has limited support. You're still recommended to use Unicode instead.\n\nAdded partial matches (`Hg issue 102 <https://github.com/mrabarnett/mrab-regex/issues/102>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA partial match is one that matches up to the end of string, but that string has been truncated and you want to know whether a complete match could be possible if the string had not been truncated.\n\nPartial matches are supported by ``match``, ``search``, ``fullmatch`` and ``finditer`` with the ``partial`` keyword argument.\n\nMatch objects have a ``partial`` attribute, which is ``True`` if it's a partial match.\n\nFor example, if you wanted a user to enter a 4-digit number and check it character by character as it was being entered:\n\n.. sourcecode:: python\n\n  >>> pattern = regex.compile(r'\\d{4}')\n\n  >>> # Initially, nothing has been entered:\n  >>> print(pattern.fullmatch('', partial=True))\n  <regex.Match object; span=(0, 0), match='', partial=True>\n\n  >>> # An empty string is OK, but it's only a partial match.\n  >>> # The user enters a letter:\n  >>> print(pattern.fullmatch('a', partial=True))\n  None\n  >>> # It'll never match.\n\n  >>> # The user deletes that and enters a digit:\n  >>> print(pattern.fullmatch('1', partial=True))\n  <regex.Match object; span=(0, 1), match='1', partial=True>\n  >>> # It matches this far, but it's only a partial match.\n\n  >>> # The user enters 2 more digits:\n  >>> print(pattern.fullmatch('123', partial=True))\n  <regex.Match object; span=(0, 3), match='123', partial=True>\n  >>> # It matches this far, but it's only a partial match.\n\n  >>> # The user enters another digit:\n  >>> print(pattern.fullmatch('1234', partial=True))\n  <regex.Match object; span=(0, 4), match='1234'>\n  >>> # It's a complete match.\n\n  >>> # If the user enters another digit:\n  >>> print(pattern.fullmatch('12345', partial=True))\n  None\n  >>> # It's no longer a match.\n\n  >>> # This is a partial match:\n  >>> pattern.match('123', partial=True).partial\n  True\n\n  >>> # This is a complete match:\n  >>> pattern.match('1233', partial=True).partial\n  False\n\n``*`` operator not working correctly with sub() (`Hg issue 106 <https://github.com/mrabarnett/mrab-regex/issues/106>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSometimes it's not clear how zero-width matches should be handled. For example, should ``.*`` match 0 characters directly after matching >0 characters?\n\n.. sourcecode:: python\n\n  >>> regex.sub('.*', 'x', 'test')\n  'xx'\n  >>> regex.sub('.*?', '|', 'test')\n  '|||||||||'\n\nAdded ``capturesdict`` (`Hg issue 86 <https://github.com/mrabarnett/mrab-regex/issues/86>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``capturesdict`` is a combination of ``groupdict`` and ``captures``:\n\n``groupdict`` returns a dict of the named groups and the last capture of those groups.\n\n``captures`` returns a list of all the captures of a group\n\n``capturesdict`` returns a dict of the named groups and lists of all the captures of those groups.\n\n.. sourcecode:: python\n\n  >>> m = regex.match(r\"(?:(?P<word>\\w+) (?P<digits>\\d+)\\n)+\", \"one 1\\ntwo 2\\nthree 3\\n\")\n  >>> m.groupdict()\n  {'word': 'three', 'digits': '3'}\n  >>> m.captures(\"word\")\n  ['one', 'two', 'three']\n  >>> m.captures(\"digits\")\n  ['1', '2', '3']\n  >>> m.capturesdict()\n  {'word': ['one', 'two', 'three'], 'digits': ['1', '2', '3']}\n\nAdded ``allcaptures`` and ``allspans`` (`Git issue 474 <https://github.com/mrabarnett/mrab-regex/issues/474>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``allcaptures`` returns a list of all the captures of all the groups.\n\n``allspans`` returns a list of all the spans of the all captures of all the groups.\n\n.. sourcecode:: python\n\n  >>> m = regex.match(r\"(?:(?P<word>\\w+) (?P<digits>\\d+)\\n)+\", \"one 1\\ntwo 2\\nthree 3\\n\")\n  >>> m.allcaptures()\n  (['one 1\\ntwo 2\\nthree 3\\n'], ['one', 'two', 'three'], ['1', '2', '3'])\n  >>> m.allspans()\n  ([(0, 20)], [(0, 3), (6, 9), (12, 17)], [(4, 5), (10, 11), (18, 19)])\n\nAllow duplicate names of groups (`Hg issue 87 <https://github.com/mrabarnett/mrab-regex/issues/87>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nGroup names can be duplicated.\n\n.. sourcecode:: python\n\n  >>> # With optional groups:\n  >>>\n  >>> # Both groups capture, the second capture 'overwriting' the first.\n  >>> m = regex.match(r\"(?P<item>\\w+)? or (?P<item>\\w+)?\", \"first or second\")\n  >>> m.group(\"item\")\n  'second'\n  >>> m.captures(\"item\")\n  ['first', 'second']\n  >>> # Only the second group captures.\n  >>> m = regex.match(r\"(?P<item>\\w+)? or (?P<item>\\w+)?\", \" or second\")\n  >>> m.group(\"item\")\n  'second'\n  >>> m.captures(\"item\")\n  ['second']\n  >>> # Only the first group captures.\n  >>> m = regex.match(r\"(?P<item>\\w+)? or (?P<item>\\w+)?\", \"first or \")\n  >>> m.group(\"item\")\n  'first'\n  >>> m.captures(\"item\")\n  ['first']\n  >>>\n  >>> # With mandatory groups:\n  >>>\n  >>> # Both groups capture, the second capture 'overwriting' the first.\n  >>> m = regex.match(r\"(?P<item>\\w*) or (?P<item>\\w*)?\", \"first or second\")\n  >>> m.group(\"item\")\n  'second'\n  >>> m.captures(\"item\")\n  ['first', 'second']\n  >>> # Again, both groups capture, the second capture 'overwriting' the first.\n  >>> m = regex.match(r\"(?P<item>\\w*) or (?P<item>\\w*)\", \" or second\")\n  >>> m.group(\"item\")\n  'second'\n  >>> m.captures(\"item\")\n  ['', 'second']\n  >>> # And yet again, both groups capture, the second capture 'overwriting' the first.\n  >>> m = regex.match(r\"(?P<item>\\w*) or (?P<item>\\w*)\", \"first or \")\n  >>> m.group(\"item\")\n  ''\n  >>> m.captures(\"item\")\n  ['first', '']\n\nAdded ``fullmatch`` (`issue #16203 <https://bugs.python.org/issue16203>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``fullmatch`` behaves like ``match``, except that it must match all of the string.\n\n.. sourcecode:: python\n\n  >>> print(regex.fullmatch(r\"abc\", \"abc\").span())\n  (0, 3)\n  >>> print(regex.fullmatch(r\"abc\", \"abcx\"))\n  None\n  >>> print(regex.fullmatch(r\"abc\", \"abcx\", endpos=3).span())\n  (0, 3)\n  >>> print(regex.fullmatch(r\"abc\", \"xabcy\", pos=1, endpos=4).span())\n  (1, 4)\n  >>>\n  >>> regex.match(r\"a.*?\", \"abcd\").group(0)\n  'a'\n  >>> regex.fullmatch(r\"a.*?\", \"abcd\").group(0)\n  'abcd'\n\nAdded ``subf`` and ``subfn``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``subf`` and ``subfn`` are alternatives to ``sub`` and ``subn`` respectively. When passed a replacement string, they treat it as a format string.\n\n.. sourcecode:: python\n\n  >>> regex.subf(r\"(\\w+) (\\w+)\", \"{0} => {2} {1}\", \"foo bar\")\n  'foo bar => bar foo'\n  >>> regex.subf(r\"(?P<word1>\\w+) (?P<word2>\\w+)\", \"{word2} {word1}\", \"foo bar\")\n  'bar foo'\n\nAdded ``expandf`` to match object\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``expandf`` is an alternative to ``expand``. When passed a replacement string, it treats it as a format string.\n\n.. sourcecode:: python\n\n  >>> m = regex.match(r\"(\\w+) (\\w+)\", \"foo bar\")\n  >>> m.expandf(\"{0} => {2} {1}\")\n  'foo bar => bar foo'\n  >>>\n  >>> m = regex.match(r\"(?P<word1>\\w+) (?P<word2>\\w+)\", \"foo bar\")\n  >>> m.expandf(\"{word2} {word1}\")\n  'bar foo'\n\nDetach searched string\n^^^^^^^^^^^^^^^^^^^^^^\n\nA match object contains a reference to the string that was searched, via its ``string`` attribute. The ``detach_string`` method will 'detach' that string, making it available for garbage collection, which might save valuable memory if that string is very large.\n\n.. sourcecode:: python\n\n  >>> m = regex.search(r\"\\w+\", \"Hello world\")\n  >>> print(m.group())\n  Hello\n  >>> print(m.string)\n  Hello world\n  >>> m.detach_string()\n  >>> print(m.group())\n  Hello\n  >>> print(m.string)\n  None\n\nRecursive patterns (`Hg issue 27 <https://github.com/mrabarnett/mrab-regex/issues/27>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nRecursive and repeated patterns are supported.\n\n``(?R)`` or ``(?0)`` tries to match the entire regex recursively. ``(?1)``, ``(?2)``, etc, try to match the relevant group.\n\n``(?&name)`` tries to match the named group.\n\n.. sourcecode:: python\n\n  >>> regex.match(r\"(Tarzan|Jane) loves (?1)\", \"Tarzan loves Jane\").groups()\n  ('Tarzan',)\n  >>> regex.match(r\"(Tarzan|Jane) loves (?1)\", \"Jane loves Tarzan\").groups()\n  ('Jane',)\n\n  >>> m = regex.search(r\"(\\w)(?:(?R)|(\\w?))\\1\", \"kayak\")\n  >>> m.group(0, 1, 2)\n  ('kayak', 'k', None)\n\nThe first two examples show how the subpattern within the group is reused, but is _not_ itself a group. In other words, ``\"(Tarzan|Jane) loves (?1)\"`` is equivalent to ``\"(Tarzan|Jane) loves (?:Tarzan|Jane)\"``.\n\nIt's possible to backtrack into a recursed or repeated group.\n\nYou can't call a group if there is more than one group with that group name or group number (``\"ambiguous group reference\"``).\n\nThe alternative forms ``(?P>name)`` and ``(?P&name)`` are also supported.\n\nFull Unicode case-folding is supported\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn version 1 behaviour, the regex module uses full case-folding when performing case-insensitive matches in Unicode.\n\n.. sourcecode:: python\n\n  >>> regex.match(r\"(?iV1)strasse\", \"stra\\N{LATIN SMALL LETTER SHARP S}e\").span()\n  (0, 6)\n  >>> regex.match(r\"(?iV1)stra\\N{LATIN SMALL LETTER SHARP S}e\", \"STRASSE\").span()\n  (0, 7)\n\nIn version 0 behaviour, it uses simple case-folding for backward compatibility with the re module.\n\nApproximate \"fuzzy\" matching (`Hg issue 12 <https://github.com/mrabarnett/mrab-regex/issues/12>`_, `Hg issue 41 <https://github.com/mrabarnett/mrab-regex/issues/41>`_, `Hg issue 109 <https://github.com/mrabarnett/mrab-regex/issues/109>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nRegex usually attempts an exact match, but sometimes an approximate, or \"fuzzy\", match is needed, for those cases where the text being searched may contain errors in the form of inserted, deleted or substituted characters.\n\nA fuzzy regex specifies which types of errors are permitted, and, optionally, either the minimum and maximum or only the maximum permitted number of each type. (You cannot specify only a minimum.)\n\nThe 3 types of error are:\n\n* Insertion, indicated by \"i\"\n\n* Deletion, indicated by \"d\"\n\n* Substitution, indicated by \"s\"\n\nIn addition, \"e\" indicates any type of error.\n\nThe fuzziness of a regex item is specified between \"{\" and \"}\" after the item.\n\nExamples:\n\n* ``foo`` match \"foo\" exactly\n\n* ``(?:foo){i}`` match \"foo\", permitting insertions\n\n* ``(?:foo){d}`` match \"foo\", permitting deletions\n\n* ``(?:foo){s}`` match \"foo\", permitting substitutions\n\n* ``(?:foo){i,s}`` match \"foo\", permitting insertions and substitutions\n\n* ``(?:foo){e}`` match \"foo\", permitting errors\n\nIf a certain type of error is specified, then any type not specified will **not** be permitted.\n\nIn the following examples I'll omit the item and write only the fuzziness:\n\n* ``{d<=3}`` permit at most 3 deletions, but no other types\n\n* ``{i<=1,s<=2}`` permit at most 1 insertion and at most 2 substitutions, but no deletions\n\n* ``{1<=e<=3}`` permit at least 1 and at most 3 errors\n\n* ``{i<=2,d<=2,e<=3}`` permit at most 2 insertions, at most 2 deletions, at most 3 errors in total, but no substitutions\n\nIt's also possible to state the costs of each type of error and the maximum permitted total cost.\n\nExamples:\n\n* ``{2i+2d+1s<=4}`` each insertion costs 2, each deletion costs 2, each substitution costs 1, the total cost must not exceed 4\n\n* ``{i<=1,d<=1,s<=1,2i+2d+1s<=4}`` at most 1 insertion, at most 1 deletion, at most 1 substitution; each insertion costs 2, each deletion costs 2, each substitution costs 1, the total cost must not exceed 4\n\nYou can also use \"<\" instead of \"<=\" if you want an exclusive minimum or maximum.\n\nYou can add a test to perform on a character that's substituted or inserted.\n\nExamples:\n\n* ``{s<=2:[a-z]}`` at most 2 substitutions, which must be in the character set ``[a-z]``.\n\n* ``{s<=2,i<=3:\\d}`` at most 2 substitutions, at most 3 insertions, which must be digits.\n\nBy default, fuzzy matching searches for the first match that meets the given constraints. The ``ENHANCEMATCH`` flag will cause it to attempt to improve the fit (i.e. reduce the number of errors) of the match that it has found.\n\nThe ``BESTMATCH`` flag will make it search for the best match instead.\n\nFurther examples to note:\n\n* ``regex.search(\"(dog){e}\", \"cat and dog\")[1]`` returns ``\"cat\"`` because that matches ``\"dog\"`` with 3 errors (an unlimited number of errors is permitted).\n\n* ``regex.search(\"(dog){e<=1}\", \"cat and dog\")[1]`` returns ``\" dog\"`` (with a leading space) because that matches ``\"dog\"`` with 1 error, which is within the limit.\n\n* ``regex.search(\"(?e)(dog){e<=1}\", \"cat and dog\")[1]`` returns ``\"dog\"`` (without a leading space) because the fuzzy search matches ``\" dog\"`` with 1 error, which is within the limit, and the ``(?e)`` then it attempts a better fit.\n\nIn the first two examples there are perfect matches later in the string, but in neither case is it the first possible match.\n\nThe match object has an attribute ``fuzzy_counts`` which gives the total number of substitutions, insertions and deletions.\n\n.. sourcecode:: python\n\n  >>> # A 'raw' fuzzy match:\n  >>> regex.fullmatch(r\"(?:cats|cat){e<=1}\", \"cat\").fuzzy_counts\n  (0, 0, 1)\n  >>> # 0 substitutions, 0 insertions, 1 deletion.\n\n  >>> # A better match might be possible if the ENHANCEMATCH flag used:\n  >>> regex.fullmatch(r\"(?e)(?:cats|cat){e<=1}\", \"cat\").fuzzy_counts\n  (0, 0, 0)\n  >>> # 0 substitutions, 0 insertions, 0 deletions.\n\nThe match object also has an attribute ``fuzzy_changes`` which gives a tuple of the positions of the substitutions, insertions and deletions.\n\n.. sourcecode:: python\n\n  >>> m = regex.search('(fuu){i<=2,d<=2,e<=5}', 'anaconda foo bar')\n  >>> m\n  <regex.Match object; span=(7, 10), match='a f', fuzzy_counts=(0, 2, 2)>\n  >>> m.fuzzy_changes\n  ([], [7, 8], [10, 11])\n\nWhat this means is that if the matched part of the string had been:\n\n.. sourcecode:: python\n\n  'anacondfuuoo bar'\n\nit would've been an exact match.\n\nHowever, there were insertions at positions 7 and 8:\n\n.. sourcecode:: python\n\n  'anaconda fuuoo bar'\n          ^^\n\nand deletions at positions 10 and 11:\n\n.. sourcecode:: python\n\n  'anaconda f~~oo bar'\n             ^^\n\nSo the actual string was:\n\n.. sourcecode:: python\n\n  'anaconda foo bar'\n\nNamed lists ``\\L<name>`` (`Hg issue 11 <https://github.com/mrabarnett/mrab-regex/issues/11>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThere are occasions where you may want to include a list (actually, a set) of options in a regex.\n\nOne way is to build the pattern like this:\n\n.. sourcecode:: python\n\n  >>> p = regex.compile(r\"first|second|third|fourth|fifth\")\n\nbut if the list is large, parsing the resulting regex can take considerable time, and care must also be taken that the strings are properly escaped and properly ordered, for example, \"cats\" before \"cat\".\n\nThe new alternative is to use a named list:\n\n.. sourcecode:: python\n\n  >>> option_set = [\"first\", \"second\", \"third\", \"fourth\", \"fifth\"]\n  >>> p = regex.compile(r\"\\L<options>\", options=option_set)\n\nThe order of the items is irrelevant, they are treated as a set. The named lists are available as the ``.named_lists`` attribute of the pattern object :\n\n.. sourcecode:: python\n\n  >>> print(p.named_lists)\n  {'options': frozenset({'third', 'first', 'fifth', 'fourth', 'second'})}\n\nIf there are any unused keyword arguments, ``ValueError`` will be raised unless you tell it otherwise:\n\n.. sourcecode:: python\n\n  >>> option_set = [\"first\", \"second\", \"third\", \"fourth\", \"fifth\"]\n  >>> p = regex.compile(r\"\\L<options>\", options=option_set, other_options=[])\n  Traceback (most recent call last):\n    File \"<stdin>\", line 1, in <module>\n    File \"C:\\Python310\\lib\\site-packages\\regex\\regex.py\", line 353, in compile\n      return _compile(pattern, flags, ignore_unused, kwargs, cache_pattern)\n    File \"C:\\Python310\\lib\\site-packages\\regex\\regex.py\", line 500, in _compile\n      complain_unused_args()\n    File \"C:\\Python310\\lib\\site-packages\\regex\\regex.py\", line 483, in complain_unused_args\n      raise ValueError('unused keyword argument {!a}'.format(any_one))\n  ValueError: unused keyword argument 'other_options'\n  >>> p = regex.compile(r\"\\L<options>\", options=option_set, other_options=[], ignore_unused=True)\n  >>> p = regex.compile(r\"\\L<options>\", options=option_set, other_options=[], ignore_unused=False)\n  Traceback (most recent call last):\n    File \"<stdin>\", line 1, in <module>\n    File \"C:\\Python310\\lib\\site-packages\\regex\\regex.py\", line 353, in compile\n      return _compile(pattern, flags, ignore_unused, kwargs, cache_pattern)\n    File \"C:\\Python310\\lib\\site-packages\\regex\\regex.py\", line 500, in _compile\n      complain_unused_args()\n    File \"C:\\Python310\\lib\\site-packages\\regex\\regex.py\", line 483, in complain_unused_args\n      raise ValueError('unused keyword argument {!a}'.format(any_one))\n  ValueError: unused keyword argument 'other_options'\n  >>>\n\nStart and end of word\n^^^^^^^^^^^^^^^^^^^^^\n\n``\\m`` matches at the start of a word.\n\n``\\M`` matches at the end of a word.\n\nCompare with ``\\b``, which matches at the start or end of a word.\n\nUnicode line separators\n^^^^^^^^^^^^^^^^^^^^^^^\n\nNormally the only line separator is ``\\n`` (``\\x0A``), but if the ``WORD`` flag is turned on then the line separators are ``\\x0D\\x0A``, ``\\x0A``, ``\\x0B``, ``\\x0C`` and ``\\x0D``, plus ``\\x85``, ``\\u2028`` and ``\\u2029`` when working with Unicode.\n\nThis affects the regex dot ``\".\"``, which, with the ``DOTALL`` flag turned off, matches any character except a line separator. It also affects the line anchors ``^`` and ``$`` (in multiline mode).\n\nSet operators\n^^^^^^^^^^^^^\n\n**Version 1 behaviour only**\n\nSet operators have been added, and a set ``[...]`` can include nested sets.\n\nThe operators, in order of increasing precedence, are:\n\n* ``||`` for union (\"x||y\" means \"x or y\")\n\n* ``~~`` (double tilde) for symmetric difference (\"x~~y\" means \"x or y, but not both\")\n\n* ``&&`` for intersection (\"x&&y\" means \"x and y\")\n\n* ``--`` (double dash) for difference (\"x--y\" means \"x but not y\")\n\nImplicit union, ie, simple juxtaposition like in ``[ab]``, has the highest precedence. Thus, ``[ab&&cd]`` is the same as ``[[a||b]&&[c||d]]``.\n\nExamples:\n\n* ``[ab]`` # Set containing 'a' and 'b'\n\n* ``[a-z]`` # Set containing 'a' .. 'z'\n\n* ``[[a-z]--[qw]]`` # Set containing 'a' .. 'z', but not 'q' or 'w'\n\n* ``[a-z--qw]`` # Same as above\n\n* ``[\\p{L}--QW]`` # Set containing all letters except 'Q' and 'W'\n\n* ``[\\p{N}--[0-9]]`` # Set containing all numbers except '0' .. '9'\n\n* ``[\\p{ASCII}&&\\p{Letter}]`` # Set containing all characters which are ASCII and letter\n\nregex.escape (`issue #2650 <https://bugs.python.org/issue2650>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nregex.escape has an additional keyword parameter ``special_only``. When True, only 'special' regex characters, such as '?', are escaped.\n\n.. sourcecode:: python\n\n  >>> regex.escape(\"foo!?\", special_only=False)\n  'foo\\\\!\\\\?'\n  >>> regex.escape(\"foo!?\", special_only=True)\n  'foo!\\\\?'\n\nregex.escape (`Hg issue 249 <https://github.com/mrabarnett/mrab-regex/issues/249>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nregex.escape has an additional keyword parameter ``literal_spaces``. When True, spaces are not escaped.\n\n.. sourcecode:: python\n\n  >>> regex.escape(\"foo bar!?\", literal_spaces=False)\n  'foo\\\\ bar!\\\\?'\n  >>> regex.escape(\"foo bar!?\", literal_spaces=True)\n  'foo bar!\\\\?'\n\nRepeated captures (`issue #7132 <https://bugs.python.org/issue7132>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA match object has additional methods which return information on all the successful matches of a repeated group. These methods are:\n\n* ``matchobject.captures([group1, ...])``\n\n  * Returns a list of the strings matched in a group or groups. Compare with ``matchobject.group([group1, ...])``.\n\n* ``matchobject.starts([group])``\n\n  * Returns a list of the start positions. Compare with ``matchobject.start([group])``.\n\n* ``matchobject.ends([group])``\n\n  * Returns a list of the end positions. Compare with ``matchobject.end([group])``.\n\n* ``matchobject.spans([group])``\n\n  * Returns a list of the spans. Compare with ``matchobject.span([group])``.\n\n.. sourcecode:: python\n\n  >>> m = regex.search(r\"(\\w{3})+\", \"123456789\")\n  >>> m.group(1)\n  '789'\n  >>> m.captures(1)\n  ['123', '456', '789']\n  >>> m.start(1)\n  6\n  >>> m.starts(1)\n  [0, 3, 6]\n  >>> m.end(1)\n  9\n  >>> m.ends(1)\n  [3, 6, 9]\n  >>> m.span(1)\n  (6, 9)\n  >>> m.spans(1)\n  [(0, 3), (3, 6), (6, 9)]\n\nAtomic grouping ``(?>...)`` (`issue #433030 <https://bugs.python.org/issue433030>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIf the following pattern subsequently fails, then the subpattern as a whole will fail.\n\nPossessive quantifiers\n^^^^^^^^^^^^^^^^^^^^^^\n\n``(?:...)?+`` ; ``(?:...)*+`` ; ``(?:...)++`` ; ``(?:...){min,max}+``\n\nThe subpattern is matched up to 'max' times. If the following pattern subsequently fails, then all the repeated subpatterns will fail as a whole. For example, ``(?:...)++`` is equivalent to ``(?>(?:...)+)``.\n\nScoped flags (`issue #433028 <https://bugs.python.org/issue433028>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``(?flags-flags:...)``\n\nThe flags will apply only to the subpattern. Flags can be turned on or off.\n\nDefinition of 'word' character (`issue #1693050 <https://bugs.python.org/issue1693050>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe definition of a 'word' character has been expanded for Unicode. It conforms to the Unicode specification at ``http://www.unicode.org/reports/tr29/``.\n\nVariable-length lookbehind\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA lookbehind can match a variable-length string.\n\nFlags argument for regex.split, regex.sub and regex.subn (`issue #3482 <https://bugs.python.org/issue3482>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``regex.split``, ``regex.sub`` and ``regex.subn`` support a 'flags' argument.\n\nPos and endpos arguments for regex.sub and regex.subn\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``regex.sub`` and ``regex.subn`` support 'pos' and 'endpos' arguments.\n\n'Overlapped' argument for regex.findall and regex.finditer\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``regex.findall`` and ``regex.finditer`` support an 'overlapped' flag which permits overlapped matches.\n\nSplititer\n^^^^^^^^^\n\n``regex.splititer`` has been added. It's a generator equivalent of ``regex.split``.\n\nSubscripting match objects for groups\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA match object accepts access to the groups via subscripting and slicing:\n\n.. sourcecode:: python\n\n  >>> m = regex.search(r\"(?P<before>.*?)(?P<num>\\d+)(?P<after>.*)\", \"pqr123stu\")\n  >>> print(m[\"before\"])\n  pqr\n  >>> print(len(m))\n  4\n  >>> print(m[:])\n  ('pqr123stu', 'pqr', '123', 'stu')\n\nNamed groups\n^^^^^^^^^^^^\n\nGroups can be named with ``(?<name>...)`` as well as the existing ``(?P<name>...)``.\n\nGroup references\n^^^^^^^^^^^^^^^^\n\nGroups can be referenced within a pattern with ``\\g<name>``. This also allows there to be more than 99 groups.\n\nNamed characters ``\\N{name}``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nNamed characters are supported. Note that only those known by Python's Unicode database will be recognised.\n\nUnicode codepoint properties, including scripts and blocks\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``\\p{property=value}``; ``\\P{property=value}``; ``\\p{value}`` ; ``\\P{value}``\n\nMany Unicode properties are supported, including blocks and scripts. ``\\p{property=value}`` or ``\\p{property:value}`` matches a character whose property ``property`` has value ``value``. The inverse of ``\\p{property=value}`` is ``\\P{property=value}`` or ``\\p{^property=value}``.\n\nIf the short form ``\\p{value}`` is used, the properties are checked in the order: ``General_Category``, ``Script``, ``Block``, binary property:\n\n* ``Latin``, the 'Latin' script (``Script=Latin``).\n\n* ``BasicLatin``, the 'BasicLatin' block (``Block=BasicLatin``).\n\n* ``Alphabetic``, the 'Alphabetic' binary property (``Alphabetic=Yes``).\n\nA short form starting with ``Is`` indicates a script or binary property:\n\n* ``IsLatin``, the 'Latin' script (``Script=Latin``).\n\n* ``IsAlphabetic``, the 'Alphabetic' binary property (``Alphabetic=Yes``).\n\nA short form starting with ``In`` indicates a block property:\n\n* ``InBasicLatin``, the 'BasicLatin' block (``Block=BasicLatin``).\n\nPOSIX character classes\n^^^^^^^^^^^^^^^^^^^^^^^\n\n``[[:alpha:]]``; ``[[:^alpha:]]``\n\nPOSIX character classes are supported. These are normally treated as an alternative form of ``\\p{...}``.\n\nThe exceptions are ``alnum``, ``digit``, ``punct`` and ``xdigit``, whose definitions are different from those of Unicode.\n\n``[[:alnum:]]`` is equivalent to ``\\p{posix_alnum}``.\n\n``[[:digit:]]`` is equivalent to ``\\p{posix_digit}``.\n\n``[[:punct:]]`` is equivalent to ``\\p{posix_punct}``.\n\n``[[:xdigit:]]`` is equivalent to ``\\p{posix_xdigit}``.\n\nSearch anchor ``\\G``\n^^^^^^^^^^^^^^^^^^^^\n\nA search anchor has been added. It matches at the position where each search started/continued and can be used for contiguous matches or in negative variable-length lookbehinds to limit how far back the lookbehind goes:\n\n.. sourcecode:: python\n\n  >>> regex.findall(r\"\\w{2}\", \"abcd ef\")\n  ['ab', 'cd', 'ef']\n  >>> regex.findall(r\"\\G\\w{2}\", \"abcd ef\")\n  ['ab', 'cd']\n\n* The search starts at position 0 and matches 'ab'.\n\n* The search continues at position 2 and matches 'cd'.\n\n* The search continues at position 4 and fails to match any letters.\n\n* The anchor stops the search start position from being advanced, so there are no more results.\n\nReverse searching\n^^^^^^^^^^^^^^^^^\n\nSearches can also work backwards:\n\n.. sourcecode:: python\n\n  >>> regex.findall(r\".\", \"abc\")\n  ['a', 'b', 'c']\n  >>> regex.findall(r\"(?r).\", \"abc\")\n  ['c', 'b', 'a']\n\nNote that the result of a reverse search is not necessarily the reverse of a forward search:\n\n.. sourcecode:: python\n\n  >>> regex.findall(r\"..\", \"abcde\")\n  ['ab', 'cd']\n  >>> regex.findall(r\"(?r)..\", \"abcde\")\n  ['de', 'bc']\n\nMatching a single grapheme ``\\X``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe grapheme matcher is supported. It conforms to the Unicode specification at ``http://www.unicode.org/reports/tr29/``.\n\nBranch reset ``(?|...|...)``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nGroup numbers will be reused across the alternatives, but groups with different names will have different group numbers.\n\n.. sourcecode:: python\n\n  >>> regex.match(r\"(?|(first)|(second))\", \"first\").groups()\n  ('first',)\n  >>> regex.match(r\"(?|(first)|(second))\", \"second\").groups()\n  ('second',)\n\nNote that there is only one group.\n\nDefault Unicode word boundary\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``WORD`` flag changes the definition of a 'word boundary' to that of a default Unicode word boundary. This applies to ``\\b`` and ``\\B``.\n\nTimeout\n^^^^^^^\n\nThe matching methods and functions support timeouts. The timeout (in seconds) applies to the entire operation:\n\n.. sourcecode:: python\n\n  >>> from time import sleep\n  >>>\n  >>> def fast_replace(m):\n  ...     return 'X'\n  ...\n  >>> def slow_replace(m):\n  ...     sleep(0.5)\n  ...     return 'X'\n  ...\n  >>> regex.sub(r'[a-z]', fast_replace, 'abcde', timeout=2)\n  'XXXXX'\n  >>> regex.sub(r'[a-z]', slow_replace, 'abcde', timeout=2)\n  Traceback (most recent call last):\n    File \"<stdin>\", line 1, in <module>\n    File \"C:\\Python310\\lib\\site-packages\\regex\\regex.py\", line 278, in sub\n      return pat.sub(repl, string, count, pos, endpos, concurrent, timeout)\n  TimeoutError: regex timed out\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/mrabarnett/mrab-regex",
        "author": "Matthew Barnett",
        "author_email": "regex@mrabarnett.plus.com",
        "license": "Apache Software License",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Scientific/Engineering :: Information Analysis",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Text Processing",
          "Topic :: Text Processing :: General"
        ],
        "requires_python": ">=3.8"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\regex-2024.7.24.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "requests",
        "version": "2.32.3",
        "summary": "Python HTTP for Humans.",
        "description": "# Requests\n\n**Requests** is a simple, yet elegant, HTTP library.\n\n```python\n>>> import requests\n>>> r = requests.get('https://httpbin.org/basic-auth/user/pass', auth=('user', 'pass'))\n>>> r.status_code\n200\n>>> r.headers['content-type']\n'application/json; charset=utf8'\n>>> r.encoding\n'utf-8'\n>>> r.text\n'{\"authenticated\": true, ...'\n>>> r.json()\n{'authenticated': True, ...}\n```\n\nRequests allows you to send HTTP/1.1 requests extremely easily. Thereâ€™s no need to manually add query strings to your URLs, or to form-encode your `PUT` & `POST` data â€” but nowadays, just use the `json` method!\n\nRequests is one of the most downloaded Python packages today, pulling in around `30M downloads / week`â€” according to GitHub, Requests is currently [depended upon](https://github.com/psf/requests/network/dependents?package_id=UGFja2FnZS01NzA4OTExNg%3D%3D) by `1,000,000+` repositories. You may certainly put your trust in this code.\n\n[![Downloads](https://static.pepy.tech/badge/requests/month)](https://pepy.tech/project/requests)\n[![Supported Versions](https://img.shields.io/pypi/pyversions/requests.svg)](https://pypi.org/project/requests)\n[![Contributors](https://img.shields.io/github/contributors/psf/requests.svg)](https://github.com/psf/requests/graphs/contributors)\n\n## Installing Requests and Supported Versions\n\nRequests is available on PyPI:\n\n```console\n$ python -m pip install requests\n```\n\nRequests officially supports Python 3.8+.\n\n## Supported Features & Bestâ€“Practices\n\nRequests is ready for the demands of building robust and reliable HTTPâ€“speaking applications, for the needs of today.\n\n- Keep-Alive & Connection Pooling\n- International Domains and URLs\n- Sessions with Cookie Persistence\n- Browser-style TLS/SSL Verification\n- Basic & Digest Authentication\n- Familiar `dict`â€“like Cookies\n- Automatic Content Decompression and Decoding\n- Multi-part File Uploads\n- SOCKS Proxy Support\n- Connection Timeouts\n- Streaming Downloads\n- Automatic honoring of `.netrc`\n- Chunked HTTP Requests\n\n## API Reference and User Guide available on [Read the Docs](https://requests.readthedocs.io)\n\n[![Read the Docs](https://raw.githubusercontent.com/psf/requests/main/ext/ss.png)](https://requests.readthedocs.io)\n\n## Cloning the repository\n\nWhen cloning the Requests repository, you may need to add the `-c\nfetch.fsck.badTimezone=ignore` flag to avoid an error about a bad commit (see\n[this issue](https://github.com/psf/requests/issues/2690) for more background):\n\n```shell\ngit clone -c fetch.fsck.badTimezone=ignore https://github.com/psf/requests.git\n```\n\nYou can also apply this setting to your global Git config:\n\n```shell\ngit config --global fetch.fsck.badTimezone ignore\n```\n\n---\n\n[![Kenneth Reitz](https://raw.githubusercontent.com/psf/requests/main/ext/kr.png)](https://kennethreitz.org) [![Python Software Foundation](https://raw.githubusercontent.com/psf/requests/main/ext/psf.png)](https://www.python.org/psf)\n",
        "description_content_type": "text/markdown",
        "home_page": "https://requests.readthedocs.io",
        "author": "Kenneth Reitz",
        "author_email": "me@kennethreitz.org",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet :: WWW/HTTP",
          "Topic :: Software Development :: Libraries"
        ],
        "requires_dist": [
          "charset-normalizer <4,>=2",
          "idna <4,>=2.5",
          "urllib3 <3,>=1.21.1",
          "certifi >=2017.4.17",
          "PySocks !=1.5.7,>=1.5.6 ; extra == 'socks'",
          "chardet <6,>=3.0.2 ; extra == 'use_chardet_on_py3'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://requests.readthedocs.io",
          "Source, https://github.com/psf/requests"
        ],
        "provides_extra": [
          "security",
          "socks",
          "use_chardet_on_py3"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\requests-2.32.3.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "requirements-parser",
        "version": "0.5.0",
        "summary": "This is a small Python module for parsing Pip requirement files.",
        "description": "Requirements Parser\n===================\n\n[![Python CI](https://github.com/madpah/requirements-parser/actions/workflows/poetry.yml/badge.svg)](https://github.com/madpah/requirements-parser/actions/workflows/poetry.yml)\n[![Documentation Status](http://readthedocs.org/projects/requirements-parser/badge/?version=latest)](http://requirements-parser.readthedocs.io/en/latest/?badge=latest)\n[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nThis is a small Python module for parsing [Pip](http://www.pip-installer.org/) requirement files.\n\nThe goal is to parse everything in the \n[Pip requirement file format](https://pip.pypa.io/en/stable/reference/pip_install/#requirements-file-format) spec.\n\nInstallation\n============\n\n    pip install requirements-parser\n\nor\n\n    poetry add requirements-parser\n\nExamples\n========\n\nRequirements parser can parse a file-like object or a text string.\n\n``` {.python}\n>>> import requirements\n>>> with open('requirements.txt', 'r') as fd:\n...     for req in requirements.parse(fd):\n...         print(req.name, req.specs)\nDjango [('>=', '1.11'), ('<', '1.12')]\nsix [('==', '1.10.0')]\n```\n\nIt can handle most if not all of the options in requirement files that\ndo not involve traversing the local filesystem. These include:\n\n-   editables (`-e git+https://github.com/toastdriven/pyelasticsearch.git]{.title-ref}`)\n-   version control URIs\n-   egg hashes and subdirectories (`[\\#egg=django-haystack&subdirectory=setup]{.title-ref}`)\n-   extras ([DocParser\\[PDF\\]]{.title-ref})\n-   URLs\n\nDocumentation\n=============\n\nFor more details and examples, the documentation is available at:\n<http://requirements-parser.readthedocs.io>.\n\n\nChange Log\n==========\n\nChange log is available on GitHub [here]()\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "Pip",
          "requirements",
          "parse"
        ],
        "home_page": "https://github.com/madpah/requirements-parser",
        "author": "Paul Horton",
        "author_email": "simplyecommerce@gmail.com",
        "maintainer": "Paul Horton",
        "maintainer_email": "simplyecommerce@gmail.com",
        "license": "Apache-2.0",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Topic :: Software Development",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: System :: Software Distribution",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "types-setuptools (>=57.0.0)"
        ],
        "requires_python": ">=3.6,<4.0",
        "project_url": [
          "Bug Tracker, https://github.com/madpah/requirements-parser/issues",
          "Repository, https://github.com/madpah/requirements-parser"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\requirements_parser-0.5.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "rfc3339-validator",
        "version": "0.1.4",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "A pure python RFC3339 validator",
        "description": "# rfc3339-validator\n\nA pure python RFC3339 validator\n\n\n[![image](https://img.shields.io/pypi/v/rfc3339_validator.svg)](https://pypi.python.org/pypi/rfc3339_validator)\n[![Build Status](https://travis-ci.org/naimetti/rfc3339-validator.svg?branch=master)](https://travis-ci.org/naimetti/rfc3339-validator)\n\n# Install\n\n```shell script\npip install rfc3339-validator\n```\n\n# Usage\n\n```python\nfrom rfc3339_validator import validate_rfc3339\n\nvalidate_rfc3339('1424-45-93T15:32:12.9023368Z')\n>>> False\n\nvalidate_rfc3339('2001-10-23T15:32:12.9023368Z')\n>>> True\n```\n\n\n  - Free software: MIT license\n\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "rfc3339",
          "validator"
        ],
        "home_page": "https://github.com/naimetti/rfc3339-validator",
        "author": "Nicolas Aimetti",
        "author_email": "naimetti@yahoo.com.ar",
        "license": "MIT license",
        "classifier": [
          "Development Status :: 2 - Pre-Alpha",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Natural Language :: English",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8"
        ],
        "requires_dist": [
          "six"
        ],
        "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\rfc3339_validator-0.1.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.0",
        "name": "rfc3987",
        "version": "1.3.8",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "Parsing and validation of URIs (RFC 3986) and IRIs (RFC 3987)",
        "description": "This module provides regular expressions according to `RFC 3986 \"Uniform\nResource Identifier (URI): Generic Syntax\"\n<http://tools.ietf.org/html/rfc3986>`_ and `RFC 3987 \"Internationalized\nResource Identifiers (IRIs)\" <http://tools.ietf.org/html/rfc3987>`_, and\nutilities for composition and relative resolution of references.\n\n\nAPI\n---\n\n**match** (string, rule='IRI_reference')\n    Convenience function for checking if `string` matches a specific rule.\n\n    Returns a match object or None::\n\n        >>> assert match('%C7X', 'pct_encoded') is None\n        >>> assert match('%C7', 'pct_encoded')\n        >>> assert match('%c7', 'pct_encoded')\n\n\n\n**parse** (string, rule='IRI_reference')\n    Parses `string` according to `rule` into a dict of subcomponents.\n\n    If `rule` is None, parse an IRI_reference `without validation\n    <http://tools.ietf.org/html/rfc3986#appendix-B>`_.\n\n    If regex_ is available, any rule is supported; with re_, `rule` must be\n    'IRI_reference' or some special case thereof ('IRI', 'absolute_IRI',\n    'irelative_ref', 'irelative_part', 'URI_reference', 'URI', 'absolute_URI',\n    'relative_ref', 'relative_part'). ::\n\n        >>> d = parse('http://tools.ietf.org/html/rfc3986#appendix-A',\n        ...           rule='URI')\n        >>> assert all([ d['scheme'] == 'http',\n        ...              d['authority'] == 'tools.ietf.org',\n        ...              d['path'] == '/html/rfc3986',\n        ...              d['query'] == None,\n        ...              d['fragment'] == 'appendix-A' ])\n\n\n\n**compose** (\\*\\*parts)\n    Returns an URI composed_ from named parts.\n\n    .. _composed: http://tools.ietf.org/html/rfc3986#section-5.3\n\n\n**resolve** (base, uriref, strict=True, return_parts=False)\n    Resolves_ an `URI reference` relative to a `base` URI.\n\n    `Test cases <http://tools.ietf.org/html/rfc3986#section-5.4>`_::\n\n        >>> base = resolve.test_cases_base\n        >>> for relative, resolved in resolve.test_cases.items():\n        ...     assert resolve(base, relative) == resolved\n\n    If `return_parts` is True, returns a dict of named parts instead of\n    a string.\n\n    Examples::\n\n        >>> assert resolve('urn:rootless', '../../name') == 'urn:name'\n        >>> assert resolve('urn:root/less', '../../name') == 'urn:/name'\n        >>> assert resolve('http://a/b', 'http:g') == 'http:g'\n        >>> assert resolve('http://a/b', 'http:g', strict=False) == 'http://a/g'\n\n    .. _Resolves: http://tools.ietf.org/html/rfc3986#section-5.2\n\n\n\n**patterns**\n    A dict of regular expressions with useful group names.\n    Compilable (with regex_ only) without need for any particular compilation\n    flag.\n\n**[bmp_][u]patterns[_no_names]**\n    Alternative versions of `patterns`.\n    [u]nicode strings without group names for the re_ module.\n    BMP only for narrow builds.\n\n**get_compiled_pattern** (rule, flags=0)\n    Returns a compiled pattern object for a rule name or template string.\n\n    Usage for validation::\n\n        >>> uri = get_compiled_pattern('^%(URI)s$')\n        >>> assert uri.match('http://tools.ietf.org/html/rfc3986#appendix-A')\n        >>> assert not get_compiled_pattern('^%(relative_ref)s$').match('#f#g')\n        >>> from unicodedata import lookup\n        >>> smp = 'urn:' + lookup('OLD ITALIC LETTER A')  # U+00010300\n        >>> assert not uri.match(smp)\n        >>> m = get_compiled_pattern('^%(IRI)s$').match(smp)\n\n    On narrow builds, non-BMP characters are (incorrectly) excluded::\n\n        >>> assert NARROW_BUILD == (not m)\n\n    For parsing, some subcomponents are captured in named groups (*only if*\n    regex_ is available, otherwise see `parse`)::\n\n        >>> match = uri.match('http://tools.ietf.org/html/rfc3986#appendix-A')\n        >>> d = match.groupdict()\n        >>> if REGEX:\n        ...     assert all([ d['scheme'] == 'http',\n        ...                  d['authority'] == 'tools.ietf.org',\n        ...                  d['path'] == '/html/rfc3986',\n        ...                  d['query'] == None,\n        ...                  d['fragment'] == 'appendix-A' ])\n\n        >>> for r in patterns.keys():\n        ...     assert get_compiled_pattern(r)\n\n\n\n**format_patterns** (\\*\\*names)\n    Returns a dict of patterns (regular expressions) keyed by\n    `rule names for URIs`_ and `rule names for IRIs`_.\n\n    See also the module level dicts of patterns, and `get_compiled_pattern`.\n\n    To wrap a rule in a named capture group, pass it as keyword argument:\n    rule_name='group_name'. By default, the formatted patterns contain no\n    named groups.\n\n    Patterns are `str` instances (be it in python 2.x or 3.x) containing ASCII\n    characters only.\n\n    Caveats:\n\n      - with re_, named capture groups cannot occur on multiple branches of an\n        alternation\n\n      - with re_ before python 3.3, ``\\u`` and ``\\U`` escapes must be\n        preprocessed (see `issue3665 <http://bugs.python.org/issue3665>`_)\n\n      - on narrow builds, character ranges beyond BMP are not supported\n\n    .. _rule names for URIs: http://tools.ietf.org/html/rfc3986#appendix-A\n    .. _rule names for IRIs: http://tools.ietf.org/html/rfc3987#section-2.2\n\n\n\nDependencies\n------------\n\nSome features require regex_.\n\nThis package's docstrings are tested on python 2.6, 2.7, and 3.2 to 3.6.\nNote that in python<=3.2, characters beyond the Basic Multilingual Plane are\nnot supported on narrow builds (see `issue12729\n<http://bugs.python.org/issue12729>`_).\n\n\nRelease notes\n-------------\n\nversion 1.3.8:\n\n- fixed deprecated escape sequence\n\nversion 1.3.6:\n\n- fixed a bug in IPv6 pattern:\n\n  >>> assert match('::0:0:0:0:0.0.0.0', 'IPv6address')\n\nversion 1.3.4:\n\n- allowed for lower case percent encoding\n\nversion 1.3.3:\n\n- fixed a bug in `resolve` which left \"../\" at the beginning of some paths\n\nversion 1.3.2:\n\n- convenience function `match`\n- patterns restricted to the BMP for narrow builds\n- adapted doctests for python 3.3\n- compatibility with python 2.6 (thanks to Thijs Janssen)\n\nversion 1.3.1:\n\n- some re_ compatibility: get_compiled_pattern, parse\n- dropped regex_ from setup.py requirements\n\nversion 1.3.0:\n\n- python 3.x compatibility\n- format_patterns\n\nversion 1.2.1:\n\n- compose, resolve\n\n\n.. _re: http://docs.python.org/library/re\n.. _regex: http://pypi.python.org/pypi/regex\n\n\nSupport\n-------\nThis is free software. You may show your appreciation with a `donation`_.\n\n.. _donation: http://danielgerber.net/Â¤#Thanks-for-python-package-rfc3987\n\n\n\n",
        "keywords": [
          "URI",
          "IRI",
          "URL",
          "rfc3986",
          "rfc3987",
          "validation"
        ],
        "home_page": "http://pypi.python.org/pypi/rfc3987",
        "download_url": "https://github.com/dgerber/rfc3987",
        "author": "Daniel Gerber",
        "author_email": "daniel.g.gerber@gmail.com",
        "license": "GNU GPLv3+",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.6",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.2",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Topic :: Internet"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\rfc3987-1.3.8.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "rpds-py",
        "version": "0.20.0",
        "summary": "Python bindings to Rust's persistent data structures (rpds)",
        "description": "===========\n``rpds.py``\n===========\n\n|PyPI| |Pythons| |CI|\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/rpds-py.svg\n  :alt: PyPI version\n  :target: https://pypi.org/project/rpds-py/\n\n.. |Pythons| image:: https://img.shields.io/pypi/pyversions/rpds-py.svg\n  :alt: Supported Python versions\n  :target: https://pypi.org/project/rpds-py/\n\n.. |CI| image:: https://github.com/crate-py/rpds/workflows/CI/badge.svg\n  :alt: Build status\n  :target: https://github.com/crate-py/rpds/actions?query=workflow%3ACI\n\n.. |ReadTheDocs| image:: https://readthedocs.org/projects/referencing/badge/?version=stable&style=flat\n   :alt: ReadTheDocs status\n   :target: https://referencing.readthedocs.io/en/stable/\n\n\nPython bindings to the `Rust rpds crate <https://docs.rs/rpds/>`_ for persistent data structures.\n\nWhat's here is quite minimal (in transparency, it was written initially to support replacing ``pyrsistent`` in the `referencing library <https://github.com/python-jsonschema/referencing>`_).\nIf you see something missing (which is very likely), a PR is definitely welcome to add it.\n\nInstallation\n------------\n\nThe distribution on PyPI is named ``rpds.py`` (equivalently ``rpds-py``), and thus can be installed via e.g.:\n\n.. code:: sh\n\n    $ pip install rpds-py\n\nNote that if you install ``rpds-py`` from source, you will need a Rust toolchain installed, as it is a build-time dependency.\nAn example of how to do so in a ``Dockerfile`` can be found `here <https://github.com/bowtie-json-schema/bowtie/blob/e77fd93598cb6e7dc1b8b1f53c00e5aa410c201a/implementations/python-jsonschema/Dockerfile#L1-L8>`_.\n\nIf you believe you are on a common platform which should have wheels built (i.e. and not need to compile from source), feel free to file an issue or pull request modifying the GitHub action used here to build wheels via ``maturin``.\n\nUsage\n-----\n\nMethods in general are named similarly to their ``rpds`` counterparts (rather than ``pyrsistent``\\ 's conventions, though probably a full drop-in ``pyrsistent``\\ -compatible wrapper module is a good addition at some point).\n\n.. code:: python\n\n    >>> from rpds import HashTrieMap, HashTrieSet, List\n\n    >>> m = HashTrieMap({\"foo\": \"bar\", \"baz\": \"quux\"})\n    >>> m.insert(\"spam\", 37) == HashTrieMap({\"foo\": \"bar\", \"baz\": \"quux\", \"spam\": 37})\n    True\n    >>> m.remove(\"foo\") == HashTrieMap({\"baz\": \"quux\"})\n    True\n\n    >>> s = HashTrieSet({\"foo\", \"bar\", \"baz\", \"quux\"})\n    >>> s.insert(\"spam\") == HashTrieSet({\"foo\", \"bar\", \"baz\", \"quux\", \"spam\"})\n    True\n    >>> s.remove(\"foo\") == HashTrieSet({\"bar\", \"baz\", \"quux\"})\n    True\n\n    >>> L = List([1, 3, 5])\n    >>> L.push_front(-1) == List([-1, 1, 3, 5])\n    True\n    >>> L.rest == List([3, 5])\n    True\n\n",
        "description_content_type": "text/x-rst; charset=UTF-8",
        "keywords": [
          "data structures",
          "rust",
          "persistent"
        ],
        "author_email": "Julian Berman <Julian+rpds@GrayVines.com>",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Rust",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://rpds.readthedocs.io/",
          "Homepage, https://github.com/crate-py/rpds",
          "Issues, https://github.com/crate-py/rpds/issues/",
          "Funding, https://github.com/sponsors/Julian",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-rpds-py?utm_source=pypi-rpds-py&utm_medium=referral&utm_campaign=pypi-link",
          "Source, https://github.com/crate-py/rpds"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\rpds_py-0.20.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "s3transfer",
        "version": "0.10.2",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "An Amazon S3 Transfer Manager",
        "description": "=====================================================\ns3transfer - An Amazon S3 Transfer Manager for Python\n=====================================================\n\nS3transfer is a Python library for managing Amazon S3 transfers.\nThis project is maintained and published by Amazon Web Services.\n\n.. note::\n\n  This project is not currently GA. If you are planning to use this code in\n  production, make sure to lock to a minor version as interfaces may break\n  from minor version to minor version. For a basic, stable interface of\n  s3transfer, try the interfaces exposed in `boto3 <https://boto3.readthedocs.io/en/latest/guide/s3.html#using-the-transfer-manager>`__\n\n\n",
        "home_page": "https://github.com/boto/s3transfer",
        "author": "Amazon Web Services",
        "author_email": "kyknapp1@gmail.com",
        "license": "Apache License 2.0",
        "license_file": [
          "LICENSE.txt",
          "NOTICE.txt"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12"
        ],
        "requires_dist": [
          "botocore (<2.0a.0,>=1.33.2)",
          "botocore[crt] (<2.0a.0,>=1.33.2) ; extra == 'crt'"
        ],
        "requires_python": ">= 3.8",
        "provides_extra": [
          "crt"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\s3transfer-0.10.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "sbommerge",
        "version": "0.2.0",
        "summary": "Software Bill of Material (SBOM) merge tool",
        "description": "# SBOMMerge\n\nSBOMMerge merges two Software Bill of Materials (SBOMs) documents together. It supports SBOMs created in both\n[SPDX](https://www.spdx.org) and [CycloneDX](https://www.cyclonedx.org) formats.\n\n## Installation\n\nTo install use the following command:\n\n`pip install sbommerge`\n\nAlternatively, just clone the repo and install dependencies using the following command:\n\n`pip install -U -r requirements.txt`\n\nThe tool requires Python 3 (3.7+). It is recommended to use a virtual python environment especially\nif you are using different versions of python. `virtualenv` is a tool for setting up virtual python environments which\nallows you to have all the dependencies for the tool set up in a single environment, or have different environments set\nup for testing using different versions of Python.\n\n## Usage\n\n```bash\nusage: sbommerge [-h] [--sbom {auto,spdx,cyclonedx}] [-d] [--format {tag,json,yaml}] [-o OUTPUT_FILE] [-V] FILE1 FILE2\n\nSBOMMerge merges two Software Bill of Materials (SBOMs) documents together.\n\npositional arguments:\n  FILE1                 first SBOM file\n  FILE2                 second SBOM file\n\noptions:\n  -h, --help            show this help message and exit\n  -V, --version         show program's version number and exit\n\nInput:\n  --sbom {auto,spdx,cyclonedx}\n                        specify type of sbom to merge (default: auto)\n\nOutput:\n  -d, --debug           show debug information\n  --format {tag,json,yaml}\n                        specify format of generated sbom (default: tag)\n  -o OUTPUT_FILE, --output-file OUTPUT_FILE\n                        output filename (default: output to stdout)\n```\n\t\t\t\t\t\t\n## Operation\n\nThe `--sbom` option is used to specify the format of the SBOM files. The default is for the type and format of the SBOM to be\nautomatically detected based on the extension of the file name.\n\n| SBOM Type | Version   | Extension      |Format         |\n| --------- | --------- | ---------------|---------------|\n| SPDX      | 2.3       | .spdx          | TagValue      |\n| SPDX      | 2.3       | .spdx.json     | JSON          |\n| SPDX      | 2.3       | .spdx.yml      | YAML          |\n| SPDX      | 2.3       | .spdx.yaml     | YAML          |\n| CycloneDX | 1.4       | .json          | JSON          |\n| CycloneDX | 1.5       | .json          | JSON          |\n\nDetails of the formats for each of the supported SBOM formats are available for\n[SPDX](https://spdx.dev/) and [CycloneDX](https://cyclonedx.org/).\n\nFor SPDX SBOM files, it is assumed that the name of a Package precedes the version information for the package.\nOnly modules with a package name and associated version information shall be processed.\n\nThe `--output-file` option is used to control the destination of the output generated by the tool. The\ndefault is to report to the console but can be stored in a file (specified using `--output-file` option).\n\n## Implementation Notes\n\nThe following design decisions have been made in processing the SBOM files:\n\n1. Package data is merged if the package version matches. Otherwise separate packages will be created.\n\n2. It is assumed that the SBOM is valid and contains syntactically valid data. Invalid files will be silently ignored.\n\n3. A non-zero return value indicates that differences were detected.\n\n## License\n\nLicensed under the Apache 2.0 Licence.\n\n## Limitations\n\nThis tool is meant to support software development and security audit functions. However the usefulness of the tool is dependent on the SBOM data\nwhich is provided to the tool. Unfortunately, the tool is unable to determine the validity or completeness of such a SBOM file; users of the tool\nare therefore reminded that they should assert the quality of any data which is provided to the tool.\n\n## Feedback and Contributions\n\nBugs and feature requests can be made via GitHub Issues.\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "security",
          "tools",
          "SBOM",
          "DevSecOps",
          "SPDX",
          "CycloneDX"
        ],
        "home_page": "https://github.com/anthonyharrison/sbommerge",
        "author": "Anthony Harrison",
        "author_email": "anthony.p.harrison@gmail.com",
        "maintainer": "Anthony Harrison",
        "maintainer_email": "anthony.p.harrison@gmail.com",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_dist": [
          "lib4sbom (>=0.4.0)"
        ],
        "requires_python": ">=3.7"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\sbommerge-0.2.0.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "semantic-version",
        "version": "2.10.0",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "A library implementing the 'SemVer' scheme.",
        "description": "Introduction\n============\n\nThis small python library provides a few tools to handle `SemVer`_ in Python.\nIt follows strictly the 2.0.0 version of the SemVer scheme.\n\n.. image:: https://github.com/rbarrois/python-semanticversion/actions/workflows/test.yml/badge.svg\n    :target: https://github.com/rbarrois/python-semanticversion/actions/workflows/test.yml\n\n.. image:: https://img.shields.io/pypi/v/semantic_version.svg\n    :target: https://python-semanticversion.readthedocs.io/en/latest/changelog.html\n    :alt: Latest Version\n\n.. image:: https://img.shields.io/pypi/pyversions/semantic_version.svg\n    :target: https://pypi.python.org/pypi/semantic_version/\n    :alt: Supported Python versions\n\n.. image:: https://img.shields.io/pypi/wheel/semantic_version.svg\n    :target: https://pypi.python.org/pypi/semantic_version/\n    :alt: Wheel status\n\n.. image:: https://img.shields.io/pypi/l/semantic_version.svg\n    :target: https://pypi.python.org/pypi/semantic_version/\n    :alt: License\n\nLinks\n-----\n\n- Package on `PyPI`_: https://pypi.org/project/semantic-version/\n- Doc on `ReadTheDocs <http://readthedocs.org/>`_: https://python-semanticversion.readthedocs.io/\n- Source on `GitHub <http://github.com/>`_: http://github.com/rbarrois/python-semanticversion/\n- Build on Github Actions: https://github.com/rbarrois/python-semanticversion/actions\n- Semantic Version specification: `SemVer`_\n\n\nGetting started\n===============\n\nInstall the package from `PyPI`_, using pip:\n\n.. code-block:: sh\n\n    pip install semantic-version\n\nOr from GitHub:\n\n.. code-block:: sh\n\n    $ git clone git://github.com/rbarrois/python-semanticversion.git\n\n\nImport it in your code:\n\n\n.. code-block:: python\n\n    import semantic_version\n\n\nThis module provides classes to handle semantic versions:\n\n- ``Version`` represents a version number (``0.1.1-alpha+build.2012-05-15``)\n- ``BaseSpec``-derived classes represent requirement specifications (``>=0.1.1,<0.3.0``):\n\n  - ``SimpleSpec`` describes a natural description syntax\n  - ``NpmSpec`` is used for NPM-style range descriptions.\n\nVersions\n--------\n\nDefining a ``Version`` is quite simple:\n\n\n.. code-block:: pycon\n\n    >>> import semantic_version\n    >>> v = semantic_version.Version('0.1.1')\n    >>> v.major\n    0\n    >>> v.minor\n    1\n    >>> v.patch\n    1\n    >>> v.prerelease\n    []\n    >>> v.build\n    []\n    >>> list(v)\n    [0, 1, 1, [], []]\n\nIf the provided version string is invalid, a ``ValueError`` will be raised:\n\n.. code-block:: pycon\n\n    >>> semantic_version.Version('0.1')\n    Traceback (most recent call last):\n      File \"<stdin>\", line 1, in <module>\n      File \"/Users/rbarrois/dev/semantic_version/src/semantic_version/base.py\", line 64, in __init__\n        major, minor, patch, prerelease, build = self.parse(version_string, partial)\n      File \"/Users/rbarrois/dev/semantic_version/src/semantic_version/base.py\", line 86, in parse\n        raise ValueError('Invalid version string: %r' % version_string)\n    ValueError: Invalid version string: '0.1'\n\n\nOne may also create a ``Version`` with named components:\n\n.. code-block:: pycon\n\n    >>> semantic_version.Version(major=0, minor=1, patch=2)\n    Version('0.1.2')\n\nIn that case, ``major``, ``minor`` and ``patch`` are mandatory, and must be integers.\n``prerelease`` and ``build``, if provided, must be tuples of strings:\n\n.. code-block:: pycon\n\n    >>> semantic_version.Version(major=0, minor=1, patch=2, prerelease=('alpha', '2'))\n    Version('0.1.2-alpha.2')\n\n\nSome user-supplied input might not match the semantic version scheme.\nFor such cases, the ``Version.coerce`` method will try to convert any\nversion-like string into a valid semver version:\n\n.. code-block:: pycon\n\n    >>> Version.coerce('0')\n    Version('0.0.0')\n    >>> Version.coerce('0.1.2.3.4')\n    Version('0.1.2+3.4')\n    >>> Version.coerce('0.1.2a3')\n    Version('0.1.2-a3')\n\nWorking with versions\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nObviously, versions can be compared:\n\n\n.. code-block:: pycon\n\n    >>> semantic_version.Version('0.1.1') < semantic_version.Version('0.1.2')\n    True\n    >>> semantic_version.Version('0.1.1') > semantic_version.Version('0.1.1-alpha')\n    True\n    >>> semantic_version.Version('0.1.1') <= semantic_version.Version('0.1.1-alpha')\n    False\n\nYou can also get a new version that represents a bump in one of the version levels:\n\n.. code-block:: pycon\n\n    >>> v = semantic_version.Version('0.1.1+build')\n    >>> new_v = v.next_major()\n    >>> str(new_v)\n    '1.0.0'\n    >>> v = semantic_version.Version('1.1.1+build')\n    >>> new_v = v.next_minor()\n    >>> str(new_v)\n    '1.2.0'\n    >>> v = semantic_version.Version('1.1.1+build')\n    >>> new_v = v.next_patch()\n    >>> str(new_v)\n    '1.1.2'\n\n\n\nRequirement specification\n-------------------------\n\npython-semanticversion provides a couple of ways to describe a range of accepted\nversions:\n\n- The ``SimpleSpec`` class provides a simple, easily understood scheme --\n  somewhat inspired from PyPI range notations;\n- The ``NpmSpec`` class supports the whole NPM range specification scheme:\n\n  .. code-block:: pycon\n\n      >>> Version('0.1.2') in NpmSpec('0.1.0-alpha.2 .. 0.2.4')\n      True\n      >>> Version('0.1.2') in NpmSpec('>=0.1.1 <0.1.3 || 2.x')\n      True\n      >>> Version('2.3.4') in NpmSpec('>=0.1.1 <0.1.3 || 2.x')\n      True\n\nThe ``SimpleSpec`` scheme\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nBasic usage is simply a comparator and a base version:\n\n.. code-block:: pycon\n\n    >>> s = SimpleSpec('>=0.1.1')  # At least 0.1.1\n    >>> s.match(Version('0.1.1'))\n    True\n    >>> s.match(Version('0.1.1-alpha1'))  # pre-release doesn't satisfy version spec\n    False\n    >>> s.match(Version('0.1.0'))\n    False\n\nCombining specifications can be expressed as follows:\n\n  .. code-block:: pycon\n\n      >>> SimpleSpec('>=0.1.1,<0.3.0')\n\nSimpler test syntax is also available using the ``in`` keyword:\n\n.. code-block:: pycon\n\n    >>> s = SimpleSpec('==0.1.1')\n    >>> Version('0.1.1+git7ccc72') in s  # build variants are equivalent to full versions\n    True\n    >>> Version('0.1.1-alpha1') in s     # pre-release variants don't match the full version.\n    False\n    >>> Version('0.1.2') in s\n    False\n\n\nRefer to the full documentation at\nhttps://python-semanticversion.readthedocs.io/en/latest/ for more details on the\n``SimpleSpec`` scheme.\n\n\n\nUsing a specification\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nThe ``SimpleSpec.filter`` method filters an iterable of ``Version``:\n\n.. code-block:: pycon\n\n    >>> s = SimpleSpec('>=0.1.0,<0.4.0')\n    >>> versions = (Version('0.%d.0' % i) for i in range(6))\n    >>> for v in s.filter(versions):\n    ...     print v\n    0.1.0\n    0.2.0\n    0.3.0\n\nIt is also possible to select the 'best' version from such iterables:\n\n\n.. code-block:: pycon\n\n    >>> s = SimpleSpec('>=0.1.0,<0.4.0')\n    >>> versions = (Version('0.%d.0' % i) for i in range(6))\n    >>> s.select(versions)\n    Version('0.3.0')\n\n\n\nContributing\n============\n\nIn order to contribute to the source code:\n\n- Open an issue on `GitHub`_: https://github.com/rbarrois/python-semanticversion/issues\n- Fork the `repository <https://github.com/rbarrois/python-semanticversion>`_\n  and submit a pull request on `GitHub`_\n- Or send me a patch (mailto:raphael.barrois+semver@polytechnique.org)\n\nWhen submitting patches or pull requests, you should respect the following rules:\n\n- Coding conventions are based on :pep:`8`\n- The whole test suite must pass after adding the changes\n- The test coverage for a new feature must be 100%\n- New features and methods should be documented in the ``reference`` section\n  and included in the ``changelog``\n- Include your name in the ``contributors`` section\n\n.. note:: All files should contain the following header::\n\n          # -*- encoding: utf-8 -*-\n          # Copyright (c) The python-semanticversion project\n\n.. _SemVer: http://semver.org/\n.. _PyPI: http://pypi.python.org/\n\n\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "semantic version",
          "versioning",
          "version"
        ],
        "home_page": "https://github.com/rbarrois/python-semanticversion",
        "author": "RaphaÃ«l Barrois",
        "author_email": "raphael.barrois+semver@polytechnique.org",
        "license": "BSD",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "Django (>=1.11) ; extra == 'dev'",
          "nose2 ; extra == 'dev'",
          "tox ; extra == 'dev'",
          "check-manifest ; extra == 'dev'",
          "coverage ; extra == 'dev'",
          "flake8 ; extra == 'dev'",
          "wheel ; extra == 'dev'",
          "zest.releaser[recommended] ; extra == 'dev'",
          "readme-renderer (<25.0) ; (python_version == \"3.4\") and extra == 'dev'",
          "colorama (<=0.4.1) ; (python_version == \"3.4\") and extra == 'dev'",
          "Sphinx ; extra == 'doc'",
          "sphinx-rtd-theme ; extra == 'doc'"
        ],
        "requires_python": ">=2.7",
        "provides_extra": [
          "dev",
          "doc"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\semantic_version-2.10.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "semver",
        "version": "3.0.2",
        "summary": "Python helper for Semantic Versioning (https://semver.org)",
        "description": "Quickstart\n==========\n\n.. teaser-begin\n\nA Python module to simplify `semantic versioning`_.\n\n|GHAction| |python-support| |downloads| |license| |docs| |black|\n|openissues| |GHDiscussion|\n\n.. teaser-end\n\nThe module follows the ``MAJOR.MINOR.PATCH`` style:\n\n* ``MAJOR`` version when you make incompatible API changes,\n* ``MINOR`` version when you add functionality in a backwards compatible manner, and\n* ``PATCH`` version when you make backwards compatible bug fixes.\n\nAdditional labels for pre-release and build metadata are supported.\n\nTo import this library, use:\n\n.. code-block:: python\n\n    >>> import semver\n\nWorking with the library is quite straightforward. To turn a version string into the\ndifferent parts, use the ``semver.Version.parse`` function:\n\n.. code-block:: python\n\n    >>> ver = semver.Version.parse('1.2.3-pre.2+build.4')\n    >>> ver.major\n    1\n    >>> ver.minor\n    2\n    >>> ver.patch\n    3\n    >>> ver.prerelease\n    'pre.2'\n    >>> ver.build\n    'build.4'\n\nTo raise parts of a version, there are a couple of functions available for\nyou. The function ``semver.Version.bump_major`` leaves the original object untouched, but\nreturns a new ``semver.Version`` instance with the raised major part:\n\n.. code-block:: python\n\n    >>> ver = semver.Version.parse(\"3.4.5\")\n    >>> ver.bump_major()\n    Version(major=4, minor=0, patch=0, prerelease=None, build=None)\n\nIt is allowed to concatenate different \"bump functions\":\n\n.. code-block:: python\n\n    >>> ver.bump_major().bump_minor()\n    Version(major=4, minor=1, patch=0, prerelease=None, build=None)\n\nTo compare two versions, semver provides the ``semver.compare`` function.\nThe return value indicates the relationship between the first and second\nversion:\n\n.. code-block:: python\n\n    >>> semver.compare(\"1.0.0\", \"2.0.0\")\n    -1\n    >>> semver.compare(\"2.0.0\", \"1.0.0\")\n    1\n    >>> semver.compare(\"2.0.0\", \"2.0.0\")\n    0\n\n\nThere are other functions to discover. Read on!\n\n\n.. |latest-version| image:: https://img.shields.io/pypi/v/semver.svg\n   :alt: Latest version on PyPI\n   :target: https://pypi.org/project/semver\n.. |python-support| image:: https://img.shields.io/pypi/pyversions/semver.svg\n   :target: https://pypi.org/project/semver\n   :alt: Python versions\n.. |downloads| image:: https://img.shields.io/pypi/dm/semver.svg\n   :alt: Monthly downloads from PyPI\n   :target: https://pypi.org/project/semver\n.. |license| image:: https://img.shields.io/pypi/l/semver.svg\n   :alt: Software license\n   :target: https://github.com/python-semver/python-semver/blob/master/LICENSE.txt\n.. |docs| image:: https://readthedocs.org/projects/python-semver/badge/?version=latest\n   :target: http://python-semver.readthedocs.io/en/latest/?badge=latest\n   :alt: Documentation Status\n.. _semantic versioning: https://semver.org/\n.. |black| image:: https://img.shields.io/badge/code%20style-black-000000.svg\n    :target: https://github.com/psf/black\n    :alt: Black Formatter\n.. |Gitter| image:: https://badges.gitter.im/python-semver/community.svg\n    :target: https://gitter.im/python-semver/community\n    :alt: Gitter\n.. |openissues| image:: http://isitmaintained.com/badge/open/python-semver/python-semver.svg\n    :target: http://isitmaintained.com/project/python-semver/python-semver\n    :alt: Percentage of open issues\n.. |GHAction| image:: https://github.com/python-semver/python-semver/workflows/Python/badge.svg\n    :alt: Python\n.. |GHDiscussion| image:: https://shields.io/badge/GitHub-%20Discussions-green?logo=github\n    :target: https://github.com/python-semver/python-semver/discussions\n    :alt: GitHub Discussion\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/python-semver/python-semver",
        "author": "Kostiantyn Rybnikov",
        "author_email": "k-bx@k-bx.com",
        "maintainer": "Sebastien Celles, Tom Schraitle",
        "maintainer_email": "s.celles@gmail.com",
        "license": "BSD",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Changelog, https://python-semver.readthedocs.io/en/latest/changelog.html",
          "Documentation, https://python-semver.rtfd.io",
          "Releases, https://github.com/python-semver/python-semver/releases",
          "Bug Tracker, https://github.com/python-semver/python-semver/issues"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\semver-3.0.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "setuptools",
        "version": "74.0.0",
        "summary": "Easily download, build, install, upgrade, and uninstall Python packages",
        "description": ".. |pypi-version| image:: https://img.shields.io/pypi/v/setuptools.svg\n   :target: https://pypi.org/project/setuptools\n\n.. |py-version| image:: https://img.shields.io/pypi/pyversions/setuptools.svg\n\n.. |test-badge| image:: https://github.com/pypa/setuptools/actions/workflows/main.yml/badge.svg\n   :target: https://github.com/pypa/setuptools/actions?query=workflow%3A%22tests%22\n   :alt: tests\n\n.. |ruff-badge| image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v2.json\n   :target: https://github.com/astral-sh/ruff\n   :alt: Ruff\n\n.. |docs-badge| image:: https://img.shields.io/readthedocs/setuptools/latest.svg\n   :target: https://setuptools.pypa.io\n\n.. |skeleton-badge| image:: https://img.shields.io/badge/skeleton-2024-informational\n   :target: https://blog.jaraco.com/skeleton\n\n.. |codecov-badge| image:: https://img.shields.io/codecov/c/github/pypa/setuptools/master.svg?logo=codecov&logoColor=white\n   :target: https://codecov.io/gh/pypa/setuptools\n\n.. |tidelift-badge| image:: https://tidelift.com/badges/github/pypa/setuptools?style=flat\n   :target: https://tidelift.com/subscription/pkg/pypi-setuptools?utm_source=pypi-setuptools&utm_medium=readme\n\n.. |discord-badge| image:: https://img.shields.io/discord/803025117553754132\n   :target: https://discord.com/channels/803025117553754132/815945031150993468\n   :alt: Discord\n\n|pypi-version| |py-version| |test-badge| |ruff-badge| |docs-badge| |skeleton-badge| |codecov-badge| |discord-badge|\n\nSee the `Quickstart <https://setuptools.pypa.io/en/latest/userguide/quickstart.html>`_\nand the `User's Guide <https://setuptools.pypa.io/en/latest/userguide/>`_ for\ninstructions on how to use Setuptools.\n\nQuestions and comments should be directed to `GitHub Discussions\n<https://github.com/pypa/setuptools/discussions>`_.\nBug reports and especially tested patches may be\nsubmitted directly to the `bug tracker\n<https://github.com/pypa/setuptools/issues>`_.\n\n\nCode of Conduct\n===============\n\nEveryone interacting in the setuptools project's codebases, issue trackers,\nchat rooms, and fora is expected to follow the\n`PSF Code of Conduct <https://github.com/pypa/.github/blob/main/CODE_OF_CONDUCT.md>`_.\n\n\nFor Enterprise\n==============\n\nAvailable as part of the Tidelift Subscription.\n\nSetuptools and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.\n\n`Learn more <https://tidelift.com/subscription/pkg/pypi-setuptools?utm_source=pypi-setuptools&utm_medium=referral&utm_campaign=github>`_.\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "CPAN",
          "PyPI",
          "distutils",
          "eggs",
          "package",
          "management"
        ],
        "author_email": "Python Packaging Authority <distutils-sig@python.org>",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: System :: Archiving :: Packaging",
          "Topic :: System :: Systems Administration",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "pytest-checkdocs >=2.4 ; extra == 'check'",
          "pytest-ruff >=0.2.1 ; (sys_platform != \"cygwin\") and extra == 'check'",
          "ruff >=0.5.2 ; (sys_platform != \"cygwin\") and extra == 'check'",
          "packaging >=24 ; extra == 'core'",
          "more-itertools >=8.8 ; extra == 'core'",
          "jaraco.text >=3.7 ; extra == 'core'",
          "wheel >=0.43.0 ; extra == 'core'",
          "platformdirs >=2.6.2 ; extra == 'core'",
          "importlib-metadata >=6 ; (python_version < \"3.10\") and extra == 'core'",
          "tomli >=2.0.1 ; (python_version < \"3.11\") and extra == 'core'",
          "importlib-resources >=5.10.2 ; (python_version < \"3.9\") and extra == 'core'",
          "pytest-cov ; extra == 'cover'",
          "sphinx >=3.5 ; extra == 'doc'",
          "jaraco.packaging >=9.3 ; extra == 'doc'",
          "rst.linker >=1.9 ; extra == 'doc'",
          "furo ; extra == 'doc'",
          "sphinx-lint ; extra == 'doc'",
          "jaraco.tidelift >=1.4 ; extra == 'doc'",
          "pygments-github-lexers ==0.0.5 ; extra == 'doc'",
          "sphinx-favicon ; extra == 'doc'",
          "sphinx-inline-tabs ; extra == 'doc'",
          "sphinx-reredirects ; extra == 'doc'",
          "sphinxcontrib-towncrier ; extra == 'doc'",
          "sphinx-notfound-page <2,>=1 ; extra == 'doc'",
          "pyproject-hooks !=1.1 ; extra == 'doc'",
          "towncrier <24.7 ; extra == 'doc'",
          "pytest-enabler >=2.2 ; extra == 'enabler'",
          "pytest !=8.1.*,>=6 ; extra == 'test'",
          "virtualenv >=13.0.0 ; extra == 'test'",
          "wheel >=0.44.0 ; extra == 'test'",
          "pip >=19.1 ; extra == 'test'",
          "packaging >=23.2 ; extra == 'test'",
          "jaraco.envs >=2.2 ; extra == 'test'",
          "pytest-xdist >=3 ; extra == 'test'",
          "jaraco.path >=3.2.0 ; extra == 'test'",
          "build[virtualenv] >=1.0.3 ; extra == 'test'",
          "filelock >=3.4.0 ; extra == 'test'",
          "ini2toml[lite] >=0.14 ; extra == 'test'",
          "tomli-w >=1.0.0 ; extra == 'test'",
          "pytest-timeout ; extra == 'test'",
          "pytest-home >=0.5 ; extra == 'test'",
          "pytest-subprocess ; extra == 'test'",
          "pyproject-hooks !=1.1 ; extra == 'test'",
          "jaraco.test ; extra == 'test'",
          "jaraco.develop >=7.21 ; (python_version >= \"3.9\" and sys_platform != \"cygwin\") and extra == 'test'",
          "pytest-perf ; (sys_platform != \"cygwin\") and extra == 'test'",
          "pytest-mypy ; extra == 'type'",
          "mypy ==1.11.* ; extra == 'type'",
          "importlib-metadata >=7.0.2 ; (python_version < \"3.10\") and extra == 'type'",
          "jaraco.develop >=7.21 ; (sys_platform != \"cygwin\") and extra == 'type'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Source, https://github.com/pypa/setuptools",
          "Documentation, https://setuptools.pypa.io/",
          "Changelog, https://setuptools.pypa.io/en/stable/history.html"
        ],
        "provides_extra": [
          "certs",
          "check",
          "core",
          "cover",
          "doc",
          "enabler",
          "ssl",
          "test",
          "type"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\setuptools-74.0.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "six",
        "version": "1.16.0",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "Python 2 and 3 compatibility utilities",
        "description": ".. image:: https://img.shields.io/pypi/v/six.svg\n   :target: https://pypi.org/project/six/\n   :alt: six on PyPI\n\n.. image:: https://travis-ci.org/benjaminp/six.svg?branch=master\n   :target: https://travis-ci.org/benjaminp/six\n   :alt: six on TravisCI\n\n.. image:: https://readthedocs.org/projects/six/badge/?version=latest\n   :target: https://six.readthedocs.io/\n   :alt: six's documentation on Read the Docs\n\n.. image:: https://img.shields.io/badge/license-MIT-green.svg\n   :target: https://github.com/benjaminp/six/blob/master/LICENSE\n   :alt: MIT License badge\n\nSix is a Python 2 and 3 compatibility library.  It provides utility functions\nfor smoothing over the differences between the Python versions with the goal of\nwriting Python code that is compatible on both Python versions.  See the\ndocumentation for more information on what is provided.\n\nSix supports Python 2.7 and 3.3+.  It is contained in only one Python\nfile, so it can be easily copied into your project. (The copyright and license\nnotice must be retained.)\n\nOnline documentation is at https://six.readthedocs.io/.\n\nBugs can be reported to https://github.com/benjaminp/six.  The code can also\nbe found there.\n\n\n",
        "home_page": "https://github.com/benjaminp/six",
        "author": "Benjamin Peterson",
        "author_email": "benjamin@python.org",
        "license": "MIT",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 3",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Topic :: Software Development :: Libraries",
          "Topic :: Utilities"
        ],
        "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\six-1.16.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "sortedcontainers",
        "version": "2.4.0",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "Sorted Containers -- Sorted List, Sorted Dict, Sorted Set",
        "description": "Python Sorted Containers\n========================\n\n`Sorted Containers`_ is an Apache2 licensed `sorted collections library`_,\nwritten in pure-Python, and fast as C-extensions.\n\nPython's standard library is great until you need a sorted collections\ntype. Many will attest that you can get really far without one, but the moment\nyou **really need** a sorted list, sorted dict, or sorted set, you're faced\nwith a dozen different implementations, most using C-extensions without great\ndocumentation and benchmarking.\n\nIn Python, we can do better. And we can do it in pure-Python!\n\n.. code-block:: python\n\n    >>> from sortedcontainers import SortedList\n    >>> sl = SortedList(['e', 'a', 'c', 'd', 'b'])\n    >>> sl\n    SortedList(['a', 'b', 'c', 'd', 'e'])\n    >>> sl *= 10_000_000\n    >>> sl.count('c')\n    10000000\n    >>> sl[-3:]\n    ['e', 'e', 'e']\n    >>> from sortedcontainers import SortedDict\n    >>> sd = SortedDict({'c': 3, 'a': 1, 'b': 2})\n    >>> sd\n    SortedDict({'a': 1, 'b': 2, 'c': 3})\n    >>> sd.popitem(index=-1)\n    ('c', 3)\n    >>> from sortedcontainers import SortedSet\n    >>> ss = SortedSet('abracadabra')\n    >>> ss\n    SortedSet(['a', 'b', 'c', 'd', 'r'])\n    >>> ss.bisect_left('c')\n    2\n\nAll of the operations shown above run in faster than linear time. The above\ndemo also takes nearly a gigabyte of memory to run. When the sorted list is\nmultiplied by ten million, it stores ten million references to each of \"a\"\nthrough \"e\". Each reference requires eight bytes in the sorted\ncontainer. That's pretty hard to beat as it's the cost of a pointer to each\nobject. It's also 66% less overhead than a typical binary tree implementation\n(e.g. Red-Black Tree, AVL-Tree, AA-Tree, Splay-Tree, Treap, etc.) for which\nevery node must also store two pointers to children nodes.\n\n`Sorted Containers`_ takes all of the work out of Python sorted collections -\nmaking your deployment and use of Python easy. There's no need to install a C\ncompiler or pre-build and distribute custom extensions. Performance is a\nfeature and testing has 100% coverage with unit tests and hours of stress.\n\n.. _`Sorted Containers`: http://www.grantjenks.com/docs/sortedcontainers/\n.. _`sorted collections library`: http://www.grantjenks.com/docs/sortedcontainers/\n\nTestimonials\n------------\n\n**Alex Martelli**, `Fellow of the Python Software Foundation`_\n\n\"Good stuff! ... I like the `simple, effective implementation`_ idea of\nsplitting the sorted containers into smaller \"fragments\" to avoid the O(N)\ninsertion costs.\"\n\n**Jeff Knupp**, `author of Writing Idiomatic Python and Python Trainer`_\n\n\"That last part, \"fast as C-extensions,\" was difficult to believe. I would need\nsome sort of `Performance Comparison`_ to be convinced this is true. The author\nincludes this in the docs. It is.\"\n\n**Kevin Samuel**, `Python and Django Trainer`_\n\nI'm quite amazed, not just by the code quality (it's incredibly readable and\nhas more comment than code, wow), but the actual amount of work you put at\nstuff that is *not* code: documentation, benchmarking, implementation\nexplanations. Even the git log is clean and the unit tests run out of the box\non Python 2 and 3.\n\n**Mark Summerfield**, a short plea for `Python Sorted Collections`_\n\nPython's \"batteries included\" standard library seems to have a battery\nmissing. And the argument that \"we never had it before\" has worn thin. It is\ntime that Python offered a full range of collection classes out of the box,\nincluding sorted ones.\n\n`Sorted Containers`_ is used in popular open source projects such as:\n`Zipline`_, an algorithmic trading library from Quantopian; `Angr`_, a binary\nanalysis platform from UC Santa Barbara; `Trio`_, an async I/O library; and\n`Dask Distributed`_, a distributed computation library supported by Continuum\nAnalytics.\n\n.. _`Fellow of the Python Software Foundation`: https://en.wikipedia.org/wiki/Alex_Martelli\n.. _`simple, effective implementation`: http://www.grantjenks.com/docs/sortedcontainers/implementation.html\n.. _`author of Writing Idiomatic Python and Python Trainer`: https://jeffknupp.com/\n.. _`Python and Django Trainer`: https://www.elephorm.com/formateur/kevin-samuel\n.. _`Python Sorted Collections`: http://www.qtrac.eu/pysorted.html\n.. _`Zipline`: https://github.com/quantopian/zipline\n.. _`Angr`: https://github.com/angr/angr\n.. _`Trio`: https://github.com/python-trio/trio\n.. _`Dask Distributed`: https://github.com/dask/distributed\n\nFeatures\n--------\n\n- Pure-Python\n- Fully documented\n- Benchmark comparison (alternatives, runtimes, load-factors)\n- 100% test coverage\n- Hours of stress testing\n- Performance matters (often faster than C implementations)\n- Compatible API (nearly identical to older blist and bintrees modules)\n- Feature-rich (e.g. get the five largest keys in a sorted dict: d.keys()[-5:])\n- Pragmatic design (e.g. SortedSet is a Python set with a SortedList index)\n- Developed on Python 3.7\n- Tested on CPython 2.7, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7 and PyPy, PyPy3\n\n.. image:: https://api.travis-ci.org/grantjenks/python-sortedcontainers.svg?branch=master\n   :target: http://www.grantjenks.com/docs/sortedcontainers/\n\n.. image:: https://ci.appveyor.com/api/projects/status/github/grantjenks/python-sortedcontainers?branch=master&svg=true\n   :target: http://www.grantjenks.com/docs/sortedcontainers/\n\nQuickstart\n----------\n\nInstalling `Sorted Containers`_ is simple with `pip\n<https://pypi.org/project/pip/>`_::\n\n    $ pip install sortedcontainers\n\nYou can access documentation in the interpreter with Python's built-in `help`\nfunction. The `help` works on modules, classes and methods in `Sorted\nContainers`_.\n\n.. code-block:: python\n\n    >>> import sortedcontainers\n    >>> help(sortedcontainers)\n    >>> from sortedcontainers import SortedDict\n    >>> help(SortedDict)\n    >>> help(SortedDict.popitem)\n\nDocumentation\n-------------\n\nComplete documentation for `Sorted Containers`_ is available at\nhttp://www.grantjenks.com/docs/sortedcontainers/\n\nUser Guide\n..........\n\nThe user guide provides an introduction to `Sorted Containers`_ and extensive\nperformance comparisons and analysis.\n\n- `Introduction`_\n- `Performance Comparison`_\n- `Load Factor Performance Comparison`_\n- `Runtime Performance Comparison`_\n- `Simulated Workload Performance Comparison`_\n- `Performance at Scale`_\n\n.. _`Introduction`: http://www.grantjenks.com/docs/sortedcontainers/introduction.html\n.. _`Performance Comparison`: http://www.grantjenks.com/docs/sortedcontainers/performance.html\n.. _`Load Factor Performance Comparison`: http://www.grantjenks.com/docs/sortedcontainers/performance-load.html\n.. _`Runtime Performance Comparison`: http://www.grantjenks.com/docs/sortedcontainers/performance-runtime.html\n.. _`Simulated Workload Performance Comparison`: http://www.grantjenks.com/docs/sortedcontainers/performance-workload.html\n.. _`Performance at Scale`: http://www.grantjenks.com/docs/sortedcontainers/performance-scale.html\n\nCommunity Guide\n...............\n\nThe community guide provides information on the development of `Sorted\nContainers`_ along with support, implementation, and history details.\n\n- `Development and Support`_\n- `Implementation Details`_\n- `Release History`_\n\n.. _`Development and Support`: http://www.grantjenks.com/docs/sortedcontainers/development.html\n.. _`Implementation Details`: http://www.grantjenks.com/docs/sortedcontainers/implementation.html\n.. _`Release History`: http://www.grantjenks.com/docs/sortedcontainers/history.html\n\nAPI Documentation\n.................\n\nThe API documentation provides information on specific functions, classes, and\nmodules in the `Sorted Containers`_ package.\n\n- `Sorted List`_\n- `Sorted Dict`_\n- `Sorted Set`_\n\n.. _`Sorted List`: http://www.grantjenks.com/docs/sortedcontainers/sortedlist.html\n.. _`Sorted Dict`: http://www.grantjenks.com/docs/sortedcontainers/sorteddict.html\n.. _`Sorted Set`: http://www.grantjenks.com/docs/sortedcontainers/sortedset.html\n\nTalks\n-----\n\n- `Python Sorted Collections | PyCon 2016 Talk`_\n- `SF Python Holiday Party 2015 Lightning Talk`_\n- `DjangoCon 2015 Lightning Talk`_\n\n.. _`Python Sorted Collections | PyCon 2016 Talk`: http://www.grantjenks.com/docs/sortedcontainers/pycon-2016-talk.html\n.. _`SF Python Holiday Party 2015 Lightning Talk`: http://www.grantjenks.com/docs/sortedcontainers/sf-python-2015-lightning-talk.html\n.. _`DjangoCon 2015 Lightning Talk`: http://www.grantjenks.com/docs/sortedcontainers/djangocon-2015-lightning-talk.html\n\nResources\n---------\n\n- `Sorted Containers Documentation`_\n- `Sorted Containers at PyPI`_\n- `Sorted Containers at Github`_\n- `Sorted Containers Issue Tracker`_\n\n.. _`Sorted Containers Documentation`: http://www.grantjenks.com/docs/sortedcontainers/\n.. _`Sorted Containers at PyPI`: https://pypi.org/project/sortedcontainers/\n.. _`Sorted Containers at Github`: https://github.com/grantjenks/python-sortedcontainers\n.. _`Sorted Containers Issue Tracker`: https://github.com/grantjenks/python-sortedcontainers/issues\n\nSorted Containers License\n-------------------------\n\nCopyright 2014-2019 Grant Jenks\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\n",
        "home_page": "http://www.grantjenks.com/docs/sortedcontainers/",
        "author": "Grant Jenks",
        "author_email": "contact@grantjenks.com",
        "license": "Apache 2.0",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Natural Language :: English",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.2",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\sortedcontainers-2.4.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "soupsieve",
        "version": "2.6",
        "summary": "A modern CSS selector implementation for Beautiful Soup.",
        "description": "[![Donate via PayPal][donate-image]][donate-link]\n[![Build][github-ci-image]][github-ci-link]\n[![Coverage Status][codecov-image]][codecov-link]\n[![PyPI Version][pypi-image]][pypi-link]\n[![PyPI Downloads][pypi-down]][pypi-link]\n[![PyPI - Python Version][python-image]][pypi-link]\n![License][license-image-mit]\n\n# Soup Sieve\n\n## Overview\n\nSoup Sieve is a CSS selector library designed to be used with [Beautiful Soup 4][bs4]. It aims to provide selecting,\nmatching, and filtering using modern CSS selectors. Soup Sieve currently provides selectors from the CSS level 1\nspecifications up through the latest CSS level 4 drafts and beyond (though some are not yet implemented).\n\nSoup Sieve was written with the intent to replace Beautiful Soup's builtin select feature, and as of Beautiful Soup\nversion 4.7.0, it now is :confetti_ball:. Soup Sieve can also be imported in order to use its API directly for\nmore controlled, specialized parsing.\n\nSoup Sieve has implemented most of the CSS selectors up through the latest CSS draft specifications, though there are a\nnumber that don't make sense in a non-browser environment. Selectors that cannot provide meaningful functionality simply\ndo not match anything. Some of the supported selectors are:\n\n- `.classes`\n- `#ids`\n- `[attributes=value]`\n- `parent child`\n- `parent > child`\n- `sibling ~ sibling`\n- `sibling + sibling`\n- `:not(element.class, element2.class)`\n- `:is(element.class, element2.class)`\n- `parent:has(> child)`\n- and [many more](https://facelessuser.github.io/soupsieve/selectors/)\n\n\n## Installation\n\nYou must have Beautiful Soup already installed:\n\n```\npip install beautifulsoup4\n```\n\nIn most cases, assuming you've installed version 4.7.0, that should be all you need to do, but if you've installed via\nsome alternative method, and Soup Sieve is not automatically installed, you can install it directly:\n\n```\npip install soupsieve\n```\n\nIf you want to manually install it from source, first ensure that [`build`](https://pypi.org/project/build/) is\ninstalled:\n\n```\npip install build\n```\n\nThen navigate to the root of the project and build the wheel and install (replacing `<ver>` with the current version):\n\n```\npython -m build -w\npip install dist/soupsieve-<ver>-py3-none-any.whl\n```\n\n## Documentation\n\nDocumentation is found here: https://facelessuser.github.io/soupsieve/.\n\n## License\n\nMIT\n\n[bs4]: https://beautiful-soup-4.readthedocs.io/en/latest/#\n\n[github-ci-image]: https://github.com/facelessuser/soupsieve/workflows/build/badge.svg?branch=master&event=push\n[github-ci-link]: https://github.com/facelessuser/soupsieve/actions?query=workflow%3Abuild+branch%3Amaster\n[codecov-image]: https://img.shields.io/codecov/c/github/facelessuser/soupsieve/master.svg?logo=codecov&logoColor=aaaaaa&labelColor=333333\n[codecov-link]: https://codecov.io/github/facelessuser/soupsieve\n[pypi-image]: https://img.shields.io/pypi/v/soupsieve.svg?logo=pypi&logoColor=aaaaaa&labelColor=333333\n[pypi-down]: https://img.shields.io/pypi/dm/soupsieve.svg?logo=pypi&logoColor=aaaaaa&labelColor=333333\n[pypi-link]: https://pypi.python.org/pypi/soupsieve\n[python-image]: https://img.shields.io/pypi/pyversions/soupsieve?logo=python&logoColor=aaaaaa&labelColor=333333\n[license-image-mit]: https://img.shields.io/badge/license-MIT-blue.svg?labelColor=333333\n[donate-image]: https://img.shields.io/badge/Donate-PayPal-3fabd1?logo=paypal\n[donate-link]: https://www.paypal.me/facelessuser\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "CSS",
          "HTML",
          "XML",
          "filter",
          "query",
          "selector",
          "soup"
        ],
        "author_email": "Isaac Muse <Isaac.Muse@gmail.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE.md"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Internet :: WWW/HTTP :: Dynamic Content",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Typing :: Typed"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://github.com/facelessuser/soupsieve"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\soupsieve-2.6.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "stack-data",
        "version": "0.6.3",
        "summary": "Extract data from python stack frames and tracebacks for informative displays",
        "description": "# stack_data\n\n[![Tests](https://github.com/alexmojaki/stack_data/actions/workflows/pytest.yml/badge.svg)](https://github.com/alexmojaki/stack_data/actions/workflows/pytest.yml) [![Coverage Status](https://coveralls.io/repos/github/alexmojaki/stack_data/badge.svg?branch=master)](https://coveralls.io/github/alexmojaki/stack_data?branch=master) [![Supports Python versions 3.5+](https://img.shields.io/pypi/pyversions/stack_data.svg)](https://pypi.python.org/pypi/stack_data)\n\nThis is a library that extracts data from stack frames and tracebacks, particularly to display more useful tracebacks than the default. It powers the tracebacks in IPython and [futurecoder](https://futurecoder.io/):\n\n![futurecoder example](https://futurecoder.io/static/img/features/traceback.png)\n\nYou can install it from PyPI:\n\n    pip install stack_data\n    \n## Basic usage\n\nHere's some code we'd like to inspect:\n\n```python\ndef foo():\n    result = []\n    for i in range(5):\n        row = []\n        result.append(row)\n        print_stack()\n        for j in range(5):\n            row.append(i * j)\n    return result\n```\n\nNote that `foo` calls a function `print_stack()`. In reality we can imagine that an exception was raised at this line, or a debugger stopped there, but this is easy to play with directly. Here's a basic implementation:\n\n```python\nimport inspect\nimport stack_data\n\n\ndef print_stack():\n    frame = inspect.currentframe().f_back\n    frame_info = stack_data.FrameInfo(frame)\n    print(f\"{frame_info.code.co_name} at line {frame_info.lineno}\")\n    print(\"-----------\")\n    for line in frame_info.lines:\n        print(f\"{'-->' if line.is_current else '   '} {line.lineno:4} | {line.render()}\")\n```\n\n(Beware that this has a major bug - it doesn't account for line gaps, which we'll learn about later)\n\nThe output of one call to `print_stack()` looks like:\n\n```\nfoo at line 9\n-----------\n       6 | for i in range(5):\n       7 |     row = []\n       8 |     result.append(row)\n-->    9 |     print_stack()\n      10 |     for j in range(5):\n```\n\nThe code for `print_stack()` is fairly self-explanatory. If you want to learn more details about a particular class or method I suggest looking through some docstrings. `FrameInfo` is a class that accepts either a frame or a traceback object and provides a bunch of nice attributes and properties (which are cached so you don't need to worry about performance). In particular `frame_info.lines` is a list of `Line` objects. `line.render()` returns the source code of that line suitable for display. Without any arguments it simply strips any common leading indentation. Later on we'll see a more powerful use for it.\n\nYou can see that `frame_info.lines` includes some lines of surrounding context. By default it includes 3 pieces of context before the main line and 1 piece after. We can configure the amount of context by passing options:\n\n```python\noptions = stack_data.Options(before=1, after=0)\nframe_info = stack_data.FrameInfo(frame, options)\n```\n\nThen the output looks like:\n\n```\nfoo at line 9\n-----------\n       8 | result.append(row)\n-->    9 | print_stack()\n```\n\nNote that these parameters are not the number of *lines* before and after to include, but the number of *pieces*. A piece is a range of one or more lines in a file that should logically be grouped together. A piece contains either a single simple statement or a part of a compound statement (loops, if, try/except, etc) that doesn't contain any other statements. Most pieces are a single line, but a multi-line statement or `if` condition is a single piece. In the example above, all pieces are one line, because nothing is spread across multiple lines. If we change our code to include some multiline bits:\n\n\n```python\ndef foo():\n    result = []\n    for i in range(5):\n        row = []\n        result.append(\n            row\n        )\n        print_stack()\n        for j in range(\n                5\n        ):\n            row.append(i * j)\n    return result\n```\n\nand then run the original code with the default options, then the output is:\n\n```\nfoo at line 11\n-----------\n       6 | for i in range(5):\n       7 |     row = []\n       8 |     result.append(\n       9 |         row\n      10 |     )\n-->   11 |     print_stack()\n      12 |     for j in range(\n      13 |             5\n      14 |     ):\n```\n\nNow lines 8-10 and lines 12-14 are each a single piece. Note that the output is essentially the same as the original in terms of the amount of code. The division of files into pieces means that the edge of the context is intuitive and doesn't crop out parts of statements or expressions. For example, if context was measured in lines instead of pieces, the last line of the above would be `for j in range(` which is much less useful.\n\nHowever, if a piece is very long, including all of it could be cumbersome. For this, `Options` has a parameter `max_lines_per_piece`, which is 6 by default. Suppose we have a piece in our code that's longer than that:\n\n```python\n        row = [\n            1,\n            2,\n            3,\n            4,\n            5,\n        ]\n```\n\n`frame_info.lines` will truncate this piece so that instead of 7 `Line` objects it will produce 5 `Line` objects and one `LINE_GAP` in the middle, making 6 objects in total for the piece. Our code doesn't currently handle gaps, so it will raise an exception. We can modify it like so:\n\n```python\n    for line in frame_info.lines:\n        if line is stack_data.LINE_GAP:\n            print(\"       (...)\")\n        else:\n            print(f\"{'-->' if line.is_current else '   '} {line.lineno:4} | {line.render()}\")\n```\n\nNow the output looks like:\n\n```\nfoo at line 15\n-----------\n       6 | for i in range(5):\n       7 |     row = [\n       8 |         1,\n       9 |         2,\n       (...)\n      12 |         5,\n      13 |     ]\n      14 |     result.append(row)\n-->   15 |     print_stack()\n      16 |     for j in range(5):\n```\n\nAlternatively, you can flip the condition around and check `if isinstance(line, stack_data.Line):`. Either way, you should always check for line gaps, or your code may appear to work at first but fail when it encounters a long piece.\n\nNote that the executing piece, i.e. the piece containing the current line being executed (line 15 in this case) is never truncated, no matter how long it is.\n\nThe lines of context never stray outside `frame_info.scope`, which is the innermost function or class definition containing the current line. For example, this is the output for a short function which has neither 3 lines before nor 1 line after the current line:\n\n```\nbar at line 6\n-----------\n       4 | def bar():\n       5 |     foo()\n-->    6 |     print_stack()\n```\n\nSometimes it's nice to ensure that the function signature is always showing. This can be done with `Options(include_signature=True)`. The result looks like this:\n\n```\nfoo at line 14\n-----------\n       9 | def foo():\n       (...)\n      11 |     for i in range(5):\n      12 |         row = []\n      13 |         result.append(row)\n-->   14 |         print_stack()\n      15 |         for j in range(5):\n```\n\nTo avoid wasting space, pieces never start or end with a blank line, and blank lines between pieces are excluded. So if our code looks like this:\n\n\n```python\n    for i in range(5):\n        row = []\n\n        result.append(row)\n        print_stack()\n\n        for j in range(5):\n```\n\nThe output doesn't change much, except you can see jumps in the line numbers:\n\n```\n      11 |     for i in range(5):\n      12 |         row = []\n      14 |         result.append(row)\n-->   15 |         print_stack()\n      17 |         for j in range(5):\n```\n\n## Variables\n\nYou can also inspect variables and other expressions in a frame, e.g:\n\n```python\n    for var in frame_info.variables:\n        print(f\"{var.name} = {repr(var.value)}\")\n```\n\nwhich may output:\n\n```python\nresult = [[0, 0, 0, 0, 0], [0, 1, 2, 3, 4], [0, 2, 4, 6, 8], [0, 3, 6, 9, 12], []]\ni = 4\nrow = []\nj = 4\n```\n\n`frame_info.variables` returns a list of `Variable` objects, which have attributes `name`, `value`, and `nodes`, which is a list of all AST representing that expression.\n\nA `Variable` may refer to an expression other than a simple variable name. It can be any expression evaluated by the library [`pure_eval`](https://github.com/alexmojaki/pure_eval) which it deems 'interesting' (see those docs for more info). This includes expressions like `foo.bar` or `foo[bar]`. In these cases `name` is the source code of that expression. `pure_eval` ensures that it only evaluates expressions that won't have any side effects, e.g. where `foo.bar` is a normal attribute rather than a descriptor such as a property.\n\n`frame_info.variables` is a list of all the interesting expressions found in `frame_info.scope`, e.g. the current function, which may include expressions not visible in `frame_info.lines`. You can restrict the list by using `frame_info.variables_in_lines` or even `frame_info.variables_in_executing_piece`. For more control you can use `frame_info.variables_by_lineno`. See the docstrings for more information.\n\n## Rendering lines with ranges and markers\n\nSometimes you may want to insert special characters into the text for display purposes, e.g. HTML or ANSI color codes. `stack_data` provides a few tools to make this easier.\n\nLet's say we have a `Line` object where `line.text` (the original raw source code of that line) is `\"foo = bar\"`, so `line.text[6:9]` is `\"bar\"`, and we want to emphasise that part by inserting HTML at positions 6 and 9 in the text. Here's how we can do that directly:\n\n```python\nmarkers = [\n    stack_data.MarkerInLine(position=6, is_start=True, string=\"<b>\"),\n    stack_data.MarkerInLine(position=9, is_start=False, string=\"</b>\"),\n]\nline.render(markers)  # returns \"foo = <b>bar</b>\"\n```\n\nHere `is_start=True` indicates that the marker is the first of a pair. This helps `line.render()` sort and insert the markers correctly so you don't end up with malformed HTML like `foo<b>.<i></b>bar</i>` where tags overlap.\n\nSince we're inserting HTML, we should actually use `line.render(markers, escape_html=True)` which will escape special HTML characters in the Python source (but not the markers) so for example `foo = bar < spam` would be rendered as `foo = <b>bar</b> &lt; spam`.\n\nUsually though you wouldn't create markers directly yourself. Instead you would start with one or more ranges and then convert them, like so:\n\n```python\nranges = [\n    stack_data.RangeInLine(start=0, end=3, data=\"foo\"),\n    stack_data.RangeInLine(start=6, end=9, data=\"bar\"),\n]\n\ndef convert_ranges(r):\n    if r.data == \"bar\":\n        return \"<b>\", \"</b>\"        \n\n# This results in `markers` being the same as in the above example.\nmarkers = stack_data.markers_from_ranges(ranges, convert_ranges)\n```\n\n`RangeInLine` has a `data` attribute which can be any object. `markers_from_ranges` accepts a converter function to which it passes all the `RangeInLine` objects. If the converter function returns a pair of strings, it creates two markers from them. Otherwise it should return `None` to indicate that the range should be ignored, as with the first range containing `\"foo\"` in this example.\n\nThe reason this is useful is because there are built in tools to create these ranges for you. For example, if we change our `print_stack()` function to contain this:\n\n```python\ndef convert_variable_ranges(r):\n    variable, _node = r.data\n    return f'<span data-value=\"{repr(variable.value)}\">', '</span>'\n\nmarkers = stack_data.markers_from_ranges(line.variable_ranges, convert_variable_ranges)\nprint(f\"{'-->' if line.is_current else '   '} {line.lineno:4} | {line.render(markers, escape_html=True)}\")\n```\n\nThen the output becomes:\n\n```\nfoo at line 15\n-----------\n       9 | def foo():\n       (...)\n      11 |     for <span data-value=\"4\">i</span> in range(5):\n      12 |         <span data-value=\"[]\">row</span> = []\n      14 |         <span data-value=\"[[0, 0, 0, 0, 0], [0, 1, 2, 3, 4], [0, 2, 4, 6, 8], [0, 3, 6, 9, 12], []]\">result</span>.append(<span data-value=\"[]\">row</span>)\n-->   15 |         print_stack()\n      17 |         for <span data-value=\"4\">j</span> in range(5):\n```\n\n`line.variable_ranges` is a list of RangeInLines for each Variable that appears at least partially in this line. The data attribute of the range is a pair `(variable, node)` where node is the particular AST node from the list `variable.nodes` that corresponds to this range.\n\nYou can also use `line.token_ranges` (e.g. if you want to do your own syntax highlighting) or `line.executing_node_ranges` if you want to highlight the currently executing node identified by the [`executing`](https://github.com/alexmojaki/executing) library. Or if you want to make your own range from an AST node, use `line.range_from_node(node, data)`. See the docstrings for more info.\n\n### Syntax highlighting with Pygments\n\nIf you'd like pretty colored text without the work, you can let [Pygments](https://pygments.org/) do it for you. Just follow these steps:\n\n1. `pip install pygments` separately as it's not a dependency of `stack_data`.\n2. Create a pygments formatter object such as `HtmlFormatter` or `Terminal256Formatter`.\n3. Pass the formatter to `Options` in the argument `pygments_formatter`.\n4. Use `line.render(pygmented=True)` to get your formatted text. In this case you can't pass any markers to `render`.\n\nIf you want, you can also highlight the executing node in the frame in combination with the pygments syntax highlighting. For this you will need:\n\n1. A pygments style - either a style class or a string that names it. See the [documentation on styles](https://pygments.org/docs/styles/) and the [styles gallery](https://blog.yjl.im/2015/08/pygments-styles-gallery.html).\n2. A modification to make to the style for the executing node, which is a string such as `\"bold\"` or `\"bg:#ffff00\"` (yellow background). See the [documentation on style rules](https://pygments.org/docs/styles/#style-rules).\n3. Pass these two things to `stack_data.style_with_executing_node(style, modifier)` to get a new style class.\n4. Pass the new style to your formatter when you create it.\n\nNote that this doesn't work with `TerminalFormatter` which just uses the basic ANSI colors and doesn't use the style passed to it in general.\n\n## Getting the full stack\n\nCurrently `print_stack()` doesn't actually print the stack, it just prints one frame. Instead of `frame_info = FrameInfo(frame, options)`, let's do this:\n\n```python\nfor frame_info in FrameInfo.stack_data(frame, options):\n```\n\nNow the output looks something like this:\n\n```\n<module> at line 18\n-----------\n      14 |         for j in range(5):\n      15 |             row.append(i * j)\n      16 |     return result\n-->   18 | bar()\n\nbar at line 5\n-----------\n       4 | def bar():\n-->    5 |     foo()\n\nfoo at line 13\n-----------\n      10 | for i in range(5):\n      11 |     row = []\n      12 |     result.append(row)\n-->   13 |     print_stack()\n      14 |     for j in range(5):\n```\n\nHowever, just as `frame_info.lines` doesn't always yield `Line` objects, `FrameInfo.stack_data` doesn't always yield `FrameInfo` objects, and we must modify our code to handle that. Let's look at some different sample code:\n\n```python\ndef factorial(x):\n    return x * factorial(x - 1)\n\n\ntry:\n    print(factorial(5))\nexcept:\n    print_stack()\n```\n\nIn this code we've forgotten to include a base case in our `factorial` function so it will fail with a `RecursionError` and there'll be many frames with similar information. Similar to the built in Python traceback, `stack_data` avoids showing all of these frames. Instead you will get a `RepeatedFrames` object which summarises the information. See its docstring for more details.\n\nHere is our updated implementation:\n\n```python\ndef print_stack():\n    for frame_info in FrameInfo.stack_data(sys.exc_info()[2]):\n        if isinstance(frame_info, FrameInfo):\n            print(f\"{frame_info.code.co_name} at line {frame_info.lineno}\")\n            print(\"-----------\")\n            for line in frame_info.lines:\n                print(f\"{'-->' if line.is_current else '   '} {line.lineno:4} | {line.render()}\")\n\n            for var in frame_info.variables:\n                print(f\"{var.name} = {repr(var.value)}\")\n\n            print()\n        else:\n            print(f\"... {frame_info.description} ...\\n\")\n```\n\nAnd the output:\n\n```\n<module> at line 9\n-----------\n       4 | def factorial(x):\n       5 |     return x * factorial(x - 1)\n       8 | try:\n-->    9 |     print(factorial(5))\n      10 | except:\n\nfactorial at line 5\n-----------\n       4 | def factorial(x):\n-->    5 |     return x * factorial(x - 1)\nx = 5\n\nfactorial at line 5\n-----------\n       4 | def factorial(x):\n-->    5 |     return x * factorial(x - 1)\nx = 4\n\n... factorial at line 5 (996 times) ...\n\nfactorial at line 5\n-----------\n       4 | def factorial(x):\n-->    5 |     return x * factorial(x - 1)\nx = -993\n```\n\nIn addition to handling repeated frames, we've passed a traceback object to `FrameInfo.stack_data` instead of a frame.\n\nIf you want, you can pass `collapse_repeated_frames=False` to `FrameInfo.stack_data` (not to `Options`) and it will just yield `FrameInfo` objects for the full stack.\n",
        "description_content_type": "text/markdown",
        "home_page": "http://github.com/alexmojaki/stack_data",
        "author": "Alex Hall",
        "author_email": "alex.mojaki@gmail.com",
        "license": "MIT",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Topic :: Software Development :: Debuggers"
        ],
        "requires_dist": [
          "executing >=1.2.0",
          "asttokens >=2.1.0",
          "pure-eval",
          "pytest ; extra == 'tests'",
          "typeguard ; extra == 'tests'",
          "pygments ; extra == 'tests'",
          "littleutils ; extra == 'tests'",
          "cython ; extra == 'tests'"
        ],
        "provides_extra": [
          "tests"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\stack_data-0.6.3.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "sw360",
        "version": "1.5.1",
        "summary": "Python interface to the SW360 software component catalogue",
        "description": "<!--\n# SPDX-FileCopyrightText: (c) 2019-2024 Siemens\n# SPDX-License-Identifier: MIT\n-->\n\n# SW360 Base Library for Python\n\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/sw360/sw360python/blob/master/License.md)\n[![Python Version](https://img.shields.io/badge/python-3.8%2C3.9%2C3.10%2C3.11-yellow?logo=python)](https://www.python.org/doc/versions/)\n[![PyPI](https://shields.io/pypi/v/sw360)](https://pypi.org/project/sw360/)\n[![Static checks](https://github.com/sw360/sw360python/actions/workflows/static-checks.yml/badge.svg)](https://github.com/sw360/sw360python/actions/workflows/static-checks.yml)\n[![Unit tests](https://github.com/sw360/sw360python/actions/workflows/unit-test.yml/badge.svg)](https://github.com/sw360/sw360python/actions/workflows/unit-test.yml)\n[![Coverage](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/tngraf/6ab639b6f9d1f6161d3db52d348d2997/raw/666fa870981726e1fa3469b6aa668c20fdd9d1b2/sw360python-cobertura-coverage.json&color=green)](https://github.com/sw360/sw360python/actions/workflows/unit-test.yml)\n[![REUSE status](https://api.reuse.software/badge/git.fsfe.org/reuse/api)](https://api.reuse.software/info/git.fsfe.org/reuse/api)\n\nThis Python project implements the REST API of [SW360](https://www.eclipse.org/sw360/)\nand allows an easy way to interact with SW360.\n\n## Documentation\n\nHave a look at the documentation: https://sw360.github.io/sw360python/\n\n## Usage\n\n### Installation\n\nThis project is available as [Python package on PyPi.org](https://pypi.org/project/sw360/).  \nInstall sw360 and required dependencies:\n\n```shell\n  pip install sw360 requests\n  ```\n\n### Using the API\n\n* Get a REST API token from your SW360 server\n* Export required environment variables (optionally but recommended):\n\n  ```shell\n  export SW360ProductionToken=<your_api_token>\n  ```\n\n* Start using the API:\n\n  ```python\n  import sw360\n  client = sw360.SW360(sw360_url, sw360_api_token)\n  ```\n\n### Contribute\n\n* All contributions in form of bug reports, feature requests or merge requests!\n* Use proper [docstrings](https://realpython.com/documenting-python-code/) to document  \n  functions and classes\n* Extend the testsuite **poetry run pytest** with the new functions/classes\n* The **documentation website** can automatically be generated by the [Sphinx autodoc extension](https://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html)\n\n### Build\n\n#### Building the Documentation\n\nThe documentation of the project is built using Sphinx:\n\n```python\npoetry run sphinx-build .\\docs-source\\ .\\docs\\\n```\n\n#### Building Python package\n\nFor building the library, you need [Poetry](https://python-poetry.org/).  \nThe build is then triggered using\n\n```shell\npoetry build\n```\n\nThis creates the source and wheel files in ```dist/``` subdirectory -- which can then be  \nuploaded or installed locally using ```pip```.\n\n## Test\n\nStart the complete test suite or a specific test case (and generate coverage report):\n\n```shell\npoetry run pytest\n```\n\nor\n\n```shell\npoetry run coverage run -m pytest\npoetry run coverage report -m --omit \"*/site-packages/*.py\"\npoetry run coverage html --omit \"*/site-packages/*.py\"\n```\n\n## Demo\n\nThe script ``check_project.py`` shows how to use the library to retrieve some information  \nof a given project on SW360. This requires colorama>=0.4.1.\n\n## License\n\nCopyright 2019-2024 Siemens\n\nThe project is licensed under the MIT license.\nSPDX-License-Identifier: MIT\n\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/sw360/sw360python",
        "author": "Thomas Graf",
        "author_email": "thomas.graf@siemens.com",
        "license": "MIT",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3 :: Only"
        ],
        "requires_dist": [
          "requests (>=2.32.2,<3.0.0)"
        ],
        "requires_python": ">=3.8,<4.0",
        "project_url": [
          "Repository, https://github.com/sw360/sw360python"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\sw360-1.5.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "tinycss2",
        "version": "1.3.0",
        "summary": "A tiny CSS parser",
        "description": "tinycss2 is a low-level CSS parser and generator written in Python: it can\nparse strings, return objects representing tokens and blocks, and generate CSS\nstrings corresponding to these objects.\n\nBased on the CSS Syntax Level 3 specification, tinycss2 knows the grammar of\nCSS but doesn't know specific rules, properties or values supported in various\nCSS modules.\n\n* Free software: BSD license\n* For Python 3.8+, tested on CPython and PyPy\n* Documentation: https://doc.courtbouillon.org/tinycss2\n* Changelog: https://github.com/Kozea/tinycss2/releases\n* Code, issues, tests: https://github.com/Kozea/tinycss2\n* Code of conduct: https://www.courtbouillon.org/code-of-conduct\n* Professional support: https://www.courtbouillon.org\n* Donation: https://opencollective.com/courtbouillon\n\ntinycss2 has been created and developed by Kozea (https://kozea.fr).\nProfessional support, maintenance and community management is provided by\nCourtBouillon (https://www.courtbouillon.org).\n\nCopyrights are retained by their contributors, no copyright assignment is\nrequired to contribute to tinycss2. Unless explicitly stated otherwise, any\ncontribution intentionally submitted for inclusion is licensed under the BSD\n3-clause license, without any additional terms or conditions. For full\nauthorship information, see the version control history.\n\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "css",
          "parser"
        ],
        "author_email": "Simon Sapin <simon.sapin@exyr.org>",
        "maintainer_email": "CourtBouillon <contact@courtbouillon.org>",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Text Processing"
        ],
        "requires_dist": [
          "webencodings >=0.4",
          "sphinx ; extra == \"doc\"",
          "sphinx_rtd_theme ; extra == \"doc\"",
          "pytest ; extra == \"test\"",
          "ruff ; extra == \"test\""
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Changelog, https://github.com/Kozea/tinycss2/releases",
          "Code, https://github.com/Kozea/tinycss2/",
          "Documentation, https://doc.courtbouillon.org/tinycss2/",
          "Donation, https://opencollective.com/courtbouillon",
          "Homepage, https://www.courtbouillon.org/tinycss2",
          "Issues, https://github.com/Kozea/tinycss2/issues"
        ],
        "provides_extra": [
          "doc",
          "test"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\tinycss2-1.3.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "toml",
        "version": "0.10.2",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "Python Library for Tom's Obvious, Minimal Language",
        "description": "****\nTOML\n****\n\n.. image:: https://img.shields.io/pypi/v/toml\n    :target: https://pypi.org/project/toml/\n\n.. image:: https://travis-ci.org/uiri/toml.svg?branch=master\n    :target: https://travis-ci.org/uiri/toml\n\n.. image:: https://img.shields.io/pypi/pyversions/toml.svg\n    :target: https://pypi.org/project/toml/\n\n\nA Python library for parsing and creating `TOML <https://en.wikipedia.org/wiki/TOML>`_.\n\nThe module passes `the TOML test suite <https://github.com/BurntSushi/toml-test>`_.\n\nSee also:\n\n* `The TOML Standard <https://github.com/toml-lang/toml>`_\n* `The currently supported TOML specification <https://github.com/toml-lang/toml/blob/v0.5.0/README.md>`_\n\nInstallation\n============\n\nTo install the latest release on `PyPI <https://pypi.org/project/toml/>`_,\nsimply run:\n\n::\n\n  pip install toml\n\nOr to install the latest development version, run:\n\n::\n\n  git clone https://github.com/uiri/toml.git\n  cd toml\n  python setup.py install\n\nQuick Tutorial\n==============\n\n*toml.loads* takes in a string containing standard TOML-formatted data and\nreturns a dictionary containing the parsed data.\n\n.. code:: pycon\n\n  >>> import toml\n  >>> toml_string = \"\"\"\n  ... # This is a TOML document.\n  ...\n  ... title = \"TOML Example\"\n  ...\n  ... [owner]\n  ... name = \"Tom Preston-Werner\"\n  ... dob = 1979-05-27T07:32:00-08:00 # First class dates\n  ...\n  ... [database]\n  ... server = \"192.168.1.1\"\n  ... ports = [ 8001, 8001, 8002 ]\n  ... connection_max = 5000\n  ... enabled = true\n  ...\n  ... [servers]\n  ...\n  ...   # Indentation (tabs and/or spaces) is allowed but not required\n  ...   [servers.alpha]\n  ...   ip = \"10.0.0.1\"\n  ...   dc = \"eqdc10\"\n  ...\n  ...   [servers.beta]\n  ...   ip = \"10.0.0.2\"\n  ...   dc = \"eqdc10\"\n  ...\n  ... [clients]\n  ... data = [ [\"gamma\", \"delta\"], [1, 2] ]\n  ...\n  ... # Line breaks are OK when inside arrays\n  ... hosts = [\n  ...   \"alpha\",\n  ...   \"omega\"\n  ... ]\n  ... \"\"\"\n  >>> parsed_toml = toml.loads(toml_string)\n\n\n*toml.dumps* takes a dictionary and returns a string containing the\ncorresponding TOML-formatted data.\n\n.. code:: pycon\n\n  >>> new_toml_string = toml.dumps(parsed_toml)\n  >>> print(new_toml_string)\n  title = \"TOML Example\"\n  [owner]\n  name = \"Tom Preston-Werner\"\n  dob = 1979-05-27T07:32:00Z\n  [database]\n  server = \"192.168.1.1\"\n  ports = [ 8001, 8001, 8002,]\n  connection_max = 5000\n  enabled = true\n  [clients]\n  data = [ [ \"gamma\", \"delta\",], [ 1, 2,],]\n  hosts = [ \"alpha\", \"omega\",]\n  [servers.alpha]\n  ip = \"10.0.0.1\"\n  dc = \"eqdc10\"\n  [servers.beta]\n  ip = \"10.0.0.2\"\n  dc = \"eqdc10\"\n\n*toml.dump* takes a dictionary and a file descriptor and returns a string containing the\ncorresponding TOML-formatted data.\n\n.. code:: pycon\n\n  >>> with open('new_toml_file.toml', 'w') as f:\n  ...     new_toml_string = toml.dump(parsed_toml, f)\n  >>> print(new_toml_string)\n  title = \"TOML Example\"\n  [owner]\n  name = \"Tom Preston-Werner\"\n  dob = 1979-05-27T07:32:00Z\n  [database]\n  server = \"192.168.1.1\"\n  ports = [ 8001, 8001, 8002,]\n  connection_max = 5000\n  enabled = true\n  [clients]\n  data = [ [ \"gamma\", \"delta\",], [ 1, 2,],]\n  hosts = [ \"alpha\", \"omega\",]\n  [servers.alpha]\n  ip = \"10.0.0.1\"\n  dc = \"eqdc10\"\n  [servers.beta]\n  ip = \"10.0.0.2\"\n  dc = \"eqdc10\"\n\nFor more functions, view the API Reference below.\n\nNote\n----\n\nFor Numpy users, by default the data types ``np.floatX`` will not be translated to floats by toml, but will instead be encoded as strings. To get around this, specify the ``TomlNumpyEncoder`` when saving your data.\n\n.. code:: pycon\n\n  >>> import toml\n  >>> import numpy as np\n  >>> a = np.arange(0, 10, dtype=np.double)\n  >>> output = {'a': a}\n  >>> toml.dumps(output)\n  'a = [ \"0.0\", \"1.0\", \"2.0\", \"3.0\", \"4.0\", \"5.0\", \"6.0\", \"7.0\", \"8.0\", \"9.0\",]\\n'\n  >>> toml.dumps(output, encoder=toml.TomlNumpyEncoder())\n  'a = [ 0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0,]\\n'\n\nAPI Reference\n=============\n\n``toml.load(f, _dict=dict)``\n  Parse a file or a list of files as TOML and return a dictionary.\n\n  :Args:\n    * ``f``: A path to a file, list of filepaths (to be read into single\n      object) or a file descriptor\n    * ``_dict``: The class of the dictionary object to be returned\n\n  :Returns:\n    A dictionary (or object ``_dict``) containing parsed TOML data\n\n  :Raises:\n    * ``TypeError``: When ``f`` is an invalid type or is a list containing\n      invalid types\n    * ``TomlDecodeError``: When an error occurs while decoding the file(s)\n\n``toml.loads(s, _dict=dict)``\n  Parse a TOML-formatted string to a dictionary.\n\n  :Args:\n    * ``s``: The TOML-formatted string to be parsed\n    * ``_dict``: Specifies the class of the returned toml dictionary\n\n  :Returns:\n    A dictionary (or object ``_dict``) containing parsed TOML data\n\n  :Raises:\n    * ``TypeError``: When a non-string object is passed\n    * ``TomlDecodeError``: When an error occurs while decoding the\n      TOML-formatted string\n\n``toml.dump(o, f, encoder=None)``\n  Write a dictionary to a file containing TOML-formatted data\n\n  :Args:\n    * ``o``: An object to be converted into TOML\n    * ``f``: A File descriptor where the TOML-formatted output should be stored\n    * ``encoder``: An instance of ``TomlEncoder`` (or subclass) for encoding the object. If ``None``, will default to ``TomlEncoder``\n\n  :Returns:\n    A string containing the TOML-formatted data corresponding to object ``o``\n\n  :Raises:\n    * ``TypeError``: When anything other than file descriptor is passed\n\n``toml.dumps(o, encoder=None)``\n  Create a TOML-formatted string from an input object\n\n  :Args:\n    * ``o``: An object to be converted into TOML\n    * ``encoder``: An instance of ``TomlEncoder`` (or subclass) for encoding the object. If ``None``, will default to ``TomlEncoder``\n\n  :Returns:\n    A string containing the TOML-formatted data corresponding to object ``o``\n\n\n\nLicensing\n=========\n\nThis project is released under the terms of the MIT Open Source License. View\n*LICENSE.txt* for more information.\n\n\n",
        "home_page": "https://github.com/uiri/toml",
        "author": "William Pearson",
        "author_email": "uiri@xqz.ca",
        "license": "MIT",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.6",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_python": ">=2.6, !=3.0.*, !=3.1.*, !=3.2.*"
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\toml-0.10.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "tomli",
        "version": "2.0.1",
        "summary": "A lil' TOML parser",
        "description": "[![Build Status](https://github.com/hukkin/tomli/workflows/Tests/badge.svg?branch=master)](https://github.com/hukkin/tomli/actions?query=workflow%3ATests+branch%3Amaster+event%3Apush)\n[![codecov.io](https://codecov.io/gh/hukkin/tomli/branch/master/graph/badge.svg)](https://codecov.io/gh/hukkin/tomli)\n[![PyPI version](https://img.shields.io/pypi/v/tomli)](https://pypi.org/project/tomli)\n\n# Tomli\n\n> A lil' TOML parser\n\n**Table of Contents**  *generated with [mdformat-toc](https://github.com/hukkin/mdformat-toc)*\n\n<!-- mdformat-toc start --slug=github --maxlevel=6 --minlevel=2 -->\n\n- [Intro](#intro)\n- [Installation](#installation)\n- [Usage](#usage)\n  - [Parse a TOML string](#parse-a-toml-string)\n  - [Parse a TOML file](#parse-a-toml-file)\n  - [Handle invalid TOML](#handle-invalid-toml)\n  - [Construct `decimal.Decimal`s from TOML floats](#construct-decimaldecimals-from-toml-floats)\n- [FAQ](#faq)\n  - [Why this parser?](#why-this-parser)\n  - [Is comment preserving round-trip parsing supported?](#is-comment-preserving-round-trip-parsing-supported)\n  - [Is there a `dumps`, `write` or `encode` function?](#is-there-a-dumps-write-or-encode-function)\n  - [How do TOML types map into Python types?](#how-do-toml-types-map-into-python-types)\n- [Performance](#performance)\n\n<!-- mdformat-toc end -->\n\n## Intro<a name=\"intro\"></a>\n\nTomli is a Python library for parsing [TOML](https://toml.io).\nTomli is fully compatible with [TOML v1.0.0](https://toml.io/en/v1.0.0).\n\n## Installation<a name=\"installation\"></a>\n\n```bash\npip install tomli\n```\n\n## Usage<a name=\"usage\"></a>\n\n### Parse a TOML string<a name=\"parse-a-toml-string\"></a>\n\n```python\nimport tomli\n\ntoml_str = \"\"\"\n           gretzky = 99\n\n           [kurri]\n           jari = 17\n           \"\"\"\n\ntoml_dict = tomli.loads(toml_str)\nassert toml_dict == {\"gretzky\": 99, \"kurri\": {\"jari\": 17}}\n```\n\n### Parse a TOML file<a name=\"parse-a-toml-file\"></a>\n\n```python\nimport tomli\n\nwith open(\"path_to_file/conf.toml\", \"rb\") as f:\n    toml_dict = tomli.load(f)\n```\n\nThe file must be opened in binary mode (with the `\"rb\"` flag).\nBinary mode will enforce decoding the file as UTF-8 with universal newlines disabled,\nboth of which are required to correctly parse TOML.\n\n### Handle invalid TOML<a name=\"handle-invalid-toml\"></a>\n\n```python\nimport tomli\n\ntry:\n    toml_dict = tomli.loads(\"]] this is invalid TOML [[\")\nexcept tomli.TOMLDecodeError:\n    print(\"Yep, definitely not valid.\")\n```\n\nNote that error messages are considered informational only.\nThey should not be assumed to stay constant across Tomli versions.\n\n### Construct `decimal.Decimal`s from TOML floats<a name=\"construct-decimaldecimals-from-toml-floats\"></a>\n\n```python\nfrom decimal import Decimal\nimport tomli\n\ntoml_dict = tomli.loads(\"precision-matters = 0.982492\", parse_float=Decimal)\nassert toml_dict[\"precision-matters\"] == Decimal(\"0.982492\")\n```\n\nNote that `decimal.Decimal` can be replaced with another callable that converts a TOML float from string to a Python type.\nThe `decimal.Decimal` is, however, a practical choice for use cases where float inaccuracies can not be tolerated.\n\nIllegal types are `dict` and `list`, and their subtypes.\nA `ValueError` will be raised if `parse_float` produces illegal types.\n\n## FAQ<a name=\"faq\"></a>\n\n### Why this parser?<a name=\"why-this-parser\"></a>\n\n- it's lil'\n- pure Python with zero dependencies\n- the fastest pure Python parser [\\*](#performance):\n  15x as fast as [tomlkit](https://pypi.org/project/tomlkit/),\n  2.4x as fast as [toml](https://pypi.org/project/toml/)\n- outputs [basic data types](#how-do-toml-types-map-into-python-types) only\n- 100% spec compliant: passes all tests in\n  [a test set](https://github.com/toml-lang/compliance/pull/8)\n  soon to be merged to the official\n  [compliance tests for TOML](https://github.com/toml-lang/compliance)\n  repository\n- thoroughly tested: 100% branch coverage\n\n### Is comment preserving round-trip parsing supported?<a name=\"is-comment-preserving-round-trip-parsing-supported\"></a>\n\nNo.\n\nThe `tomli.loads` function returns a plain `dict` that is populated with builtin types and types from the standard library only.\nPreserving comments requires a custom type to be returned so will not be supported,\nat least not by the `tomli.loads` and `tomli.load` functions.\n\nLook into [TOML Kit](https://github.com/sdispater/tomlkit) if preservation of style is what you need.\n\n### Is there a `dumps`, `write` or `encode` function?<a name=\"is-there-a-dumps-write-or-encode-function\"></a>\n\n[Tomli-W](https://github.com/hukkin/tomli-w) is the write-only counterpart of Tomli, providing `dump` and `dumps` functions.\n\nThe core library does not include write capability, as most TOML use cases are read-only, and Tomli intends to be minimal.\n\n### How do TOML types map into Python types?<a name=\"how-do-toml-types-map-into-python-types\"></a>\n\n| TOML type        | Python type         | Details                                                      |\n| ---------------- | ------------------- | ------------------------------------------------------------ |\n| Document Root    | `dict`              |                                                              |\n| Key              | `str`               |                                                              |\n| String           | `str`               |                                                              |\n| Integer          | `int`               |                                                              |\n| Float            | `float`             |                                                              |\n| Boolean          | `bool`              |                                                              |\n| Offset Date-Time | `datetime.datetime` | `tzinfo` attribute set to an instance of `datetime.timezone` |\n| Local Date-Time  | `datetime.datetime` | `tzinfo` attribute set to `None`                             |\n| Local Date       | `datetime.date`     |                                                              |\n| Local Time       | `datetime.time`     |                                                              |\n| Array            | `list`              |                                                              |\n| Table            | `dict`              |                                                              |\n| Inline Table     | `dict`              |                                                              |\n\n## Performance<a name=\"performance\"></a>\n\nThe `benchmark/` folder in this repository contains a performance benchmark for comparing the various Python TOML parsers.\nThe benchmark can be run with `tox -e benchmark-pypi`.\nRunning the benchmark on my personal computer output the following:\n\n```console\nfoo@bar:~/dev/tomli$ tox -e benchmark-pypi\nbenchmark-pypi installed: attrs==19.3.0,click==7.1.2,pytomlpp==1.0.2,qtoml==0.3.0,rtoml==0.7.0,toml==0.10.2,tomli==1.1.0,tomlkit==0.7.2\nbenchmark-pypi run-test-pre: PYTHONHASHSEED='2658546909'\nbenchmark-pypi run-test: commands[0] | python -c 'import datetime; print(datetime.date.today())'\n2021-07-23\nbenchmark-pypi run-test: commands[1] | python --version\nPython 3.8.10\nbenchmark-pypi run-test: commands[2] | python benchmark/run.py\nParsing data.toml 5000 times:\n------------------------------------------------------\n    parser |  exec time | performance (more is better)\n-----------+------------+-----------------------------\n     rtoml |    0.901 s | baseline (100%)\n  pytomlpp |     1.08 s | 83.15%\n     tomli |     3.89 s | 23.15%\n      toml |     9.36 s | 9.63%\n     qtoml |     11.5 s | 7.82%\n   tomlkit |     56.8 s | 1.59%\n```\n\nThe parsers are ordered from fastest to slowest, using the fastest parser as baseline.\nTomli performed the best out of all pure Python TOML parsers,\nlosing only to pytomlpp (wraps C++) and rtoml (wraps Rust).\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "toml"
        ],
        "author_email": "Taneli Hukkinen <hukkin@users.noreply.github.com>",
        "classifier": [
          "License :: OSI Approved :: MIT License",
          "Operating System :: MacOS",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX :: Linux",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Typing :: Typed"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Changelog, https://github.com/hukkin/tomli/blob/master/CHANGELOG.md",
          "Homepage, https://github.com/hukkin/tomli"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\tomli-2.0.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "tomlkit",
        "version": "0.13.2",
        "summary": "Style preserving TOML library",
        "description": "[github_release]: https://img.shields.io/github/release/sdispater/tomlkit.svg?logo=github&logoColor=white\n[pypi_version]: https://img.shields.io/pypi/v/tomlkit.svg?logo=python&logoColor=white\n[python_versions]: https://img.shields.io/pypi/pyversions/tomlkit.svg?logo=python&logoColor=white\n[github_license]: https://img.shields.io/github/license/sdispater/tomlkit.svg?logo=github&logoColor=white\n[github_action]: https://github.com/sdispater/tomlkit/actions/workflows/tests.yml/badge.svg\n\n[![GitHub Release][github_release]](https://github.com/sdispater/tomlkit/releases/)\n[![PyPI Version][pypi_version]](https://pypi.org/project/tomlkit/)\n[![Python Versions][python_versions]](https://pypi.org/project/tomlkit/)\n[![License][github_license]](https://github.com/sdispater/tomlkit/blob/master/LICENSE)\n<br>\n[![Tests][github_action]](https://github.com/sdispater/tomlkit/actions/workflows/tests.yml)\n\n# TOML Kit - Style-preserving TOML library for Python\n\nTOML Kit is a **1.0.0-compliant** [TOML](https://toml.io/) library.\n\nIt includes a parser that preserves all comments, indentations, whitespace and internal element ordering,\nand makes them accessible and editable via an intuitive API.\n\nYou can also create new TOML documents from scratch using the provided helpers.\n\nPart of the implementation has been adapted, improved and fixed from [Molten](https://github.com/LeopoldArkham/Molten).\n\n## Usage\n\nSee the [documentation](https://tomlkit.readthedocs.io/) for more information.\n\n## Installation\n\nIf you are using [Poetry](https://poetry.eustace.io),\nadd `tomlkit` to your `pyproject.toml` file by using:\n\n```bash\npoetry add tomlkit\n```\n\nIf not, you can use `pip`:\n\n```bash\npip install tomlkit\n```\n\n## Running tests\n\nPlease clone the repo with submodules with the following command\n`git clone --recurse-submodules https://github.com/sdispater/tomlkit.git`.\nWe need the submodule - `toml-test` for running the tests.\n\nYou can run the tests with `poetry run pytest -q tests`\n\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/sdispater/tomlkit",
        "author": "SÃ©bastien Eustace",
        "author_email": "sebastien@eustace.io",
        "license": "MIT",
        "classifier": [
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Repository, https://github.com/sdispater/tomlkit"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\tomlkit-0.13.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "tornado",
        "version": "6.4.1",
        "summary": "Tornado is a Python web framework and asynchronous networking library, originally developed at FriendFeed.",
        "description": "Tornado Web Server\n==================\n\n.. image:: https://badges.gitter.im/Join%20Chat.svg\n   :alt: Join the chat at https://gitter.im/tornadoweb/tornado\n   :target: https://gitter.im/tornadoweb/tornado?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n\n`Tornado <http://www.tornadoweb.org>`_ is a Python web framework and\nasynchronous networking library, originally developed at `FriendFeed\n<http://friendfeed.com>`_.  By using non-blocking network I/O, Tornado\ncan scale to tens of thousands of open connections, making it ideal for\n`long polling <http://en.wikipedia.org/wiki/Push_technology#Long_Polling>`_,\n`WebSockets <http://en.wikipedia.org/wiki/WebSocket>`_, and other\napplications that require a long-lived connection to each user.\n\nHello, world\n------------\n\nHere is a simple \"Hello, world\" example web app for Tornado:\n\n.. code-block:: python\n\n    import asyncio\n    import tornado\n\n    class MainHandler(tornado.web.RequestHandler):\n        def get(self):\n            self.write(\"Hello, world\")\n\n    def make_app():\n        return tornado.web.Application([\n            (r\"/\", MainHandler),\n        ])\n\n    async def main():\n        app = make_app()\n        app.listen(8888)\n        await asyncio.Event().wait()\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n\nThis example does not use any of Tornado's asynchronous features; for\nthat see this `simple chat room\n<https://github.com/tornadoweb/tornado/tree/stable/demos/chat>`_.\n\nDocumentation\n-------------\n\nDocumentation and links to additional resources are available at\nhttps://www.tornadoweb.org\n",
        "description_content_type": "text/x-rst",
        "home_page": "http://www.tornadoweb.org/",
        "author": "Facebook",
        "author_email": "python-tornado@googlegroups.com",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_python": ">= 3.8",
        "project_url": [
          "Source, https://github.com/tornadoweb/tornado"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\tornado-6.4.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "traitlets",
        "version": "5.14.3",
        "summary": "Traitlets Python configuration system",
        "description": "# Traitlets\n\n[![Tests](https://github.com/ipython/traitlets/actions/workflows/tests.yml/badge.svg)](https://github.com/ipython/traitlets/actions/workflows/tests.yml)\n[![Documentation Status](https://readthedocs.org/projects/traitlets/badge/?version=latest)](https://traitlets.readthedocs.io/en/latest/?badge=latest)\n[![Tidelift](https://tidelift.com/subscription/pkg/pypi-traitlets)](https://tidelift.com/badges/package/pypi/traitlets)\n\n|               |                                      |\n| ------------- | ------------------------------------ |\n| **home**      | https://github.com/ipython/traitlets |\n| **pypi-repo** | https://pypi.org/project/traitlets/  |\n| **docs**      | https://traitlets.readthedocs.io/    |\n| **license**   | Modified BSD License                 |\n\nTraitlets is a pure Python library enabling:\n\n- the enforcement of strong typing for attributes of Python objects\n  (typed attributes are called _\"traits\"_);\n- dynamically calculated default values;\n- automatic validation and coercion of trait attributes when attempting a\n  change;\n- registering for receiving notifications when trait values change;\n- reading configuring values from files or from command line\n  arguments - a distinct layer on top of traitlets, so you may use\n  traitlets without the configuration machinery.\n\nIts implementation relies on the [descriptor](https://docs.python.org/howto/descriptor.html)\npattern, and it is a lightweight pure-python alternative of the\n[_traits_ library](https://docs.enthought.com/traits/).\n\nTraitlets powers the configuration system of IPython and Jupyter\nand the declarative API of IPython interactive widgets.\n\n## Installation\n\nFor a local installation, make sure you have\n[pip installed](https://pip.pypa.io/en/stable/installing/) and run:\n\n```bash\npip install traitlets\n```\n\nFor a **development installation**, clone this repository, change into the\n`traitlets` root directory, and run pip:\n\n```bash\ngit clone https://github.com/ipython/traitlets.git\ncd traitlets\npip install -e .\n```\n\n## Running the tests\n\n```bash\npip install \"traitlets[test]\"\npy.test traitlets\n```\n\n## Code Styling\n\n`traitlets` has adopted automatic code formatting so you shouldn't\nneed to worry too much about your code style.\nAs long as your code is valid,\nthe pre-commit hook should take care of how it should look.\n\nTo install `pre-commit` locally, run the following::\n\n```\npip install pre-commit\npre-commit install\n```\n\nYou can invoke the pre-commit hook by hand at any time with::\n\n```\npre-commit run\n```\n\nwhich should run any autoformatting on your code\nand tell you about any errors it couldn't fix automatically.\nYou may also install [black integration](https://github.com/psf/black#editor-integration)\ninto your text editor to format code automatically.\n\nIf you have already committed files before setting up the pre-commit\nhook with `pre-commit install`, you can fix everything up using\n`pre-commit run --all-files`. You need to make the fixing commit\nyourself after that.\n\nSome of the hooks only run on CI by default, but you can invoke them by\nrunning with the `--hook-stage manual` argument.\n\n## Usage\n\nAny class with trait attributes must inherit from `HasTraits`.\nFor the list of available trait types and their properties, see the\n[Trait Types](https://traitlets.readthedocs.io/en/latest/trait_types.html)\nsection of the documentation.\n\n### Dynamic default values\n\nTo calculate a default value dynamically, decorate a method of your class with\n`@default({traitname})`. This method will be called on the instance, and\nshould return the default value. In this example, the `_username_default`\nmethod is decorated with `@default('username')`:\n\n```Python\nimport getpass\nfrom traitlets import HasTraits, Unicode, default\n\nclass Identity(HasTraits):\n    username = Unicode()\n\n    @default('username')\n    def _username_default(self):\n        return getpass.getuser()\n```\n\n### Callbacks when a trait attribute changes\n\nWhen a trait changes, an application can follow this trait change with\nadditional actions.\n\nTo do something when a trait attribute is changed, decorate a method with\n[`traitlets.observe()`](https://traitlets.readthedocs.io/en/latest/api.html?highlight=observe#traitlets.observe).\nThe method will be called with a single argument, a dictionary which contains\nan owner, new value, old value, name of the changed trait, and the event type.\n\nIn this example, the `_num_changed` method is decorated with `` @observe(`num`) ``:\n\n```Python\nfrom traitlets import HasTraits, Integer, observe\n\nclass TraitletsExample(HasTraits):\n    num = Integer(5, help=\"a number\").tag(config=True)\n\n    @observe('num')\n    def _num_changed(self, change):\n        print(\"{name} changed from {old} to {new}\".format(**change))\n```\n\nand is passed the following dictionary when called:\n\n```Python\n{\n  'owner': object,  # The HasTraits instance\n  'new': 6,         # The new value\n  'old': 5,         # The old value\n  'name': \"foo\",    # The name of the changed trait\n  'type': 'change', # The event type of the notification, usually 'change'\n}\n```\n\n### Validation and coercion\n\nEach trait type (`Int`, `Unicode`, `Dict` etc.) may have its own validation or\ncoercion logic. In addition, we can register custom cross-validators\nthat may depend on the state of other attributes. For example:\n\n```Python\nfrom traitlets import HasTraits, TraitError, Int, Bool, validate\n\nclass Parity(HasTraits):\n    value = Int()\n    parity = Int()\n\n    @validate('value')\n    def _valid_value(self, proposal):\n        if proposal['value'] % 2 != self.parity:\n            raise TraitError('value and parity should be consistent')\n        return proposal['value']\n\n    @validate('parity')\n    def _valid_parity(self, proposal):\n        parity = proposal['value']\n        if parity not in [0, 1]:\n            raise TraitError('parity should be 0 or 1')\n        if self.value % 2 != parity:\n            raise TraitError('value and parity should be consistent')\n        return proposal['value']\n\nparity_check = Parity(value=2)\n\n# Changing required parity and value together while holding cross validation\nwith parity_check.hold_trait_notifications():\n    parity_check.value = 1\n    parity_check.parity = 1\n```\n\nHowever, we **recommend** that custom cross-validators don't modify the state\nof the HasTraits instance.\n\n## About the IPython Development Team\n\nThe IPython Development Team is the set of all contributors to the IPython project.\nThis includes all of the IPython subprojects.\n\nThe core team that coordinates development on GitHub can be found here:\nhttps://github.com/jupyter/.\n\n## Our Copyright Policy\n\nIPython uses a shared copyright model. Each contributor maintains copyright\nover their contributions to IPython. But, it is important to note that these\ncontributions are typically only changes to the repositories. Thus, the IPython\nsource code, in its entirety is not the copyright of any single person or\ninstitution. Instead, it is the collective copyright of the entire IPython\nDevelopment Team. If individual contributors want to maintain a record of what\nchanges/contributions they have specific copyright on, they should indicate\ntheir copyright in the commit message of the change, when they commit the\nchange to one of the IPython repositories.\n\nWith this in mind, the following banner should be used in any source code file\nto indicate the copyright and license terms:\n\n```\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License.\n```\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "Interactive",
          "Interpreter",
          "Shell",
          "Web"
        ],
        "author_email": "IPython Development Team <ipython-dev@python.org>",
        "license": "BSD 3-Clause License\n\n- Copyright (c) 2001-, IPython Development Team\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Framework :: IPython",
          "Framework :: Jupyter",
          "Intended Audience :: Developers",
          "Intended Audience :: Science/Research",
          "Intended Audience :: System Administrators",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "myst-parser; extra == 'docs'",
          "pydata-sphinx-theme; extra == 'docs'",
          "sphinx; extra == 'docs'",
          "argcomplete>=3.0.3; extra == 'test'",
          "mypy>=1.7.0; extra == 'test'",
          "pre-commit; extra == 'test'",
          "pytest-mock; extra == 'test'",
          "pytest-mypy-testing; extra == 'test'",
          "pytest<8.2,>=7.0; extra == 'test'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://github.com/ipython/traitlets",
          "Documentation, https://traitlets.readthedocs.io",
          "Source, https://github.com/ipython/traitlets",
          "Funding, https://numfocus.org",
          "Tracker, https://github.com/ipython/traitlets/issues"
        ],
        "provides_extra": [
          "docs",
          "test"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\traitlets-5.14.3.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "types-python-dateutil",
        "version": "2.9.0.20240821",
        "summary": "Typing stubs for python-dateutil",
        "description": "## Typing stubs for python-dateutil\n\nThis is a [PEP 561](https://peps.python.org/pep-0561/)\ntype stub package for the [`python-dateutil`](https://github.com/dateutil/dateutil) package.\nIt can be used by type-checking tools like\n[mypy](https://github.com/python/mypy/),\n[pyright](https://github.com/microsoft/pyright),\n[pytype](https://github.com/google/pytype/),\nPyCharm, etc. to check code that uses\n`python-dateutil`.\n\nThis version of `types-python-dateutil` aims to provide accurate annotations\nfor `python-dateutil==2.9.*`.\nThe source for this package can be found at\nhttps://github.com/python/typeshed/tree/main/stubs/python-dateutil. All fixes for\ntypes and metadata should be contributed there.\n\nThis stub package is marked as [partial](https://peps.python.org/pep-0561/#partial-stub-packages).\nIf you find that annotations are missing, feel free to contribute and help complete them.\n\n\nSee https://github.com/python/typeshed/blob/main/README.md for more details.\nThis package was generated from typeshed commit\n[`b19d9670f9cdef5eedd97dc2455cdf2822c95e7d`](https://github.com/python/typeshed/commit/b19d9670f9cdef5eedd97dc2455cdf2822c95e7d) and was tested\nwith mypy 1.11.1, pyright 1.1.376, and\npytype 2024.4.11.\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/python/typeshed",
        "license": "Apache-2.0",
        "classifier": [
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python :: 3",
          "Typing :: Stubs Only"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "GitHub, https://github.com/python/typeshed",
          "Changes, https://github.com/typeshed-internal/stub_uploader/blob/main/data/changelogs/python-dateutil.md",
          "Issue tracker, https://github.com/python/typeshed/issues",
          "Chat, https://gitter.im/python/typing"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\types_python_dateutil-2.9.0.20240821.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "types-setuptools",
        "version": "73.0.0.20240822",
        "summary": "Typing stubs for setuptools",
        "description": "## Typing stubs for setuptools\n\nThis is a [PEP 561](https://peps.python.org/pep-0561/)\ntype stub package for the [`setuptools`](https://github.com/pypa/setuptools) package.\nIt can be used by type-checking tools like\n[mypy](https://github.com/python/mypy/),\n[pyright](https://github.com/microsoft/pyright),\n[pytype](https://github.com/google/pytype/),\nPyCharm, etc. to check code that uses\n`setuptools`.\n\nThis version of `types-setuptools` aims to provide accurate annotations\nfor `setuptools==73.0.*`.\nThe source for this package can be found at\nhttps://github.com/python/typeshed/tree/main/stubs/setuptools. All fixes for\ntypes and metadata should be contributed there.\n\nIf using `setuptools >= 71.1` *only* for `pkg_resources`,\nyou don't need `types-setuptools` since `pkg_resources` is now typed.\n\nSee https://github.com/python/typeshed/blob/main/README.md for more details.\nThis package was generated from typeshed commit\n[`7865a78de1929ee54797baca0fe07ac33567739f`](https://github.com/python/typeshed/commit/7865a78de1929ee54797baca0fe07ac33567739f) and was tested\nwith mypy 1.11.1, pyright 1.1.377, and\npytype 2024.4.11.\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/python/typeshed",
        "license": "Apache-2.0",
        "classifier": [
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python :: 3",
          "Typing :: Stubs Only"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "GitHub, https://github.com/python/typeshed",
          "Changes, https://github.com/typeshed-internal/stub_uploader/blob/main/data/changelogs/setuptools.md",
          "Issue tracker, https://github.com/python/typeshed/issues",
          "Chat, https://gitter.im/python/typing"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\types_setuptools-73.0.0.20240822.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "typing_extensions",
        "version": "4.12.2",
        "summary": "Backported and Experimental Type Hints for Python 3.8+",
        "description": "# Typing Extensions\n\n[![Chat at https://gitter.im/python/typing](https://badges.gitter.im/python/typing.svg)](https://gitter.im/python/typing)\n\n[Documentation](https://typing-extensions.readthedocs.io/en/latest/#) â€“\n[PyPI](https://pypi.org/project/typing-extensions/)\n\n## Overview\n\nThe `typing_extensions` module serves two related purposes:\n\n- Enable use of new type system features on older Python versions. For example,\n  `typing.TypeGuard` is new in Python 3.10, but `typing_extensions` allows\n  users on previous Python versions to use it too.\n- Enable experimentation with new type system PEPs before they are accepted and\n  added to the `typing` module.\n\n`typing_extensions` is treated specially by static type checkers such as\nmypy and pyright. Objects defined in `typing_extensions` are treated the same\nway as equivalent forms in `typing`.\n\n`typing_extensions` uses\n[Semantic Versioning](https://semver.org/). The\nmajor version will be incremented only for backwards-incompatible changes.\nTherefore, it's safe to depend\non `typing_extensions` like this: `typing_extensions >=x.y, <(x+1)`,\nwhere `x.y` is the first version that includes all features you need.\n\n## Included items\n\nSee [the documentation](https://typing-extensions.readthedocs.io/en/latest/#) for a\ncomplete listing of module contents.\n\n## Contributing\n\nSee [CONTRIBUTING.md](https://github.com/python/typing_extensions/blob/main/CONTRIBUTING.md)\nfor how to contribute to `typing_extensions`.\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "annotations",
          "backport",
          "checker",
          "checking",
          "function",
          "hinting",
          "hints",
          "type",
          "typechecking",
          "typehinting",
          "typehints",
          "typing"
        ],
        "author_email": "\"Guido van Rossum, Jukka Lehtosalo, Åukasz Langa, Michael Lee\" <levkivskyi@gmail.com>",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Python Software Foundation License",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Software Development"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Bug Tracker, https://github.com/python/typing_extensions/issues",
          "Changes, https://github.com/python/typing_extensions/blob/main/CHANGELOG.md",
          "Documentation, https://typing-extensions.readthedocs.io/",
          "Home, https://github.com/python/typing_extensions",
          "Q & A, https://github.com/python/typing/discussions",
          "Repository, https://github.com/python/typing_extensions"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\typing_extensions-4.12.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "tzdata",
        "version": "2024.1",
        "summary": "Provider of IANA time zone data",
        "description": "tzdata: Python package providing IANA time zone data\n====================================================\n\nThis is a Python package containing ``zic``-compiled binaries for the IANA time\nzone database. It is intended to be a fallback for systems that do not have\nsystem time zone data installed (or don't have it installed in a standard\nlocation), as a part of `PEP 615 <https://www.python.org/dev/peps/pep-0615/>`_\n\nThis repository generates a ``pip``-installable package, published on PyPI as\n`tzdata <https://pypi.org/project/tzdata>`_.\n\nFor more information, see `the documentation <https://tzdata.readthedocs.io>`_.\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/python/tzdata",
        "author": "Python Software Foundation",
        "author_email": "datetime-sig@python.org",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE",
          "licenses/LICENSE_APACHE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 3"
        ],
        "requires_python": ">=2",
        "project_url": [
          "Bug Reports, https://github.com/python/tzdata/issues",
          "Source, https://github.com/python/tzdata",
          "Documentation, https://tzdata.readthedocs.io"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\tzdata-2024.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "tzlocal",
        "version": "5.2",
        "summary": "tzinfo object for the local timezone",
        "description": "tzlocal\n=======\n\nAPI CHANGE!\n-----------\n\nWith version 3.0 of tzlocal, tzlocal no longer returned `pytz` objects, but\n`zoneinfo` objects, which has a different API. Since 4.0, it now restored\npartial compatibility for `pytz` users through Paul Ganssle's\n`pytz_deprecation_shim`.\n\ntzlocal 4.0 also adds an official function `get_localzone_name()` to get only\nthe timezone name, instead of a timezone object. On unix, it can raise an\nerror if you don't have a timezone name configured, where `get_localzone()`\nwill succeed, so only use that if you need the timezone name.\n\n4.0 also adds way more information on what is going wrong in your\nconfiguration when the configuration files are unclear or contradictory.\n\nVersion 5.0 removes the `pytz_deprecation_shim`, and now only returns\n`zoneinfo` objects, like verion 3.0 did. If you need `pytz` objects, you have\nto stay on version 4.0. If there are bugs in version 4.0, I will release\nupdates, but there will be no further functional changes on the 4.x branch.\n\n\nInfo\n----\n\nThis Python module returns the `IANA time zone name\n<https://www.iana.org/time-zones>`_ for your local time zone or a ``tzinfo``\nobject with the local timezone information, under Unix and Windows.\n\nIt requires Python 3.8 or later, and will use the ``backports.tzinfo``\npackage, for Python 3.8.\n\nThis module attempts to fix a glaring hole in the ``pytz`` and ``zoneinfo``\nmodules, that there is no way to get the local timezone information, unless\nyou know the zoneinfo name, and under several Linux distros that's hard or\nimpossible to figure out.\n\nWith ``tzlocal`` you only need to call ``get_localzone()`` and you will get a\n``tzinfo`` object with the local time zone info. On some Unices you will\nstill not get to know what the timezone name is, but you don't need that when\nyou have the tzinfo file. However, if the timezone name is readily available\nit will be used.\n\nWhat it's not for\n-----------------\n\nIt's not for converting the current time between UTC and your local time. There are\nother, simpler ways of doing this. This is ig you need to know things like the name\nof the time zone, or if you need to be able to convert between your time zone and\nanother time zone for times that are in the future or in the past.\n\nFor current time conversions to and from UTC, look in the Python ``time`` module.\n\n\nSupported systems\n-----------------\n\nThese are the systems that are in theory supported:\n\n * Windows 2000 and later\n\n * Any unix-like system with a ``/etc/localtime`` or ``/usr/local/etc/localtime``\n\nIf you have one of the above systems and it does not work, it's a bug.\nPlease report it.\n\nPlease note that if you are getting a time zone called ``local``, this is not\na bug, it's actually the main feature of ``tzlocal``, that even if your\nsystem does NOT have a configuration file with the zoneinfo name of your time\nzone, it will still work.\n\nYou can also use ``tzlocal`` to get the name of your local timezone, but only\nif your system is configured to make that possible. ``tzlocal`` looks for the\ntimezone name in ``/etc/timezone``, ``/var/db/zoneinfo``,\n``/etc/sysconfig/clock`` and ``/etc/conf.d/clock``. If your\n``/etc/localtime`` is a symlink it can also extract the name from that\nsymlink.\n\nIf you need the name of your local time zone, then please make sure your\nsystem is properly configured to allow that.\n\nIf your unix system doesn't have a timezone configured, tzlocal will default\nto UTC.\n\nNotes on Docker\n---------------\n\nIt turns out that Docker images frequently have broken timezone setups.\nThis usually resuts in a warning that the configuration is wrong, or that\nthe timezone offset doesn't match the found timezone.\n\nThe easiest way to fix that is to set a TZ variable in your docker setup\nto whatever timezone you want, which is usually the timezone your host\ncomputer has.\n\nUsage\n-----\n\nLoad the local timezone:\n\n    >>> from tzlocal import get_localzone\n    >>> tz = get_localzone()\n    >>> tz\n    zoneinfo.ZoneInfo(key='Europe/Warsaw')\n\nCreate a local datetime:\n\n    >>> from datetime import datetime\n    >>> dt = datetime(2015, 4, 10, 7, 22, tzinfo=tz)\n    >>> dt\n    datetime.datetime(2015, 4, 10, 7, 22, tzinfo=zoneinfo.ZoneInfo(key='Europe/Warsaw'))\n\nLookup another timezone with ``zoneinfo`` (``backports.zoneinfo`` on Python 3.8 or earlier):\n\n    >>> from zoneinfo import ZoneInfo\n    >>> eastern = ZoneInfo('US/Eastern')\n\nConvert the datetime:\n\n    >>> dt.astimezone(eastern)\n    datetime.datetime(2015, 4, 10, 1, 22, tzinfo=zoneinfo.ZoneInfo(key='US/Eastern'))\n\nIf you just want the name of the local timezone, use `get_localzone_name()`:\n\n    >>> from tzlocal import get_localzone_name\n    >>> get_localzone_name()\n    \"Europe/Warsaw\"\n\nPlease note that under Unix, `get_localzone_name()` may fail if there is no zone\nconfigured, where `get_localzone()` would generally succeed.\n\nTroubleshooting\n---------------\n\nIf you don't get the result you expect, try running it with debugging turned on.\nStart a python interpreter that has tzlocal installed, and run the following code::\n\n    import logging\n    logging.basicConfig(level=\"DEBUG\")\n    import tzlocal\n    tzlocal.get_localzone()\n\nThe output should look something like this, and this will tell you what\nconfigurations were found::\n\n    DEBUG:root:/etc/timezone found, contents:\n     Europe/Warsaw\n\n    DEBUG:root:/etc/localtime found\n    DEBUG:root:2 found:\n     {'/etc/timezone': 'Europe/Warsaw', '/etc/localtime is a symlink to': 'Europe/Warsaw'}\n    zoneinfo.ZoneInfo(key='Europe/Warsaw')\n\n\nDevelopment\n-----------\n\nFor ease of development, there is a Makefile that will help you with basic tasks,\nlike creating a development environment with all the necessary tools (although\nyou need a supported Python version installed first)::\n\n    $ make devenv\n\nTo run tests::\n\n    $ make test\n\nCheck the syntax::\n\n    $ make check\n\n\nMaintainer\n----------\n\n* Lennart Regebro, regebro@gmail.com\n\nContributors\n------------\n\n* Marc Van Olmen\n* Benjamen Meyer\n* Manuel Ebert\n* Xiaokun Zhu\n* Cameris\n* Edward Betts\n* McK KIM\n* Cris Ewing\n* Ayala Shachar\n* Lev Maximov\n* Jakub Wilk\n* John Quarles\n* Preston Landers\n* Victor Torres\n* Jean Jordaan\n* Zackary Welch\n* MickaÃ«l Schoentgen\n* Gabriel Corona\n* Alex GrÃ¶nholm\n* Julin S\n* Miroslav Å edivÃ½\n* revansSZ\n* Sam Treweek\n* Peter Di Pasquale\n* Rongrong\n\n(Sorry if I forgot someone)\n\nLicense\n-------\n\n* MIT https://opensource.org/licenses/MIT\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "timezone"
        ],
        "author_email": "Lennart Regebro <regebro@gmail.com>",
        "license": "MIT",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "License :: OSI Approved :: MIT License",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: Unix",
          "Operating System :: MacOS :: MacOS X",
          "Typing :: Typed",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12"
        ],
        "requires_dist": [
          "tzdata ; platform_system == \"Windows\"",
          "backports.zoneinfo ; python_version < \"3.9\"",
          "pytest (>=4.3) ; extra == 'devenv'",
          "pytest-mock (>=3.3) ; extra == 'devenv'",
          "pytest-cov ; extra == 'devenv'",
          "check-manifest ; extra == 'devenv'",
          "zest.releaser ; extra == 'devenv'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Source code, https://github.com/regebro/tzlocal",
          "Changelog, https://github.com/regebro/tzlocal/blob/master/CHANGES.txt",
          "Issue tracker, https://github.com/regebro/tzlocal/issues"
        ],
        "provides_extra": [
          "devenv"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\tzlocal-5.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "uri-template",
        "version": "1.3.0",
        "summary": "RFC 6570 URI Template Processor",
        "description": "# uri-template\n\nAn implementation of RFC 6570 URI Templates.\n\nThis packages implements URI Template expansion in strict adherence to RFC 6570,\nbut adds a few extensions.\n\n## RFC 6570 Extensions\n\n### Non-string Values\n\nRFC 6570 is silent regarding variable values that are not strings, lists, associative arrays, or null.\n\nThis package handles value types as follows:\n\n  * Values that are instances of `str` are treated as strings.\n  * Values implementing `collections.abc.Sequence` are treated as lists.\n  * Values implementing `collections.abc.Mapping` are treated as associative arrays.\n  * `None` values are treated as null.\n  * Boolean values are converted to the lower case strings 'true' and 'false'.\n  * All other values will be converted to strings using the Python `str()` function.\n\n### Nested Structures\n\nThis package handles variable values with nested structure,\nfor example, lists containing other lists or associative arrays,\nor associative arrays containing lists or other associative arrays.\n\nNested values for variables that do not use the array modifier ('[]') are treated as follows:\n\n  * Lists containing lists are flattened into a single list.\n  * Lists containing associative arrays are treated as a single combined associative array.\n  * Associative arrays represent nested data using dot notation (\".\") for the variable names.\n\nNested values for variables that use the array modifier extend the variable name with \nthe value's index or key written as an array subscript, e.g. \"foo[0]\" or \"foo[bar]\".\n\n### Default Values\n\nThis package allows default string values for variables per early drafts of RFC 6570.\ne.g. \"{foo=bar}\" will expand to \"bar\" if a value for `foo` is not given.\n\nList and associtative array default values are not supported at this time.\n\n### Specifying Value Keys\n\nSometimes a URI Template is used to provide glue between an API and a given set of data.\nIn this case, the names of values needed in the final URL may not match the data provided \nfor the expansion.\n\nThis package allows specifying the key used to pass data into the template. \ne.g. \"{?foo/bar}\" will expand to \"?foo=<the value provided as bar>\"\n\n### Partial expansion\n\nThis package allows partial expansion of URI Templates.\n\nIn a partial expansion, missing values preseve their expansion in the resultant output.\ne.g. a partial expansion of \"{one}/{two}\" with a value for `one` of \"foo\" and `two` missing will result in:\n\"foo/{two}\".\n\nIn order to allow partial expansions to preserve value joiners with expanded output,\nexpansions accept an optional \"trailing joiner\" of \",\", \".\", \"/\", \";\", or \"&\",\nif this joiner is present after all variables, \nit will be appended to the output of the expansion and will suppress the output prefix.\ne.g.: \"{#one,two}\" with a missing value for `one` and a value of \"bar\" for `two`, \nwill partially expand to: \"#{#one,}bar\", which when provided with a value of \"foo\" for `one` \nwill expand to \"#foo,bar\"\n\nSome partial expansions that have some output, but have missing values, \nwill convert the remaining variables to a different type of expansion so that \nfurther expansions will produce the same output as if all values were originally present.\n\n   * Partial Simple String Expansions will convert to Comma Expansions.\n   * Partial Reserved Expansions Partial Fragment Expansions will convert to Reserved Comma Expansions.\n   * Partial Form-Style Query Expansions will convert to Form-Style Query Continuations.\n\nIn order to preserve the resultant value of templates that are paritally expanded, \nthe following additional Expression Expansions are supported:\n\n#### Comma Expansion: {,var}\n\nSimilar to Label Expansion with Dot-Prefix, \nComma Expansion prefixes the expansion output with a single comma \",\".\n\n#### Reserved Comma Expansion: {,+var}\n\nSimilar to Comma Expansion, \nReserved Comma Expansion prefixes the expansion output with a single comma \",\",\nbut otherwise performs a Reserved Expansion ({+var}).\n\n## API \n\nThe package provides three functions:\n\n#### uri_template.expand(template: str, **kwargs) -> (str | None): ...\n\nExpand the given template, skipping missing values per RFC 6570.\n\nReturns `None` if the template is invalid or expansion fails.\n\n\n#### uri_template.partial(template: str, **kwargs) -> (str | None): ...\n\nPartially expand the given template, \nreplacing missing variables with further expansions.\n\nReturns `None` if the template is invalid or expansion fails.\n\n\n#### uri_template.validate(template: str) -> bool: ...\n\nReturn `True` if the template is valid.\n\n---\n\nAnd the following classes:\n\n### uri_template.URITemplate\n\n#### URITemplate(template: str)\n\nConstruct a URITemplate for a given template string.\n\nRaises `ExpansionInvalid`, `ExpansionReserved`, or `VariableInvalid` if the template is invalid or unsupported.\n\n#### URITemplate.variables: Iterable[Variable]\n\nAll variables present in the template.\nDuplicates are returned once, order is preserved.\n\n#### URITemplate.variable_names: Iterable[str]\n\nThe names of all variables present in the template.\nDuplicates are returned once, order is preserved.\n\n#### URITemplate.expanded: bool\n\nDetermine if template is fully expanded.\n\n#### URITemplate.expand(**kwargs) -> str\n\nReturns the result of the expansion, skips missing variables.\n\nRaises `ExpansionFailed` if the expansion fails due to a composite value being passed to a variable with a prefix modifier.\n\n#### URITemplate.partial(**kwargs) -> URITemplate\n\nExpand the template, replacing missing variables with further expansions.\n\nRaises `ExpansionFailed` if the expansion fails due to a composite value being passed to a variable with a prefix modifier.\n\n#### URITemplate.__str__() -> str\n\nConvert the URITemplate object back into its original string form.\n\n---\n\n### uri_template.Variable\n\n#### Variable(var_spec: str)\n\nConstruct a Variable.\n\n#### Variable.name: str\n\nThe name of the variable\n\n#### Variable.max_length: int\n\nThe speicified max length, or `0`.\n\n#### Variable.explode: bool\n\nExplode modifier is present.\n\n#### Variable.array: bool\n\nArray modifier is present.\n\n#### Variable.default: (str | None)\n\nSpecified default value, or `None`.\n\n#### Variable.__str__() -> str\n\nConvert the variable back to its original string form.\n\n---\n\nAnd the following exceptions:\n\n#### uri_template.ExpansionInvalid\n\nExpansion specification is invalid. \n\nRaised by URITemplate constructor.\n\n#### uri_template.ExpansionReserved\n\nExpansion contains a reserved operator.\n\nRaised by URITemplate constructor.\n\n#### uri_template.VariableInvalid\n\nVariable specification is invalid.\n\nRaised by URITemplate constructor.\n\n#### uri_template.ExpansionFailed\n\nExpansion failed, currently only possible when a composite value is passed to a variable with a prefix modifier.\n\nRaised by URITemplate.expand() or URITemplate.partial() methods.\n\n\n## Installation\n\nInstall with pip:\n\n    pip install uri-template\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "config"
        ],
        "author_email": "Peter Linss <pypi@linss.com>",
        "license": "MIT License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "types-PyYAML ; extra == 'dev'",
          "mypy ; extra == 'dev'",
          "flake8 ; extra == 'dev'",
          "flake8-annotations ; extra == 'dev'",
          "flake8-bandit ; extra == 'dev'",
          "flake8-bugbear ; extra == 'dev'",
          "flake8-commas ; extra == 'dev'",
          "flake8-comprehensions ; extra == 'dev'",
          "flake8-continuation ; extra == 'dev'",
          "flake8-datetimez ; extra == 'dev'",
          "flake8-docstrings ; extra == 'dev'",
          "flake8-import-order ; extra == 'dev'",
          "flake8-literal ; extra == 'dev'",
          "flake8-modern-annotations ; extra == 'dev'",
          "flake8-noqa ; extra == 'dev'",
          "flake8-pyproject ; extra == 'dev'",
          "flake8-requirements ; extra == 'dev'",
          "flake8-typechecking-import ; extra == 'dev'",
          "flake8-use-fstring ; extra == 'dev'",
          "pep8-naming ; extra == 'dev'"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "homepage, https://gitlab.linss.com/open-source/python/uri-template"
        ],
        "provides_extra": [
          "dev"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\uri_template-1.3.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "urllib3",
        "version": "2.2.2",
        "summary": "HTTP library with thread-safe connection pooling, file post, and more.",
        "description": "<h1 align=\"center\">\n\n![urllib3](https://github.com/urllib3/urllib3/raw/main/docs/_static/banner_github.svg)\n\n</h1>\n\n<p align=\"center\">\n  <a href=\"https://pypi.org/project/urllib3\"><img alt=\"PyPI Version\" src=\"https://img.shields.io/pypi/v/urllib3.svg?maxAge=86400\" /></a>\n  <a href=\"https://pypi.org/project/urllib3\"><img alt=\"Python Versions\" src=\"https://img.shields.io/pypi/pyversions/urllib3.svg?maxAge=86400\" /></a>\n  <a href=\"https://discord.gg/urllib3\"><img alt=\"Join our Discord\" src=\"https://img.shields.io/discord/756342717725933608?color=%237289da&label=discord\" /></a>\n  <a href=\"https://github.com/urllib3/urllib3/actions?query=workflow%3ACI\"><img alt=\"Coverage Status\" src=\"https://img.shields.io/badge/coverage-100%25-success\" /></a>\n  <a href=\"https://github.com/urllib3/urllib3/actions?query=workflow%3ACI\"><img alt=\"Build Status on GitHub\" src=\"https://github.com/urllib3/urllib3/workflows/CI/badge.svg\" /></a>\n  <a href=\"https://urllib3.readthedocs.io\"><img alt=\"Documentation Status\" src=\"https://readthedocs.org/projects/urllib3/badge/?version=latest\" /></a><br>\n  <a href=\"https://deps.dev/pypi/urllib3\"><img alt=\"OpenSSF Scorecard\" src=\"https://api.securityscorecards.dev/projects/github.com/urllib3/urllib3/badge\" /></a>\n  <a href=\"https://slsa.dev\"><img alt=\"SLSA 3\" src=\"https://slsa.dev/images/gh-badge-level3.svg\" /></a>\n  <a href=\"https://bestpractices.coreinfrastructure.org/projects/6227\"><img alt=\"CII Best Practices\" src=\"https://bestpractices.coreinfrastructure.org/projects/6227/badge\" /></a>\n</p>\n\nurllib3 is a powerful, *user-friendly* HTTP client for Python. Much of the\nPython ecosystem already uses urllib3 and you should too.\nurllib3 brings many critical features that are missing from the Python\nstandard libraries:\n\n- Thread safety.\n- Connection pooling.\n- Client-side SSL/TLS verification.\n- File uploads with multipart encoding.\n- Helpers for retrying requests and dealing with HTTP redirects.\n- Support for gzip, deflate, brotli, and zstd encoding.\n- Proxy support for HTTP and SOCKS.\n- 100% test coverage.\n\nurllib3 is powerful and easy to use:\n\n```python3\n>>> import urllib3\n>>> resp = urllib3.request(\"GET\", \"http://httpbin.org/robots.txt\")\n>>> resp.status\n200\n>>> resp.data\nb\"User-agent: *\\nDisallow: /deny\\n\"\n```\n\n## Installing\n\nurllib3 can be installed with [pip](https://pip.pypa.io):\n\n```bash\n$ python -m pip install urllib3\n```\n\nAlternatively, you can grab the latest source code from [GitHub](https://github.com/urllib3/urllib3):\n\n```bash\n$ git clone https://github.com/urllib3/urllib3.git\n$ cd urllib3\n$ pip install .\n```\n\n\n## Documentation\n\nurllib3 has usage and reference documentation at [urllib3.readthedocs.io](https://urllib3.readthedocs.io).\n\n\n## Community\n\nurllib3 has a [community Discord channel](https://discord.gg/urllib3) for asking questions and\ncollaborating with other contributors. Drop by and say hello ðŸ‘‹\n\n\n## Contributing\n\nurllib3 happily accepts contributions. Please see our\n[contributing documentation](https://urllib3.readthedocs.io/en/latest/contributing.html)\nfor some tips on getting started.\n\n\n## Security Disclosures\n\nTo report a security vulnerability, please use the\n[Tidelift security contact](https://tidelift.com/security).\nTidelift will coordinate the fix and disclosure with maintainers.\n\n\n## Maintainers\n\n- [@sethmlarson](https://github.com/sethmlarson) (Seth M. Larson)\n- [@pquentin](https://github.com/pquentin) (Quentin Pradet)\n- [@illia-v](https://github.com/illia-v) (Illia Volochii)\n- [@theacodes](https://github.com/theacodes) (Thea Flowers)\n- [@haikuginger](https://github.com/haikuginger) (Jess Shapiro)\n- [@lukasa](https://github.com/lukasa) (Cory Benfield)\n- [@sigmavirus24](https://github.com/sigmavirus24) (Ian Stapleton Cordasco)\n- [@shazow](https://github.com/shazow) (Andrey Petrov)\n\nðŸ‘‹\n\n\n## Sponsorship\n\nIf your company benefits from this library, please consider [sponsoring its\ndevelopment](https://urllib3.readthedocs.io/en/latest/sponsors.html).\n\n\n## For Enterprise\n\nProfessional support for urllib3 is available as part of the [Tidelift\nSubscription][1].  Tidelift gives software development teams a single source for\npurchasing and maintaining their software, with professional grade assurances\nfrom the experts who know it best, while seamlessly integrating with existing\ntools.\n\n[1]: https://tidelift.com/subscription/pkg/pypi-urllib3?utm_source=pypi-urllib3&utm_medium=referral&utm_campaign=readme\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "filepost",
          "http",
          "httplib",
          "https",
          "pooling",
          "ssl",
          "threadsafe",
          "urllib"
        ],
        "author_email": "Andrey Petrov <andrey.petrov@shazow.net>",
        "maintainer_email": "Seth Michael Larson <sethmichaellarson@gmail.com>, Quentin Pradet <quentin@pradet.me>, Illia Volochii <illia.volochii@gmail.com>",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet :: WWW/HTTP",
          "Topic :: Software Development :: Libraries"
        ],
        "requires_dist": [
          "brotli>=1.0.9; (platform_python_implementation == 'CPython') and extra == 'brotli'",
          "brotlicffi>=0.8.0; (platform_python_implementation != 'CPython') and extra == 'brotli'",
          "h2<5,>=4; extra == 'h2'",
          "pysocks!=1.5.7,<2.0,>=1.5.6; extra == 'socks'",
          "zstandard>=0.18.0; extra == 'zstd'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Changelog, https://github.com/urllib3/urllib3/blob/main/CHANGES.rst",
          "Documentation, https://urllib3.readthedocs.io",
          "Code, https://github.com/urllib3/urllib3",
          "Issue tracker, https://github.com/urllib3/urllib3/issues"
        ],
        "provides_extra": [
          "brotli",
          "h2",
          "socks",
          "zstd"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\urllib3-2.2.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "virtualenv",
        "version": "20.26.3",
        "summary": "Virtual Python Environment builder",
        "description": "# virtualenv\n\n[![PyPI](https://img.shields.io/pypi/v/virtualenv?style=flat-square)](https://pypi.org/project/virtualenv)\n[![PyPI - Implementation](https://img.shields.io/pypi/implementation/virtualenv?style=flat-square)](https://pypi.org/project/virtualenv)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/virtualenv?style=flat-square)](https://pypi.org/project/virtualenv)\n[![Documentation](https://readthedocs.org/projects/virtualenv/badge/?version=latest&style=flat-square)](http://virtualenv.pypa.io)\n[![Discord](https://img.shields.io/discord/803025117553754132)](https://discord.gg/pypa)\n[![Downloads](https://static.pepy.tech/badge/virtualenv/month)](https://pepy.tech/project/virtualenv)\n[![PyPI - License](https://img.shields.io/pypi/l/virtualenv?style=flat-square)](https://opensource.org/licenses/MIT)\n[![Build Status](https://github.com/pypa/virtualenv/workflows/check/badge.svg?branch=main&event=push)](https://github.com/pypa/virtualenv/actions?query=workflow%3Acheck)\n\nA tool for creating isolated `virtual` python environments.\n\n- [Installation](https://virtualenv.pypa.io/en/latest/installation.html)\n- [Documentation](https://virtualenv.pypa.io)\n- [Changelog](https://virtualenv.pypa.io/en/latest/changelog.html)\n- [Issues](https://github.com/pypa/virtualenv/issues)\n- [PyPI](https://pypi.org/project/virtualenv)\n- [Github](https://github.com/pypa/virtualenv)\n\n## Code of Conduct\n\nEveryone interacting in the virtualenv project's codebases, issue trackers, chat rooms, and mailing lists is expected to\nfollow the [PSF Code of Conduct](https://github.com/pypa/.github/blob/main/CODE_OF_CONDUCT.md).\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "environments",
          "isolated",
          "virtual"
        ],
        "maintainer_email": "Bernat Gabor <gaborjbernat@gmail.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries",
          "Topic :: Software Development :: Testing",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "distlib<1,>=0.3.7",
          "filelock<4,>=3.12.2",
          "importlib-metadata>=6.6; python_version < '3.8'",
          "platformdirs<5,>=3.9.1",
          "furo>=2023.7.26; extra == 'docs'",
          "proselint>=0.13; extra == 'docs'",
          "sphinx!=7.3,>=7.1.2; extra == 'docs'",
          "sphinx-argparse>=0.4; extra == 'docs'",
          "sphinxcontrib-towncrier>=0.2.1a0; extra == 'docs'",
          "towncrier>=23.6; extra == 'docs'",
          "covdefaults>=2.3; extra == 'test'",
          "coverage-enable-subprocess>=1; extra == 'test'",
          "coverage>=7.2.7; extra == 'test'",
          "flaky>=3.7; extra == 'test'",
          "packaging>=23.1; extra == 'test'",
          "pytest-env>=0.8.2; extra == 'test'",
          "pytest-freezer>=0.4.8; (platform_python_implementation == 'PyPy' or (platform_python_implementation == 'CPython' and sys_platform == 'win32' and python_version >= '3.13')) and extra == 'test'",
          "pytest-mock>=3.11.1; extra == 'test'",
          "pytest-randomly>=3.12; extra == 'test'",
          "pytest-timeout>=2.1; extra == 'test'",
          "pytest>=7.4; extra == 'test'",
          "setuptools>=68; extra == 'test'",
          "time-machine>=2.10; (platform_python_implementation == 'CPython') and extra == 'test'"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Documentation, https://virtualenv.pypa.io",
          "Homepage, https://github.com/pypa/virtualenv",
          "Source, https://github.com/pypa/virtualenv",
          "Tracker, https://github.com/pypa/virtualenv/issues"
        ],
        "provides_extra": [
          "docs",
          "test"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\virtualenv-20.26.3.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "wcwidth",
        "version": "0.2.13",
        "summary": "Measures the displayed width of unicode strings in a terminal",
        "description": "|pypi_downloads| |codecov| |license|\n\n============\nIntroduction\n============\n\nThis library is mainly for CLI programs that carefully produce output for\nTerminals, or make pretend to be an emulator.\n\n**Problem Statement**: The printable length of *most* strings are equal to the\nnumber of cells they occupy on the screen ``1 character : 1 cell``.  However,\nthere are categories of characters that *occupy 2 cells* (full-wide), and\nothers that *occupy 0* cells (zero-width).\n\n**Solution**: POSIX.1-2001 and POSIX.1-2008 conforming systems provide\n`wcwidth(3)`_ and `wcswidth(3)`_ C functions of which this python module's\nfunctions precisely copy.  *These functions return the number of cells a\nunicode string is expected to occupy.*\n\nInstallation\n------------\n\nThe stable version of this package is maintained on pypi, install using pip::\n\n    pip install wcwidth\n\nExample\n-------\n\n**Problem**: given the following phrase (Japanese),\n\n   >>>  text = u'ã‚³ãƒ³ãƒ‹ãƒãƒ'\n\nPython **incorrectly** uses the *string length* of 5 codepoints rather than the\n*printable length* of 10 cells, so that when using the `rjust` function, the\noutput length is wrong::\n\n    >>> print(len('ã‚³ãƒ³ãƒ‹ãƒãƒ'))\n    5\n\n    >>> print('ã‚³ãƒ³ãƒ‹ãƒãƒ'.rjust(20, '_'))\n    _______________ã‚³ãƒ³ãƒ‹ãƒãƒ\n\nBy defining our own \"rjust\" function that uses wcwidth, we can correct this::\n\n   >>> def wc_rjust(text, length, padding=' '):\n   ...    from wcwidth import wcswidth\n   ...    return padding * max(0, (length - wcswidth(text))) + text\n   ...\n\nOur **Solution** uses wcswidth to determine the string length correctly::\n\n   >>> from wcwidth import wcswidth\n   >>> print(wcswidth('ã‚³ãƒ³ãƒ‹ãƒãƒ'))\n   10\n\n   >>> print(wc_rjust('ã‚³ãƒ³ãƒ‹ãƒãƒ', 20, '_'))\n   __________ã‚³ãƒ³ãƒ‹ãƒãƒ\n\n\nChoosing a Version\n------------------\n\nExport an environment variable, ``UNICODE_VERSION``. This should be done by\n*terminal emulators* or those developers experimenting with authoring one of\ntheir own, from shell::\n\n   $ export UNICODE_VERSION=13.0\n\nIf unspecified, the latest version is used. If your Terminal Emulator does not\nexport this variable, you can use the `jquast/ucs-detect`_ utility to\nautomatically detect and export it to your shell.\n\nwcwidth, wcswidth\n-----------------\nUse function ``wcwidth()`` to determine the length of a *single unicode\ncharacter*, and ``wcswidth()`` to determine the length of many, a *string\nof unicode characters*.\n\nBriefly, return values of function ``wcwidth()`` are:\n\n``-1``\n  Indeterminate (not printable).\n\n``0``\n  Does not advance the cursor, such as NULL or Combining.\n\n``2``\n  Characters of category East Asian Wide (W) or East Asian\n  Full-width (F) which are displayed using two terminal cells.\n\n``1``\n  All others.\n\nFunction ``wcswidth()`` simply returns the sum of all values for each character\nalong a string, or ``-1`` when it occurs anywhere along a string.\n\nFull API Documentation at https://wcwidth.readthedocs.org\n\n==========\nDeveloping\n==========\n\nInstall wcwidth in editable mode::\n\n   pip install -e .\n\nExecute unit tests using tox_::\n\n   tox -e py27,py35,py36,py37,py38,py39,py310,py311,py312\n\nUpdating Unicode Version\n------------------------\n\nRegenerate python code tables from latest Unicode Specification data files::\n\n   tox -e update\n\nThe script is located at ``bin/update-tables.py``, requires Python 3.9 or\nlater. It is recommended but not necessary to run this script with the newest\nPython, because the newest Python has the latest ``unicodedata`` for generating\ncomments.\n\nBuilding Documentation\n----------------------\n\nThis project is using `sphinx`_ 4.5 to build documentation::\n\n   tox -e sphinx\n\nThe output will be in ``docs/_build/html/``.\n\nUpdating Requirements\n---------------------\n\nThis project is using `pip-tools`_ to manage requirements.\n\nTo upgrade requirements for updating unicode version, run::\n\n   tox -e update_requirements_update\n\nTo upgrade requirements for testing, run::\n\n   tox -e update_requirements37,update_requirements39\n\nTo upgrade requirements for building documentation, run::\n\n   tox -e update_requirements_docs\n\nUtilities\n---------\n\nSupplementary tools for browsing and testing terminals for wide unicode\ncharacters are found in the `bin/`_ of this project's source code.  Just ensure\nto first ``pip install -r requirements-develop.txt`` from this projects main\nfolder. For example, an interactive browser for testing::\n\n  python ./bin/wcwidth-browser.py\n\n====\nUses\n====\n\nThis library is used in:\n\n- `jquast/blessed`_: a thin, practical wrapper around terminal capabilities in\n  Python.\n\n- `prompt-toolkit/python-prompt-toolkit`_: a Library for building powerful\n  interactive command lines in Python.\n\n- `dbcli/pgcli`_: Postgres CLI with autocompletion and syntax highlighting.\n\n- `thomasballinger/curtsies`_: a Curses-like terminal wrapper with a display\n  based on compositing 2d arrays of text.\n\n- `selectel/pyte`_: Simple VTXXX-compatible linux terminal emulator.\n\n- `astanin/python-tabulate`_: Pretty-print tabular data in Python, a library\n  and a command-line utility.\n\n- `rspeer/python-ftfy`_: Fixes mojibake and other glitches in Unicode\n  text.\n\n- `nbedos/termtosvg`_: Terminal recorder that renders sessions as SVG\n  animations.\n\n- `peterbrittain/asciimatics`_: Package to help people create full-screen text\n  UIs.\n\n- `python-cmd2/cmd2`_: A tool for building interactive command line apps\n\n- `stratis-storage/stratis-cli`_: CLI for the Stratis project\n\n- `ihabunek/toot`_: A Mastodon CLI/TUI client\n\n- `saulpw/visidata`_: Terminal spreadsheet multitool for discovering and\n  arranging data\n\n===============\nOther Languages\n===============\n\n- `timoxley/wcwidth`_: JavaScript\n- `janlelis/unicode-display_width`_: Ruby\n- `alecrabbit/php-wcwidth`_: PHP\n- `Text::CharWidth`_: Perl\n- `bluebear94/Terminal-WCWidth`_: Perl 6\n- `mattn/go-runewidth`_: Go\n- `grepsuzette/wcwidth`_: Haxe\n- `aperezdc/lua-wcwidth`_: Lua\n- `joachimschmidt557/zig-wcwidth`_: Zig\n- `fumiyas/wcwidth-cjk`_: `LD_PRELOAD` override\n- `joshuarubin/wcwidth9`_: Unicode version 9 in C\n\n=======\nHistory\n=======\n\n0.2.13 *2024-01-06*\n  * **Bugfix** zero-width support for Hangul Jamo (Korean)\n\n0.2.12 *2023-11-21*\n  * re-release to remove .pyi file misplaced in wheel files `Issue #101`_.\n\n0.2.11 *2023-11-20*\n  * Include tests files in the source distribution (`PR #98`_, `PR #100`_).\n\n0.2.10 *2023-11-13*\n  * **Bugfix** accounting of some kinds of emoji sequences using U+FE0F\n    Variation Selector 16 (`PR #97`_).\n  * **Updated** `Specification <Specification_from_pypi_>`_.\n\n0.2.9 *2023-10-30*\n  * **Bugfix** zero-width characters used in Emoji ZWJ sequences, Balinese,\n    Jamo, Devanagari, Tamil, Kannada and others (`PR #91`_).\n  * **Updated** to include `Specification <Specification_from_pypi_>`_ of\n    character measurements.\n\n0.2.8 *2023-09-30*\n  * Include requirements files in the source distribution (`PR #82`_).\n\n0.2.7 *2023-09-28*\n  * **Updated** tables to include Unicode Specification 15.1.0.\n  * Include ``bin``, ``docs``, and ``tox.ini`` in the source distribution\n\n0.2.6 *2023-01-14*\n  * **Updated** tables to include Unicode Specification 14.0.0 and 15.0.0.\n  * **Changed** developer tools to use pip-compile, and to use jinja2 templates\n    for code generation in `bin/update-tables.py` to prepare for possible\n    compiler optimization release.\n\n0.2.1 .. 0.2.5 *2020-06-23*\n  * **Repository** changes to update tests and packaging issues, and\n    begin tagging repository with matching release versions.\n\n0.2.0 *2020-06-01*\n  * **Enhancement**: Unicode version may be selected by exporting the\n    Environment variable ``UNICODE_VERSION``, such as ``13.0``, or ``6.3.0``.\n    See the `jquast/ucs-detect`_ CLI utility for automatic detection.\n  * **Enhancement**:\n    API Documentation is published to readthedocs.org.\n  * **Updated** tables for *all* Unicode Specifications with files\n    published in a programmatically consumable format, versions 4.1.0\n    through 13.0\n\n0.1.9 *2020-03-22*\n  * **Performance** optimization by `Avram Lubkin`_, `PR #35`_.\n  * **Updated** tables to Unicode Specification 13.0.0.\n\n0.1.8 *2020-01-01*\n  * **Updated** tables to Unicode Specification 12.0.0. (`PR #30`_).\n\n0.1.7 *2016-07-01*\n  * **Updated** tables to Unicode Specification 9.0.0. (`PR #18`_).\n\n0.1.6 *2016-01-08 Production/Stable*\n  * ``LICENSE`` file now included with distribution.\n\n0.1.5 *2015-09-13 Alpha*\n  * **Bugfix**:\n    Resolution of \"combining_ character width\" issue, most especially\n    those that previously returned -1 now often (correctly) return 0.\n    resolved by `Philip Craig`_ via `PR #11`_.\n  * **Deprecated**:\n    The module path ``wcwidth.table_comb`` is no longer available,\n    it has been superseded by module path ``wcwidth.table_zero``.\n\n0.1.4 *2014-11-20 Pre-Alpha*\n  * **Feature**: ``wcswidth()`` now determines printable length\n    for (most) combining_ characters.  The developer's tool\n    `bin/wcwidth-browser.py`_ is improved to display combining_\n    characters when provided the ``--combining`` option\n    (`Thomas Ballinger`_ and `Leta Montopoli`_ `PR #5`_).\n  * **Feature**: added static analysis (prospector_) to testing\n    framework.\n\n0.1.3 *2014-10-29 Pre-Alpha*\n  * **Bugfix**: 2nd parameter of wcswidth was not honored.\n    (`Thomas Ballinger`_, `PR #4`_).\n\n0.1.2 *2014-10-28 Pre-Alpha*\n  * **Updated** tables to Unicode Specification 7.0.0.\n    (`Thomas Ballinger`_, `PR #3`_).\n\n0.1.1 *2014-05-14 Pre-Alpha*\n  * Initial release to pypi, Based on Unicode Specification 6.3.0\n\nThis code was originally derived directly from C code of the same name,\nwhose latest version is available at\nhttps://www.cl.cam.ac.uk/~mgk25/ucs/wcwidth.c::\n\n * Markus Kuhn -- 2007-05-26 (Unicode 5.0)\n *\n * Permission to use, copy, modify, and distribute this software\n * for any purpose and without fee is hereby granted. The author\n * disclaims all warranties with regard to this software.\n\n.. _`Specification_from_pypi`: https://wcwidth.readthedocs.io/en/latest/specs.html\n.. _`tox`: https://tox.wiki/en/latest/\n.. _`prospector`: https://github.com/landscapeio/prospector\n.. _`combining`: https://en.wikipedia.org/wiki/Combining_character\n.. _`bin/`: https://github.com/jquast/wcwidth/tree/master/bin\n.. _`bin/wcwidth-browser.py`: https://github.com/jquast/wcwidth/blob/master/bin/wcwidth-browser.py\n.. _`Thomas Ballinger`: https://github.com/thomasballinger\n.. _`Leta Montopoli`: https://github.com/lmontopo\n.. _`Philip Craig`: https://github.com/philipc\n.. _`PR #3`: https://github.com/jquast/wcwidth/pull/3\n.. _`PR #4`: https://github.com/jquast/wcwidth/pull/4\n.. _`PR #5`: https://github.com/jquast/wcwidth/pull/5\n.. _`PR #11`: https://github.com/jquast/wcwidth/pull/11\n.. _`PR #18`: https://github.com/jquast/wcwidth/pull/18\n.. _`PR #30`: https://github.com/jquast/wcwidth/pull/30\n.. _`PR #35`: https://github.com/jquast/wcwidth/pull/35\n.. _`PR #82`: https://github.com/jquast/wcwidth/pull/82\n.. _`PR #91`: https://github.com/jquast/wcwidth/pull/91\n.. _`PR #97`: https://github.com/jquast/wcwidth/pull/97\n.. _`PR #98`: https://github.com/jquast/wcwidth/pull/98\n.. _`PR #100`: https://github.com/jquast/wcwidth/pull/100\n.. _`Issue #101`: https://github.com/jquast/wcwidth/issues/101\n.. _`jquast/blessed`: https://github.com/jquast/blessed\n.. _`selectel/pyte`: https://github.com/selectel/pyte\n.. _`thomasballinger/curtsies`: https://github.com/thomasballinger/curtsies\n.. _`dbcli/pgcli`: https://github.com/dbcli/pgcli\n.. _`prompt-toolkit/python-prompt-toolkit`: https://github.com/prompt-toolkit/python-prompt-toolkit\n.. _`timoxley/wcwidth`: https://github.com/timoxley/wcwidth\n.. _`wcwidth(3)`:  https://man7.org/linux/man-pages/man3/wcwidth.3.html\n.. _`wcswidth(3)`: https://man7.org/linux/man-pages/man3/wcswidth.3.html\n.. _`astanin/python-tabulate`: https://github.com/astanin/python-tabulate\n.. _`janlelis/unicode-display_width`: https://github.com/janlelis/unicode-display_width\n.. _`rspeer/python-ftfy`: https://github.com/rspeer/python-ftfy\n.. _`alecrabbit/php-wcwidth`: https://github.com/alecrabbit/php-wcwidth\n.. _`Text::CharWidth`: https://metacpan.org/pod/Text::CharWidth\n.. _`bluebear94/Terminal-WCWidth`: https://github.com/bluebear94/Terminal-WCWidth\n.. _`mattn/go-runewidth`: https://github.com/mattn/go-runewidth\n.. _`grepsuzette/wcwidth`: https://github.com/grepsuzette/wcwidth\n.. _`jquast/ucs-detect`: https://github.com/jquast/ucs-detect\n.. _`Avram Lubkin`: https://github.com/avylove\n.. _`nbedos/termtosvg`: https://github.com/nbedos/termtosvg\n.. _`peterbrittain/asciimatics`: https://github.com/peterbrittain/asciimatics\n.. _`aperezdc/lua-wcwidth`: https://github.com/aperezdc/lua-wcwidth\n.. _`joachimschmidt557/zig-wcwidth`: https://github.com/joachimschmidt557/zig-wcwidth\n.. _`fumiyas/wcwidth-cjk`: https://github.com/fumiyas/wcwidth-cjk\n.. _`joshuarubin/wcwidth9`: https://github.com/joshuarubin/wcwidth9\n.. _`python-cmd2/cmd2`: https://github.com/python-cmd2/cmd2\n.. _`stratis-storage/stratis-cli`: https://github.com/stratis-storage/stratis-cli\n.. _`ihabunek/toot`: https://github.com/ihabunek/toot\n.. _`saulpw/visidata`: https://github.com/saulpw/visidata\n.. _`pip-tools`: https://pip-tools.readthedocs.io/\n.. _`sphinx`: https://www.sphinx-doc.org/\n.. |pypi_downloads| image:: https://img.shields.io/pypi/dm/wcwidth.svg?logo=pypi\n    :alt: Downloads\n    :target: https://pypi.org/project/wcwidth/\n.. |codecov| image:: https://codecov.io/gh/jquast/wcwidth/branch/master/graph/badge.svg\n    :alt: codecov.io Code Coverage\n    :target: https://app.codecov.io/gh/jquast/wcwidth/\n.. |license| image:: https://img.shields.io/pypi/l/wcwidth.svg\n    :target: https://pypi.org/project/wcwidth/\n    :alt: MIT License\n",
        "keywords": [
          "cjk",
          "combining",
          "console",
          "eastasian",
          "emoji",
          "emulator",
          "terminal",
          "unicode",
          "wcswidth",
          "wcwidth",
          "xterm"
        ],
        "home_page": "https://github.com/jquast/wcwidth",
        "author": "Jeff Quast",
        "author_email": "contact@jeffquast.com",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "License :: OSI Approved :: MIT License",
          "Operating System :: POSIX",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Software Development :: Libraries",
          "Topic :: Software Development :: Localization",
          "Topic :: Software Development :: Internationalization",
          "Topic :: Terminals"
        ],
        "requires_dist": [
          "backports.functools-lru-cache >=1.2.1 ; python_version < \"3.2\""
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\wcwidth-0.2.13.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "webcolors",
        "version": "24.8.0",
        "summary": "A library for working with the color formats defined by HTML and CSS.",
        "description": ".. -*-restructuredtext-*-\n\n.. image:: https://github.com/ubernostrum/webcolors/workflows/CI/badge.svg\n   :alt: CI status image\n   :target: https://github.com/ubernostrum/webcolors/actions?query=workflow%3ACI\n\n``webcolors`` is a module for working with and converting between the\nvarious HTML/CSS color formats.\n\nSupport is included for normalizing and converting between the\nfollowing formats (RGB colorspace only; conversion to/from HSL can be\nhandled by the ``colorsys`` module in the Python standard library):\n\n* Specification-defined color names\n\n* Six-digit hexadecimal\n\n* Three-digit hexadecimal\n\n* Integer ``rgb()`` triplet\n\n* Percentage ``rgb()`` triplet\n\nFor example:\n\n.. code-block:: python\n\n    >>> import webcolors\n    >>> webcolors.hex_to_name(\"#daa520\")\n    'goldenrod'\n\nImplementations are also provided for the HTML5 color parsing and\nserialization algorithms. For example, parsing the infamous\n\"chucknorris\" string into an ``rgb()`` triplet:\n\n.. code-block:: python\n\n    >>> import webcolors\n    >>> webcolors.html5_parse_legacy_color(\"chucknorris\")\n    HTML5SimpleColor(red=192, green=0, blue=0)\n\nFull documentation is `available online <https://webcolors.readthedocs.io/>`_.\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "color",
          "css",
          "html",
          "web"
        ],
        "author_email": "James Bennett <james@b-list.org>",
        "license": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "furo ; extra == 'docs'",
          "sphinx ; extra == 'docs'",
          "sphinx-copybutton ; extra == 'docs'",
          "sphinx-inline-tabs ; extra == 'docs'",
          "sphinx-notfound-page ; extra == 'docs'",
          "sphinxext-opengraph ; extra == 'docs'",
          "coverage[toml] ; extra == 'tests'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "documentation, https://webcolors.readthedocs.io",
          "homepage, https://github.com/ubernostrum/webcolors"
        ],
        "provides_extra": [
          "docs",
          "tests"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\webcolors-24.8.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.0",
        "name": "webencodings",
        "version": "0.5.1",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "Character encoding aliases for legacy web content",
        "description": "python-webencodings\n===================\n\nThis is a Python implementation of the `WHATWG Encoding standard\n<http://encoding.spec.whatwg.org/>`_.\n\n* Latest documentation: http://packages.python.org/webencodings/\n* Source code and issue tracker:\n  https://github.com/gsnedders/python-webencodings\n* PyPI releases: http://pypi.python.org/pypi/webencodings\n* License: BSD\n* Python 2.6+ and 3.3+\n\nIn order to be compatible with legacy web content\nwhen interpreting something like ``Content-Type: text/html; charset=latin1``,\ntools need to use a particular set of aliases for encoding labels\nas well as some overriding rules.\nFor example, ``US-ASCII`` and ``iso-8859-1`` on the web are actually\naliases for ``windows-1252``, and an UTF-8 or UTF-16 BOM takes precedence\nover any other encoding declaration.\nThe Encoding standard defines all such details so that implementations do\nnot have to reverse-engineer each other.\n\nThis module has encoding labels and BOM detection,\nbut the actual implementation for encoders and decoders is Pythonâ€™s.\n\n\n",
        "home_page": "https://github.com/SimonSapin/python-webencodings",
        "author": "Geoffrey Sneddon",
        "author_email": "me@gsnedders.com",
        "license": "BSD",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.6",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet :: WWW/HTTP"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\webencodings-0.5.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "wheel",
        "version": "0.38.4",
        "summary": "A built-package format for Python",
        "description": "wheel\n=====\n\nThis library is the reference implementation of the Python wheel packaging\nstandard, as defined in `PEP 427`_.\n\nIt has two different roles:\n\n#. A setuptools_ extension for building wheels that provides the\n   ``bdist_wheel`` setuptools command\n#. A command line tool for working with wheel files\n\nIt should be noted that wheel is **not** intended to be used as a library, and\nas such there is no stable, public API.\n\n.. _PEP 427: https://www.python.org/dev/peps/pep-0427/\n.. _setuptools: https://pypi.org/project/setuptools/\n\nDocumentation\n-------------\n\nThe documentation_ can be found on Read The Docs.\n\n.. _documentation: https://wheel.readthedocs.io/\n\nCode of Conduct\n---------------\n\nEveryone interacting in the wheel project's codebases, issue trackers, chat\nrooms, and mailing lists is expected to follow the `PSF Code of Conduct`_.\n\n.. _PSF Code of Conduct: https://github.com/pypa/.github/blob/main/CODE_OF_CONDUCT.md\n",
        "keywords": [
          "wheel",
          "packaging"
        ],
        "home_page": "https://github.com/pypa/wheel",
        "author": "Daniel Holth",
        "author_email": "dholth@fastmail.fm",
        "maintainer": "Alex GrÃ¶nholm",
        "maintainer_email": "alex.gronholm@nextday.fi",
        "license": "MIT",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Topic :: System :: Archiving :: Packaging",
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11"
        ],
        "requires_dist": [
          "pytest (>=3.0.0) ; extra == 'test'"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Documentation, https://wheel.readthedocs.io/",
          "Changelog, https://wheel.readthedocs.io/en/stable/news.html",
          "Issue Tracker, https://github.com/pypa/wheel/issues"
        ],
        "provides_extra": [
          "test"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\wheel-0.38.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.0",
        "name": "yarg",
        "version": "0.1.9",
        "platform": [
          "linux"
        ],
        "summary": "A semi hard Cornish cheese, also queries PyPI (PyPI client)",
        "description": "yarg(1) -- A semi hard Cornish cheese, also queries PyPI\n========================================================\n\n.. image:: https://img.shields.io/travis/kura/yarg.svg?style=flat\n\n.. image:: https://img.shields.io/coveralls/kura/yarg.svg?style=flat\n\n.. image:: https://pypip.in/version/yarg/badge.svg?style=flat\n\n.. image:: https://pypip.in/download/yarg/badge.svg?style=flat\n\n.. image:: https://pypip.in/py_versions/yarg/badge.svg?style=flat\n\n.. image:: https://pypip.in/implementation/yarg/badge.svg?style=flat\n\n.. image:: https://pypip.in/status/yarg/badge.svg?style=flat\n\n.. image:: https://pypip.in/wheel/yarg/badge.svg?style=flat\n\n.. image:: https://pypip.in/license/yarg/badge.svg?style=flat\n\nYarg is a PyPI client.\n\n.. code-block:: python\n\n    >>> import yarg\n    >>> package = yarg.get(\"yarg\")\n    >>> package.name\n    u'yarg'\n    >>> package.author\n    Author(name=u'Kura', email=u'kura@kura.io')\n\nFull documentation is at <https://yarg.readthedocs.org>.\n\nYarg is released under the `MIT license\n<https://github.com/kura/yarg/blob/master/LICENSE>`_. The `source code is on\nGitHub <https://github.com/kura/yarg>`_ and `issues are also tracked on\nGitHub <https://github.com/kura/yarg/issues>`_.\n\n\nRelease History\n===============\n\n0.1.8 (2014-08-10)\n------------------\n\nSplatting bugs\n~~~~~~~~~~~~~~\n\n- Integration issue with Python 3, requests, yarg and JSON. Attempt to decode\n  requests response if decode attribute exists.\n\n0.1.6 & 0.1.7 (2014-08-10)\n--------------------------\n\nSplatting bugs\n~~~~~~~~~~~~~~\n\n- Bug in setup.py causing installs to fail for sdist (source) releases.\n\n0.1.5 (2014-08-10)\n------------------\n\nAPI changes\n~~~~~~~~~~~\n\n- Changed sort order of `yarg.package.Package.release_ids` to sort\n  based on the upload time of the release ID.\n\nSplatting bugs\n~~~~~~~~~~~~~~\n\n- `yarg.package.Package.latest_release_id` will now return the latest\n  release ID from the PyPI info source, rather than the final list item in\n  `yarg.package.Package.release_ids`.\n\n  Addtionally `yarg.package.Package.latest_release` will do the same as\n  it gets the latest release information from\n  `yarg.package.Package.latest_release_id`.\n\n0.1.4 (2014-08-09)\n------------------\n\nAPI changes\n~~~~~~~~~~~\n\n- New method `yarg.newest_packages` for querying new packages\n  from the PyPI RSS feed.\n- New method `yarg.latest_updated_packages` for querying\n  the latest updated packages from the PyPI RSS feed.\n\nOther\n~~~~~\n\n- Additional test coverage\n- Additional documentation coverage\n\n0.1.2 (2014-08-08)\n------------------\n\nBug fixes\n~~~~~~~~~\n\n- `yarg.get` will now raise an Exception for errors **including**\n  300 and above. Previously only raised for above 300.\n- Fix an issue on Python 3.X and PyPy3 where\n  `yarg.exceptions.HTTPError` was using a method that was\n  removed in Python 3.\n- Added dictionary key lookups for `home_page`, `bugtrack_url`\n  and `docs_url`. Caused `KeyError` exceptions if they were not\n  returned by PyPI.\n\nOther\n~~~~~\n\n- More test coverage.\n\n0.1.1 (2014-08-08)\n------------------\n\nAPI changes\n~~~~~~~~~~~\n\n- New `yarg.package.Package` property `has_wheel`.\n- New `yarg.package.Package` property `has_egg`.\n- New `yarg.package.Package` property `has_source`.\n- New `yarg.package.Package` property `python_versions`.\n- New `yarg.package.Package` property `python_implementations`.\n- Added `yarg.exceptions.HTTPError` to `yarg.__init__`\n  for easier access.\n- Added `yarg.json2package` to `yarg.__init__` to expose it for\n  use.\n\n0.1.0 (2014-08-08)\n------------------\n\n- Initial release\n\n\n",
        "keywords": [
          "pypi",
          "client",
          "packages"
        ],
        "home_page": "https://yarg.readthedocs.org/",
        "author": "Kura",
        "author_email": "kura@kura.io",
        "license": "MIT",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2.6",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: System :: Archiving :: Packaging"
        ],
        "requires_dist": [
          "requests"
        ]
      },
      "metadata_location": "C:\\Program Files\\Python312\\Lib\\site-packages\\yarg-0.1.9.dist-info",
      "installer": "pip",
      "requested": false
    }
  ],
  "environment": {
    "implementation_name": "cpython",
    "implementation_version": "3.12.6",
    "os_name": "nt",
    "platform_machine": "AMD64",
    "platform_release": "10",
    "platform_system": "Windows",
    "platform_version": "10.0.19045",
    "python_full_version": "3.12.6",
    "platform_python_implementation": "CPython",
    "python_version": "3.12",
    "sys_platform": "win32"
  }
}
